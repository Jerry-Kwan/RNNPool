Number of dataloader workers: 32
Batch size: 256

loading annotations into memory...
Done (t=2.83s)
creating index...
index created!
Len of trainloader: 451

loading annotations into memory...
Done (t=0.16s)
creating index...
index created!
Len of testloader: 32

use 4 GPUs!
DataParallel device_ids: [0, 1, 2, 3]

------Epoch: 0------
[batch_idx--0] train_loss: 0.0027082713786512613, acc: 0.47265625, lr: 0.05
[batch_idx--50] train_loss: 0.002649411061486485, acc: 0.5791207107843137, lr: 0.04999993260712715
[batch_idx--100] train_loss: 0.0026566733855127108, acc: 0.5900371287128713, lr: 0.04999973042887193
[batch_idx--150] train_loss: 0.0026156862099833834, acc: 0.605546357615894, lr: 0.049999393466324364
[batch_idx--200] train_loss: 0.002585471152508659, acc: 0.6158465485074627, lr: 0.04999892172130118
[batch_idx--250] train_loss: 0.0025565310277460345, acc: 0.6245331175298805, lr: 0.04999831519634575
[batch_idx--300] train_loss: 0.002551607434108754, acc: 0.6273878737541528, lr: 0.0499975738947281
[batch_idx--350] train_loss: 0.002526934539893923, acc: 0.6352052172364673, lr: 0.04999669782044491
[batch_idx--400] train_loss: 0.0025021979077823665, acc: 0.6414237842892768, lr: 0.049995686978219496
[batch_idx--450] train_loss: 0.0024804974447937243, acc: 0.6481410768216058, lr: 0.04999454137350172
total time of one epoch: 238.95588779449463 s
train_loss:  0.0024804974447937243  acc:  0.6481410768216058
->>lr:0.049995
test_loss:  0.0030249756017709313  test_acc:  0.5284774785953592
best acc:  0
Saving..
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(

------Epoch: 1------
[batch_idx--0] train_loss: 0.0023197068367153406, acc: 0.64453125, lr: 0.04999451708687114
[batch_idx--50] train_loss: 0.0024270259948703005, acc: 0.6760110294117647, lr: 0.04999323403077913
[batch_idx--100] train_loss: 0.0023422732552753228, acc: 0.6884282178217822, lr: 0.04999181622541965
[batch_idx--150] train_loss: 0.002290447974972279, acc: 0.6974337748344371, lr: 0.0499902636784367
[batch_idx--200] train_loss: 0.002258005152938341, acc: 0.703125, lr: 0.04998857639820074
[batch_idx--250] train_loss: 0.002238406438892522, acc: 0.7067355577689243, lr: 0.04998675439380862
[batch_idx--300] train_loss: 0.0022155946341847563, acc: 0.7109115448504983, lr: 0.04998479767508354
[batch_idx--350] train_loss: 0.0022029573787030288, acc: 0.7125178062678063, lr: 0.04998270625257502
[batch_idx--400] train_loss: 0.0021859907851138724, acc: 0.7153990024937655, lr: 0.04998048013755882
[batch_idx--450] train_loss: 0.002186530811043761, acc: 0.7160325615301837, lr: 0.049978119342036866
total time of one epoch: 233.8177616596222 s
train_loss:  0.002186530811043761  acc:  0.7160325615301837
->>lr:0.049978
test_loss:  0.0029908781652785454  test_acc:  0.666087603921082
best acc:  52.84774785953592
Saving..

------Epoch: 2------
[batch_idx--0] train_loss: 0.0018885411554947495, acc: 0.7578125, lr: 0.04997807075247146
[batch_idx--50] train_loss: 0.0021001981050871752, acc: 0.7323069852941176, lr: 0.04997557259595109
[batch_idx--100] train_loss: 0.002090379727156003, acc: 0.734375, lr: 0.04997293978538365
[batch_idx--150] train_loss: 0.0020752353848124674, acc: 0.7361082367549668, lr: 0.04997017233496374
[batch_idx--200] train_loss: 0.002071740249964172, acc: 0.7368042599502488, lr: 0.04996727025961189
[batch_idx--250] train_loss: 0.002071831206998888, acc: 0.7366160358565738, lr: 0.04996423357497442
[batch_idx--300] train_loss: 0.0020681462189541555, acc: 0.7376323712624585, lr: 0.04996106229742341
[batch_idx--350] train_loss: 0.002068947509469788, acc: 0.7375912571225072, lr: 0.04995775644405658
[batch_idx--400] train_loss: 0.0020608445498836864, acc: 0.738846243765586, lr: 0.049954316032697205
[batch_idx--450] train_loss: 0.002058928892868364, acc: 0.740106571319471, lr: 0.049950741081894026
total time of one epoch: 232.42661952972412 s
train_loss:  0.002058928892868364  acc:  0.740106571319471
->>lr:0.049951
test_loss:  0.0021437522990485547  test_acc:  0.7256483434669314
best acc:  66.6087603921082
Saving..

------Epoch: 3------
[batch_idx--0] train_loss: 0.0021901133004575968, acc: 0.71875, lr: 0.04995066821070679
[batch_idx--50] train_loss: 0.002023262467107498, acc: 0.7411917892156863, lr: 0.04994695604953209
[batch_idx--100] train_loss: 0.00201609949834903, acc: 0.7424582301980198, lr: 0.0499431093885944
[batch_idx--150] train_loss: 0.0019990578077930883, acc: 0.745990273178808, lr: 0.04993912824863275
[batch_idx--200] train_loss: 0.0019952418173742087, acc: 0.7470654539800995, lr: 0.049935012651111166
[batch_idx--250] train_loss: 0.0019944229314430243, acc: 0.7467629482071713, lr: 0.0499307626182186
[batch_idx--300] train_loss: 0.0019883593730783194, acc: 0.7483648255813954, lr: 0.0499263781728688
[batch_idx--350] train_loss: 0.001988892839489202, acc: 0.7488871082621082, lr: 0.04992185933870021
[batch_idx--400] train_loss: 0.0019851285773224924, acc: 0.7493570760598504, lr: 0.049917206140075804
[batch_idx--450] train_loss: 0.0019893275136299094, acc: 0.7494619363349186, lr: 0.04991241860208297
total time of one epoch: 238.82752633094788 s
train_loss:  0.0019893275136299094  acc:  0.7494619363349186
->>lr:0.049912
test_loss:  0.002114728601624673  test_acc:  0.7302394838069239
best acc:  72.56483434669313
Saving..

------Epoch: 4------
[batch_idx--0] train_loss: 0.002234232146292925, acc: 0.71875, lr: 0.049912321481237615
[batch_idx--50] train_loss: 0.001961455196507421, acc: 0.7549785539215687, lr: 0.04990739694368515
[batch_idx--100] train_loss: 0.0019519974115664268, acc: 0.7577738242574258, lr: 0.04990233811964985
[batch_idx--150] train_loss: 0.001961243221696639, acc: 0.7553290562913907, lr: 0.049897145036406014
[batch_idx--200] train_loss: 0.001955992095658917, acc: 0.7562189054726368, lr: 0.04989181772195179
[batch_idx--250] train_loss: 0.0019478680119771822, acc: 0.7576413097609562, lr: 0.04988635620500901
[batch_idx--300] train_loss: 0.0019444009409815173, acc: 0.757734634551495, lr: 0.049880760515023076
[batch_idx--350] train_loss: 0.001947856322129886, acc: 0.7572671830484331, lr: 0.04987503068216274
[batch_idx--400] train_loss: 0.0019425855237674757, acc: 0.7579099127182045, lr: 0.04986916673732
[batch_idx--450] train_loss: 0.0019445987326800814, acc: 0.7584354497170827, lr: 0.049863168712109905
total time of one epoch: 237.82154846191406 s
train_loss:  0.0019445987326800814  acc:  0.7584354497170827
->>lr:0.049863
test_loss:  0.002004766589226387  test_acc:  0.7673408611490259
best acc:  73.02394838069239
Saving..

------Epoch: 5------
[batch_idx--0] train_loss: 0.0018724488327279687, acc: 0.765625, lr: 0.049863047384206834
[batch_idx--50] train_loss: 0.0019068632265735492, acc: 0.7650122549019608, lr: 0.04985691263034154
[batch_idx--100] train_loss: 0.0019134055191448124, acc: 0.7648128094059405, lr: 0.049850643862176046
[batch_idx--150] train_loss: 0.0019225866883832788, acc: 0.7629346026490066, lr: 0.04984424111350797
[batch_idx--200] train_loss: 0.0019065740573873272, acc: 0.7657221703980099, lr: 0.0498377044188573
[batch_idx--250] train_loss: 0.0019024005155097619, acc: 0.7657961902390438, lr: 0.04983103381346615
[batch_idx--300] train_loss: 0.0018988756097054907, acc: 0.7659624169435216, lr: 0.049824229333298636
[batch_idx--350] train_loss: 0.0018937711576079456, acc: 0.7669048254985755, lr: 0.049817291015040614
[batch_idx--400] train_loss: 0.0018909036006518358, acc: 0.7669400716957606, lr: 0.04981021889609956
[batch_idx--450] train_loss: 0.0018889628578077381, acc: 0.7676866733779985, lr: 0.0498030130146043
total time of one epoch: 239.85328936576843 s
train_loss:  0.0018889628578077381  acc:  0.7676866733779985
->>lr:0.049803
test_loss:  0.001867567994396656  test_acc:  0.7772676510733342
best acc:  76.7340861149026
Saving..

------Epoch: 6------
[batch_idx--0] train_loss: 0.0017076177755370736, acc: 0.8203125, lr: 0.04980286753286195
[batch_idx--50] train_loss: 0.0018510989657621465, acc: 0.7734375, lr: 0.04979552525358963
[batch_idx--100] train_loss: 0.001874331524365093, acc: 0.7682936262376238, lr: 0.04978804929098283
[batch_idx--150] train_loss: 0.001864635626113178, acc: 0.769479511589404, lr: 0.049780439685347705
[batch_idx--200] train_loss: 0.0018661165348166108, acc: 0.7703669154228856, lr: 0.0497726964777109
[batch_idx--250] train_loss: 0.0018648420357557228, acc: 0.7709474601593626, lr: 0.049764819709819365
[batch_idx--300] train_loss: 0.0018573883229377757, acc: 0.7725680024916943, lr: 0.04975680942414015
[batch_idx--350] train_loss: 0.001851643757706248, acc: 0.7737713675213675, lr: 0.04974866566386016
[batch_idx--400] train_loss: 0.0018491038838935612, acc: 0.7744505922693267, lr: 0.049740388472885894
[batch_idx--450] train_loss: 0.0018519735675740028, acc: 0.7745252889922588, lr: 0.04973197789584324
total time of one epoch: 235.31167364120483 s
train_loss:  0.0018519735675740028  acc:  0.7745252889922588
->>lr:0.049732
test_loss:  0.0019440699420949783  test_acc:  0.7688298796376721
best acc:  77.72676510733342

------Epoch: 7------
[batch_idx--0] train_loss: 0.0022151076700538397, acc: 0.73046875, lr: 0.049731808324074714
[batch_idx--50] train_loss: 0.00179832681155234, acc: 0.7837775735294118, lr: 0.04972326173996171
[batch_idx--100] train_loss: 0.0018309925724337302, acc: 0.7754873143564357, lr: 0.049714581862117906
[batch_idx--150] train_loss: 0.0018280819436189849, acc: 0.7761278973509934, lr: 0.049705768737340256
[batch_idx--200] train_loss: 0.001834544572117391, acc: 0.775342039800995, lr: 0.04969682241314409
[batch_idx--250] train_loss: 0.0018331361197091015, acc: 0.7754917828685259, lr: 0.0496877429377629
[batch_idx--300] train_loss: 0.00183160402007599, acc: 0.7761498131229236, lr: 0.04967853036014805
[batch_idx--350] train_loss: 0.001826209351128535, acc: 0.7767984330484331, lr: 0.04966918472996849
[batch_idx--400] train_loss: 0.001828304741315618, acc: 0.77669108478803, lr: 0.04965970609761053
[batch_idx--450] train_loss: 0.0018322468336749052, acc: 0.7763477626965668, lr: 0.04965009451417756
total time of one epoch: 239.24686288833618 s
train_loss:  0.0018322468336749052  acc:  0.7763477626965668
->>lr:0.049650
test_loss:  0.0018250857841467084  test_acc:  0.7837200645241346
best acc:  77.72676510733342
Saving..

------Epoch: 8------
[batch_idx--0] train_loss: 0.0021622683852910995, acc: 0.734375, lr: 0.04964990092676263
[batch_idx--50] train_loss: 0.0018059703402732517, acc: 0.7815563725490197, lr: 0.0496401537866232
[batch_idx--100] train_loss: 0.0018097464811278156, acc: 0.7804764851485149, lr: 0.04963027380082368
[batch_idx--150] train_loss: 0.0018016887868797739, acc: 0.7819484685430463, lr: 0.04962026102263131
[batch_idx--200] train_loss: 0.0018045477515818615, acc: 0.7810945273631841, lr: 0.04961011550602926
[batch_idx--250] train_loss: 0.0017942314326533106, acc: 0.783179780876494, lr: 0.04959983730571641
[batch_idx--300] train_loss: 0.0017947344967253827, acc: 0.7825737126245847, lr: 0.04958942647710693
[batch_idx--350] train_loss: 0.00179068047846495, acc: 0.7838541666666666, lr: 0.04957888307633007
[batch_idx--400] train_loss: 0.0017871268774659148, acc: 0.7842210879052369, lr: 0.04956820716022985
[batch_idx--450] train_loss: 0.0017941326100020885, acc: 0.7838459402228625, lr: 0.049557398786364705
total time of one epoch: 237.2355694770813 s
train_loss:  0.0017941326100020885  acc:  0.7838459402228625
->>lr:0.049557
test_loss:  0.001807022925301275  test_acc:  0.7830996401538652
best acc:  78.37200645241344

------Epoch: 9------
[batch_idx--0] train_loss: 0.0019499296322464943, acc: 0.76953125, lr: 0.049557181268217225
[batch_idx--50] train_loss: 0.0018028666096392507, acc: 0.7792585784313726, lr: 0.04954623784746919
[batch_idx--100] train_loss: 0.0017620538727905932, acc: 0.7872834158415841, lr: 0.04953516208740226
[batch_idx--150] train_loss: 0.0017651509923786418, acc: 0.7864497102649006, lr: 0.049523954047730606
[batch_idx--200] train_loss: 0.0017656335243445575, acc: 0.7869441853233831, lr: 0.04951261378888158
[batch_idx--250] train_loss: 0.0017678904012253737, acc: 0.7864012699203188, lr: 0.049501141371995405
[batch_idx--300] train_loss: 0.0017690369387488329, acc: 0.7862852990033222, lr: 0.0494895368589248
[batch_idx--350] train_loss: 0.0017660878972811068, acc: 0.7867254273504274, lr: 0.0494778003122347
[batch_idx--400] train_loss: 0.0017637797126760172, acc: 0.7865687344139651, lr: 0.049465931795201847
[batch_idx--450] train_loss: 0.001767582829819089, acc: 0.7866577567952234, lr: 0.049453931371814544
total time of one epoch: 235.4334454536438 s
train_loss:  0.001767582829819089  acc:  0.7866577567952234
->>lr:0.049454
test_loss:  0.0017024519085839717  test_acc:  0.796748976299789
best acc:  78.37200645241344
Saving..

------Epoch: 10------
[batch_idx--0] train_loss: 0.0016719895647838712, acc: 0.828125, lr: 0.049453690018345146
[batch_idx--50] train_loss: 0.0017799998944004376, acc: 0.7883731617647058, lr: 0.04944155511713453
[batch_idx--100] train_loss: 0.0017575725318292284, acc: 0.7880569306930693, lr: 0.04942928844099462
[batch_idx--150] train_loss: 0.0017511750569887804, acc: 0.7901748758278145, lr: 0.0494168900560603
[batch_idx--200] train_loss: 0.0017408898073614607, acc: 0.7914917599502488, lr: 0.04940436002917662
[batch_idx--250] train_loss: 0.0017364354084331202, acc: 0.7918015438247012, lr: 0.04939169842789834
[batch_idx--300] train_loss: 0.001739093467231184, acc: 0.7908014950166113, lr: 0.04937890532048959
[batch_idx--350] train_loss: 0.001738071796534705, acc: 0.7914552172364673, lr: 0.04936598077592351
[batch_idx--400] train_loss: 0.0017361321815747089, acc: 0.7914101465087282, lr: 0.049352924863881875
[batch_idx--450] train_loss: 0.001741065030465103, acc: 0.7909883014545076, lr: 0.04933973765475472
total time of one epoch: 235.76777267456055 s
train_loss:  0.001741065030465103  acc:  0.7909883014545076
->>lr:0.049340
test_loss:  0.0017477635939965282  test_acc:  0.7978657401662738
best acc:  79.6748976299789
Saving..

------Epoch: 11------
[batch_idx--0] train_loss: 0.0017697663279250264, acc: 0.7890625, lr: 0.04933947257182901
[batch_idx--50] train_loss: 0.0017366818284761964, acc: 0.7945772058823529, lr: 0.04932615151292455
[batch_idx--100] train_loss: 0.0017046268423097117, acc: 0.7978805693069307, lr: 0.04931269930128121
[batch_idx--150] train_loss: 0.0017072391173561777, acc: 0.7967456539735099, lr: 0.04929911600942565
[batch_idx--200] train_loss: 0.0017109519821726046, acc: 0.7958061256218906, lr: 0.04928540171059123
[batch_idx--250] train_loss: 0.0017093868566253982, acc: 0.7955988545816733, lr: 0.04927155647871764
[batch_idx--300] train_loss: 0.0017089656615270877, acc: 0.7955383098006644, lr: 0.04925758038845046
[batch_idx--350] train_loss: 0.0017119884418663263, acc: 0.79512775997151, lr: 0.04924347351514081
[batch_idx--400] train_loss: 0.0017133156871748274, acc: 0.7949754519950125, lr: 0.049229235934844906
[batch_idx--450] train_loss: 0.0017215921237537662, acc: 0.7946245704169126, lr: 0.04921486772432365
total time of one epoch: 236.27080059051514 s
train_loss:  0.0017215921237537662  acc:  0.7946245704169126
->>lr:0.049215
test_loss:  0.0018641643391632977  test_acc:  0.7797493485544112
best acc:  79.78657401662737

------Epoch: 12------
[batch_idx--0] train_loss: 0.0014411206357181072, acc: 0.8515625, lr: 0.04921457902821578
[batch_idx--50] train_loss: 0.0017040810734946646, acc: 0.7972579656862745, lr: 0.04920007765467417
[batch_idx--100] train_loss: 0.0016988233218227726, acc: 0.7986154084158416, lr: 0.049185445808112044
[batch_idx--150] train_loss: 0.0016997078270188824, acc: 0.7977028145695364, lr: 0.049170683567415975
[batch_idx--200] train_loss: 0.0017045887728078077, acc: 0.7967389614427861, lr: 0.04915579101217554
[batch_idx--250] train_loss: 0.00170390263702572, acc: 0.7963303037848606, lr: 0.04914076822268292
[batch_idx--300] train_loss: 0.0016993514542155389, acc: 0.7971475290697675, lr: 0.04912561527993242
[batch_idx--350] train_loss: 0.001699663506969385, acc: 0.7967970975783476, lr: 0.049110332265620074
[batch_idx--400] train_loss: 0.0016968941793282356, acc: 0.7971185317955112, lr: 0.049094919262143176
[batch_idx--450] train_loss: 0.0016987092280108963, acc: 0.7973929947582185, lr: 0.049079376352599846
total time of one epoch: 236.5502622127533 s
train_loss:  0.0016987092280108963  acc:  0.7973929947582185
->>lr:0.049079
test_loss:  0.0018269885287478332  test_acc:  0.7828514704057575
best acc:  79.78657401662737

------Epoch: 13------
[batch_idx--0] train_loss: 0.0016912302235141397, acc: 0.76953125, lr: 0.049079064169941455
[batch_idx--50] train_loss: 0.0016822184016015015, acc: 0.8017769607843137, lr: 0.04906338884254441
[batch_idx--100] train_loss: 0.0016804790345601515, acc: 0.8009746287128713, lr: 0.04904758377907498
[batch_idx--150] train_loss: 0.0016778746676871811, acc: 0.8011951572847682, lr: 0.04903164906474507
[batch_idx--200] train_loss: 0.0016854356757749743, acc: 0.7999067164179104, lr: 0.04901558478546556
[batch_idx--250] train_loss: 0.0016821231901742132, acc: 0.8004388695219123, lr: 0.04899939102784589
[batch_idx--300] train_loss: 0.0016836963390523066, acc: 0.8001842815614618, lr: 0.04898306787919357
[batch_idx--350] train_loss: 0.0016833549137213971, acc: 0.8004362535612536, lr: 0.04896661542751371
[batch_idx--400] train_loss: 0.001680682024841854, acc: 0.8007325436408977, lr: 0.04895003376150854
[batch_idx--450] train_loss: 0.0016848448440616181, acc: 0.8000746346374146, lr: 0.04893332297057697
total time of one epoch: 236.84233379364014 s
train_loss:  0.0016848448440616181  acc:  0.8000746346374146
->>lr:0.048933
test_loss:  0.0016461352450570423  test_acc:  0.804442238491128
best acc:  79.78657401662737
Saving..

------Epoch: 14------
[batch_idx--0] train_loss: 0.0015372373163700104, acc: 0.82421875, lr: 0.048932987438301684
[batch_idx--50] train_loss: 0.0016547703234405786, acc: 0.8022365196078431, lr: 0.04891614503276587
[batch_idx--100] train_loss: 0.001642350914270276, acc: 0.8052289603960396, lr: 0.04889917368501234
[batch_idx--150] train_loss: 0.0016556495179218666, acc: 0.8026438327814569, lr: 0.04888207348654094
[batch_idx--200] train_loss: 0.0016581262189626176, acc: 0.8017335199004975, lr: 0.048864844529546175
[batch_idx--250] train_loss: 0.0016594517162529774, acc: 0.801730577689243, lr: 0.04884748690691675
[batch_idx--300] train_loss: 0.0016555350592539358, acc: 0.8024813122923588, lr: 0.048830000712235096
[batch_idx--350] train_loss: 0.001654386345265258, acc: 0.8025730056980057, lr: 0.048812386039776785
[batch_idx--400] train_loss: 0.0016590897475794292, acc: 0.8024177836658354, lr: 0.0487946429845101
[batch_idx--450] train_loss: 0.0016593313484180804, acc: 0.8028170236400874, lr: 0.048776771642095464
total time of one epoch: 236.96788001060486 s
train_loss:  0.0016593313484180804  acc:  0.8028170236400874
->>lr:0.048777
test_loss:  0.0017039568981294198  test_acc:  0.797617570418166
best acc:  80.44422384911279

------Epoch: 15------
[batch_idx--0] train_loss: 0.001572660868987441, acc: 0.82421875, lr: 0.048776412907378844
[batch_idx--50] train_loss: 0.0016253046079666592, acc: 0.8075214460784313, lr: 0.04875841081133997
[batch_idx--100] train_loss: 0.0016406576418880336, acc: 0.8051516089108911, lr: 0.04874028062349638
[batch_idx--150] train_loss: 0.0016397807279922413, acc: 0.804765107615894, lr: 0.0487220224415957
[batch_idx--200] train_loss: 0.001643074185828405, acc: 0.8043765547263682, lr: 0.04870363636407563
[batch_idx--250] train_loss: 0.0016480207789236628, acc: 0.8035669820717132, lr: 0.04868512249006343
[batch_idx--300] train_loss: 0.0016469524359559499, acc: 0.8039607558139535, lr: 0.048666480919375345
[batch_idx--350] train_loss: 0.0016469514492283605, acc: 0.8039418625356125, lr: 0.0486477117525161
[batch_idx--400] train_loss: 0.001646860464629334, acc: 0.804405003117207, lr: 0.04862881509067834
[batch_idx--450] train_loss: 0.0016476789654722712, acc: 0.8044312146353317, lr: 0.04860979103574209
total time of one epoch: 236.5101399421692 s
train_loss:  0.0016476789654722712  acc:  0.8044312146353317
->>lr:0.048610
test_loss:  0.0016091097368615957  test_acc:  0.8116391611862513
best acc:  80.44422384911279
Saving..

------Epoch: 16------
[batch_idx--0] train_loss: 0.001485214801505208, acc: 0.84375, lr: 0.04860940925593703
[batch_idx--50] train_loss: 0.0016188392502383567, acc: 0.8106617647058824, lr: 0.048590255365709406
[batch_idx--100] train_loss: 0.0016122418375095666, acc: 0.8123452970297029, lr: 0.04857097429027534
[batch_idx--150] train_loss: 0.0016111707745045916, acc: 0.8105856788079471, lr: 0.0485515661335874
[batch_idx--200] train_loss: 0.0016235777388896738, acc: 0.8083799751243781, lr: 0.048532031000283304
[batch_idx--250] train_loss: 0.0016219504423387557, acc: 0.8083291832669323, lr: 0.048512368995685354
[batch_idx--300] train_loss: 0.001622345464449512, acc: 0.8083471760797342, lr: 0.04849258022579986
[batch_idx--350] train_loss: 0.0016279716483792264, acc: 0.8076923076923077, lr: 0.04847266479731658
[batch_idx--400] train_loss: 0.0016308162541957827, acc: 0.806684460723192, lr: 0.048452622817608176
[batch_idx--450] train_loss: 0.0016336006518102516, acc: 0.8074860277016003, lr: 0.04843245439472954
total time of one epoch: 232.58317685127258 s
train_loss:  0.0016336006518102516  acc:  0.8074860277016003
->>lr:0.048432
test_loss:  0.0015743550776192768  test_acc:  0.8225586301029905
best acc:  81.16391611862514
Saving..

------Epoch: 17------
[batch_idx--0] train_loss: 0.0017408662242814898, acc: 0.80078125, lr: 0.04843204973729729
[batch_idx--50] train_loss: 0.0016262489827532395, acc: 0.8098958333333334, lr: 0.048411752454410206
[batch_idx--100] train_loss: 0.0016138958952177575, acc: 0.8110689975247525, lr: 0.0483913289487026
[batch_idx--150] train_loss: 0.0016172706467154998, acc: 0.8099906870860927, lr: 0.04837077933028638
[batch_idx--200] train_loss: 0.001616249278544527, acc: 0.810498289800995, lr: 0.04835010370995336
[batch_idx--250] train_loss: 0.0016155284527963791, acc: 0.810616907370518, lr: 0.0483293021991747
[batch_idx--300] train_loss: 0.001616445335596676, acc: 0.8106442068106312, lr: 0.04830837491010029
[batch_idx--350] train_loss: 0.0016199222658402645, acc: 0.809806801994302, lr: 0.04828732195555814
[batch_idx--400] train_loss: 0.0016151337037815195, acc: 0.810220542394015, lr: 0.04826614344905377
[batch_idx--450] train_loss: 0.0016188570706417349, acc: 0.8103759502898601, lr: 0.04824483950476961
total time of one epoch: 233.55397701263428 s
train_loss:  0.0016188570706417349  acc:  0.8103759502898601
->>lr:0.048245
test_loss:  0.0017916847472008027  test_acc:  0.7857054225089961
best acc:  82.25586301029904

------Epoch: 18------
[batch_idx--0] train_loss: 0.0014113816432654858, acc: 0.859375, lr: 0.04824441214720629
[batch_idx--50] train_loss: 0.001610037414174454, acc: 0.8095894607843137, lr: 0.04822298037471885
[batch_idx--100] train_loss: 0.001595438603256451, acc: 0.8109529702970297, lr: 0.04820142339716232
[batch_idx--150] train_loss: 0.0016044641086301267, acc: 0.8099389486754967, lr: 0.04817974133075961
[batch_idx--200] train_loss: 0.0016045073401738904, acc: 0.8099152674129353, lr: 0.04815793429240808
[batch_idx--250] train_loss: 0.0016039469765417604, acc: 0.8103056523904383, lr: 0.04813600239967885
[batch_idx--300] train_loss: 0.0016055450170607216, acc: 0.8100861710963455, lr: 0.04811394577081616
[batch_idx--350] train_loss: 0.0016064285177955048, acc: 0.8097066417378918, lr: 0.04809176452473679
[batch_idx--400] train_loss: 0.0016120272996879537, acc: 0.8091100374064838, lr: 0.048069458781029376
[batch_idx--450] train_loss: 0.001621795841939671, acc: 0.8089613635574686, lr: 0.048047028659953764
total time of one epoch: 233.60261273384094 s
train_loss:  0.001621795841939671  acc:  0.8089613635574686
->>lr:0.048047
test_loss:  0.0016684887655941927  test_acc:  0.8132522645489515
best acc:  82.25586301029904

------Epoch: 19------
[batch_idx--0] train_loss: 0.0015432668151333928, acc: 0.796875, lr: 0.04804657878971252
[batch_idx--50] train_loss: 0.0016244164503672544, acc: 0.8110447303921569, lr: 0.04802402192830846
[batch_idx--100] train_loss: 0.0015884921793816703, acc: 0.8159421410891089, lr: 0.04800134093450581
[batch_idx--150] train_loss: 0.001590376343602771, acc: 0.8150093129139073, lr: 0.04797853593058756
[batch_idx--200] train_loss: 0.001590194929488448, acc: 0.8139381218905473, lr: 0.04795560703950527
[batch_idx--250] train_loss: 0.0015907551262126975, acc: 0.8138072709163346, lr: 0.047932554384878465
[batch_idx--300] train_loss: 0.0015857306570495383, acc: 0.8145374792358804, lr: 0.0479093780909939
[batch_idx--350] train_loss: 0.0015888890016696646, acc: 0.8138577279202279, lr: 0.047886078282804945
[batch_idx--400] train_loss: 0.0015881865609325748, acc: 0.8140488622194514, lr: 0.047862655085930884
[batch_idx--450] train_loss: 0.0015963307395073087, acc: 0.8133700142326518, lr: 0.04783910862665624
total time of one epoch: 236.82642340660095 s
train_loss:  0.0015963307395073087  acc:  0.8133700142326518
->>lr:0.047839
test_loss:  0.0015682368039463572  test_acc:  0.8167266410224594
best acc:  82.25586301029904

------Epoch: 20------
[batch_idx--0] train_loss: 0.001285783015191555, acc: 0.83984375, lr: 0.04783863644106502
[batch_idx--50] train_loss: 0.0015689506761583628, acc: 0.8157935049019608, lr: 0.047814964384929284
[batch_idx--100] train_loss: 0.0015820872031687067, acc: 0.8128480816831684, lr: 0.047791169323514016
[batch_idx--150] train_loss: 0.0015785693783091, acc: 0.8141814983443708, lr: 0.047767251385108636
[batch_idx--200] train_loss: 0.0015738118794371388, acc: 0.8153956778606966, lr: 0.04774321069866503
[batch_idx--250] train_loss: 0.0015791955777811279, acc: 0.814445343625498, lr: 0.04771904739379687
[batch_idx--300] train_loss: 0.001577083302578236, acc: 0.8145504568106312, lr: 0.0476947616007789
[batch_idx--350] train_loss: 0.0015779993433155056, acc: 0.8143251424501424, lr: 0.0476703534505463
[batch_idx--400] train_loss: 0.001575139805237923, acc: 0.8148184226932669, lr: 0.047645823074693894
[batch_idx--450] train_loss: 0.0015819848502452401, acc: 0.8140816468219529, lr: 0.047621170605475466
total time of one epoch: 235.2090482711792 s
train_loss:  0.0015819848502452401  acc:  0.8140816468219529
->>lr:0.047621
test_loss:  0.0015716299937904169  test_acc:  0.8184638292592133
best acc:  82.25586301029904

------Epoch: 21------
[batch_idx--0] train_loss: 0.0015756842913106084, acc: 0.8203125, lr: 0.04762067631165049
[batch_idx--50] train_loss: 0.0015838494885018935, acc: 0.8176317401960784, lr: 0.047595899444129244
[batch_idx--100] train_loss: 0.0015696290613032213, acc: 0.8183013613861386, lr: 0.04757100075240174
[batch_idx--150] train_loss: 0.001572668578611403, acc: 0.8176221026490066, lr: 0.04754598037070751
[batch_idx--200] train_loss: 0.0015762329115462837, acc: 0.8163285136815921, lr: 0.047520838433942204
[batch_idx--250] train_loss: 0.0015690816757436175, acc: 0.8174800796812749, lr: 0.04749557507765681
[batch_idx--300] train_loss: 0.001564095401285569, acc: 0.8185215946843853, lr: 0.047470190438056926
[batch_idx--350] train_loss: 0.001565880281784362, acc: 0.8181646189458689, lr: 0.047444684652002064
[batch_idx--400] train_loss: 0.001568733860838443, acc: 0.8173803771820449, lr: 0.04741905785700488
[batch_idx--450] train_loss: 0.0015700682604574017, acc: 0.8172058874579096, lr: 0.04739331019123044
total time of one epoch: 236.56084823608398 s
train_loss:  0.0015700682604574017  acc:  0.8172058874579096
->>lr:0.047393
test_loss:  0.0015535055074846794  test_acc:  0.822930884725152
best acc:  82.25586301029904
Saving..

------Epoch: 22------
[batch_idx--0] train_loss: 0.001519438112154603, acc: 0.81640625, lr: 0.047392794005985325
[batch_idx--50] train_loss: 0.0015450719237218007, acc: 0.8226102941176471, lr: 0.04736692319503155
[batch_idx--100] train_loss: 0.0015614343170851175, acc: 0.8183400371287128, lr: 0.047340931794380904
[batch_idx--150] train_loss: 0.001555034594721352, acc: 0.8187862168874173, lr: 0.04731481994416418
[batch_idx--200] train_loss: 0.001552441982153933, acc: 0.8191270211442786, lr: 0.04728858778516159
[batch_idx--250] train_loss: 0.0015560168614314194, acc: 0.8185383466135459, lr: 0.04726223545880198
[batch_idx--300] train_loss: 0.0015602643246548963, acc: 0.8180024916943521, lr: 0.04723576310716207
[batch_idx--350] train_loss: 0.0015634371304720045, acc: 0.8178752670940171, lr: 0.047209170872965694
[batch_idx--400] train_loss: 0.0015592258043257412, acc: 0.8182960567331671, lr: 0.047182458899583
[batch_idx--450] train_loss: 0.0015661431121558017, acc: 0.8179956260631097, lr: 0.04715562733102973
total time of one epoch: 235.74489665031433 s
train_loss:  0.0015661431121558017  acc:  0.8179956260631097
->>lr:0.047156
test_loss:  0.0015123306388431337  test_acc:  0.8287628738056831
best acc:  82.2930884725152
Saving..

------Epoch: 23------
[batch_idx--0] train_loss: 0.0014797858893871307, acc: 0.828125, lr: 0.04715508948078037
[batch_idx--50] train_loss: 0.0015654131980138081, acc: 0.8138020833333334, lr: 0.047128136074186804
[batch_idx--100] train_loss: 0.0015523834534376712, acc: 0.8169090346534653, lr: 0.04710106336530035
[batch_idx--150] train_loss: 0.0015537529722756602, acc: 0.8172599337748344, lr: 0.04707387150008163
[batch_idx--200] train_loss: 0.001549014720871155, acc: 0.8181747512437811, lr: 0.04704656062513368
[batch_idx--250] train_loss: 0.0015479560943312972, acc: 0.8182426543824701, lr: 0.04701913088770116
[batch_idx--300] train_loss: 0.0015481064348261914, acc: 0.8183139534883721, lr: 0.04699158243566958
[batch_idx--350] train_loss: 0.0015475065682874064, acc: 0.8189436431623932, lr: 0.04696391541756448
[batch_idx--400] train_loss: 0.0015468017068666004, acc: 0.8188902743142145, lr: 0.046936129982550645
[batch_idx--450] train_loss: 0.001559069561404621, acc: 0.8182733363418614, lr: 0.0469082262804313
total time of one epoch: 234.45234751701355 s
train_loss:  0.001559069561404621  acc:  0.8182733363418614
->>lr:0.046908
test_loss:  0.0015512216710943725  test_acc:  0.822062290606775
best acc:  82.87628738056831

------Epoch: 24------
[batch_idx--0] train_loss: 0.001609033439308405, acc: 0.81640625, lr: 0.04690766700109659
[batch_idx--50] train_loss: 0.0016047126983347185, acc: 0.8137254901960784, lr: 0.04687964282151817
[batch_idx--100] train_loss: 0.0015821797487390514, acc: 0.8153233292079208, lr: 0.046851500679380806
[batch_idx--150] train_loss: 0.0015739941806069866, acc: 0.8160958195364238, lr: 0.046823240726410885
[batch_idx--200] train_loss: 0.0015667868808226946, acc: 0.8173585199004975, lr: 0.046794863114969956
[batch_idx--250] train_loss: 0.0015618240690801247, acc: 0.8181181523904383, lr: 0.04676636799805392
[batch_idx--300] train_loss: 0.0015580956506979129, acc: 0.8182879983388704, lr: 0.046737755529292206
[batch_idx--350] train_loss: 0.001559402195317538, acc: 0.8184984864672364, lr: 0.046709025862946923
[batch_idx--400] train_loss: 0.0015594361322650923, acc: 0.8189292394014963, lr: 0.046680179153912066
[batch_idx--450] train_loss: 0.0015576229655006458, acc: 0.8194188912417121, lr: 0.04665121555771262
total time of one epoch: 239.50425267219543 s
train_loss:  0.0015576229655006458  acc:  0.8194188912417121
->>lr:0.046651
test_loss:  0.001539893253282395  test_acc:  0.822930884725152
best acc:  82.87628738056831

------Epoch: 25------
[batch_idx--0] train_loss: 0.0018234801245853305, acc: 0.765625, lr: 0.046650635094610975
[batch_idx--50] train_loss: 0.0015241218840374665, acc: 0.8245251225490197, lr: 0.04662155243437907
[batch_idx--100] train_loss: 0.0015311133817280873, acc: 0.8222849628712872, lr: 0.04659235320306443
[batch_idx--150] train_loss: 0.0015380934392725, acc: 0.8212955298013245, lr: 0.046563037558092685
[batch_idx--200] train_loss: 0.00153847295554605, acc: 0.8207789179104478, lr: 0.04653360565751704
[batch_idx--250] train_loss: 0.0015419791308806771, acc: 0.8200479332669323, lr: 0.04650405766001754
[batch_idx--300] train_loss: 0.00153297895141738, acc: 0.8213896387043189, lr: 0.04647439372490014
[batch_idx--350] train_loss: 0.0015356570141963088, acc: 0.8204571759259259, lr: 0.046444614012095875
[batch_idx--400] train_loss: 0.0015380619377701396, acc: 0.8197767300498753, lr: 0.046414718682159954
[batch_idx--450] train_loss: 0.0015426816981110325, acc: 0.8195751032735099, lr: 0.04638470789627097
total time of one epoch: 233.25345611572266 s
train_loss:  0.0015426816981110325  acc:  0.8195751032735099
->>lr:0.046385
test_loss:  0.0015894797247978842  test_acc:  0.8189601687554288
best acc:  82.87628738056831

------Epoch: 26------
[batch_idx--0] train_loss: 0.0014886982971802354, acc: 0.82421875, lr: 0.04638410650401267
[batch_idx--50] train_loss: 0.0015799297549414868, acc: 0.8126531862745098, lr: 0.04635397811974326
[batch_idx--100] train_loss: 0.0015572538590150895, acc: 0.8170250618811881, lr: 0.04632373460699926
[batch_idx--150] train_loss: 0.0015480545101169225, acc: 0.8189414321192053, lr: 0.04629337612883644
[batch_idx--200] train_loss: 0.001537855470724478, acc: 0.8203125, lr: 0.046262902848930414
[batch_idx--250] train_loss: 0.0015378578930566333, acc: 0.8205615039840638, lr: 0.04623231493157573
[batch_idx--300] train_loss: 0.0015328277395171828, acc: 0.8209354235880398, lr: 0.046201612541685
[batch_idx--350] train_loss: 0.00153248010208549, acc: 0.8211026531339032, lr: 0.046170795844788
[batch_idx--400] train_loss: 0.001532346063045009, acc: 0.8210236128428927, lr: 0.04613986500703078
[batch_idx--450] train_loss: 0.001533026030159056, acc: 0.821293435623286, lr: 0.0461088201951748
total time of one epoch: 232.31282424926758 s
train_loss:  0.001533026030159056  acc:  0.821293435623286
->>lr:0.046109
test_loss:  0.0014855691185215298  test_acc:  0.8337262687678372
best acc:  82.87628738056831
Saving..

------Epoch: 27------
[batch_idx--0] train_loss: 0.001716738916002214, acc: 0.7734375, lr: 0.04610819813755038
[batch_idx--50] train_loss: 0.001509905546246206, acc: 0.8247549019607843, lr: 0.04607703724454855
[batch_idx--100] train_loss: 0.001517748098248745, acc: 0.8244121287128713, lr: 0.046045762716179425
[batch_idx--150] train_loss: 0.0015145887332407154, acc: 0.8252535182119205, lr: 0.04601437472105743
[batch_idx--200] train_loss: 0.0015223890569626322, acc: 0.8246074315920398, lr: 0.04598287342840873
[batch_idx--250] train_loss: 0.0015146945931566545, acc: 0.8254482071713147, lr: 0.04595125900807036
[batch_idx--300] train_loss: 0.001521071384311267, acc: 0.8242576827242525, lr: 0.045919531630489216
[batch_idx--350] train_loss: 0.0015177144937647076, acc: 0.8242076210826211, lr: 0.045887691466721246
[batch_idx--400] train_loss: 0.0015169764460155049, acc: 0.824588918329177, lr: 0.04585573868843045
[batch_idx--450] train_loss: 0.0015231701532323768, acc: 0.8239316832714271, lr: 0.04582367346788801
total time of one epoch: 231.05097150802612 s
train_loss:  0.0015231701532323768  acc:  0.8239316832714271
->>lr:0.045824
test_loss:  0.0015170618268600068  test_acc:  0.8321131654051371
best acc:  83.37262687678373

------Epoch: 28------
[batch_idx--0] train_loss: 0.0014686782378703356, acc: 0.82421875, lr: 0.04582303101775249
[batch_idx--50] train_loss: 0.0015312902875902021, acc: 0.8214613970588235, lr: 0.04579085128421578
[batch_idx--100] train_loss: 0.001522547191949469, acc: 0.8246441831683168, lr: 0.04575855945826332
[batch_idx--150] train_loss: 0.0015242130091623557, acc: 0.8237272350993378, lr: 0.04572615571399419
[batch_idx--200] train_loss: 0.0015228426741871668, acc: 0.8231693097014925, lr: 0.045693640226110915
[batch_idx--250] train_loss: 0.0015291708639351674, acc: 0.8215263944223108, lr: 0.045661013169918455
[batch_idx--300] train_loss: 0.0015285757982923937, acc: 0.8218568313953488, lr: 0.04562827472132332
[batch_idx--350] train_loss: 0.0015291865331988432, acc: 0.8223602207977208, lr: 0.045595425056832534
[batch_idx--400] train_loss: 0.0015284503250385163, acc: 0.8225724750623441, lr: 0.04556246435355277
[batch_idx--450] train_loss: 0.0015280963606325744, acc: 0.823098552435172, lr: 0.04552939278918935
total time of one epoch: 232.62459707260132 s
train_loss:  0.0015280963606325744  acc:  0.823098552435172
->>lr:0.045529
test_loss:  0.0016201605260157677  test_acc:  0.8067998510981511
best acc:  83.37262687678373

------Epoch: 29------
[batch_idx--0] train_loss: 0.0014776416355744004, acc: 0.8203125, lr: 0.045528730228342605
[batch_idx--50] train_loss: 0.0015239961052715195, acc: 0.8230698529411765, lr: 0.04549554576936571
[batch_idx--100] train_loss: 0.0015150229942219534, acc: 0.8241800742574258, lr: 0.04546225081009201
[batch_idx--150] train_loss: 0.0015048193159383654, acc: 0.8253052566225165, lr: 0.04542884553002893
[batch_idx--200] train_loss: 0.001507298909104545, acc: 0.8249378109452736, lr: 0.04539533010927871
[batch_idx--250] train_loss: 0.0015017469237332205, acc: 0.8257750249003984, lr: 0.04536170472853737
[batch_idx--300] train_loss: 0.001501991792560317, acc: 0.8254645971760798, lr: 0.045327969569093796
[batch_idx--350] train_loss: 0.0015016082074609917, acc: 0.82596599002849, lr: 0.04529412481282874
[batch_idx--400] train_loss: 0.0015030417456628378, acc: 0.8257286471321695, lr: 0.04526017064221382
[batch_idx--450] train_loss: 0.0015119380014472492, acc: 0.8251293088485437, lr: 0.04522610724031057
total time of one epoch: 231.69056868553162 s
train_loss:  0.0015119380014472492  acc:  0.8251293088485437
->>lr:0.045226
test_loss:  0.0014835768855968588  test_acc:  0.831368656160814
best acc:  83.37262687678373

------Epoch: 30------
[batch_idx--0] train_loss: 0.0014282857300713658, acc: 0.84375, lr: 0.04522542485937369
[batch_idx--50] train_loss: 0.001481658016678457, acc: 0.8305759803921569, lr: 0.04519125023075707
[batch_idx--100] train_loss: 0.0014886390809707418, acc: 0.8289371905940595, lr: 0.045156966742431685
[batch_idx--150] train_loss: 0.0015031148306408663, acc: 0.8264176324503312, lr: 0.04512257457923455
[batch_idx--200] train_loss: 0.0015082452683686394, acc: 0.8258512126865671, lr: 0.04508807392658861
[batch_idx--250] train_loss: 0.0015109924110676722, acc: 0.8256038346613546, lr: 0.0450534649705017
[batch_idx--300] train_loss: 0.0015024349122057573, acc: 0.8268661752491694, lr: 0.04501874789756559
[batch_idx--350] train_loss: 0.0015061102698734853, acc: 0.8259771189458689, lr: 0.04498392289495493
[batch_idx--400] train_loss: 0.0015039265642356025, acc: 0.8261475218204489, lr: 0.04494899015042629
[batch_idx--450] train_loss: 0.0015050880330320772, acc: 0.8265612524733572, lr: 0.04491394985231711
total time of one epoch: 234.22711038589478 s
train_loss:  0.0015050880330320772  acc:  0.8265612524733572
->>lr:0.044914
test_loss:  0.001504981195324629  test_acc:  0.8275220250651446
best acc:  83.37262687678373

------Epoch: 31------
[batch_idx--0] train_loss: 0.0015671529108658433, acc: 0.80859375, lr: 0.04491324795060491
[batch_idx--50] train_loss: 0.0015187859421084617, acc: 0.8228400735294118, lr: 0.04487809814247016
[batch_idx--100] train_loss: 0.0014981074422358138, acc: 0.826771349009901, lr: 0.044842841162964144
[batch_idx--150] train_loss: 0.0014970564292682124, acc: 0.8262624172185431, lr: 0.04480747720217241
[batch_idx--200] train_loss: 0.0014989261818929246, acc: 0.8260261194029851, lr: 0.04477200645075726
[batch_idx--250] train_loss: 0.00150128256574095, acc: 0.8258528386454184, lr: 0.04473642909995676
[batch_idx--300] train_loss: 0.0014987555920359897, acc: 0.8259317898671097, lr: 0.044700745341583706
[batch_idx--350] train_loss: 0.00149715635786231, acc: 0.8256655092592593, lr: 0.044664955368024575
[batch_idx--400] train_loss: 0.0014936023971247035, acc: 0.8263715710723192, lr: 0.044629059372238496
[batch_idx--450] train_loss: 0.0014983289088346106, acc: 0.8260492241469087, lr: 0.044593057547756214
total time of one epoch: 233.25129628181458 s
train_loss:  0.0014983289088346106  acc:  0.8260492241469087
->>lr:0.044593
test_loss:  0.00152371191981413  test_acc:  0.8241717334656905
best acc:  83.37262687678373

------Epoch: 32------
[batch_idx--0] train_loss: 0.001289971056394279, acc: 0.8671875, lr: 0.044592336433146
[batch_idx--50] train_loss: 0.0015005105193339142, acc: 0.8278186274509803, lr: 0.04455622686336067
[batch_idx--100] train_loss: 0.0014826974515701728, acc: 0.830368193069307, lr: 0.0445200118575505
[batch_idx--150] train_loss: 0.0014917663004039633, acc: 0.8291597682119205, lr: 0.04448369161096615
[batch_idx--200] train_loss: 0.0014813051243956707, acc: 0.830010105721393, lr: 0.044447266319425686
[batch_idx--250] train_loss: 0.0014843233681072396, acc: 0.8295723356573705, lr: 0.044410736179313494
[batch_idx--300] train_loss: 0.001482534573097834, acc: 0.8298639950166113, lr: 0.04437410138757928
[batch_idx--350] train_loss: 0.0014841628729888475, acc: 0.8293825676638177, lr: 0.04433736214173695
[batch_idx--400] train_loss: 0.0014851747035394955, acc: 0.8292647288029925, lr: 0.04430051863986356
[batch_idx--450] train_loss: 0.001493022488015352, acc: 0.8283663692852432, lr: 0.04426357108059828
total time of one epoch: 233.45967292785645 s
train_loss:  0.001493022488015352  acc:  0.8283663692852432
->>lr:0.044264
test_loss:  0.0013984989174720829  test_acc:  0.8461347561732225
best acc:  83.37262687678373
Saving..

------Epoch: 33------
[batch_idx--0] train_loss: 0.0015221595531329513, acc: 0.81640625, lr: 0.044262831069394735
[batch_idx--50] train_loss: 0.00149966997103583, acc: 0.8245251225490197, lr: 0.04422577757680957
[batch_idx--100] train_loss: 0.0014963597600984543, acc: 0.8258044554455446, lr: 0.04418862042979371
[batch_idx--150] train_loss: 0.0014994657677074043, acc: 0.8264176324503312, lr: 0.044151359828677295
[batch_idx--200] train_loss: 0.0014934383844725082, acc: 0.8277557524875622, lr: 0.04411399597434825
[batch_idx--250] train_loss: 0.001489726683232503, acc: 0.8275491782868526, lr: 0.04407652906825116
[batch_idx--300] train_loss: 0.0014861568037352441, acc: 0.8273203903654485, lr: 0.04403895931238623
[batch_idx--350] train_loss: 0.0014787070168596175, acc: 0.8285256410256411, lr: 0.044001286909308164
[batch_idx--400] train_loss: 0.0014810621932362603, acc: 0.8282321539900249, lr: 0.04396351206212508
[batch_idx--450] train_loss: 0.0014877151870514836, acc: 0.8283142986079772, lr: 0.043925634974497405
total time of one epoch: 230.34671640396118 s
train_loss:  0.0014877151870514836  acc:  0.8283142986079772
->>lr:0.043926
test_loss:  0.0013940711074083107  test_acc:  0.8443975679364686
best acc:  84.61347561732225

------Epoch: 34------
[batch_idx--0] train_loss: 0.0014446384739130735, acc: 0.81640625, lr: 0.043924876391293916
[batch_idx--50] train_loss: 0.0014748614915993576, acc: 0.8311121323529411, lr: 0.0438868952287954
[batch_idx--100] train_loss: 0.0014692362026763287, acc: 0.8292465965346535, lr: 0.04384881223892658
[batch_idx--150] train_loss: 0.001475237178098139, acc: 0.8282543460264901, lr: 0.04381062762700922
[batch_idx--200] train_loss: 0.0014721486162607425, acc: 0.8293104788557214, lr: 0.043772341598912995
[batch_idx--250] train_loss: 0.0014700714959781543, acc: 0.830148157370518, lr: 0.04373395436105431
[batch_idx--300] train_loss: 0.0014756575820076456, acc: 0.8292800041528239, lr: 0.04369546612039528
[batch_idx--350] train_loss: 0.0014715218263813574, acc: 0.829605146011396, lr: 0.04365687708444255
[batch_idx--400] train_loss: 0.0014771952530708247, acc: 0.828514650872818, lr: 0.04361818746124621
[batch_idx--450] train_loss: 0.0014814850533004852, acc: 0.8283142986079772, lr: 0.04357939745939863
total time of one epoch: 233.68854022026062 s
train_loss:  0.0014814850533004852  acc:  0.8283142986079772
->>lr:0.043579
test_loss:  0.0014019859999784363  test_acc:  0.8425362948256607
best acc:  84.61347561732225

------Epoch: 35------
[batch_idx--0] train_loss: 0.0014296761946752667, acc: 0.83984375, lr: 0.04357862063693486
[batch_idx--50] train_loss: 0.0014860867180258913, acc: 0.8245251225490197, lr: 0.04353972846431615
[batch_idx--100] train_loss: 0.0014793544876306216, acc: 0.8260751856435643, lr: 0.043500736336052385
[batch_idx--150] train_loss: 0.0014738630987580447, acc: 0.8285647764900662, lr: 0.04346164446236689
[batch_idx--200] train_loss: 0.0014684298197363518, acc: 0.830126710199005, lr: 0.04342245305402075
[batch_idx--250] train_loss: 0.0014658200631541502, acc: 0.8307395418326693, lr: 0.04338316232231171
[batch_idx--300] train_loss: 0.0014651257980249797, acc: 0.830499896179402, lr: 0.043343772479072985
[batch_idx--350] train_loss: 0.001466014557464998, acc: 0.8302506232193733, lr: 0.043304283736672146
[batch_idx--400] train_loss: 0.0014643051622068495, acc: 0.8303557512468828, lr: 0.04326469630800999
[batch_idx--450] train_loss: 0.001467590286128204, acc: 0.8299545249418544, lr: 0.04322501040651934
total time of one epoch: 231.33633089065552 s
train_loss:  0.001467590286128204  acc:  0.8299545249418544
->>lr:0.043225
test_loss:  0.001530810671033716  test_acc:  0.8262811763246061
best acc:  84.61347561732225

------Epoch: 36------
[batch_idx--0] train_loss: 0.001380785251967609, acc: 0.82421875, lr: 0.04322421568553529
[batch_idx--50] train_loss: 0.0014566072975011432, acc: 0.8318780637254902, lr: 0.04318442956218869
[batch_idx--100] train_loss: 0.0014574300880442457, acc: 0.8316831683168316, lr: 0.04314454539876614
[batch_idx--150] train_loss: 0.001462092970047664, acc: 0.8296771523178808, lr: 0.043104563410300306
[batch_idx--200] train_loss: 0.0014603184657727382, acc: 0.830204446517413, lr: 0.043064483812351256
[batch_idx--250] train_loss: 0.0014611112456620332, acc: 0.8301792828685259, lr: 0.04302430682100536
[batch_idx--300] train_loss: 0.0014669369787064402, acc: 0.8293708471760798, lr: 0.042984032652874024
[batch_idx--350] train_loss: 0.00146355206164083, acc: 0.8299056267806267, lr: 0.04294366152509261
[batch_idx--400] train_loss: 0.0014602260906806685, acc: 0.8305798004987531, lr: 0.04290319365531922
[batch_idx--450] train_loss: 0.0014657029661519975, acc: 0.830319019682716, lr: 0.04286262926173353
total time of one epoch: 237.07512760162354 s
train_loss:  0.0014657029661519975  acc:  0.830319019682716
->>lr:0.042863
test_loss:  0.001452150789646168  test_acc:  0.8378210696116144
best acc:  84.61347561732225

------Epoch: 37------
[batch_idx--0] train_loss: 0.0017168407794088125, acc: 0.796875, lr: 0.04286181699082009
[batch_idx--50] train_loss: 0.0014959484722246142, acc: 0.8245251225490197, lr: 0.04282115436825425
[batch_idx--100] train_loss: 0.0014828656417419119, acc: 0.8285117574257426, lr: 0.04278039566418517
[batch_idx--150] train_loss: 0.0014775237161049385, acc: 0.8287199917218543, lr: 0.04273954109836054
[batch_idx--200] train_loss: 0.0014747563965006995, acc: 0.8292910447761194, lr: 0.0426985908910449
[batch_idx--250] train_loss: 0.0014763303236494144, acc: 0.8294633964143426, lr: 0.042657545263018404
[batch_idx--300] train_loss: 0.0014700508801006647, acc: 0.8305388289036545, lr: 0.042616404435575676
[batch_idx--350] train_loss: 0.00147289819610796, acc: 0.830016915954416, lr: 0.04257516863052461
[batch_idx--400] train_loss: 0.0014652022189040321, acc: 0.8310571228179551, lr: 0.04253383807018514
[batch_idx--450] train_loss: 0.0014683045680939967, acc: 0.8314298607977227, lr: 0.042492412977388094
total time of one epoch: 230.98471403121948 s
train_loss:  0.0014683045680939967  acc:  0.8314298607977227
->>lr:0.042492
test_loss:  0.0014312481418675414  test_acc:  0.844025313314307
best acc:  84.61347561732225

------Epoch: 38------
[batch_idx--0] train_loss: 0.001452553435228765, acc: 0.83203125, lr: 0.042491583512834136
[batch_idx--50] train_loss: 0.0014691012135396402, acc: 0.8332567401960784, lr: 0.04245006222701923
[batch_idx--100] train_loss: 0.0014465782032947582, acc: 0.8350092821782178, lr: 0.04240844686041831
[batch_idx--150] train_loss: 0.0014454617553594097, acc: 0.8346957781456954, lr: 0.042366737637397726
[batch_idx--200] train_loss: 0.0014480435908007534, acc: 0.8335665422885572, lr: 0.04232493478282982
[batch_idx--250] train_loss: 0.001444404410472904, acc: 0.8343656623505976, lr: 0.042283038522091754
[batch_idx--300] train_loss: 0.0014436128023281643, acc: 0.8346137873754153, lr: 0.04224104908106427
[batch_idx--350] train_loss: 0.001444596735537689, acc: 0.8342570334757835, lr: 0.0421989666861305
[batch_idx--400] train_loss: 0.0014446575300271004, acc: 0.834505533042394, lr: 0.04215679156417471
[batch_idx--450] train_loss: 0.0014477510959738664, acc: 0.8343458187246156, lr: 0.04211452394258114
total time of one epoch: 237.8357138633728 s
train_loss:  0.0014477510959738664  acc:  0.8343458187246156
->>lr:0.042115
test_loss:  0.0013600505785842083  test_acc:  0.8499813872688919
best acc:  84.61347561732225
Saving..

------Epoch: 39------
[batch_idx--0] train_loss: 0.0014540439005941153, acc: 0.828125, lr: 0.04211367764821722
[batch_idx--50] train_loss: 0.001456200010508445, acc: 0.8335631127450981, lr: 0.04207131591176148
[batch_idx--100] train_loss: 0.0014559694803273767, acc: 0.831721844059406, lr: 0.042028862136503926
[batch_idx--150] train_loss: 0.0014563967244058157, acc: 0.8317208195364238, lr: 0.0419863165513311
[batch_idx--200] train_loss: 0.0014505911767899767, acc: 0.8328086131840796, lr: 0.041943679385624544
[batch_idx--250] train_loss: 0.0014535416227457415, acc: 0.8325448207171314, lr: 0.04190095086925955
[batch_idx--300] train_loss: 0.0014517992758888293, acc: 0.8331213662790697, lr: 0.041858131232603915
[batch_idx--350] train_loss: 0.0014507419932527504, acc: 0.8335225249287749, lr: 0.04181522070651669
[batch_idx--400] train_loss: 0.0014464248766068212, acc: 0.8340769170822943, lr: 0.04177221952234698
[batch_idx--450] train_loss: 0.0014494594070028066, acc: 0.8346929565730552, lr: 0.041729127911932645
total time of one epoch: 230.87082767486572 s
train_loss:  0.0014494594070028066  acc:  0.8346929565730552
->>lr:0.041729
test_loss:  0.001389813986734593  test_acc:  0.8446457376845763
best acc:  84.9981387268892

------Epoch: 40------
[batch_idx--0] train_loss: 0.0012035174295306206, acc: 0.85546875, lr: 0.04172826515897146
[batch_idx--50] train_loss: 0.0014495431815328844, acc: 0.8321078431372549, lr: 0.04168508155313258
[batch_idx--100] train_loss: 0.0014535044873188628, acc: 0.8315284653465347, lr: 0.04164180799084732
[batch_idx--150] train_loss: 0.0014405349240212745, acc: 0.8339973096026491, lr: 0.04159844470542206
[batch_idx--200] train_loss: 0.001437091670550443, acc: 0.8341301305970149, lr: 0.041554991930646906
[batch_idx--250] train_loss: 0.0014369935896507357, acc: 0.8345524153386454, lr: 0.041511449900794445
[batch_idx--300] train_loss: 0.0014379864618138864, acc: 0.8343542358803987, lr: 0.04146781885061848
[batch_idx--350] train_loss: 0.0014363496293687923, acc: 0.8347355769230769, lr: 0.04142409901535277
[batch_idx--400] train_loss: 0.001438373302636747, acc: 0.8341158821695761, lr: 0.04138029063070971
[batch_idx--450] train_loss: 0.001444470871759892, acc: 0.8342937480473496, lr: 0.041336393932879134
total time of one epoch: 232.2231113910675 s
train_loss:  0.001444470871759892  acc:  0.8342937480473496
->>lr:0.041336
test_loss:  0.0013889896653695207  test_acc:  0.8468792654175455
best acc:  84.9981387268892

------Epoch: 41------
[batch_idx--0] train_loss: 0.0013345200568437576, acc: 0.83203125, lr: 0.04133551509975264
[batch_idx--50] train_loss: 0.0014388213121313968, acc: 0.8340226715686274, lr: 0.041291528566287365
[batch_idx--100] train_loss: 0.0014472279494794288, acc: 0.8334235767326733, lr: 0.041247454198189024
[batch_idx--150] train_loss: 0.0014432936896021102, acc: 0.8338420943708609, lr: 0.04120329223308148
[batch_idx--200] train_loss: 0.001446105367782067, acc: 0.8335471082089553, lr: 0.041159042909060875
[batch_idx--250] train_loss: 0.0014435916000873265, acc: 0.834054407370518, lr: 0.04111470646469433
[batch_idx--300] train_loss: 0.001437918627263353, acc: 0.8352626661129569, lr: 0.04107028313901867
[batch_idx--350] train_loss: 0.0014382768492015381, acc: 0.8350583155270656, lr: 0.04102577317153916
[batch_idx--400] train_loss: 0.0014382104532783874, acc: 0.8347100997506235, lr: 0.04098117680222813
[batch_idx--450] train_loss: 0.0014414076004765086, acc: 0.8349706668518069, lr: 0.04093649427152381
total time of one epoch: 234.1351456642151 s
train_loss:  0.0014414076004765086  acc:  0.8349706668518069
->>lr:0.040936
test_loss:  0.0013967238136402267  test_acc:  0.8436530586921455
best acc:  84.9981387268892

------Epoch: 42------
[batch_idx--0] train_loss: 0.001402221736498177, acc: 0.83203125, lr: 0.040935599743717244
[batch_idx--50] train_loss: 0.0014193635274126542, acc: 0.8383118872549019, lr: 0.04089082957657292
[batch_idx--100] train_loss: 0.0014244042184794008, acc: 0.836981745049505, lr: 0.04084597373513602
[batch_idx--150] train_loss: 0.0014299808952044572, acc: 0.8364548841059603, lr: 0.04080103246124366
[batch_idx--200] train_loss: 0.0014256130549500682, acc: 0.8369675062189055, lr: 0.04075600599719357
[batch_idx--250] train_loss: 0.0014261613234476857, acc: 0.836995766932271, lr: 0.04071089458574278
[batch_idx--300] train_loss: 0.0014333268252365366, acc: 0.8355351951827242, lr: 0.04066569847010627
[batch_idx--350] train_loss: 0.0014308213098425727, acc: 0.8359597578347578, lr: 0.040620417893955756
[batch_idx--400] train_loss: 0.0014319022669761147, acc: 0.8359764650872819, lr: 0.04057505310141827
[batch_idx--450] train_loss: 0.0014372978646678164, acc: 0.8362463984448224, lr: 0.04052960433707492
total time of one epoch: 232.41217970848083 s
train_loss:  0.0014372978646678164  acc:  0.8362463984448224
->>lr:0.040530
test_loss:  0.0014046829234046429  test_acc:  0.8429085494478223
best acc:  84.9981387268892

------Epoch: 43------
[batch_idx--0] train_loss: 0.001409847871400416, acc: 0.8203125, lr: 0.040528694506957764
[batch_idx--50] train_loss: 0.0015007781901159416, acc: 0.8222273284313726, lr: 0.04048316034380937
[batch_idx--100] train_loss: 0.0014765920500169592, acc: 0.8286664603960396, lr: 0.040437542704288454
[batch_idx--150] train_loss: 0.0014579266761522124, acc: 0.832057119205298, lr: 0.04039184183433934
[batch_idx--200] train_loss: 0.0014407225254348557, acc: 0.834052394278607, lr: 0.04034605798035504
[batch_idx--250] train_loss: 0.0014327321460366664, acc: 0.8358908117529881, lr: 0.04030019138917598
[batch_idx--300] train_loss: 0.0014298456663767068, acc: 0.836469580564784, lr: 0.040254242308088696
[batch_idx--350] train_loss: 0.0014266644616444141, acc: 0.8365495904558404, lr: 0.040208210984824425
[batch_idx--400] train_loss: 0.0014260926703687877, acc: 0.8367947319201995, lr: 0.04016209766755781
[batch_idx--450] train_loss: 0.0014282089366499683, acc: 0.8368972819106467, lr: 0.040115902604905565
total time of one epoch: 232.48854088783264 s
train_loss:  0.0014282089366499683  acc:  0.8368972819106467
->>lr:0.040116
test_loss:  0.001371764840137753  test_acc:  0.8435289738180916
best acc:  84.9981387268892

------Epoch: 44------
[batch_idx--0] train_loss: 0.0013048273976892233, acc: 0.859375, lr: 0.040114977871559376
[batch_idx--50] train_loss: 0.0014223679626250967, acc: 0.8397671568627451, lr: 0.04006869968519579
[batch_idx--100] train_loss: 0.0014346546717080297, acc: 0.8368657178217822, lr: 0.04002234025699524
[batch_idx--150] train_loss: 0.0014362845690119148, acc: 0.8364548841059603, lr: 0.039975899836901335
[batch_idx--200] train_loss: 0.001432876465772626, acc: 0.8364622201492538, lr: 0.03992937867529435
[batch_idx--250] train_loss: 0.0014286385283274836, acc: 0.8372292081673307, lr: 0.03988277702298985
[batch_idx--300] train_loss: 0.0014238270197645374, acc: 0.8381177325581395, lr: 0.03983609513123738
[batch_idx--350] train_loss: 0.00142059629176746, acc: 0.8385305377492878, lr: 0.03978933325171908
[batch_idx--400] train_loss: 0.0014211109716287277, acc: 0.8383143703241895, lr: 0.03974249163654834
[batch_idx--450] train_loss: 0.0014269690673945617, acc: 0.8377390911931127, lr: 0.03969557053826845
total time of one epoch: 233.7931830883026 s
train_loss:  0.0014269690673945617  acc:  0.8377390911931127
->>lr:0.039696
test_loss:  0.0014052743547266567  test_acc:  0.8425362948256607
best acc:  84.9981387268892

------Epoch: 45------
[batch_idx--0] train_loss: 0.001577281393110752, acc: 0.81640625, lr: 0.03969463130731183
[batch_idx--50] train_loss: 0.0014402878986598522, acc: 0.8363204656862745, lr: 0.0396476293968751
[batch_idx--100] train_loss: 0.0014194656315600813, acc: 0.8390315594059405, lr: 0.03960054851477232
[batch_idx--150] train_loss: 0.0014170180175095699, acc: 0.8393781043046358, lr: 0.039553388914836764
[batch_idx--200] train_loss: 0.0014117339502009957, acc: 0.8394745024875622, lr: 0.039506150851326104
[batch_idx--250] train_loss: 0.0014063447321472, acc: 0.8404195717131474, lr: 0.039458834578921055
[batch_idx--300] train_loss: 0.0014100447776680966, acc: 0.8400254360465116, lr: 0.03941144035272397
[batch_idx--350] train_loss: 0.0014105654401874482, acc: 0.8399772970085471, lr: 0.03936396842825749
[batch_idx--400] train_loss: 0.0014122907906083245, acc: 0.83984375, lr: 0.03931641906146319
[batch_idx--450] train_loss: 0.0014156602452632832, acc: 0.8403079112715659, lr: 0.03926879250870011
total time of one epoch: 232.6943235397339 s
train_loss:  0.0014156602452632832  acc:  0.8403079112715659
->>lr:0.039269
test_loss:  0.0013181649399004883  test_acc:  0.8539521032386153
best acc:  84.9981387268892
Saving..

------Epoch: 46------
[batch_idx--0] train_loss: 0.0011552565265446901, acc: 0.87109375, lr: 0.0392678391921108
[batch_idx--50] train_loss: 0.0014101661714341711, acc: 0.8417585784313726, lr: 0.03922013417419226
[batch_idx--100] train_loss: 0.001397559017007525, acc: 0.8421256188118812, lr: 0.03917235248941817
[batch_idx--150] train_loss: 0.001400610246226833, acc: 0.8405163493377483, lr: 0.03912449439540013
[batch_idx--200] train_loss: 0.0014059614802511473, acc: 0.8404073383084577, lr: 0.0390765601501617
[batch_idx--250] train_loss: 0.0014062760058285823, acc: 0.8399215637450199, lr: 0.03902855001213699
[batch_idx--300] train_loss: 0.0014090434890983014, acc: 0.8395452657807309, lr: 0.0389804642401693
[batch_idx--350] train_loss: 0.0014080626477468812, acc: 0.8395432692307693, lr: 0.03893230309350968
[batch_idx--400] train_loss: 0.0014112547926600104, acc: 0.8391618609725686, lr: 0.03888406683181559
[batch_idx--450] train_loss: 0.0014189760171808851, acc: 0.8387544693997987, lr: 0.03883575571514944
total time of one epoch: 230.94261622428894 s
train_loss:  0.0014189760171808851  acc:  0.8387544693997987
->>lr:0.038836
test_loss:  0.001414196143479897  test_acc:  0.8471274351656533
best acc:  85.39521032386152

------Epoch: 47------
[batch_idx--0] train_loss: 0.0014272937551140785, acc: 0.8203125, lr: 0.038834788731083605
[batch_idx--50] train_loss: 0.0014281966951767019, acc: 0.8363970588235294, lr: 0.038786401530680796
[batch_idx--100] train_loss: 0.0014165450569869269, acc: 0.8374458539603961, lr: 0.03873794000186154
[batch_idx--150] train_loss: 0.0014198831635656834, acc: 0.8380587748344371, lr: 0.03868940440590278
[batch_idx--200] train_loss: 0.001414567098341215, acc: 0.8389692164179104, lr: 0.03864079500448077
[batch_idx--250] train_loss: 0.0014089401839189677, acc: 0.8398281872509961, lr: 0.03859211205966969
[batch_idx--300] train_loss: 0.001403244771527442, acc: 0.8411415074750831, lr: 0.038543355833940224
[batch_idx--350] train_loss: 0.0014040089528105538, acc: 0.8407118055555556, lr: 0.03849452659015813
[batch_idx--400] train_loss: 0.0014046367711882267, acc: 0.8400872817955112, lr: 0.03844562459158286
[batch_idx--450] train_loss: 0.0014074239412358656, acc: 0.8401516992397681, lr: 0.0383966501018661
total time of one epoch: 233.82543802261353 s
train_loss:  0.0014074239412358656  acc:  0.8401516992397681
->>lr:0.038397
test_loss:  0.0014829756397366125  test_acc:  0.8343466931381065
best acc:  85.39521032386152

------Epoch: 48------
[batch_idx--0] train_loss: 0.0014369732234627008, acc: 0.828125, lr: 0.03839566987447492
[batch_idx--50] train_loss: 0.0014136567661611765, acc: 0.8381587009803921, lr: 0.038346621715813135
[batch_idx--100] train_loss: 0.001413919315166255, acc: 0.8370204207920792, lr: 0.038297501599776934
[batch_idx--150] train_loss: 0.0014087390509242845, acc: 0.8381622516556292, lr: 0.03824830979119395
[batch_idx--200] train_loss: 0.0014064940091092788, acc: 0.8389497823383084, lr: 0.038199046555278386
[batch_idx--250] train_loss: 0.001407930915025007, acc: 0.8384431025896414, lr: 0.038149712157629516
[batch_idx--300] train_loss: 0.0014053600209075153, acc: 0.8392208264119602, lr: 0.038100306864230285
[batch_idx--350] train_loss: 0.0014043908060111764, acc: 0.8394987535612536, lr: 0.038050830941445866
[batch_idx--400] train_loss: 0.0014051455357564878, acc: 0.8394443578553616, lr: 0.03800128465602222
[batch_idx--450] train_loss: 0.001410486243920494, acc: 0.8393879959732009, lr: 0.03795166827508467
total time of one epoch: 232.85947561264038 s
train_loss:  0.001410486243920494  acc:  0.8393879959732009
->>lr:0.037952
test_loss:  0.0013796997389821206  test_acc:  0.8467551805434917
best acc:  85.39521032386152

------Epoch: 49------
[batch_idx--0] train_loss: 0.0015577415470033884, acc: 0.82421875, lr: 0.03795067523432826
[batch_idx--50] train_loss: 0.0013836066366410722, acc: 0.844515931372549, lr: 0.037900987631550954
[batch_idx--100] train_loss: 0.001388383908243389, acc: 0.842551051980198, lr: 0.03785123047400412
[batch_idx--150] train_loss: 0.001387434065594825, acc: 0.8427669701986755, lr: 0.03780140402994997
[batch_idx--200] train_loss: 0.0013874531289173374, acc: 0.8423507462686567, lr: 0.03775150856802428
[batch_idx--250] train_loss: 0.0013917427235449929, acc: 0.8415245268924303, lr: 0.03770154435723495
[batch_idx--300] train_loss: 0.0013936764535113575, acc: 0.841452969269103, lr: 0.037651511666960506
[batch_idx--350] train_loss: 0.0013946756296671736, acc: 0.8417913105413105, lr: 0.03760141076694869
[batch_idx--400] train_loss: 0.0013965511226566726, acc: 0.8412464931421446, lr: 0.037551241927314974
[batch_idx--450] train_loss: 0.0013989114637102916, acc: 0.8413580032630957, lr: 0.03750100541854115
total time of one epoch: 231.76733684539795 s
train_loss:  0.0013989114637102916  acc:  0.8413580032630957
->>lr:0.037501
test_loss:  0.0013805727373504923  test_acc:  0.8437771435661993
best acc:  85.39521032386152

------Epoch: 50------
[batch_idx--0] train_loss: 0.0012965478235855699, acc: 0.85546875, lr: 0.037500000000000006
[batch_idx--50] train_loss: 0.0014295357133389688, acc: 0.8378523284313726, lr: 0.037449694747731944
[batch_idx--100] train_loss: 0.0013986222220049931, acc: 0.8406946163366337, lr: 0.03739932237380827
[batch_idx--150] train_loss: 0.0013954719784515387, acc: 0.8412924254966887, lr: 0.03734888314980809
[batch_idx--200] train_loss: 0.0014003685244650982, acc: 0.8410875310945274, lr: 0.037298377347670955
[batch_idx--250] train_loss: 0.0013976298677048598, acc: 0.8414155876494024, lr: 0.03724780523969534
[batch_idx--300] train_loss: 0.00139996151291329, acc: 0.8405056063122923, lr: 0.03719716709853723
[batch_idx--350] train_loss: 0.0013990032996058974, acc: 0.8400218126780626, lr: 0.037146463197208594
[batch_idx--400] train_loss: 0.0013976739278235043, acc: 0.840428226309227, lr: 0.03709569380907597
[batch_idx--450] train_loss: 0.0013953110859246504, acc: 0.8413232894782519, lr: 0.03704485920785895
total time of one epoch: 234.63131141662598 s
train_loss:  0.0013953110859246504  acc:  0.8413232894782519
->>lr:0.037045
test_loss:  0.001351387895119517  test_acc:  0.8507258965132151
best acc:  85.39521032386152

------Epoch: 51------
[batch_idx--0] train_loss: 0.0012212136061862111, acc: 0.86328125, lr: 0.037043841852542884
[batch_idx--50] train_loss: 0.0013692104189163621, acc: 0.8428308823529411, lr: 0.03699294101633032
[batch_idx--100] train_loss: 0.0013783018134700337, acc: 0.8427831064356436, lr: 0.036941975521017835
[batch_idx--150] train_loss: 0.0013790740600682252, acc: 0.8433619619205298, lr: 0.0368909456413823
[batch_idx--200] train_loss: 0.0013775102549756122, acc: 0.8429143345771144, lr: 0.03683985165254776
[batch_idx--250] train_loss: 0.001376893380619734, acc: 0.8431586155378487, lr: 0.03678869382998386
[batch_idx--300] train_loss: 0.0013745219784748563, acc: 0.8431530315614618, lr: 0.03673747244950439
[batch_idx--350] train_loss: 0.0013802372144025743, acc: 0.8429153311965812, lr: 0.03668618778726586
[batch_idx--400] train_loss: 0.001381727221754015, acc: 0.8423375155860349, lr: 0.0366348401197659
[batch_idx--450] train_loss: 0.0013850437611787369, acc: 0.84200888672892, lr: 0.036583429723841876
total time of one epoch: 236.6918351650238 s
train_loss:  0.0013850437611787369  acc:  0.84200888672892
->>lr:0.036583
test_loss:  0.0013647901463085552  test_acc:  0.8477478595359226
best acc:  85.39521032386152

------Epoch: 52------
[batch_idx--0] train_loss: 0.001455327495932579, acc: 0.8125, lr: 0.036582400877996545
[batch_idx--50] train_loss: 0.0014247573505831407, acc: 0.8343290441176471, lr: 0.03653092678462853
[batch_idx--100] train_loss: 0.0013886848856501355, acc: 0.8404625618811881, lr: 0.036479390523077894
[batch_idx--150] train_loss: 0.0013810459552147727, acc: 0.8410596026490066, lr: 0.036427792371198774
[batch_idx--200] train_loss: 0.0013783602455204622, acc: 0.8422730099502488, lr: 0.036376132607179
[batch_idx--250] train_loss: 0.0013734122035112158, acc: 0.8433453685258964, lr: 0.03632441150953856
[batch_idx--300] train_loss: 0.0013735126707845203, acc: 0.84375, lr: 0.036272629357128106
[batch_idx--350] train_loss: 0.0013744175312058878, acc: 0.8438724180911681, lr: 0.0362207864291275
[batch_idx--400] train_loss: 0.0013789567031532973, acc: 0.8434772443890274, lr: 0.03616888300504424
[batch_idx--450] train_loss: 0.0013796187730090756, acc: 0.8437792897559621, lr: 0.03611691936471199
total time of one epoch: 233.77853536605835 s
train_loss:  0.0013796187730090756  acc:  0.8437792897559621
->>lr:0.036117
test_loss:  0.0013865687545675071  test_acc:  0.8443975679364686
best acc:  85.39521032386152

------Epoch: 53------
[batch_idx--0] train_loss: 0.001439378596842289, acc: 0.859375, lr: 0.036115879479623185
[batch_idx--50] train_loss: 0.0014005880620257527, acc: 0.8431372549019608, lr: 0.0360638547073383
[batch_idx--100] train_loss: 0.0013942926416708396, acc: 0.843440594059406, lr: 0.036011770285057136
[batch_idx--150] train_loss: 0.0013862211173955375, acc: 0.8441897764900662, lr: 0.03595962649358918
[batch_idx--200] train_loss: 0.0013837465855399546, acc: 0.8445273631840796, lr: 0.03590742361406404
[batch_idx--250] train_loss: 0.001382733067679423, acc: 0.8444814492031872, lr: 0.03585516192792988
[batch_idx--300] train_loss: 0.001381030962554942, acc: 0.8441393272425249, lr: 0.03580284171695191
[batch_idx--350] train_loss: 0.0013797407521417848, acc: 0.8443843482905983, lr: 0.03575046326321087
[batch_idx--400] train_loss: 0.0013776558487353257, acc: 0.844422147755611, lr: 0.035698026849101526
[batch_idx--450] train_loss: 0.0013806749876641216, acc: 0.8445169576838962, lr: 0.03564553275733112
total time of one epoch: 233.30475115776062 s
train_loss:  0.0013806749876641216  acc:  0.8445169576838962
->>lr:0.035646
test_loss:  0.0014077761707537847  test_acc:  0.8477478595359226
best acc:  85.39521032386152

------Epoch: 54------
[batch_idx--0] train_loss: 0.0013909321278333664, acc: 0.8515625, lr: 0.03564448228912682
[batch_idx--50] train_loss: 0.0014527276062461384, acc: 0.8350183823529411, lr: 0.035591929657709624
[batch_idx--100] train_loss: 0.0014188285515929508, acc: 0.8391862623762376, lr: 0.03553931992064693
[batch_idx--150] train_loss: 0.0014053536471078135, acc: 0.8403870033112583, lr: 0.035486653361580446
[batch_idx--200] train_loss: 0.0013950930014067324, acc: 0.841748289800995, lr: 0.03543393026445823
[batch_idx--250] train_loss: 0.001388602455024166, acc: 0.8423182270916335, lr: 0.03538115091353316
[batch_idx--300] train_loss: 0.0013914397117864353, acc: 0.8424003322259136, lr: 0.035328315593361394
[batch_idx--350] train_loss: 0.0013844368371056482, acc: 0.8430154914529915, lr: 0.03527542458880086
[batch_idx--400] train_loss: 0.0013801381415792014, acc: 0.8434967269326683, lr: 0.035222478185009704
[batch_idx--450] train_loss: 0.0013822559883487169, acc: 0.8433540458916235, lr: 0.035169476667444736
total time of one epoch: 231.6632785797119 s
train_loss:  0.0013822559883487169  acc:  0.8433540458916235
->>lr:0.035169
test_loss:  0.0015037729716771352  test_acc:  0.8317409107829755
best acc:  85.39521032386152

------Epoch: 55------
[batch_idx--0] train_loss: 0.0016335166292265058, acc: 0.796875, lr: 0.035168416076895005
[batch_idx--50] train_loss: 0.001362200703143197, acc: 0.8460477941176471, lr: 0.03511535863766653
[batch_idx--100] train_loss: 0.0013774011127355664, acc: 0.8430538366336634, lr: 0.03506224666219176
[batch_idx--150] train_loss: 0.0013723233660732376, acc: 0.8441639072847682, lr: 0.03500908043682018
[batch_idx--200] train_loss: 0.0013638501732021718, acc: 0.8460820895522388, lr: 0.034955860248193804
[batch_idx--250] train_loss: 0.001363417394347934, acc: 0.8460844123505976, lr: 0.034902586383245504
[batch_idx--300] train_loss: 0.0013567001529446374, acc: 0.8472409676079734, lr: 0.03484925912919761
[batch_idx--350] train_loss: 0.001352714580627015, acc: 0.8478676994301995, lr: 0.03479587877356025
[batch_idx--400] train_loss: 0.0013561672403330815, acc: 0.8475003896508728, lr: 0.034742445604129875
[batch_idx--450] train_loss: 0.0013587863788463376, acc: 0.8470510639775055, lr: 0.034688959908987675
total time of one epoch: 236.2230942249298 s
train_loss:  0.0013587863788463376  acc:  0.8470510639775055
->>lr:0.034689
test_loss:  0.001416061619461463  test_acc:  0.8374488149894528
best acc:  85.39521032386152

------Epoch: 56------
[batch_idx--0] train_loss: 0.0014650480588898063, acc: 0.828125, lr: 0.034687889661302575
[batch_idx--50] train_loss: 0.0013522920130258974, acc: 0.8448223039215687, lr: 0.034634350687009215
[batch_idx--100] train_loss: 0.001366508970184639, acc: 0.8439433787128713, lr: 0.034580759769790186
[batch_idx--150] train_loss: 0.0013716308799393425, acc: 0.843827607615894, lr: 0.034527117198577144
[batch_idx--200] train_loss: 0.0013685750981227527, acc: 0.8446634017412935, lr: 0.034473423262580266
[batch_idx--250] train_loss: 0.0013653856546310078, acc: 0.8450883964143426, lr: 0.03441967825128663
[batch_idx--300] train_loss: 0.0013662609573379407, acc: 0.8447233181063123, lr: 0.0343658824544587
[batch_idx--350] train_loss: 0.0013605372063507806, acc: 0.8453970797720798, lr: 0.034312036162132735
[batch_idx--400] train_loss: 0.0013580014188878443, acc: 0.8455716178304239, lr: 0.034258139664617236
[batch_idx--450] train_loss: 0.0013574668010259347, acc: 0.8460443642170306, lr: 0.0342041932524914
total time of one epoch: 235.25583672523499 s
train_loss:  0.0013574668010259347  acc:  0.8460443642170306
->>lr:0.034204
test_loss:  0.0013184546462831877  test_acc:  0.8545725276088845
best acc:  85.39521032386152
Saving..

------Epoch: 57------
[batch_idx--0] train_loss: 0.0011705541983246803, acc: 0.87890625, lr: 0.03420311381711696
[batch_idx--50] train_loss: 0.0013323341149325465, acc: 0.8498008578431373, lr: 0.03414911679172232
[batch_idx--100] train_loss: 0.0013248933845725242, acc: 0.8519492574257426, lr: 0.034095070439506506
[batch_idx--150] train_loss: 0.0013386879450894447, acc: 0.8499844784768212, lr: 0.03404097505185664
[batch_idx--200] train_loss: 0.0013410586282258752, acc: 0.8493081467661692, lr: 0.0339868309204242
[batch_idx--250] train_loss: 0.0013459763597266608, acc: 0.8482009462151394, lr: 0.03393263833712346
[batch_idx--300] train_loss: 0.001341456941103074, acc: 0.8483829941860465, lr: 0.03387839759412996
[batch_idx--350] train_loss: 0.0013443816392191624, acc: 0.8480902777777778, lr: 0.03382410898387883
[batch_idx--400] train_loss: 0.0013461957271663737, acc: 0.848133572319202, lr: 0.033769772799063326
[batch_idx--450] train_loss: 0.0013513057734984735, acc: 0.8479709792758704, lr: 0.03371538933263315
total time of one epoch: 234.00377082824707 s
train_loss:  0.0013513057734984735  acc:  0.8479709792758704
->>lr:0.033715
test_loss:  0.001341648286115829  test_acc:  0.8523389998759151
best acc:  85.45725276088845

------Epoch: 58------
[batch_idx--0] train_loss: 0.0011858167126774788, acc: 0.86328125, lr: 0.03371430118304538
[batch_idx--50] train_loss: 0.0013769754190363136, acc: 0.8423713235294118, lr: 0.03365986979142943
[batch_idx--100] train_loss: 0.0013809459327747769, acc: 0.8428217821782178, lr: 0.03360539171073317
[batch_idx--150] train_loss: 0.0013729785769462388, acc: 0.8447330298013245, lr: 0.03355086723467137
[batch_idx--200] train_loss: 0.0013672428788265112, acc: 0.8453047263681592, lr: 0.03349629665720888
[batch_idx--250] train_loss: 0.001360660514412114, acc: 0.8468158615537849, lr: 0.03344168027255918
[batch_idx--300] train_loss: 0.0013565831837798175, acc: 0.8469035506644518, lr: 0.033387018375182646
[batch_idx--350] train_loss: 0.0013569785866414082, acc: 0.8467214209401709, lr: 0.03333231125978507
[batch_idx--400] train_loss: 0.001354761522418896, acc: 0.8469353958852868, lr: 0.03327755922131603
[batch_idx--450] train_loss: 0.0013568274544635832, acc: 0.8472333113479362, lr: 0.033222762554967304
total time of one epoch: 235.36232233047485 s
train_loss:  0.0013568274544635832  acc:  0.8472333113479362
->>lr:0.033223
test_loss:  0.0013428112571241542  test_acc:  0.8501054721429457
best acc:  85.45725276088845

------Epoch: 59------
[batch_idx--0] train_loss: 0.0011380987707525492, acc: 0.86328125, lr: 0.03322166616846458
[batch_idx--50] train_loss: 0.0013313582509427385, acc: 0.8491115196078431, lr: 0.033166824286034645
[batch_idx--100] train_loss: 0.0013385830714487204, acc: 0.8498220915841584, lr: 0.03311193837274467
[batch_idx--150] train_loss: 0.0013420988076261633, acc: 0.8494929635761589, lr: 0.03305700872450816
[batch_idx--200] train_loss: 0.0013512202639327344, acc: 0.847772854477612, lr: 0.03300203563747449
[batch_idx--250] train_loss: 0.0013527824799437448, acc: 0.8481698207171314, lr: 0.0329470194080272
[batch_idx--300] train_loss: 0.001349676875366622, acc: 0.8482142857142857, lr: 0.032891960332782424
[batch_idx--350] train_loss: 0.0013526242828007225, acc: 0.8473668981481481, lr: 0.03283685870858731
[batch_idx--400] train_loss: 0.001351424365158093, acc: 0.847568578553616, lr: 0.03278171483251839
[batch_idx--450] train_loss: 0.0013537262539392327, acc: 0.8473634880411012, lr: 0.03272652900188
total time of one epoch: 235.64508032798767 s
train_loss:  0.0013537262539392327  acc:  0.8473634880411012
->>lr:0.032727
test_loss:  0.0013138564315767025  test_acc:  0.8573023948380692
best acc:  85.45725276088845
Saving..

------Epoch: 60------
[batch_idx--0] train_loss: 0.0013478539185598493, acc: 0.83984375, lr: 0.032725424859373686
[batch_idx--50] train_loss: 0.0013187386588576961, acc: 0.8528645833333334, lr: 0.032670196541591943
[batch_idx--100] train_loss: 0.0013323476962228812, acc: 0.8506729579207921, lr: 0.03261492687048379
[batch_idx--150] train_loss: 0.0013375953024882354, acc: 0.8494412251655629, lr: 0.03255961614403176
[batch_idx--200] train_loss: 0.0013318095386343363, acc: 0.8503381529850746, lr: 0.03250426466043975
[batch_idx--250] train_loss: 0.0013305568646461484, acc: 0.8505509213147411, lr: 0.03244887271813142
[batch_idx--300] train_loss: 0.0013350501600065056, acc: 0.8499013704318937, lr: 0.032393440615748524
[batch_idx--350] train_loss: 0.001332724786315782, acc: 0.8501379985754985, lr: 0.03233796865214936
[batch_idx--400] train_loss: 0.0013328723849245624, acc: 0.8500136377805486, lr: 0.03228245712640712
[batch_idx--450] train_loss: 0.0013353402805592386, acc: 0.8503575519838928, lr: 0.0322269063378083
total time of one epoch: 233.7009620666504 s
train_loss:  0.0013353402805592386  acc:  0.8503575519838928
->>lr:0.032227
test_loss:  0.0013522368933548332  test_acc:  0.8525871696240228
best acc:  85.73023948380693

------Epoch: 61------
[batch_idx--0] train_loss: 0.0010240814881399274, acc: 0.8984375, lr: 0.03222579492361179
[batch_idx--50] train_loss: 0.0013663838183799503, acc: 0.8442095588235294, lr: 0.032170204395443734
[batch_idx--100] train_loss: 0.0013416544591897343, acc: 0.8481977103960396, lr: 0.03211457520962184
[batch_idx--150] train_loss: 0.0013420264551181667, acc: 0.8492084023178808, lr: 0.032058907666066935
[batch_idx--200] train_loss: 0.0013348205311603807, acc: 0.8500077736318408, lr: 0.03200320206490668
[batch_idx--250] train_loss: 0.0013334858198780046, acc: 0.8500996015936255, lr: 0.03194745870647391
[batch_idx--300] train_loss: 0.0013298909848964344, acc: 0.8501219892026578, lr: 0.03189167789130505
[batch_idx--350] train_loss: 0.0013279748319029979, acc: 0.8504718660968661, lr: 0.031835859920138446
[batch_idx--400] train_loss: 0.0013234739338728295, acc: 0.8505883728179551, lr: 0.03178000509391275
[batch_idx--450] train_loss: 0.0013331950161393085, acc: 0.8499149512271323, lr: 0.03172411371376536
total time of one epoch: 234.6656837463379 s
train_loss:  0.0013331950161393085  acc:  0.8499149512271323
->>lr:0.031724
test_loss:  0.0013937069673309818  test_acc:  0.848244199032138
best acc:  85.73023948380693

------Epoch: 62------
[batch_idx--0] train_loss: 0.0013238382525742054, acc: 0.83984375, lr: 0.031722995515381644
[batch_idx--50] train_loss: 0.0013345095201158057, acc: 0.8468137254901961, lr: 0.03166706716067022
[batch_idx--100] train_loss: 0.0013315465594042498, acc: 0.849009900990099, lr: 0.03161110286093404
[batch_idx--150] train_loss: 0.0013290286597653928, acc: 0.8499327400662252, lr: 0.031555102917900694
[batch_idx--200] train_loss: 0.0013242841637994519, acc: 0.8506879664179104, lr: 0.03149906763348994
[batch_idx--250] train_loss: 0.001330582348934089, acc: 0.8504419820717132, lr: 0.0314429973098121
[batch_idx--300] train_loss: 0.0013316813260750022, acc: 0.8495639534883721, lr: 0.031386892249166375
[batch_idx--350] train_loss: 0.001331807913502779, acc: 0.8495704237891738, lr: 0.03133075275403927
[batch_idx--400] train_loss: 0.0013283045905551634, acc: 0.8503448410224439, lr: 0.03127457912710293
[batch_idx--450] train_loss: 0.0013337048195367403, acc: 0.8502360537369389, lr: 0.031218371671213524
total time of one epoch: 233.37897109985352 s
train_loss:  0.0013337048195367403  acc:  0.8502360537369389
->>lr:0.031218
test_loss:  0.0013220831150895593  test_acc:  0.8573023948380692
best acc:  85.73023948380693

------Epoch: 63------
[batch_idx--0] train_loss: 0.0013247865717858076, acc: 0.84375, lr: 0.031217247179121367
[batch_idx--50] train_loss: 0.0013219756987311092, acc: 0.8492647058823529, lr: 0.0311610055298914
[batch_idx--100] train_loss: 0.001314939591010092, acc: 0.850518254950495, lr: 0.031104730664032437
[batch_idx--150] train_loss: 0.0013180017642467129, acc: 0.8510709850993378, lr: 0.031048422884946483
[batch_idx--200] train_loss: 0.001314078983549603, acc: 0.851679104477612, lr: 0.030992082496212964
[batch_idx--250] train_loss: 0.0013147595039832284, acc: 0.8518270667330677, lr: 0.030935709801587143
[batch_idx--300] train_loss: 0.0013227752348767018, acc: 0.8511472176079734, lr: 0.03087930510499845
[batch_idx--350] train_loss: 0.0013205367070821743, acc: 0.8514623397435898, lr: 0.030822868710548842
[batch_idx--400] train_loss: 0.00132010571113985, acc: 0.8517378428927681, lr: 0.030766400922511174
[batch_idx--450] train_loss: 0.0013256141257748724, acc: 0.8517113895928073, lr: 0.030709902045327583
total time of one epoch: 234.44386649131775 s
train_loss:  0.0013256141257748724  acc:  0.8517113895928073
->>lr:0.030710
test_loss:  0.0013231642230862586  test_acc:  0.8586673284526616
best acc:  85.73023948380693
Saving..

------Epoch: 64------
[batch_idx--0] train_loss: 0.0013163279509171844, acc: 0.8515625, lr: 0.030708771752766397
[batch_idx--50] train_loss: 0.0013265255656020314, acc: 0.8524050245098039, lr: 0.030652241478464032
[batch_idx--100] train_loss: 0.0013239109372295956, acc: 0.852761448019802, lr: 0.03059568073049836
[batch_idx--150] train_loss: 0.0013193156900168058, acc: 0.8530887831125827, lr: 0.030539089813812693
[batch_idx--200] train_loss: 0.0013169054577905517, acc: 0.8526313743781094, lr: 0.03048246903351297
[batch_idx--250] train_loss: 0.0013247164892982617, acc: 0.8514379980079682, lr: 0.030425818694866172
[batch_idx--300] train_loss: 0.0013283408947746915, acc: 0.8509136212624585, lr: 0.030369139103298623
[batch_idx--350] train_loss: 0.00132653672457739, acc: 0.8509837962962963, lr: 0.030312430564394355
[batch_idx--400] train_loss: 0.0013261959441540358, acc: 0.8513092269326683, lr: 0.03025569338389348
[batch_idx--450] train_loss: 0.0013281801352688955, acc: 0.8514163224216337, lr: 0.03019892786769053
total time of one epoch: 232.12982988357544 s
train_loss:  0.0013281801352688955  acc:  0.8514163224216337
->>lr:0.030199
test_loss:  0.001314750464268159  test_acc:  0.8561856309715845
best acc:  85.86673284526616

------Epoch: 65------
[batch_idx--0] train_loss: 0.0014694274868816137, acc: 0.8359375, lr: 0.03019779227044398
[batch_idx--50] train_loss: 0.0013548860842289001, acc: 0.8484987745098039, lr: 0.03014099816711588
[batch_idx--100] train_loss: 0.0013419606902701135, acc: 0.8493966584158416, lr: 0.030084176346456905
[batch_idx--150] train_loss: 0.001336038887457589, acc: 0.8510192466887417, lr: 0.030027327114817932
[batch_idx--200] train_loss: 0.0013308112894124652, acc: 0.8511738184079602, lr: 0.029970450778697578
[batch_idx--250] train_loss: 0.0013270645121305409, acc: 0.8512201195219123, lr: 0.02991354764474065
[batch_idx--300] train_loss: 0.0013276569798984796, acc: 0.8508876661129569, lr: 0.02985661801973638
[batch_idx--350] train_loss: 0.0013259141331145863, acc: 0.8513176638176638, lr: 0.02979966221061685
[batch_idx--400] train_loss: 0.0013275351807907074, acc: 0.8510462125935162, lr: 0.029742680524455323
[batch_idx--450] train_loss: 0.00132687014386047, acc: 0.8513468948519457, lr: 0.02968567326846454
total time of one epoch: 235.05481910705566 s
train_loss:  0.00132687014386047  acc:  0.8513468948519457
->>lr:0.029686
test_loss:  0.0013133009690211243  test_acc:  0.8602804318153617
best acc:  85.86673284526616
Saving..

------Epoch: 66------
[batch_idx--0] train_loss: 0.0011644808109849691, acc: 0.8671875, lr: 0.02968453286464312
[batch_idx--50] train_loss: 0.0013371278011404416, acc: 0.8510263480392157, lr: 0.029627499844060053
[batch_idx--100] train_loss: 0.0013261463695971093, acc: 0.8528387995049505, lr: 0.029570441874636297
[batch_idx--150] train_loss: 0.001315083036304063, acc: 0.8526748758278145, lr: 0.029513359263995894
[batch_idx--200] train_loss: 0.0013208513064726965, acc: 0.8520483519900498, lr: 0.029456252319895716
[batch_idx--250] train_loss: 0.001321924843851373, acc: 0.8519826942231076, lr: 0.029399121350223874
[batch_idx--300] train_loss: 0.0013194820987512403, acc: 0.8516144102990033, lr: 0.029341966662997956
[batch_idx--350] train_loss: 0.0013210937878955422, acc: 0.8511284722222222, lr: 0.02928478856636346
[batch_idx--400] train_loss: 0.0013159244239128235, acc: 0.8521372350374065, lr: 0.02922758736859208
[batch_idx--450] train_loss: 0.0013209430528474573, acc: 0.851919672301871, lr: 0.02917036337808005
total time of one epoch: 234.17881083488464 s
train_loss:  0.0013209430528474573  acc:  0.851919672301871
->>lr:0.029170
test_loss:  0.0012595983508029932  test_acc:  0.863382553666708
best acc:  86.02804318153618
Saving..

------Epoch: 67------
[batch_idx--0] train_loss: 0.0013424570206552744, acc: 0.83984375, lr: 0.02916921866790256
[batch_idx--50] train_loss: 0.0013266837968509278, acc: 0.8487285539215687, lr: 0.029111971746632322
[batch_idx--100] train_loss: 0.0013252393985720406, acc: 0.8488165222772277, lr: 0.02905470265595496
[batch_idx--150] train_loss: 0.0013114336881145145, acc: 0.851510761589404, lr: 0.028997411704632756
[batch_idx--200] train_loss: 0.0013027898353334534, acc: 0.8533698694029851, lr: 0.02894009920154584
[batch_idx--250] train_loss: 0.0013032788304107419, acc: 0.8533210906374502, lr: 0.02888276545569057
[batch_idx--300] train_loss: 0.0013038715103214167, acc: 0.8532625622923588, lr: 0.0288254107761778
[batch_idx--350] train_loss: 0.001304680772757216, acc: 0.85372150997151, lr: 0.028768035472231265
[batch_idx--400] train_loss: 0.001308723738674827, acc: 0.8531113622194514, lr: 0.0287106398531859
[batch_idx--450] train_loss: 0.0013093188853514962, acc: 0.8535078279584823, lr: 0.02865322422848614
total time of one epoch: 233.82400465011597 s
train_loss:  0.0013093188853514962  acc:  0.8535078279584823
->>lr:0.028653
test_loss:  0.0013341816820094242  test_acc:  0.8561856309715845
best acc:  86.33825536667081

------Epoch: 68------
[batch_idx--0] train_loss: 0.0013098085764795542, acc: 0.859375, lr: 0.028652075714060296
[batch_idx--50] train_loss: 0.0012998785161614126, acc: 0.8520986519607843, lr: 0.028594640002494582
[batch_idx--100] train_loss: 0.0012992199355883912, acc: 0.8528774752475248, lr: 0.028537184910679542
[batch_idx--150] train_loss: 0.001304544938654201, acc: 0.8532439983443708, lr: 0.028479710748380266
[batch_idx--200] train_loss: 0.0012994152664633199, acc: 0.8539723258706468, lr: 0.028422217825464665
[batch_idx--250] train_loss: 0.0013011283235646696, acc: 0.8538502241035857, lr: 0.028364706451901797
[batch_idx--300] train_loss: 0.0013046234465541435, acc: 0.8532495847176079, lr: 0.028307176937760206
[batch_idx--350] train_loss: 0.0013017292111910392, acc: 0.8538995726495726, lr: 0.028249629593206222
[batch_idx--400] train_loss: 0.0012999221123987227, acc: 0.8543679862842892, lr: 0.02819206472850232
[batch_idx--450] train_loss: 0.001302733604327482, acc: 0.8544017079182143, lr: 0.02813448265400542
total time of one epoch: 234.61134910583496 s
train_loss:  0.001302733604327482  acc:  0.8544017079182143
->>lr:0.028134
test_loss:  0.001279040510977804  test_acc:  0.8631343839186003
best acc:  86.33825536667081

------Epoch: 69------
[batch_idx--0] train_loss: 0.0015471501974388957, acc: 0.8125, lr: 0.028133330839107608
[batch_idx--50] train_loss: 0.0013250494763876002, acc: 0.8536305147058824, lr: 0.028075731530447786
[batch_idx--100] train_loss: 0.0013073794382375361, acc: 0.8551206683168316, lr: 0.028018115639197247
[batch_idx--150] train_loss: 0.0013106641789824263, acc: 0.8536579056291391, lr: 0.027960483475988025
[batch_idx--200] train_loss: 0.0013063797670467502, acc: 0.853525342039801, lr: 0.02790283535153988
[batch_idx--250] train_loss: 0.0013042211141140456, acc: 0.8536790338645418, lr: 0.027845171576658636
[batch_idx--300] train_loss: 0.001300923598224786, acc: 0.854015261627907, lr: 0.027787492462234484
[batch_idx--350] train_loss: 0.0012984283724826286, acc: 0.8546897257834758, lr: 0.02772979831924033
[batch_idx--400] train_loss: 0.0013011999454690688, acc: 0.8543485037406484, lr: 0.02767208945873009
[batch_idx--450] train_loss: 0.0013080194348580397, acc: 0.8545318846113792, lr: 0.027614366191837037
total time of one epoch: 230.57154655456543 s
train_loss:  0.0013080194348580397  acc:  0.8545318846113792
->>lr:0.027614
test_loss:  0.001271782589692427  test_acc:  0.8604045166894155
best acc:  86.33825536667081

------Epoch: 70------
[batch_idx--0] train_loss: 0.0010159523226320744, acc: 0.88671875, lr: 0.02761321158169134
[batch_idx--50] train_loss: 0.0013026915257796645, acc: 0.8530177696078431, lr: 0.027555473940897853
[batch_idx--100] train_loss: 0.0013101553373813335, acc: 0.8525680693069307, lr: 0.027497722522445946
[batch_idx--150] train_loss: 0.0013107831924475284, acc: 0.8534509519867549, lr: 0.027439957637698322
[batch_idx--200] train_loss: 0.0013010330815030383, acc: 0.8543221393034826, lr: 0.027382179598090313
[batch_idx--250] train_loss: 0.0013002326739376849, acc: 0.8549084910358565, lr: 0.027324388715128153
[batch_idx--300] train_loss: 0.0012989968836517923, acc: 0.8551053779069767, lr: 0.027266585300387343
[batch_idx--350] train_loss: 0.0013033748173852718, acc: 0.8545116631054132, lr: 0.027208769665510946
[batch_idx--400] train_loss: 0.0012971481431433536, acc: 0.8554005610972568, lr: 0.027150942122207884
[batch_idx--450] train_loss: 0.001301329569351124, acc: 0.8551220189537265, lr: 0.027093102982251305
total time of one epoch: 229.34745693206787 s
train_loss:  0.001301329569351124  acc:  0.8551220189537265
->>lr:0.027093
test_loss:  0.0012789126816096473  test_acc:  0.860032262067254
best acc:  86.33825536667081

------Epoch: 71------
[batch_idx--0] train_loss: 0.0013551674783229828, acc: 0.81640625, lr: 0.02709194608330789
[batch_idx--50] train_loss: 0.0013330099606594327, acc: 0.8472732843137255, lr: 0.027034095436018247
[batch_idx--100] train_loss: 0.001302555578617877, acc: 0.8535736386138614, lr: 0.026976233822045795
[batch_idx--150] train_loss: 0.001309719401186591, acc: 0.8527524834437086, lr: 0.026918361553347366
[batch_idx--200] train_loss: 0.0013058983905597668, acc: 0.8524370335820896, lr: 0.026860478941937244
[batch_idx--250] train_loss: 0.0012978284916120666, acc: 0.8537257221115537, lr: 0.026802586299885446
[batch_idx--300] train_loss: 0.001291155860955793, acc: 0.854858803986711, lr: 0.026744683939316106
[batch_idx--350] train_loss: 0.0012955179209475992, acc: 0.8538884437321937, lr: 0.026686772172405743
[batch_idx--400] train_loss: 0.0012970076461074097, acc: 0.8538127337905237, lr: 0.02662885131138157
[batch_idx--450] train_loss: 0.0013009095950178293, acc: 0.8539591071614538, lr: 0.026570921668519862
total time of one epoch: 232.44110751152039 s
train_loss:  0.0013009095950178293  acc:  0.8539591071614538
->>lr:0.026571
test_loss:  0.0012544358667124441  test_acc:  0.8607767713115771
best acc:  86.33825536667081

------Epoch: 72------
[batch_idx--0] train_loss: 0.0011856612982228398, acc: 0.8828125, lr: 0.026569762988232833
[batch_idx--50] train_loss: 0.0012900075423257315, acc: 0.8576899509803921, lr: 0.026511824709652916
[batch_idx--100] train_loss: 0.0013024983973712614, acc: 0.8536896658415841, lr: 0.02645387828017616
[batch_idx--150] train_loss: 0.0013035339764350198, acc: 0.8534768211920529, lr: 0.026395924012216673
[batch_idx--200] train_loss: 0.0012857716875753148, acc: 0.855488184079602, lr: 0.02633796221823084
[batch_idx--250] train_loss: 0.0012915977791686398, acc: 0.8551108067729084, lr: 0.026279993210715575
[batch_idx--300] train_loss: 0.0012922615058057975, acc: 0.8553000415282392, lr: 0.026222017302206753
[batch_idx--350] train_loss: 0.0012896831729117665, acc: 0.8561142272079773, lr: 0.02616403480527739
[batch_idx--400] train_loss: 0.001291320138980177, acc: 0.85612141521197, lr: 0.02610604603253605
[batch_idx--450] train_loss: 0.0012938535752575198, acc: 0.8561460756066234, lr: 0.026048051296625147
total time of one epoch: 234.160138130188 s
train_loss:  0.0012938535752575198  acc:  0.8561460756066234
->>lr:0.026048
test_loss:  0.001255397894850202  test_acc:  0.8659883360218389
best acc:  86.33825536667081
Saving..

------Epoch: 73------
[batch_idx--0] train_loss: 0.001318840542808175, acc: 0.85546875, lr: 0.02604689134322999
[batch_idx--50] train_loss: 0.0012672294020269286, acc: 0.8592984068627451, lr: 0.025988890847003655
[batch_idx--100] train_loss: 0.0012750571707752303, acc: 0.8576732673267327, lr: 0.025930885019241706
[batch_idx--150] train_loss: 0.0012757249561212464, acc: 0.8572795943708609, lr: 0.025872874172678507
[batch_idx--200] train_loss: 0.001282301349437967, acc: 0.8564793221393034, lr: 0.02581485862007545
[batch_idx--250] train_loss: 0.001284328166189496, acc: 0.8561223854581673, lr: 0.02575683867421932
[batch_idx--300] train_loss: 0.001282042407769512, acc: 0.8566626868770764, lr: 0.02569881464792059
[batch_idx--350] train_loss: 0.0012802478608256074, acc: 0.8567819622507122, lr: 0.02564078685401172
[batch_idx--400] train_loss: 0.0012810392790947788, acc: 0.8568714931421446, lr: 0.025582755605345495
[batch_idx--450] train_loss: 0.0012907843068089477, acc: 0.8565886763633839, lr: 0.02552472121479332
total time of one epoch: 229.0747504234314 s
train_loss:  0.0012907843068089477  acc:  0.8565886763633839
->>lr:0.025525
test_loss:  0.0013115659128689178  test_acc:  0.8564338007196922
best acc:  86.59883360218389

------Epoch: 74------
[batch_idx--0] train_loss: 0.0011532186763361096, acc: 0.86328125, lr: 0.025523560497083927
[batch_idx--50] train_loss: 0.001321112234875852, acc: 0.8529411764705882, lr: 0.025465523224145754
[batch_idx--100] train_loss: 0.0013002663203007957, acc: 0.8545018564356436, lr: 0.02540748344137178
[batch_idx--150] train_loss: 0.0013025147541247258, acc: 0.8534768211920529, lr: 0.02534944146167944
[batch_idx--200] train_loss: 0.0013000597807796515, acc: 0.8547108208955224, lr: 0.025291397597997967
[batch_idx--250] train_loss: 0.0012976515182921017, acc: 0.8546906125498008, lr: 0.025233352163266793
[batch_idx--300] train_loss: 0.0012923265340122273, acc: 0.8551053779069767, lr: 0.025175305470433812
[batch_idx--350] train_loss: 0.0012918317387347505, acc: 0.8549234330484331, lr: 0.025117257832453683
[batch_idx--400] train_loss: 0.0012900128854935677, acc: 0.8550109102244389, lr: 0.025059209562286185
[batch_idx--450] train_loss: 0.0012898868788541302, acc: 0.8551567327385705, lr: 0.02500116097289448
total time of one epoch: 228.7028238773346 s
train_loss:  0.0012898868788541302  acc:  0.8551567327385705
->>lr:0.025001
test_loss:  0.0014072877440089874  test_acc:  0.8472515200397072
best acc:  86.59883360218389

------Epoch: 75------
[batch_idx--0] train_loss: 0.001295163994655013, acc: 0.859375, lr: 0.025
[batch_idx--50] train_loss: 0.0012975352104095852, acc: 0.8570006127450981, lr: 0.024941951407416053
[batch_idx--100] train_loss: 0.0012871989839719517, acc: 0.8572478341584159, lr: 0.024883903127797022
[batch_idx--150] train_loss: 0.0012820535832831007, acc: 0.8574089403973509, lr: 0.02482585547410613
[batch_idx--200] train_loss: 0.0012793547250284113, acc: 0.8578008395522388, lr: 0.024767808759303227
[batch_idx--250] train_loss: 0.0012758581962184128, acc: 0.858425672310757, lr: 0.024709763296343102
[batch_idx--300] train_loss: 0.0012783724650279604, acc: 0.8576749377076412, lr: 0.024651719398173802
[batch_idx--350] train_loss: 0.001276729728773162, acc: 0.8577724358974359, lr: 0.024593677377734924
[batch_idx--400] train_loss: 0.0012732163474295855, acc: 0.8584593204488778, lr: 0.02453563754795596
[batch_idx--450] train_loss: 0.0012730202158583188, acc: 0.8587756448085535, lr: 0.024477600221754565
total time of one epoch: 229.88510966300964 s
train_loss:  0.0012730202158583188  acc:  0.8587756448085535
->>lr:0.024478
test_loss:  0.0012668308759537386  test_acc:  0.8632584687926542
best acc:  86.59883360218389

------Epoch: 76------
[batch_idx--0] train_loss: 0.0012262673117220402, acc: 0.875, lr: 0.02447643950291608
[batch_idx--50] train_loss: 0.0012682429480585543, acc: 0.8606770833333334, lr: 0.024418405052717584
[batch_idx--100] train_loss: 0.001275523101777244, acc: 0.8588722153465347, lr: 0.024360373738147447
[batch_idx--150] train_loss: 0.0012708314010620562, acc: 0.859349130794702, lr: 0.024302345872077406
[batch_idx--200] train_loss: 0.0012610599561362753, acc: 0.8604827425373134, lr: 0.024244321767360646
[batch_idx--250] train_loss: 0.001264966756478323, acc: 0.8592038097609562, lr: 0.024186301736830045
[batch_idx--300] train_loss: 0.001259248290656512, acc: 0.8595826411960132, lr: 0.024128286093296536
[batch_idx--350] train_loss: 0.001264168242088113, acc: 0.8587183938746439, lr: 0.02407027514954738
[batch_idx--400] train_loss: 0.001266825190824259, acc: 0.858790523690773, lr: 0.024012269218344526
[batch_idx--450] train_loss: 0.001268789935412847, acc: 0.8586888603464435, lr: 0.023954268612422863
total time of one epoch: 229.16619682312012 s
train_loss:  0.001268789935412847  acc:  0.8586888603464435
->>lr:0.023954
test_loss:  0.001251340766656575  test_acc:  0.866732845266162
best acc:  86.59883360218389
Saving..

------Epoch: 77------
[batch_idx--0] train_loss: 0.0012062188470736146, acc: 0.8515625, lr: 0.02395310865677001
[batch_idx--50] train_loss: 0.0012857950265135836, acc: 0.8510263480392157, lr: 0.023895113804784887
[batch_idx--100] train_loss: 0.001278060456129289, acc: 0.8554300742574258, lr: 0.02383712490971616
[batch_idx--150] train_loss: 0.0012728975860661032, acc: 0.8569174254966887, lr: 0.023779142284206876
[batch_idx--200] train_loss: 0.0012752433754596396, acc: 0.8570817786069652, lr: 0.023721166240866298
[batch_idx--250] train_loss: 0.001274384962639723, acc: 0.8572429033864541, lr: 0.0236631970922682
[batch_idx--300] train_loss: 0.0012750073585139458, acc: 0.8574153862126246, lr: 0.023605235150949158
[batch_idx--350] train_loss: 0.0012749806494237138, acc: 0.8574719551282052, lr: 0.02354728072940694
[batch_idx--400] train_loss: 0.0012736444206481005, acc: 0.8575436408977556, lr: 0.02348933414009873
[batch_idx--450] train_loss: 0.0012769334634564439, acc: 0.8575346270003819, lr: 0.02343139569543949
total time of one epoch: 228.0059003829956 s
train_loss:  0.0012769334634564439  acc:  0.8575346270003819
->>lr:0.023431
test_loss:  0.0012594713423947038  test_acc:  0.8616453654299541
best acc:  86.6732845266162

------Epoch: 78------
[batch_idx--0] train_loss: 0.0011597264092415571, acc: 0.875, lr: 0.023430237011767167
[batch_idx--50] train_loss: 0.0012648709360327498, acc: 0.8612132352941176, lr: 0.02337230719645424
[batch_idx--100] train_loss: 0.0012679411349633691, acc: 0.859065594059406, lr: 0.023314386156732855
[batch_idx--150] train_loss: 0.0012705795519325316, acc: 0.8589352235099338, lr: 0.023256474204880216
[batch_idx--200] train_loss: 0.0012713431685338196, acc: 0.8583644278606966, lr: 0.023198571653124563
[batch_idx--250] train_loss: 0.0012693636024749255, acc: 0.8580054780876494, lr: 0.02314067881364343
[batch_idx--300] train_loss: 0.0012702773544825984, acc: 0.8577138704318937, lr: 0.02308279599856199
[batch_idx--350] train_loss: 0.0012713977722106156, acc: 0.8579393696581197, lr: 0.023024923519951404
[batch_idx--400] train_loss: 0.0012690632264687218, acc: 0.858030704488778, lr: 0.02296706168982706
[batch_idx--450] train_loss: 0.001273560604604235, acc: 0.8581421182351512, lr: 0.022909210820146964
total time of one epoch: 228.04896807670593 s
train_loss:  0.001273560604604235  acc:  0.8581421182351512
->>lr:0.022909
test_loss:  0.0012381118933162555  test_acc:  0.8654919965256235
best acc:  86.6732845266162

------Epoch: 79------
[batch_idx--0] train_loss: 0.0012685904512181878, acc: 0.84765625, lr: 0.022908053916692112
[batch_idx--50] train_loss: 0.001271669380823333, acc: 0.8556985294117647, lr: 0.022850214547982983
[batch_idx--100] train_loss: 0.0012612031014304203, acc: 0.8585628094059405, lr: 0.022792386769691267
[batch_idx--150] train_loss: 0.0012617760672486873, acc: 0.859349130794702, lr: 0.022734570893591363
[batch_idx--200] train_loss: 0.001266076429330035, acc: 0.8587725435323383, lr: 0.022676767231393526
[batch_idx--250] train_loss: 0.0012701799985451764, acc: 0.8582700448207171, lr: 0.02261897609474213
[batch_idx--300] train_loss: 0.0012728649917123623, acc: 0.8576360049833887, lr: 0.022561197795214035
[batch_idx--350] train_loss: 0.0012706191314814182, acc: 0.8577501780626781, lr: 0.022503432644316902
[batch_idx--400] train_loss: 0.0012702595490725371, acc: 0.8576118298004988, lr: 0.022445680953487472
[batch_idx--450] train_loss: 0.0012684021153252455, acc: 0.8586194327767557, lr: 0.022387943034089947
total time of one epoch: 228.94001150131226 s
train_loss:  0.0012684021153252455  acc:  0.8586194327767557
->>lr:0.022388
test_loss:  0.0012204485516317991  test_acc:  0.8690904578731853
best acc:  86.6732845266162
Saving..

------Epoch: 80------
[batch_idx--0] train_loss: 0.0012603300856426358, acc: 0.875, lr: 0.022386788418308663
[batch_idx--50] train_loss: 0.0012348976086679043, acc: 0.8654258578431373, lr: 0.022329064866462054
[batch_idx--100] train_loss: 0.001251397451551834, acc: 0.8617342202970297, lr: 0.022271355714774788
[batch_idx--150] train_loss: 0.0012533860658881385, acc: 0.8609012831125827, lr: 0.022213661274381714
[batch_idx--200] train_loss: 0.0012507536825005763, acc: 0.861201803482587, lr: 0.022155981856338363
[batch_idx--250] train_loss: 0.0012478378610184557, acc: 0.8618650398406374, lr: 0.022098317771619257
[batch_idx--300] train_loss: 0.001251339387385317, acc: 0.8616590531561462, lr: 0.022040669331116272
[batch_idx--350] train_loss: 0.0012476534302083727, acc: 0.8619791666666666, lr: 0.021983036845636923
[batch_idx--400] train_loss: 0.001253277219267576, acc: 0.8612161003740648, lr: 0.02192542062590272
[batch_idx--450] train_loss: 0.0012588163611934986, acc: 0.8611014683930989, lr: 0.02186782098254747
total time of one epoch: 227.13873076438904 s
train_loss:  0.0012588163611934986  acc:  0.8611014683930989
->>lr:0.021868
test_loss:  0.0012252386509151816  test_acc:  0.8652438267775158
best acc:  86.90904578731853

------Epoch: 81------
[batch_idx--0] train_loss: 0.0012307044817134738, acc: 0.875, lr: 0.02186666916089239
[batch_idx--50] train_loss: 0.001268651819212691, acc: 0.8592218137254902, lr: 0.021809086745365924
[batch_idx--100] train_loss: 0.0012697384930169672, acc: 0.8577506188118812, lr: 0.021751521533424346
[batch_idx--150] train_loss: 0.0012661585043067273, acc: 0.8586765314569537, lr: 0.021693973835426473
[batch_idx--200] train_loss: 0.0012603792268087836, acc: 0.8596276430348259, lr: 0.021636443961636685
[batch_idx--250] train_loss: 0.001257084920887364, acc: 0.8598418824701195, lr: 0.021578932222223245
[batch_idx--300] train_loss: 0.0012579894397621262, acc: 0.8595956187707641, lr: 0.021521438927256664
[batch_idx--350] train_loss: 0.0012558448187107395, acc: 0.8602541844729344, lr: 0.021463964386708015
[batch_idx--400] train_loss: 0.001250611884232629, acc: 0.8611771352867831, lr: 0.021406508910447243
[batch_idx--450] train_loss: 0.0012563112093153237, acc: 0.8607716874370812, lr: 0.021349072808241526
total time of one epoch: 227.2722523212433 s
train_loss:  0.0012563112093153237  acc:  0.8607716874370812
->>lr:0.021349
test_loss:  0.0012330874765550902  test_acc:  0.8689663729991314
best acc:  86.90904578731853

------Epoch: 82------
[batch_idx--0] train_loss: 0.0012588136596605182, acc: 0.8515625, lr: 0.021347924285939714
[batch_idx--50] train_loss: 0.001250622367175917, acc: 0.8632046568627451, lr: 0.02129050826428394
[batch_idx--100] train_loss: 0.0012387682823233749, acc: 0.865524443069307, lr: 0.021233112242092567
[batch_idx--150] train_loss: 0.0012528808195365975, acc: 0.8625051738410596, lr: 0.02117573652881221
[batch_idx--200] train_loss: 0.0012480703104908268, acc: 0.8632035136815921, lr: 0.02111838143378
[batch_idx--250] train_loss: 0.0012435125956029827, acc: 0.8635613794820717, lr: 0.021061047266221912
[batch_idx--300] train_loss: 0.0012427888767317283, acc: 0.8634629360465116, lr: 0.021003734335251087
[batch_idx--350] train_loss: 0.0012438048567474313, acc: 0.8631477029914529, lr: 0.020946442949866164
[batch_idx--400] train_loss: 0.0012450112452895433, acc: 0.8625019482543641, lr: 0.020889173418949643
[batch_idx--450] train_loss: 0.0012484242630819281, acc: 0.8623077724164265, lr: 0.020831926051266162
total time of one epoch: 229.2991304397583 s
train_loss:  0.0012484242630819281  acc:  0.8623077724164265
->>lr:0.020832
test_loss:  0.0012267447517148643  test_acc:  0.8685941183769699
best acc:  86.90904578731853

------Epoch: 83------
[batch_idx--0] train_loss: 0.0012881004950031638, acc: 0.828125, lr: 0.020830781332097453
[batch_idx--50] train_loss: 0.0012559387992665755, acc: 0.8574601715686274, lr: 0.020773556888877096
[batch_idx--100] train_loss: 0.001256523374929139, acc: 0.8587948638613861, lr: 0.020716355232228204
[batch_idx--150] train_loss: 0.0012462666383111813, acc: 0.8607978062913907, lr: 0.020659176670549492
[batch_idx--200] train_loss: 0.0012415136145172985, acc: 0.8615127487562189, lr: 0.020602021512115154
[batch_idx--250] train_loss: 0.0012451917991928934, acc: 0.8609001494023905, lr: 0.02054489006507322
[batch_idx--300] train_loss: 0.0012457710889978736, acc: 0.8605429817275747, lr: 0.02048778263744388
[batch_idx--350] train_loss: 0.001249636941492568, acc: 0.8600872507122507, lr: 0.02043069953711782
[batch_idx--400] train_loss: 0.0012473863667978016, acc: 0.8606608478802993, lr: 0.020373641071854572
[batch_idx--450] train_loss: 0.0012528021156903743, acc: 0.8604419064810637, lr: 0.020316607549280843
total time of one epoch: 237.67175722122192 s
train_loss:  0.0012528021156903743  acc:  0.8604419064810637
->>lr:0.020317
test_loss:  0.001238594625114226  test_acc:  0.8688422881250776
best acc:  86.90904578731853

------Epoch: 84------
[batch_idx--0] train_loss: 0.001227010739967227, acc: 0.87109375, lr: 0.020315467135356893
[batch_idx--50] train_loss: 0.0012442117817152072, acc: 0.8636642156862745, lr: 0.02025845937110404
[batch_idx--100] train_loss: 0.0012459525749742026, acc: 0.8630105198019802, lr: 0.020201477170534773
[batch_idx--150] train_loss: 0.0012493686136074167, acc: 0.8618843129139073, lr: 0.020144520840864624
[batch_idx--200] train_loss: 0.0012409869426240523, acc: 0.8623484141791045, lr: 0.02008759068916964
[batch_idx--250] train_loss: 0.0012448098129255185, acc: 0.861398157370518, lr: 0.020030687022384752
[batch_idx--300] train_loss: 0.0012461239041952398, acc: 0.8612307931893688, lr: 0.019973810147302068
[batch_idx--350] train_loss: 0.0012479223025049961, acc: 0.8611556267806267, lr: 0.01991696037056928
[batch_idx--400] train_loss: 0.001245689445391223, acc: 0.8617518703241895, lr: 0.01986013799868798
[batch_idx--450] train_loss: 0.0012509821707452436, acc: 0.8616395320581803, lr: 0.01980334333801198
total time of one epoch: 229.68987131118774 s
train_loss:  0.0012509821707452436  acc:  0.8616395320581803
->>lr:0.019803
test_loss:  0.0012533168503391725  test_acc:  0.8641270629110311
best acc:  86.90904578731853

------Epoch: 85------
[batch_idx--0] train_loss: 0.0011266227811574936, acc: 0.87109375, lr: 0.019802207729556022
[batch_idx--50] train_loss: 0.0012644530735069922, acc: 0.8574601715686274, lr: 0.0197454416497602
[batch_idx--100] train_loss: 0.0012489001757677385, acc: 0.8618502475247525, lr: 0.019688703899547008
[batch_idx--150] train_loss: 0.0012591548151466131, acc: 0.859271523178808, lr: 0.01963199478481404
[batch_idx--200] train_loss: 0.0012509602038606779, acc: 0.8603467039800995, lr: 0.019575314611304503
[batch_idx--250] train_loss: 0.001247949881082126, acc: 0.8601998256972112, lr: 0.019518663684605593
[batch_idx--300] train_loss: 0.0012500424033179383, acc: 0.8604910714285714, lr: 0.01946204231014678
[batch_idx--350] train_loss: 0.001245716995655153, acc: 0.8610665954415955, lr: 0.019405450793198248
[batch_idx--400] train_loss: 0.0012452634628583442, acc: 0.8610310162094763, lr: 0.01934888943886919
[batch_idx--450] train_loss: 0.0012499298619097167, acc: 0.8608237581143472, lr: 0.019292358552106172
total time of one epoch: 227.35853505134583 s
train_loss:  0.0012499298619097167  acc:  0.8608237581143472
->>lr:0.019292
test_loss:  0.001216420330840344  test_acc:  0.8687182032510237
best acc:  86.90904578731853

------Epoch: 86------
[batch_idx--0] train_loss: 0.0012268819846212864, acc: 0.8671875, lr: 0.019291228247233613
[batch_idx--50] train_loss: 0.0012200071656729514, acc: 0.8635110294117647, lr: 0.019234728751373553
[batch_idx--100] train_loss: 0.0012430681825135973, acc: 0.8636680074257426, lr: 0.01917826033856888
[batch_idx--150] train_loss: 0.0012457024746278412, acc: 0.863177773178808, lr: 0.019121823313265066
[batch_idx--200] train_loss: 0.001242408819962293, acc: 0.863300684079602, lr: 0.01906541797973838
[batch_idx--250] train_loss: 0.001242485700455305, acc: 0.8636391932270916, lr: 0.01900904464209422
[batch_idx--300] train_loss: 0.001242256390148978, acc: 0.8630346760797342, lr: 0.018952703604265476
[batch_idx--350] train_loss: 0.0012441963228354619, acc: 0.8621906160968661, lr: 0.018896395170010898
[batch_idx--400] train_loss: 0.0012404250587508584, acc: 0.8629890118453866, lr: 0.01884011964291346
[batch_idx--450] train_loss: 0.0012423734746367225, acc: 0.8630541187905717, lr: 0.018783877326378724
total time of one epoch: 235.86725544929504 s
train_loss:  0.0012423734746367225  acc:  0.8630541187905717
->>lr:0.018784
test_loss:  0.001229455771983476  test_acc:  0.870951730983993
best acc:  86.90904578731853
Saving..

------Epoch: 87------
[batch_idx--0] train_loss: 0.0012941835448145866, acc: 0.86328125, lr: 0.018782752820878636
[batch_idx--50] train_loss: 0.0012129604743391859, acc: 0.8654258578431373, lr: 0.018726544691500546
[batch_idx--100] train_loss: 0.0012160154107939637, acc: 0.8650216584158416, lr: 0.01867037038501655
[batch_idx--150] train_loss: 0.0012244956405210426, acc: 0.8644194950331126, lr: 0.018614230204286455
[batch_idx--200] train_loss: 0.0012273717545950554, acc: 0.8639614427860697, lr: 0.018558124451986114
[batch_idx--250] train_loss: 0.0012291891616769135, acc: 0.8639193227091634, lr: 0.018502053430605753
[batch_idx--300] train_loss: 0.0012315996505623294, acc: 0.8632163621262459, lr: 0.01844601744244835
[batch_idx--350] train_loss: 0.001232085166767006, acc: 0.8633368945868946, lr: 0.018390016789628004
[batch_idx--400] train_loss: 0.0012326886843451, acc: 0.8633591801745636, lr: 0.018334051774068303
[batch_idx--450] train_loss: 0.0012339112653174304, acc: 0.8633057937306905, lr: 0.0182781226975007
total time of one epoch: 233.01103901863098 s
train_loss:  0.0012339112653174304  acc:  0.8633057937306905
->>lr:0.018278
test_loss:  0.0012752722441698957  test_acc:  0.8616453654299541
best acc:  87.0951730983993

------Epoch: 88------
[batch_idx--0] train_loss: 0.0014048839220777154, acc: 0.8359375, lr: 0.01827700448461836
[batch_idx--50] train_loss: 0.001255359486950671, acc: 0.8619025735294118, lr: 0.018221112376465492
[batch_idx--100] train_loss: 0.0012498082936566212, acc: 0.8615021658415841, lr: 0.018165256816209563
[batch_idx--150] train_loss: 0.0012323357679862653, acc: 0.863229511589404, lr: 0.018109438104991903
[batch_idx--200] train_loss: 0.0012341793727903482, acc: 0.863164645522388, lr: 0.01805365654375518
[batch_idx--250] train_loss: 0.0012436269300589078, acc: 0.8620829183266933, lr: 0.017997912433241763
[batch_idx--300] train_loss: 0.0012405229045118382, acc: 0.862048380398671, lr: 0.017942206073992117
[batch_idx--350] train_loss: 0.0012378629815746152, acc: 0.8625467414529915, lr: 0.017886537766343167
[batch_idx--400] train_loss: 0.0012360267993469173, acc: 0.8628623753117207, lr: 0.017830907810426684
[batch_idx--450] train_loss: 0.0012382386633710222, acc: 0.8630107265595168, lr: 0.017775316506167683
total time of one epoch: 234.0941665172577 s
train_loss:  0.0012382386633710222  acc:  0.8630107265595168
->>lr:0.017775
test_loss:  0.0012250103907899329  test_acc:  0.8694627124953468
best acc:  87.0951730983993

------Epoch: 89------
[batch_idx--0] train_loss: 0.0013652588240802288, acc: 0.8515625, lr: 0.017774205076388213
[batch_idx--50] train_loss: 0.0012203876257819287, acc: 0.8657322303921569, lr: 0.017718653505586445
[batch_idx--100] train_loss: 0.0012235567331000572, acc: 0.8641321163366337, lr: 0.01766314119165336
[batch_idx--150] train_loss: 0.0012237426673759096, acc: 0.8638245033112583, lr: 0.017607668433879703
[batch_idx--200] train_loss: 0.0012223675562675802, acc: 0.863261815920398, lr: 0.017552235531342955
[batch_idx--250] train_loss: 0.0012229262390619226, acc: 0.8633590637450199, lr: 0.017496842782905715
[batch_idx--300] train_loss: 0.001227581775105215, acc: 0.8629957433554817, lr: 0.017441490487214106
[batch_idx--350] train_loss: 0.0012250213608201435, acc: 0.8635372150997151, lr: 0.017386178942696135
[batch_idx--400] train_loss: 0.0012245712963808468, acc: 0.8637683135910225, lr: 0.01733090844756013
[batch_idx--450] train_loss: 0.0012321681528843838, acc: 0.8630194050057278, lr: 0.017275679299793074
total time of one epoch: 236.29345321655273 s
train_loss:  0.0012321681528843838  acc:  0.8630194050057278
->>lr:0.017276
test_loss:  0.0012345832062649186  test_acc:  0.8692145427472391
best acc:  87.0951730983993

------Epoch: 90------
[batch_idx--0] train_loss: 0.0013342512538656592, acc: 0.83984375, lr: 0.017274575140626316
[batch_idx--50] train_loss: 0.0012167418779640952, acc: 0.8642769607843137, lr: 0.017219388473930602
[batch_idx--100] train_loss: 0.0012179485235206489, acc: 0.8657564975247525, lr: 0.017164243755855953
[batch_idx--150] train_loss: 0.0012229457142954039, acc: 0.8655836092715232, lr: 0.017109141283711254
[batch_idx--200] train_loss: 0.0012263756260433379, acc: 0.8650691853233831, lr: 0.0170540813545776
[batch_idx--250] train_loss: 0.0012292465620833742, acc: 0.8645573954183267, lr: 0.016999064265306747
[batch_idx--300] train_loss: 0.00122704463577721, acc: 0.8650851328903655, lr: 0.016944090312519478
[batch_idx--350] train_loss: 0.0012228425953370065, acc: 0.8655626780626781, lr: 0.01688915979260398
[batch_idx--400] train_loss: 0.001219844047422579, acc: 0.8658821695760599, lr: 0.016834273001714316
[batch_idx--450] train_loss: 0.0012214790459265914, acc: 0.8657791509008227, lr: 0.016779430235768767
total time of one epoch: 237.9905867576599 s
train_loss:  0.0012214790459265914  acc:  0.8657791509008227
->>lr:0.016779
test_loss:  0.0012161560335353374  test_acc:  0.8724407494726393
best acc:  87.0951730983993
Saving..

------Epoch: 91------
[batch_idx--0] train_loss: 0.0013587464345619082, acc: 0.84375, lr: 0.01677833383153542
[batch_idx--50] train_loss: 0.0011924379299778271, acc: 0.8681832107843137, lr: 0.016723536275641708
[batch_idx--100] train_loss: 0.00119113840570784, acc: 0.8681930693069307, lr: 0.01666878334172139
[batch_idx--150] train_loss: 0.0011893801621642483, acc: 0.8686361754966887, lr: 0.01661407532497108
[batch_idx--200] train_loss: 0.001206011145343235, acc: 0.8664684390547264, lr: 0.016559412520345193
[batch_idx--250] train_loss: 0.0012039279932085708, acc: 0.8664871762948207, lr: 0.016504795222554415
[batch_idx--300] train_loss: 0.0012059041683367172, acc: 0.8666035091362126, lr: 0.01645022372606408
[batch_idx--350] train_loss: 0.0012076639398160335, acc: 0.8666199252136753, lr: 0.01639569832509256
[batch_idx--400] train_loss: 0.0012107727048451783, acc: 0.8661744077306733, lr: 0.016341219313609757
[batch_idx--450] train_loss: 0.0012150629590606434, acc: 0.8661696809803173, lr: 0.01628678698533542
total time of one epoch: 234.84203553199768 s
train_loss:  0.0012150629590606434  acc:  0.8661696809803173
->>lr:0.016287
test_loss:  0.001197064162513609  test_acc:  0.8724407494726393
best acc:  87.24407494726393

------Epoch: 92------
[batch_idx--0] train_loss: 0.0011313254944980145, acc: 0.87890625, lr: 0.016285698816954627
[batch_idx--50] train_loss: 0.0012074559082404948, acc: 0.8691023284313726, lr: 0.016231314407882003
[batch_idx--100] train_loss: 0.001203397019203789, acc: 0.8686571782178217, lr: 0.016176977274562434
[batch_idx--150] train_loss: 0.0012087015221543017, acc: 0.8669029387417219, lr: 0.016122687709950775
[batch_idx--200] train_loss: 0.001210523242494601, acc: 0.8667016480099502, lr: 0.01606844600674539
[batch_idx--250] train_loss: 0.001213952435405027, acc: 0.8665027390438247, lr: 0.016014252457386614
[batch_idx--300] train_loss: 0.001215314492389894, acc: 0.8666294642857143, lr: 0.015960107354055172
[batch_idx--350] train_loss: 0.0012139510821041644, acc: 0.8664641203703703, lr: 0.01590601098867059
[batch_idx--400] train_loss: 0.0012164553609953037, acc: 0.8661938902743143, lr: 0.015851963652889624
[batch_idx--450] train_loss: 0.0012211244751573474, acc: 0.86557954663797, lr: 0.015797965638104688
total time of one epoch: 234.4486677646637 s
train_loss:  0.0012211244751573474  acc:  0.86557954663797
->>lr:0.015798
test_loss:  0.001262189525723058  test_acc:  0.8607767713115771
best acc:  87.24407494726393

------Epoch: 93------
[batch_idx--0] train_loss: 0.0011287238448858261, acc: 0.8828125, lr: 0.01579688618288306
[batch_idx--50] train_loss: 0.001174676935097166, acc: 0.87109375, lr: 0.01574293877543077
[batch_idx--100] train_loss: 0.0011849796847846028, acc: 0.8700108292079208, lr: 0.015689041276774486
[batch_idx--150] train_loss: 0.0011985115279036494, acc: 0.8676272764900662, lr: 0.015635193977498796
[batch_idx--200] train_loss: 0.001198994987343081, acc: 0.867304104477612, lr: 0.015581397167917649
[batch_idx--250] train_loss: 0.0012037318786123834, acc: 0.8667673057768924, lr: 0.01552765113807274
[batch_idx--300] train_loss: 0.0012044070259145032, acc: 0.8666813745847176, lr: 0.015473956177732033
[batch_idx--350] train_loss: 0.001209837659474388, acc: 0.8661413817663818, lr: 0.01542031257638813
[batch_idx--400] train_loss: 0.0012084406073625546, acc: 0.8664374220698254, lr: 0.015366720623256752
[batch_idx--450] train_loss: 0.0012142749466851612, acc: 0.8662738223348492, lr: 0.015313180607275165
total time of one epoch: 236.40718817710876 s
train_loss:  0.0012142749466851612  acc:  0.8662738223348492
->>lr:0.015313
test_loss:  0.00121013518043333  test_acc:  0.8685941183769699
best acc:  87.24407494726393

------Epoch: 94------
[batch_idx--0] train_loss: 0.0011305182706564665, acc: 0.859375, lr: 0.015312110338697428
[batch_idx--50] train_loss: 0.0012034048365118604, acc: 0.8693321078431373, lr: 0.015258623595981367
[batch_idx--100] train_loss: 0.001202669274177181, acc: 0.8689665841584159, lr: 0.015205189373212608
[batch_idx--150] train_loss: 0.0012076008337895256, acc: 0.8678859685430463, lr: 0.015151807958478031
[batch_idx--200] train_loss: 0.001208348729096316, acc: 0.8675178793532339, lr: 0.015098479639579785
[batch_idx--250] train_loss: 0.0012058310632304516, acc: 0.8673586902390438, lr: 0.015045204704033754
[batch_idx--300] train_loss: 0.001205513189025409, acc: 0.8673042981727574, lr: 0.01499198343906803
[batch_idx--350] train_loss: 0.0012001680345221442, acc: 0.8682447471509972, lr: 0.014938816131621303
[batch_idx--400] train_loss: 0.0012030494424045328, acc: 0.8677914588528678, lr: 0.014885703068341395
[batch_idx--450] train_loss: 0.0012057317274645218, acc: 0.8676536952823967, lr: 0.014832644535583656
total time of one epoch: 234.75803518295288 s
train_loss:  0.0012057317274645218  acc:  0.8676536952823967
->>lr:0.014833
test_loss:  0.001263251257957485  test_acc:  0.8671050998883236
best acc:  87.24407494726393

------Epoch: 95------
[batch_idx--0] train_loss: 0.0011293148854747415, acc: 0.87109375, lr: 0.014831583923105
[batch_idx--50] train_loss: 0.0011911065256058732, acc: 0.8680300245098039, lr: 0.014778581306178257
[batch_idx--100] train_loss: 0.0011849780734121283, acc: 0.8700881806930693, lr: 0.014725633797313148
[batch_idx--150] train_loss: 0.0011912299337833872, acc: 0.8694381208609272, lr: 0.014672741681972468
[batch_idx--200] train_loss: 0.0012001797110328812, acc: 0.8685673196517413, lr: 0.01461990524532032
[batch_idx--250] train_loss: 0.001200227493112276, acc: 0.868183515936255, lr: 0.014567124772220653
[batch_idx--300] train_loss: 0.0012023736729729066, acc: 0.8676936254152824, lr: 0.014514400547235684
[batch_idx--350] train_loss: 0.0012039844702234083, acc: 0.8672208867521367, lr: 0.014461732854624376
[batch_idx--400] train_loss: 0.0012056926924948978, acc: 0.8669147443890274, lr: 0.014409121978340905
[batch_idx--450] train_loss: 0.0012087384526250462, acc: 0.8668465997847745, lr: 0.014356568202033099
total time of one epoch: 234.90747237205505 s
train_loss:  0.0012087384526250462  acc:  0.8668465997847745
->>lr:0.014357
test_loss:  0.0011763734924895308  test_acc:  0.8771559746866857
best acc:  87.24407494726393
Saving..

------Epoch: 96------
[batch_idx--0] train_loss: 0.0013518708292394876, acc: 0.86328125, lr: 0.014355517710873192
[batch_idx--50] train_loss: 0.0011698499495419218, acc: 0.8733149509803921, lr: 0.014303022468435317
[batch_idx--100] train_loss: 0.0011921693210139648, acc: 0.8676129331683168, lr: 0.014250584898001182
[batch_idx--150] train_loss: 0.0011914180027357986, acc: 0.8679118377483444, lr: 0.014198205282284266
[batch_idx--200] train_loss: 0.0011904567129103773, acc: 0.8676344838308457, lr: 0.014145883903685591
[batch_idx--250] train_loss: 0.0011931605979362391, acc: 0.8670785607569721, lr: 0.014093621044292189
[batch_idx--300] train_loss: 0.0011921698916734402, acc: 0.8673951411960132, lr: 0.014041416985875627
[batch_idx--350] train_loss: 0.001191183711081064, acc: 0.8674434650997151, lr: 0.013989272009890398
[batch_idx--400] train_loss: 0.001193421193313764, acc: 0.8673141365336658, lr: 0.013937186397472484
[batch_idx--450] train_loss: 0.0011996424207306414, acc: 0.8669941333703614, lr: 0.01388516042943782
total time of one epoch: 234.86716651916504 s
train_loss:  0.0011996424207306414  acc:  0.8669941333703614
->>lr:0.013885
test_loss:  0.0012121042545239081  test_acc:  0.8699590519915622
best acc:  87.71559746866856

------Epoch: 97------
[batch_idx--0] train_loss: 0.0014053713530302048, acc: 0.84375, lr: 0.01388412052037681
[batch_idx--50] train_loss: 0.0012025459299740545, acc: 0.8677236519607843, lr: 0.01383215567857612
[batch_idx--100] train_loss: 0.0011913302668029129, acc: 0.8700881806930693, lr: 0.013780251047424422
[batch_idx--150] train_loss: 0.0011889643154557275, acc: 0.8701624586092715, lr: 0.013728406906761904
[batch_idx--200] train_loss: 0.0011989041883150922, acc: 0.8687616604477612, lr: 0.013676623536102595
[batch_idx--250] train_loss: 0.0012020176623027726, acc: 0.8682302041832669, lr: 0.013624901214632912
[batch_idx--300] train_loss: 0.0012044845444020317, acc: 0.867719580564784, lr: 0.01357324022121012
[batch_idx--350] train_loss: 0.0012034814931821088, acc: 0.8676660434472935, lr: 0.013521640834360844
[batch_idx--400] train_loss: 0.0011974307377485935, acc: 0.8682200748129676, lr: 0.013470103332279566
[batch_idx--450] train_loss: 0.0011984253121234694, acc: 0.8683219356406429, lr: 0.013418627992827087
total time of one epoch: 233.12658786773682 s
train_loss:  0.0011984253121234694  acc:  0.8683219356406429
->>lr:0.013419
test_loss:  0.0011810320569913017  test_acc:  0.8754187864499318
best acc:  87.71559746866856

------Epoch: 98------
[batch_idx--0] train_loss: 0.0010224984725937247, acc: 0.890625, lr: 0.013417599122003463
[batch_idx--50] train_loss: 0.0011823461242659273, acc: 0.8726256127450981, lr: 0.013366187474337023
[batch_idx--100] train_loss: 0.0011903650310618968, acc: 0.8705522896039604, lr: 0.013314838549554453
[batch_idx--150] train_loss: 0.0011928728608173991, acc: 0.8701107201986755, lr: 0.013263552624499875
[batch_idx--200] train_loss: 0.0011992514065689228, acc: 0.8691697761194029, lr: 0.01321232997567776
[batch_idx--250] train_loss: 0.00119689172871255, acc: 0.8694440986055777, lr: 0.01316117087925142
[batch_idx--300] train_loss: 0.0011940803931889889, acc: 0.8694196428571429, lr: 0.013110075611041534
[batch_idx--350] train_loss: 0.001199154557721249, acc: 0.8683671652421653, lr: 0.01305904444652466
[batch_idx--400] train_loss: 0.001198505124592796, acc: 0.8684636066084788, lr: 0.013008077660831736
[batch_idx--450] train_loss: 0.0012014702518025114, acc: 0.8685649321345507, lr: 0.01295717552874661
total time of one epoch: 234.07854580879211 s
train_loss:  0.0012014702518025114  acc:  0.8685649321345507
->>lr:0.012957
test_loss:  0.0011912330140072295  test_acc:  0.8734334284650701
best acc:  87.71559746866856

------Epoch: 99------
[batch_idx--0] train_loss: 0.0012978952145203948, acc: 0.83984375, lr: 0.012956158147457115
[batch_idx--50] train_loss: 0.0012117711913899756, acc: 0.8666513480392157, lr: 0.012905322244772761
[batch_idx--100] train_loss: 0.0012167960026135466, acc: 0.8657178217821783, lr: 0.012854551549694835
[batch_idx--150] train_loss: 0.0012073986223029183, acc: 0.8662303394039735, lr: 0.012803846335949954
[batch_idx--200] train_loss: 0.0012036553173979273, acc: 0.8666627798507462, lr: 0.012753206876911727
[batch_idx--250] train_loss: 0.001202545605323452, acc: 0.8673898157370518, lr: 0.012702633445599246
[batch_idx--300] train_loss: 0.0012006608574369618, acc: 0.8672134551495017, lr: 0.012652126314675622
[batch_idx--350] train_loss: 0.001196477497016422, acc: 0.8676660434472935, lr: 0.012601685756446507
[batch_idx--400] train_loss: 0.0011981541383488945, acc: 0.8673433603491272, lr: 0.012551312042858621
[batch_idx--450] train_loss: 0.0011980917189531094, acc: 0.8676103030513417, lr: 0.012501005445498313
total time of one epoch: 233.44730257987976 s
train_loss:  0.0011980917189531094  acc:  0.8676103030513417
->>lr:0.012501
test_loss:  0.0011776151129323446  test_acc:  0.8756669561980395
best acc:  87.71559746866856

------Epoch: 100------
[batch_idx--0] train_loss: 0.0011040675453841686, acc: 0.88671875, lr: 0.012500000000000006
[batch_idx--50] train_loss: 0.0011955311889394972, acc: 0.8698682598039216, lr: 0.012449762140604802
[batch_idx--100] train_loss: 0.001181121311602321, acc: 0.8712871287128713, lr: 0.012399591944936346
[batch_idx--150] train_loss: 0.0011715194478705033, acc: 0.8727493791390728, lr: 0.012349489683483728
[batch_idx--200] train_loss: 0.0011668643871882922, acc: 0.8735813121890548, lr: 0.012299455626369788
[batch_idx--250] train_loss: 0.001172149086146582, acc: 0.8723076444223108, lr: 0.012249490043349598
[batch_idx--300] train_loss: 0.0011784046682594127, acc: 0.8710807724252492, lr: 0.01219959320380913
[batch_idx--350] train_loss: 0.0011790714344736772, acc: 0.8704371438746439, lr: 0.012149765376763677
[batch_idx--400] train_loss: 0.0011838069982522462, acc: 0.8701196228179551, lr: 0.012100006830856476
[batch_idx--450] train_loss: 0.0011868506762331883, acc: 0.8698406637275662, lr: 0.01205031783435723
total time of one epoch: 234.75114154815674 s
train_loss:  0.0011868506762331883  acc:  0.8698406637275662
->>lr:0.012050
test_loss:  0.0012282705315142474  test_acc:  0.8680977788807545
best acc:  87.71559746866856

------Epoch: 101------
[batch_idx--0] train_loss: 0.001384684699587524, acc: 0.83203125, lr: 0.012049324765671741
[batch_idx--50] train_loss: 0.0011908729884810016, acc: 0.8693321078431373, lr: 0.01199970698555119
[batch_idx--100] train_loss: 0.0011828296689897553, acc: 0.8709777227722773, lr: 0.011950159295598187
[batch_idx--150] train_loss: 0.0011755738334902964, acc: 0.8712489652317881, lr: 0.011900681962945607
[batch_idx--200] train_loss: 0.0011789771008295985, acc: 0.8708799751243781, lr: 0.011851275254347019
[batch_idx--250] train_loss: 0.0011811864558158376, acc: 0.8706891185258964, lr: 0.011801939436175232
[batch_idx--300] train_loss: 0.0011817687163995796, acc: 0.8710548172757475, lr: 0.01175267477442085
[batch_idx--350] train_loss: 0.0011792033181082658, acc: 0.8712606837606838, lr: 0.011703481534690844
[batch_idx--400] train_loss: 0.0011855533617685671, acc: 0.870139105361596, lr: 0.011654359982207095
[batch_idx--450] train_loss: 0.0011886036581573406, acc: 0.8696584163571354, lr: 0.011605310381805019
total time of one epoch: 234.61706805229187 s
train_loss:  0.0011886036581573406  acc:  0.8696584163571354
->>lr:0.011605
test_loss:  0.0011722607867920985  test_acc:  0.8754187864499318
best acc:  87.71559746866856

------Epoch: 102------
[batch_idx--0] train_loss: 0.0010918827028945088, acc: 0.89453125, lr: 0.01160433012552509
[batch_idx--50] train_loss: 0.0011712415166674, acc: 0.8710171568627451, lr: 0.011555354188677439
[batch_idx--100] train_loss: 0.0011628572731094417, acc: 0.8724860767326733, lr: 0.011506450737694249
[batch_idx--150] train_loss: 0.0011773287127448233, acc: 0.8706281043046358, lr: 0.011457620036235043
[batch_idx--200] train_loss: 0.001174581960534019, acc: 0.8715018656716418, lr: 0.011408862347567132
[batch_idx--250] train_loss: 0.0011746196247418355, acc: 0.8709848107569721, lr: 0.011360177934564142
[batch_idx--300] train_loss: 0.0011778889928613341, acc: 0.8706135797342193, lr: 0.011311567059704701
[batch_idx--350] train_loss: 0.0011778995850749653, acc: 0.8709935897435898, lr: 0.01126302998507092
[batch_idx--400] train_loss: 0.0011826008580046756, acc: 0.8702949657107232, lr: 0.011214566972347026
[batch_idx--450] train_loss: 0.001189562646576369, acc: 0.8702138369146388, lr: 0.01116617828281797
total time of one epoch: 236.43511629104614 s
train_loss:  0.001189562646576369  acc:  0.8702138369146388
->>lr:0.011166
test_loss:  0.0011824798529993321  test_acc:  0.876039210820201
best acc:  87.71559746866856

------Epoch: 103------
[batch_idx--0] train_loss: 0.0011922981357201934, acc: 0.875, lr: 0.011165211268916392
[batch_idx--50] train_loss: 0.001204406601769448, acc: 0.8664981617647058, lr: 0.011116898657806221
[batch_idx--100] train_loss: 0.001181555438168937, acc: 0.869430693069307, lr: 0.01106866089646273
[batch_idx--150] train_loss: 0.0011782158884707074, acc: 0.8693087748344371, lr: 0.011020498244956429
[batch_idx--200] train_loss: 0.0011828887630810044, acc: 0.8687422263681592, lr: 0.010972410962952879
[batch_idx--250] train_loss: 0.0011776875671132864, acc: 0.869070592629482, lr: 0.010924399309711284
[batch_idx--300] train_loss: 0.0011770584171118086, acc: 0.8690692483388704, lr: 0.010876463544083113
[batch_idx--350] train_loss: 0.001174193346425838, acc: 0.8698139245014245, lr: 0.010828603924510663
[batch_idx--400] train_loss: 0.001173218041879039, acc: 0.8703241895261845, lr: 0.010780820709025727
[batch_idx--450] train_loss: 0.001179413297417453, acc: 0.8697104870344013, lr: 0.010733114155248157
total time of one epoch: 235.60344290733337 s
train_loss:  0.001179413297417453  acc:  0.8697104870344013
->>lr:0.010733
test_loss:  0.0011547732654968671  test_acc:  0.8781486536791165
best acc:  87.71559746866856
Saving..

------Epoch: 104------
[batch_idx--0] train_loss: 0.0012160586193203926, acc: 0.84765625, lr: 0.010732160807889211
[batch_idx--50] train_loss: 0.0011991664000293788, acc: 0.8686427696078431, lr: 0.010684532714024482
[batch_idx--100] train_loss: 0.0011807732113480274, acc: 0.8711324257425742, lr: 0.010636981800997085
[batch_idx--150] train_loss: 0.001171388015743123, acc: 0.8718956953642384, lr: 0.01058950832517444
[batch_idx--200] train_loss: 0.0011709769417425219, acc: 0.8722209266169154, lr: 0.010542112542506449
[batch_idx--250] train_loss: 0.001167747528344185, acc: 0.8725255229083665, lr: 0.01049479470852415
[batch_idx--300] train_loss: 0.0011735630930986168, acc: 0.8717556063122923, lr: 0.010447555078338317
[batch_idx--350] train_loss: 0.001174280922422106, acc: 0.8712495548433048, lr: 0.010400393906638123
[batch_idx--400] train_loss: 0.0011760993948336366, acc: 0.8711229738154613, lr: 0.010353311447689712
[batch_idx--450] train_loss: 0.0011793433971757107, acc: 0.8707085083486652, lr: 0.01030630795533484
total time of one epoch: 235.12164640426636 s
train_loss:  0.0011793433971757107  acc:  0.8707085083486652
->>lr:0.010306
test_loss:  0.0011680776763900158  test_acc:  0.878644993175332
best acc:  87.81486536791165
Saving..

------Epoch: 105------
[batch_idx--0] train_loss: 0.001205327338539064, acc: 0.87109375, lr: 0.010305368692688175
[batch_idx--50] train_loss: 0.0011991777254140698, acc: 0.8684129901960784, lr: 0.010258446007324987
[batch_idx--100] train_loss: 0.0011849517439547373, acc: 0.8701268564356436, lr: 0.010211602800015714
[batch_idx--150] train_loss: 0.001167322558332358, acc: 0.8725682947019867, lr: 0.010164839323312217
[batch_idx--200] train_loss: 0.0011646454960955724, acc: 0.8724347014925373, lr: 0.010118155829336504
[batch_idx--250] train_loss: 0.0011684403347085226, acc: 0.8721987051792829, lr: 0.010071552569779364
[batch_idx--300] train_loss: 0.0011682445693922004, acc: 0.8722098214285714, lr: 0.010025029795898983
[batch_idx--350] train_loss: 0.0011699336428033385, acc: 0.8718171296296297, lr: 0.00997858775851964
[batch_idx--400] train_loss: 0.0011711400407227106, acc: 0.8715515897755611, lr: 0.00993222670803032
[batch_idx--450] train_loss: 0.001175375056999454, acc: 0.8715242822924983, lr: 0.009885946894383374
total time of one epoch: 234.83567833900452 s
train_loss:  0.001175375056999454  acc:  0.8715242822924983
->>lr:0.009886
test_loss:  0.0011716459303787378  test_acc:  0.8775282293088472
best acc:  87.86449931753319

------Epoch: 106------
[batch_idx--0] train_loss: 0.0008831318700686097, acc: 0.90625, lr: 0.00988502212844063
[batch_idx--50] train_loss: 0.001184400803336472, acc: 0.8677236519607843, lr: 0.009838825433419594
[batch_idx--100] train_loss: 0.0011743912796056506, acc: 0.8688892326732673, lr: 0.009792710478807351
[batch_idx--150] train_loss: 0.001179364644413481, acc: 0.8686879139072847, lr: 0.009746677513229449
[batch_idx--200] train_loss: 0.0011746975233018473, acc: 0.8697722325870647, lr: 0.00970072678486938
[batch_idx--250] train_loss: 0.001172989888155677, acc: 0.8704089890438247, lr: 0.009654858541467274
[batch_idx--300] train_loss: 0.001173946425741062, acc: 0.8703929609634552, lr: 0.009609073030318542
[batch_idx--350] train_loss: 0.001172018465930941, acc: 0.8705706908831908, lr: 0.009563370498272567
[batch_idx--400] train_loss: 0.001171921346623432, acc: 0.8708599594763092, lr: 0.009517751191731351
[batch_idx--450] train_loss: 0.001175143438526752, acc: 0.8707605790259312, lr: 0.00947221535664816
total time of one epoch: 234.93274450302124 s
train_loss:  0.001175143438526752  acc:  0.8707605790259312
->>lr:0.009472
test_loss:  0.0011767160990114232  test_acc:  0.8770318898126318
best acc:  87.86449931753319

------Epoch: 107------
[batch_idx--0] train_loss: 0.0012230961583554745, acc: 0.8671875, lr: 0.009471305493042243
[batch_idx--50] train_loss: 0.0011781539240687648, acc: 0.8716299019607843, lr: 0.00942585505176061
[batch_idx--100] train_loss: 0.0011611438626054637, acc: 0.872447400990099, lr: 0.009380488577388602
[batch_idx--150] train_loss: 0.0011638008464368319, acc: 0.8728011175496688, lr: 0.009335206314516387
[batch_idx--200] train_loss: 0.0011632256748488367, acc: 0.8727262126865671, lr: 0.0092900085072801
[batch_idx--250] train_loss: 0.0011631080658598043, acc: 0.8723076444223108, lr: 0.009244895399360565
[batch_idx--300] train_loss: 0.0011645339998305215, acc: 0.8725083056478405, lr: 0.009199867233981912
[batch_idx--350] train_loss: 0.0011631770588807825, acc: 0.8723401887464387, lr: 0.009154924253910346
[batch_idx--400] train_loss: 0.00116651323641374, acc: 0.8719022755610972, lr: 0.009110066701452797
[batch_idx--450] train_loss: 0.0011693336893086814, acc: 0.871767278786406, lr: 0.0090652948184556
total time of one epoch: 231.99012422561646 s
train_loss:  0.0011693336893086814  acc:  0.871767278786406
->>lr:0.009065
test_loss:  0.0011780631314407938  test_acc:  0.8774041444347934
best acc:  87.86449931753319

------Epoch: 108------
[batch_idx--0] train_loss: 0.0012701142113655806, acc: 0.85546875, lr: 0.009064400256282757
[batch_idx--50] train_loss: 0.0011457865418610619, acc: 0.8746936274509803, lr: 0.009019716004806225
[batch_idx--100] train_loss: 0.0011499766554305384, acc: 0.8744972153465347, lr: 0.0089751179099095
[batch_idx--150] train_loss: 0.00115520234176556, acc: 0.8730856788079471, lr: 0.008930606212040063
[batch_idx--200] train_loss: 0.001156105735485178, acc: 0.872978855721393, lr: 0.00888618115117962
[batch_idx--250] train_loss: 0.0011525615097572692, acc: 0.8731480328685259, lr: 0.00884184296684277
[batch_idx--300] train_loss: 0.0011533390000799787, acc: 0.8732739825581395, lr: 0.00879759189807571
[batch_idx--350] train_loss: 0.0011562856850864372, acc: 0.872985665954416, lr: 0.008753428183455004
[batch_idx--400] train_loss: 0.0011565500421523863, acc: 0.8731101932668329, lr: 0.008709352061086187
[batch_idx--450] train_loss: 0.001161749996085845, acc: 0.8731124379491096, lr: 0.008665363768602597
total time of one epoch: 230.86319088935852 s
train_loss:  0.001161749996085845  acc:  0.8731124379491096
->>lr:0.008665
test_loss:  0.001158156171154482  test_acc:  0.8797617570418166
best acc:  87.86449931753319
Saving..

------Epoch: 109------
[batch_idx--0] train_loss: 0.0010545162949711084, acc: 0.87890625, lr: 0.008664484900247363
[batch_idx--50] train_loss: 0.0011714852606768116, acc: 0.8730085784313726, lr: 0.00862058643856546
[batch_idx--100] train_loss: 0.001156286022967041, acc: 0.872292698019802, lr: 0.0085767762853424
[batch_idx--150] train_loss: 0.0011568356807257314, acc: 0.8728011175496688, lr: 0.008533054676777554
[batch_idx--200] train_loss: 0.0011605610491809857, acc: 0.8726484763681592, lr: 0.008489421848592919
[batch_idx--250] train_loss: 0.0011634568679628828, acc: 0.8723854581673307, lr: 0.008445878036031801
[batch_idx--300] train_loss: 0.0011599719380508131, acc: 0.8729625207641196, lr: 0.008402423473857626
[batch_idx--350] train_loss: 0.0011572314277384164, acc: 0.8731859864672364, lr: 0.008359058396352615
[batch_idx--400] train_loss: 0.0011572245388823629, acc: 0.8730614869077307, lr: 0.008315783037316537
[batch_idx--450] train_loss: 0.0011613769841791297, acc: 0.8731297948415315, lr: 0.008272597630065468
total time of one epoch: 229.59973216056824 s
train_loss:  0.0011613769841791297  acc:  0.8731297948415315
->>lr:0.008273
test_loss:  0.001168503577056276  test_acc:  0.8771559746866857
best acc:  87.97617570418166

------Epoch: 110------
[batch_idx--0] train_loss: 0.0010418695164844394, acc: 0.89453125, lr: 0.008271734841028545
[batch_idx--50] train_loss: 0.0011396446737789495, acc: 0.8741574754901961, lr: 0.008228641424457422
[batch_idx--100] train_loss: 0.001152019188762412, acc: 0.8731435643564357, lr: 0.00818563842948918
[batch_idx--150] train_loss: 0.0011425022196197353, acc: 0.8752328228476821, lr: 0.008142726087971458
[batch_idx--200] train_loss: 0.0011470906815227511, acc: 0.8750971703980099, lr: 0.00809990463126313
[batch_idx--250] train_loss: 0.0011525034771831446, acc: 0.8736616035856574, lr: 0.008057174290233077
[batch_idx--300] train_loss: 0.0011481571473812443, acc: 0.8741694352159468, lr: 0.008014535295258926
[batch_idx--350] train_loss: 0.001149706480304241, acc: 0.8737758190883191, lr: 0.00797198787622585
[batch_idx--400] train_loss: 0.0011546740050316136, acc: 0.8736264806733167, lr: 0.007929532262525246
[batch_idx--450] train_loss: 0.0011558160909999888, acc: 0.8734942895823932, lr: 0.007887168683053591
total time of one epoch: 233.2914023399353 s
train_loss:  0.0011558160909999888  acc:  0.8734942895823932
->>lr:0.007887
test_loss:  0.0011543909034387012  test_acc:  0.8801340116639782
best acc:  87.97617570418166
Saving..

------Epoch: 111------
[batch_idx--0] train_loss: 0.0010694635566323996, acc: 0.87890625, lr: 0.00788632235178279
[batch_idx--50] train_loss: 0.001170648441093006, acc: 0.8696384803921569, lr: 0.00784405288251919
[batch_idx--100] train_loss: 0.0011642339747712606, acc: 0.8698561262376238, lr: 0.007801875908340622
[batch_idx--150] train_loss: 0.0011476399716211865, acc: 0.8728528559602649, lr: 0.007759791656641275
[batch_idx--200] train_loss: 0.001148860908833921, acc: 0.8725318718905473, lr: 0.007717800354315446
[batch_idx--250] train_loss: 0.0011493223689151445, acc: 0.8728056523904383, lr: 0.007675902227756282
[batch_idx--300] train_loss: 0.001153534560416364, acc: 0.8728457225913622, lr: 0.007634097502854598
[batch_idx--350] train_loss: 0.0011518808697652805, acc: 0.8732082443019943, lr: 0.007592386404997634
[batch_idx--400] train_loss: 0.0011532694215136128, acc: 0.8731004519950125, lr: 0.007550769159067847
[batch_idx--450] train_loss: 0.0011636362522845672, acc: 0.872800013885514, lr: 0.00750924598944171
total time of one epoch: 230.63988375663757 s
train_loss:  0.0011636362522845672  acc:  0.872800013885514
->>lr:0.007509
test_loss:  0.0011752189825450625  test_acc:  0.8756669561980395
best acc:  88.01340116639781

------Epoch: 112------
[batch_idx--0] train_loss: 0.0011377277551218867, acc: 0.84765625, lr: 0.007508416487165862
[batch_idx--50] train_loss: 0.0011575029758900842, acc: 0.8724724264705882, lr: 0.007466989505996053
[batch_idx--100] train_loss: 0.0011471953942661754, acc: 0.8739170792079208, lr: 0.007425657052821996
[batch_idx--150] train_loss: 0.0011563867150145948, acc: 0.8724130794701986, lr: 0.007384419350484717
[batch_idx--200] train_loss: 0.0011473572115061703, acc: 0.8738339552238806, lr: 0.0073432766213143985
[batch_idx--250] train_loss: 0.0011531348255336788, acc: 0.8734904133466136, lr: 0.007302229087129178
[batch_idx--300] train_loss: 0.0011580002320500282, acc: 0.8727808347176079, lr: 0.007261276969233954
[batch_idx--350] train_loss: 0.0011581167740550985, acc: 0.8725293803418803, lr: 0.007220420488419194
[batch_idx--400] train_loss: 0.0011545352238878385, acc: 0.8731101932668329, lr: 0.007179659864959754
[batch_idx--450] train_loss: 0.0011579798056097154, acc: 0.8734682542437602, lr: 0.007138995318613667
total time of one epoch: 232.0781855583191 s
train_loss:  0.0011579798056097154  acc:  0.8734682542437602
->>lr:0.007139
test_loss:  0.0011873209313018576  test_acc:  0.8733093435910163
best acc:  88.01340116639781

------Epoch: 113------
[batch_idx--0] train_loss: 0.001190327457152307, acc: 0.8671875, lr: 0.007138183009179922
[batch_idx--50] train_loss: 0.0011712464974170515, acc: 0.8707107843137255, lr: 0.007097616687346986
[batch_idx--100] train_loss: 0.0011493260228757443, acc: 0.8731822400990099, lr: 0.00705714688495745
[batch_idx--150] train_loss: 0.0011521822962576882, acc: 0.8725941639072847, lr: 0.007016773820201414
[batch_idx--200] train_loss: 0.0011512018043422765, acc: 0.873095460199005, lr: 0.00697649771074741
[batch_idx--250] train_loss: 0.0011552116758026835, acc: 0.8729612798804781, lr: 0.006936318773741257
[batch_idx--300] train_loss: 0.00115074104694433, acc: 0.8733518480066446, lr: 0.00689623722580488
[batch_idx--350] train_loss: 0.0011551396205206734, acc: 0.8727519586894587, lr: 0.006856253283035133
[batch_idx--400] train_loss: 0.0011543845246892023, acc: 0.8729543329177057, lr: 0.00681636716100264
[batch_idx--450] train_loss: 0.0011542068385269276, acc: 0.8734682542437602, lr: 0.006776579074750619
total time of one epoch: 232.44957494735718 s
train_loss:  0.0011542068385269276  acc:  0.8734682542437602
->>lr:0.006777
test_loss:  0.0011755289041399883  test_acc:  0.8774041444347934
best acc:  88.01340116639781

------Epoch: 114------
[batch_idx--0] train_loss: 0.001173366792500019, acc: 0.86328125, lr: 0.006775784314464717
[batch_idx--50] train_loss: 0.001159562955281752, acc: 0.8725490196078431, lr: 0.006736096445698165
[batch_idx--100] train_loss: 0.0011537911792258077, acc: 0.8731435643564357, lr: 0.0066965070454860194
[batch_idx--150] train_loss: 0.0011500854200116107, acc: 0.8733185016556292, lr: 0.006657016327271753
[batch_idx--200] train_loss: 0.0011516677613013346, acc: 0.8738922574626866, lr: 0.006617624503966805
[batch_idx--250] train_loss: 0.0011426337975619057, acc: 0.8750155627490039, lr: 0.006578331787949427
[batch_idx--300] train_loss: 0.0011449164571317896, acc: 0.8747534260797342, lr: 0.006539138391063526
[batch_idx--350] train_loss: 0.0011408226748602067, acc: 0.8753227386039886, lr: 0.006500044524617568
[batch_idx--400] train_loss: 0.0011430442474893946, acc: 0.8749707761845387, lr: 0.0064610503993833834
[batch_idx--450] train_loss: 0.0011470997234364858, acc: 0.8749783038844725, lr: 0.006422156225595066
total time of one epoch: 231.5253767967224 s
train_loss:  0.0011470997234364858  acc:  0.8749783038844725
->>lr:0.006422
test_loss:  0.0011654664674605783  test_acc:  0.8770318898126318
best acc:  88.01340116639781

------Epoch: 115------
[batch_idx--0] train_loss: 0.001007966697216034, acc: 0.87109375, lr: 0.00642137936306515
[batch_idx--50] train_loss: 0.001176421055752857, acc: 0.8710171568627451, lr: 0.006382587355775901
[batch_idx--100] train_loss: 0.001144470797971555, acc: 0.8744972153465347, lr: 0.006343895722960522
[batch_idx--150] train_loss: 0.0011404225520253034, acc: 0.8746378311258278, lr: 0.006305304673222229
[batch_idx--200] train_loss: 0.0011328334696544566, acc: 0.8756024564676617, lr: 0.0062668144146219495
[batch_idx--250] train_loss: 0.0011296225138902813, acc: 0.8757470119521913, lr: 0.006228425154677217
[batch_idx--300] train_loss: 0.001138513357428048, acc: 0.8745717400332226, lr: 0.0061901371003610295
[batch_idx--350] train_loss: 0.0011396179261930458, acc: 0.8747551638176638, lr: 0.00615195045810075
[batch_idx--400] train_loss: 0.0011389660653356286, acc: 0.874805174563591, lr: 0.006113865433776986
[batch_idx--450] train_loss: 0.0011405913766985504, acc: 0.8752299788245912, lr: 0.006075882232722457
total time of one epoch: 231.57445740699768 s
train_loss:  0.0011405913766985504  acc:  0.8752299788245912
->>lr:0.006076
test_loss:  0.0011766231659846502  test_acc:  0.8759151259461472
best acc:  88.01340116639781

------Epoch: 116------
[batch_idx--0] train_loss: 0.0011020933743566275, acc: 0.87890625, lr: 0.006075123608706093
[batch_idx--50] train_loss: 0.0011660072475434373, acc: 0.8737745098039216, lr: 0.006037244478350651
[batch_idx--100] train_loss: 0.0011491577912094348, acc: 0.8749613242574258, lr: 0.00599946758436096
[batch_idx--150] train_loss: 0.0011473359765225885, acc: 0.875, lr: 0.005961793130408489
[batch_idx--200] train_loss: 0.0011426040011374696, acc: 0.8758356654228856, lr: 0.005924221319612417
[batch_idx--250] train_loss: 0.001141051032007171, acc: 0.8758403884462151, lr: 0.005886752354538527
[batch_idx--300] train_loss: 0.0011429531900815518, acc: 0.875687811461794, lr: 0.0058493864371981065
[batch_idx--350] train_loss: 0.0011406559271584038, acc: 0.8757345085470085, lr: 0.005812123769046874
[batch_idx--400] train_loss: 0.0011389076952448584, acc: 0.8756039588528678, lr: 0.005774964550983902
[batch_idx--450] train_loss: 0.0011441473955062286, acc: 0.8758374700593605, lr: 0.005737908983350504
total time of one epoch: 232.37237310409546 s
train_loss:  0.0011441473955062286  acc:  0.8758374700593605
->>lr:0.005738
test_loss:  0.0011615277756708612  test_acc:  0.8788931629234397
best acc:  88.01340116639781

------Epoch: 117------
[batch_idx--0] train_loss: 0.0011949590407311916, acc: 0.8515625, lr: 0.005737168930605272
[batch_idx--50] train_loss: 0.0011625506586449988, acc: 0.8724724264705882, lr: 0.005700219292222111
[batch_idx--100] train_loss: 0.0011372171125679027, acc: 0.8770111386138614, lr: 0.005663373707252357
[batch_idx--150] train_loss: 0.0011427802186372955, acc: 0.8761382450331126, lr: 0.005626632374346372
[batch_idx--200] train_loss: 0.0011366454517209338, acc: 0.876846237562189, lr: 0.005589995491592479
[batch_idx--250] train_loss: 0.0011428419194013564, acc: 0.8756691982071713, lr: 0.005553463256515865
[batch_idx--300] train_loss: 0.0011387119836257491, acc: 0.8763237126245847, lr: 0.005517035866077508
[batch_idx--350] train_loss: 0.0011401126287914707, acc: 0.8759570868945868, lr: 0.0054807135166731365
[batch_idx--400] train_loss: 0.0011395012888421032, acc: 0.8762663653366584, lr: 0.005444496404132135
[batch_idx--450] train_loss: 0.0011415006876401503, acc: 0.8766272086645607, lr: 0.005408384723716528
total time of one epoch: 232.45384097099304 s
train_loss:  0.0011415006876401503  acc:  0.8766272086645607
->>lr:0.005408
test_loss:  0.0011744632298189915  test_acc:  0.8755428713239856
best acc:  88.01340116639781

------Epoch: 118------
[batch_idx--0] train_loss: 0.0011471896432340145, acc: 0.8671875, lr: 0.005407663566854007
[batch_idx--50] train_loss: 0.0011505913171990245, acc: 0.8744638480392157, lr: 0.005371659627775735
[batch_idx--100] train_loss: 0.0011463064485976455, acc: 0.8743425123762376, lr: 0.005335761513517229
[batch_idx--150] train_loss: 0.0011475938557344951, acc: 0.8741204470198676, lr: 0.0052999694176206515
[batch_idx--200] train_loss: 0.001137441358371494, acc: 0.8756607587064676, lr: 0.005264283533056586
[batch_idx--250] train_loss: 0.001127423704889384, acc: 0.8770698456175299, lr: 0.0052287040522229575
[batch_idx--300] train_loss: 0.0011274536889420816, acc: 0.8767519725913622, lr: 0.005193231166944048
[batch_idx--350] train_loss: 0.001126426124502175, acc: 0.8768251424501424, lr: 0.005157865068469426
[batch_idx--400] train_loss: 0.001128490295573521, acc: 0.8766852400249376, lr: 0.005122605947472936
[batch_idx--450] train_loss: 0.0011344070980161688, acc: 0.8764970319713958, lr: 0.0050874539940516635
total time of one epoch: 231.28678846359253 s
train_loss:  0.0011344070980161688  acc:  0.8764970319713958
->>lr:0.005087
test_loss:  0.0011644250687749351  test_acc:  0.8797617570418166
best acc:  88.01340116639781

------Epoch: 119------
[batch_idx--0] train_loss: 0.001062690862454474, acc: 0.8828125, lr: 0.005086752049395094
[batch_idx--50] train_loss: 0.0011047486891495246, acc: 0.8812806372549019, lr: 0.005051709602139323
[batch_idx--100] train_loss: 0.001125547903506915, acc: 0.8768177599009901, lr: 0.005016774704691432
[batch_idx--150] train_loss: 0.0011288014372397486, acc: 0.8775351821192053, lr: 0.004981947545400465
[batch_idx--200] train_loss: 0.001141890229550723, acc: 0.8748639614427861, lr: 0.004947228312034608
[batch_idx--250] train_loss: 0.0011358236359706913, acc: 0.8764006474103586, lr: 0.004912617191780173
[batch_idx--300] train_loss: 0.0011327394427023086, acc: 0.8765962416943521, lr: 0.004878114371240583
[batch_idx--350] train_loss: 0.001133110707206519, acc: 0.8763688568376068, lr: 0.004843720036435387
[batch_idx--400] train_loss: 0.0011323141646826932, acc: 0.8764611907730673, lr: 0.004809434372799207
[batch_idx--450] train_loss: 0.001135617768609934, acc: 0.8768875620508904, lr: 0.004775257565180805
total time of one epoch: 231.20773458480835 s
train_loss:  0.001135617768609934  acc:  0.8768875620508904
->>lr:0.004775
test_loss:  0.001163286247669371  test_acc:  0.8756669561980395
best acc:  88.01340116639781

------Epoch: 120------
[batch_idx--0] train_loss: 0.001009753905236721, acc: 0.875, lr: 0.004774575140626317
[batch_idx--50] train_loss: 0.001119104184338129, acc: 0.8770680147058824, lr: 0.004740509555968578
[batch_idx--100] train_loss: 0.0011203391494755033, acc: 0.8773978960396039, lr: 0.004706553198931926
[batch_idx--150] train_loss: 0.001120588466192022, acc: 0.8777421357615894, lr: 0.004672706252589681
[batch_idx--200] train_loss: 0.00111838814713274, acc: 0.8779345460199005, lr: 0.004638968899425284
[batch_idx--250] train_loss: 0.0011173636372854184, acc: 0.8780969870517928, lr: 0.004605341321331294
[batch_idx--300] train_loss: 0.0011236497432695843, acc: 0.876764950166113, lr: 0.004571823699608443
[batch_idx--350] train_loss: 0.0011221868317027675, acc: 0.8770254629629629, lr: 0.0045384162149646355
[batch_idx--400] train_loss: 0.0011237191693611126, acc: 0.876909289276808, lr: 0.004505119047513989
[batch_idx--450] train_loss: 0.001129022015597938, acc: 0.8770437740826882, lr: 0.0044719323767758445
total time of one epoch: 231.1923234462738 s
train_loss:  0.001129022015597938  acc:  0.8770437740826882
->>lr:0.004472
test_loss:  0.0011595413172003914  test_acc:  0.8787690780493858
best acc:  88.01340116639781

------Epoch: 121------
[batch_idx--0] train_loss: 0.0011276999721303582, acc: 0.85546875, lr: 0.004471269771657399
[batch_idx--50] train_loss: 0.001141865390772913, acc: 0.8744638480392157, lr: 0.004438195991889007
[batch_idx--100] train_loss: 0.0011222499548365352, acc: 0.8783647896039604, lr: 0.004405233069644058
[batch_idx--150] train_loss: 0.0011331096128868988, acc: 0.8768625827814569, lr: 0.004372381182639854
[batch_idx--200] train_loss: 0.0011218152586973055, acc: 0.8777985074626866, lr: 0.004339640507995033
[batch_idx--250] train_loss: 0.0011239651705609612, acc: 0.8774277888446215, lr: 0.00430701122222864
[batch_idx--300] train_loss: 0.0011220255168928358, acc: 0.8775695598006644, lr: 0.004274493501259191
[batch_idx--350] train_loss: 0.001123885387300044, acc: 0.8769809472934473, lr: 0.004242087520403681
[batch_idx--400] train_loss: 0.0011245131115498778, acc: 0.8770846321695761, lr: 0.004209793454376692
[batch_idx--450] train_loss: 0.0011243343198864687, acc: 0.877269413684174, lr: 0.0041776114772894115
total time of one epoch: 231.98448848724365 s
train_loss:  0.0011243343198864687  acc:  0.877269413684174
->>lr:0.004178
test_loss:  0.0011520403696062074  test_acc:  0.8783968234272242
best acc:  88.01340116639781

------Epoch: 122------
[batch_idx--0] train_loss: 0.0012470078654587269, acc: 0.83984375, lr: 0.004176968982247515
[batch_idx--50] train_loss: 0.0011118789255966013, acc: 0.8808210784313726, lr: 0.004144901514621361
[batch_idx--100] train_loss: 0.0011213662760968476, acc: 0.879215655940594, lr: 0.0041129464857952575
[batch_idx--150] train_loss: 0.0011231820072072083, acc: 0.8778714817880795, lr: 0.004081104068052505
[batch_idx--200] train_loss: 0.0011186453106057882, acc: 0.8784398320895522, lr: 0.00404937443306925
[batch_idx--250] train_loss: 0.0011156456316802725, acc: 0.8778324203187251, lr: 0.004017757751913604
[batch_idx--300] train_loss: 0.0011148002366860245, acc: 0.8779459094684385, lr: 0.003986254195044678
[batch_idx--350] train_loss: 0.0011163415606836775, acc: 0.8777043269230769, lr: 0.003954863932311695
[batch_idx--400] train_loss: 0.001119538055740975, acc: 0.8776009195760599, lr: 0.003923587132953052
[batch_idx--450] train_loss: 0.0011194303008982584, acc: 0.878163293643906, lr: 0.003892423965595415
total time of one epoch: 232.62770581245422 s
train_loss:  0.0011194303008982584  acc:  0.878163293643906
->>lr:0.003892
test_loss:  0.0011646161490330433  test_acc:  0.876907804938578
best acc:  88.01340116639781

------Epoch: 123------
[batch_idx--0] train_loss: 0.0009893305832520127, acc: 0.890625, lr: 0.003891801862449629
[batch_idx--50] train_loss: 0.001136930093315302, acc: 0.8728553921568627, lr: 0.003860754772816863
[batch_idx--100] train_loss: 0.0011249846798404683, acc: 0.876353650990099, lr: 0.0038298216539413596
[batch_idx--150] train_loss: 0.0011101655364468299, acc: 0.87890625, lr: 0.0037990026725968685
[batch_idx--200] train_loss: 0.0011102715359458616, acc: 0.8789839863184079, lr: 0.003768297994941761
[batch_idx--250] train_loss: 0.0011051521224685874, acc: 0.8794820717131474, lr: 0.0037377077865181603
[batch_idx--300] train_loss: 0.0011036961474394011, acc: 0.8793215323920266, lr: 0.003707232212251013
[batch_idx--350] train_loss: 0.0011072211178812992, acc: 0.8785501246438746, lr: 0.003676871436447249
[batch_idx--400] train_loss: 0.0011122905690759475, acc: 0.8777762624688279, lr: 0.0036466256227948553
[batch_idx--450] train_loss: 0.0011117722473532447, acc: 0.87811122296664, lr: 0.003616494934362016
total time of one epoch: 233.79525446891785 s
train_loss:  0.0011117722473532447  acc:  0.87811122296664
->>lr:0.003616
test_loss:  0.0011605690720507638  test_acc:  0.8779004839310088
best acc:  88.01340116639781

------Epoch: 124------
[batch_idx--0] train_loss: 0.0015476914122700691, acc: 0.83984375, lr: 0.003615893495987335
[batch_idx--50] train_loss: 0.0011367940871209344, acc: 0.875765931372549, lr: 0.003585880402627581
[batch_idx--100] train_loss: 0.001123334565269069, acc: 0.876353650990099, lr: 0.0035559827619909834
[batch_idx--150] train_loss: 0.0011206707421425014, acc: 0.8763969370860927, lr: 0.0035262007352685563
[batch_idx--200] train_loss: 0.0011197003366226394, acc: 0.8764381218905473, lr: 0.003496534483028016
[batch_idx--250] train_loss: 0.001122194042000771, acc: 0.8767585906374502, lr: 0.0034669841652128805
[batch_idx--300] train_loss: 0.0011219299675670894, acc: 0.8767909053156147, lr: 0.00343754994114161
[batch_idx--350] train_loss: 0.001119669306588139, acc: 0.8773370726495726, lr: 0.0034082319695067616
[batch_idx--400] train_loss: 0.0011198893666994338, acc: 0.877474283042394, lr: 0.003379030408374123
[batch_idx--450] train_loss: 0.0011246396937274127, acc: 0.8773388412538619, lr: 0.00334994541518186
total time of one epoch: 235.85470724105835 s
train_loss:  0.0011246396937274127  acc:  0.8773388412538619
->>lr:0.003350
test_loss:  0.0011704304086938657  test_acc:  0.8756669561980395
best acc:  88.01340116639781

------Epoch: 125------
[batch_idx--0] train_loss: 0.0009060251759365201, acc: 0.8984375, lr: 0.003349364905389038
[batch_idx--50] train_loss: 0.0011016412218119583, acc: 0.8805147058823529, lr: 0.003320398973036992
[batch_idx--100] train_loss: 0.0011109606936887497, acc: 0.8777846534653465, lr: 0.0032915499247325843
[batch_idx--150] train_loss: 0.001110768625250592, acc: 0.8782336506622517, lr: 0.003262817916013447
[batch_idx--200] train_loss: 0.0011123996479923267, acc: 0.8781094527363185, lr: 0.0032342031017861847
[batch_idx--250] train_loss: 0.0011104545416866997, acc: 0.8782993027888446, lr: 0.003205705636325565
[batch_idx--300] train_loss: 0.0011170942851100921, acc: 0.8774657392026578, lr: 0.0031773256732736594
[batch_idx--350] train_loss: 0.0011181452273765309, acc: 0.8770365918803419, lr: 0.0031490633656390573
[batch_idx--400] train_loss: 0.0011177643797676221, acc: 0.8771528210723192, lr: 0.0031209188657960046
[batch_idx--450] train_loss: 0.0011219430038378357, acc: 0.8769049189433124, lr: 0.0030928923254835983
total time of one epoch: 233.2084288597107 s
train_loss:  0.0011219430038378357  acc:  0.8769049189433124
->>lr:0.003093
test_loss:  0.001160097613658898  test_acc:  0.8765355503164164
best acc:  88.01340116639781

------Epoch: 126------
[batch_idx--0] train_loss: 0.0012497090501710773, acc: 0.8515625, lr: 0.0030923329989034107
[batch_idx--50] train_loss: 0.0010913303966506146, acc: 0.8845741421568627, lr: 0.003064426932974329
[batch_idx--100] train_loss: 0.0010898552954860842, acc: 0.8839340965346535, lr: 0.003036639131148192
[batch_idx--150] train_loss: 0.0010997039687647083, acc: 0.8815449089403974, lr: 0.003008969743240972
[batch_idx--200] train_loss: 0.0011065748244505468, acc: 0.8798585199004975, lr: 0.002981418918430234
[batch_idx--250] train_loss: 0.00110471948115823, acc: 0.879871140438247, lr: 0.002953986805254319
[batch_idx--300] train_loss: 0.001106598704938848, acc: 0.8795551287375415, lr: 0.002926673551611542
[batch_idx--350] train_loss: 0.0011024678927286397, acc: 0.8798967236467237, lr: 0.002899479304759398
[batch_idx--400] train_loss: 0.0011042351655933791, acc: 0.879490726309227, lr: 0.0028724042113137424
[batch_idx--450] train_loss: 0.0011106883673710614, acc: 0.8795258096990315, lr: 0.002845448417248059
total time of one epoch: 236.15664172172546 s
train_loss:  0.0011106883673710614  acc:  0.8795258096990315
->>lr:0.002845
test_loss:  0.0011594861353844503  test_acc:  0.8781486536791165
best acc:  88.01340116639781

------Epoch: 127------
[batch_idx--0] train_loss: 0.0010291689541190863, acc: 0.89453125, lr: 0.0028449105192196373
[batch_idx--50] train_loss: 0.0011020965826259378, acc: 0.8800551470588235, lr: 0.0028180765602363435
[batch_idx--100] train_loss: 0.0011111384425957751, acc: 0.8790609529702971, lr: 0.0027913621935367313
[batch_idx--150] train_loss: 0.001127821107669456, acc: 0.8767591059602649, lr: 0.002764767563149445
[batch_idx--200] train_loss: 0.0011185042158149145, acc: 0.8772154850746269, lr: 0.002738292812457563
[batch_idx--250] train_loss: 0.0011224955342620966, acc: 0.8761983316733067, lr: 0.00271193808419784
[batch_idx--300] train_loss: 0.0011202190937690956, acc: 0.8763237126245847, lr: 0.002685703520459948
[batch_idx--350] train_loss: 0.0011122285584425633, acc: 0.8776152955840456, lr: 0.0026595892626856965
[batch_idx--400] train_loss: 0.0011075815025361677, acc: 0.8783997038653366, lr: 0.0026335954516682747
[batch_idx--450] train_loss: 0.0011137424420097103, acc: 0.8783368625681258, lr: 0.0026077222275514957
total time of one epoch: 236.19858813285828 s
train_loss:  0.0011137424420097103  acc:  0.8783368625681258
->>lr:0.002608
test_loss:  0.0011534160820096788  test_acc:  0.881126690656409
best acc:  88.01340116639781
Saving..

------Epoch: 128------
[batch_idx--0] train_loss: 0.001085391384549439, acc: 0.90234375, lr: 0.0026072059940146775
[batch_idx--50] train_loss: 0.0011130525632396194, acc: 0.8799019607843137, lr: 0.002581455912238459
[batch_idx--100] train_loss: 0.001101591168455595, acc: 0.8816909034653465, lr: 0.0025558266984695406
[batch_idx--150] train_loss: 0.0011170917045670431, acc: 0.8792942880794702, lr: 0.002530318490886033
[batch_idx--200] train_loss: 0.0011113385608493911, acc: 0.8791783271144279, lr: 0.0025049314270136516
[batch_idx--250] train_loss: 0.0011132589870214136, acc: 0.8783771165338645, lr: 0.0024796656437249655
[batch_idx--300] train_loss: 0.0011111791280447893, acc: 0.8785039451827242, lr: 0.0024545212772386807
[batch_idx--350] train_loss: 0.0011095967444928198, acc: 0.878639155982906, lr: 0.0024294984631188735
[batch_idx--400] train_loss: 0.001110782813712806, acc: 0.8788575436408977, lr: 0.0024045973362742893
[batch_idx--450] train_loss: 0.0011127533582316082, acc: 0.879135279619537, lr: 0.0023798180309576172
total time of one epoch: 234.18051648139954 s
train_loss:  0.0011127533582316082  acc:  0.879135279619537
->>lr:0.002380
test_loss:  0.0011535671145881372  test_acc:  0.878644993175332
best acc:  88.1126690656409

------Epoch: 129------
[batch_idx--0] train_loss: 0.0010277273831889033, acc: 0.86328125, lr: 0.0023793236883495163
[batch_idx--50] train_loss: 0.0010985123260658892, acc: 0.8799785539215687, lr: 0.002354668778617275
[batch_idx--100] train_loss: 0.0011024736346317327, acc: 0.8800665222772277, lr: 0.0023301359595992556
[batch_idx--150] train_loss: 0.00109677054088205, acc: 0.8806394867549668, lr: 0.0023057253635624278
[batch_idx--200] train_loss: 0.0011047031542179707, acc: 0.8801500310945274, lr: 0.0022814371221148186
[batch_idx--250] train_loss: 0.0011084392510050261, acc: 0.879902265936255, lr: 0.0022572713662047635
[batch_idx--300] train_loss: 0.0011120345457023833, acc: 0.8792825996677741, lr: 0.0022332282261202457
[batch_idx--350] train_loss: 0.0011088430537892627, acc: 0.8797965633903134, lr: 0.0022093078314881667
[batch_idx--400] train_loss: 0.001107057211618694, acc: 0.8799388248129676, lr: 0.002185510311273653
[batch_idx--450] train_loss: 0.0011024300758932673, acc: 0.880879647307946, lr: 0.0021618357937793764
total time of one epoch: 235.38379168510437 s
train_loss:  0.0011024300758932673  acc:  0.880879647307946
->>lr:0.002162
test_loss:  0.0011623839720970852  test_acc:  0.8767837200645241
best acc:  88.1126690656409

------Epoch: 130------
[batch_idx--0] train_loss: 0.0012030904181301594, acc: 0.859375, lr: 0.0021613635589349755
[batch_idx--50] train_loss: 0.0010829873978817726, acc: 0.8823529411764706, lr: 0.0021378146357049848
[batch_idx--100] train_loss: 0.0010942880491873637, acc: 0.8810720915841584, lr: 0.0021143889723431067
[batch_idx--150] train_loss: 0.0011073066139846595, acc: 0.879009726821192, lr: 0.0020910866951471623
[batch_idx--200] train_loss: 0.001105732501389468, acc: 0.878886815920398, lr: 0.0020679079297497515
[batch_idx--250] train_loss: 0.0011008631865182276, acc: 0.879886703187251, lr: 0.0020448528011175527
[batch_idx--300] train_loss: 0.0010991161437767041, acc: 0.8801650747508306, lr: 0.0020219214335506857
[batch_idx--350] train_loss: 0.0011027575098376116, acc: 0.8798410790598291, lr: 0.0019991139506819965
[batch_idx--400] train_loss: 0.0011007452071261153, acc: 0.8802018391521197, lr: 0.001976430475476429
[batch_idx--450] train_loss: 0.0011048284099506903, acc: 0.88003783802548, lr: 0.0019538711302303584
total time of one epoch: 235.11302185058594 s
train_loss:  0.0011048284099506903  acc:  0.88003783802548
->>lr:0.001954
test_loss:  0.0011584582511034685  test_acc:  0.8805062662861397
best acc:  88.1126690656409

------Epoch: 131------
[batch_idx--0] train_loss: 0.0012455051764845848, acc: 0.86328125, lr: 0.00195342121028749
[batch_idx--50] train_loss: 0.0010890005733909121, acc: 0.8825061274509803, lr: 0.001930988602895767
[batch_idx--100] train_loss: 0.0011074246802957415, acc: 0.8793316831683168, lr: 0.001908680370460203
[batch_idx--150] train_loss: 0.0011066047086176888, acc: 0.8787251655629139, lr: 0.0018864966332540673
[batch_idx--200] train_loss: 0.0011031833733316158, acc: 0.878886815920398, lr: 0.0018644375108794243
[batch_idx--250] train_loss: 0.0011003699380462892, acc: 0.8796065737051793, lr: 0.0018425031222664813
[batch_idx--300] train_loss: 0.0011037571672458462, acc: 0.8792696220930233, lr: 0.0018206935856729584
[batch_idx--350] train_loss: 0.001101349857390362, acc: 0.879707532051282, lr: 0.0017990090186834396
[batch_idx--400] train_loss: 0.0011022451945970721, acc: 0.8797927057356608, lr: 0.0017774495382087503
[batch_idx--450] train_loss: 0.001108579596622702, acc: 0.8797167355156733, lr: 0.001756015260485311
total time of one epoch: 235.79589319229126 s
train_loss:  0.001108579596622702  acc:  0.8797167355156733
->>lr:0.001756
test_loss:  0.00115486343240661  test_acc:  0.8800099267899243
best acc:  88.1126690656409

------Epoch: 132------
[batch_idx--0] train_loss: 0.0011978186666965485, acc: 0.8515625, lr: 0.0017555878527937164
[batch_idx--50] train_loss: 0.0011157151380115572, acc: 0.8784466911764706, lr: 0.0017342814009232738
[batch_idx--100] train_loss: 0.0011169562521989983, acc: 0.8779780321782178, lr: 0.0017131003845420657
[batch_idx--150] train_loss: 0.001100183196291821, acc: 0.8792166804635762, lr: 0.0016920449178460556
[batch_idx--200] train_loss: 0.001102092975880302, acc: 0.8796641791044776, lr: 0.0016711151143543159
[batch_idx--250] train_loss: 0.0011042643478047474, acc: 0.8795131972111554, lr: 0.0016503110869084154
[batch_idx--300] train_loss: 0.0011018963118371527, acc: 0.8798146802325582, lr: 0.0016296329476718054
[batch_idx--350] train_loss: 0.001101012835199507, acc: 0.8800302706552706, lr: 0.0016090808081292208
[batch_idx--400] train_loss: 0.0011008707366644537, acc: 0.8798414120947631, lr: 0.0015886547790860768
[batch_idx--450] train_loss: 0.0011017339482355685, acc: 0.880003124240636, lr: 0.0015683549706678873
total time of one epoch: 235.81674695014954 s
train_loss:  0.0011017339482355685  acc:  0.880003124240636
->>lr:0.001568
test_loss:  0.0011526745296705004  test_acc:  0.8808785209083013
best acc:  88.1126690656409

------Epoch: 133------
[batch_idx--0] train_loss: 0.0011691800318658352, acc: 0.890625, lr: 0.0015679502627027138
[batch_idx--50] train_loss: 0.0011367121763874357, acc: 0.8756893382352942, lr: 0.0015477793120675237
[batch_idx--100] train_loss: 0.001113604776685744, acc: 0.8780553836633663, lr: 0.0015277348024344995
[batch_idx--150] train_loss: 0.001099961408528049, acc: 0.8794753725165563, lr: 0.001507816841872195
[batch_idx--200] train_loss: 0.0010985405044166825, acc: 0.8796058768656716, lr: 0.0014880255377669072
[batch_idx--250] train_loss: 0.001099768872289321, acc: 0.8789996264940239, lr: 0.0014683609968220602
[batch_idx--300] train_loss: 0.0010955039896395837, acc: 0.8799833887043189, lr: 0.0014488233250576467
[batch_idx--350] train_loss: 0.0010939677449227166, acc: 0.8800747863247863, lr: 0.0014294126278096538
[batch_idx--400] train_loss: 0.0010919897665241803, acc: 0.880231062967581, lr: 0.0014101290097294967
[batch_idx--450] train_loss: 0.0010948554951285448, acc: 0.8801419793800118, lr: 0.0013909725747834447
total time of one epoch: 234.90212106704712 s
train_loss:  0.0010948554951285448  acc:  0.8801419793800118
->>lr:0.001391
test_loss:  0.0011540425871779123  test_acc:  0.8795135872937089
best acc:  88.1126690656409

------Epoch: 134------
[batch_idx--0] train_loss: 0.0009585669031366706, acc: 0.89453125, lr: 0.001390590744062975
[batch_idx--50] train_loss: 0.0011013576911543222, acc: 0.8777573529411765, lr: 0.0013715641423086456
[batch_idx--100] train_loss: 0.001097352159241823, acc: 0.8792930074257426, lr: 0.0013526649316081968
[batch_idx--150] train_loss: 0.0010977925737357594, acc: 0.8802773178807947, lr: 0.0013338932138554
[batch_idx--200] train_loss: 0.0010958958978403305, acc: 0.880869092039801, lr: 0.0013152490902566538
[batch_idx--250] train_loss: 0.0010965499853941639, acc: 0.8807426543824701, lr: 0.0012967326613304436
[batch_idx--300] train_loss: 0.001094644969488584, acc: 0.8811903031561462, lr: 0.0012783440269067943
[batch_idx--350] train_loss: 0.0010951104178557709, acc: 0.8807313924501424, lr: 0.0012600832861267342
[batch_idx--400] train_loss: 0.001091214923270539, acc: 0.8811077774314214, lr: 0.0012419505374417718
[batch_idx--450] train_loss: 0.001094527574144913, acc: 0.880905682646579, lr: 0.0012239458786133446
total time of one epoch: 234.5566964149475 s
train_loss:  0.001094527574144913  acc:  0.880905682646579
->>lr:0.001224
test_loss:  0.0011544661543951805  test_acc:  0.878644993175332
best acc:  88.1126690656409

------Epoch: 135------
[batch_idx--0] train_loss: 0.0010614118073135614, acc: 0.875, lr: 0.0012235870926211618
[batch_idx--50] train_loss: 0.0011069037262167708, acc: 0.8822763480392157, lr: 0.0012057131854440546
[batch_idx--100] train_loss: 0.0010996003679027504, acc: 0.8822710396039604, lr: 0.0011879675634946297
[batch_idx--150] train_loss: 0.0010995183996578665, acc: 0.8822175082781457, lr: 0.0011703503224471529
[batch_idx--200] train_loss: 0.001095008481217465, acc: 0.8824238184079602, lr: 0.001152861557283752
[batch_idx--250] train_loss: 0.0010983474637044082, acc: 0.881816484063745, lr: 0.0011355013622938726
[batch_idx--300] train_loss: 0.0010912633310319652, acc: 0.8823842400332226, lr: 0.0011182698310737928
[batch_idx--350] train_loss: 0.0010956066209183437, acc: 0.8817886396011396, lr: 0.0011011670565261005
[batch_idx--400] train_loss: 0.0010917529705017713, acc: 0.8819552680798005, lr: 0.0010841931308592041
[batch_idx--450] train_loss: 0.0010934073269650685, acc: 0.881842954837366, lr: 0.00106734814558683
total time of one epoch: 235.38379311561584 s
train_loss:  0.0010934073269650685  acc:  0.881842954837366
->>lr:0.001067
test_loss:  0.0011523390529261939  test_acc:  0.8823675393969476
best acc:  88.1126690656409
Saving..

------Epoch: 136------
[batch_idx--0] train_loss: 0.0010426536900922656, acc: 0.875, lr: 0.001067012561698319
[batch_idx--50] train_loss: 0.001109211323280618, acc: 0.8773743872549019, lr: 0.0010502991891848613
[batch_idx--100] train_loss: 0.0010878098817394659, acc: 0.8803372524752475, lr: 0.0010337149398027378
[batch_idx--150] train_loss: 0.0010996481264164263, acc: 0.8798116721854304, lr: 0.001017259902964765
[batch_idx--200] train_loss: 0.0010964035740543842, acc: 0.8807719216417911, lr: 0.0010009341673871241
[batch_idx--250] train_loss: 0.0010901514470458506, acc: 0.8816764193227091, lr: 0.000984737821088863
[batch_idx--300] train_loss: 0.001090371890180741, acc: 0.8814109219269103, lr: 0.000968670951391451
[batch_idx--350] train_loss: 0.0010874221984302345, acc: 0.8816439636752137, lr: 0.0009527336449182884
[batch_idx--400] train_loss: 0.0010902307706390348, acc: 0.8813415679551122, lr: 0.0009369259875942449
[batch_idx--450] train_loss: 0.0010933435586388358, acc: 0.8811573575866977, lr: 0.0009212480646451971
total time of one epoch: 237.518958568573 s
train_loss:  0.0010933435586388358  acc:  0.8811573575866977
->>lr:0.000921
test_loss:  0.0011521555646978488  test_acc:  0.8824916242710014
best acc:  88.23675393969475
Saving..

------Epoch: 137------
[batch_idx--0] train_loss: 0.0009603796643204987, acc: 0.890625, lr: 0.0009209358300585474
[batch_idx--50] train_loss: 0.001092993553873955, acc: 0.8810508578431373, lr: 0.0009053903232463079
[batch_idx--100] train_loss: 0.0010930851123775217, acc: 0.8826577970297029, lr: 0.0008899747208313852
[batch_idx--150] train_loss: 0.0010993690075759856, acc: 0.8805101407284768, lr: 0.0008746891059259105
[batch_idx--200] train_loss: 0.0011003291175297615, acc: 0.8795670087064676, lr: 0.0008595335609412142
[batch_idx--250] train_loss: 0.0011014150538151543, acc: 0.8795754482071713, lr: 0.0008445081675873518
[batch_idx--300] train_loss: 0.0010983967185530972, acc: 0.8800872093023255, lr: 0.0008296130068726787
[batch_idx--350] train_loss: 0.00109540050062603, acc: 0.8802083333333334, lr: 0.0008148481591034013
[batch_idx--400] train_loss: 0.0010970485208851013, acc: 0.8803479582294265, lr: 0.0008002137038831625
[batch_idx--450] train_loss: 0.0010952321353363643, acc: 0.8810271808935328, lr: 0.000785709720112604
total time of one epoch: 233.89973139762878 s
train_loss:  0.0010952321353363643  acc:  0.8810271808935328
->>lr:0.000786
test_loss:  0.0011479440294848674  test_acc:  0.8816230301526244
best acc:  88.24916242710013

------Epoch: 138------
[batch_idx--0] train_loss: 0.0010342979803681374, acc: 0.890625, lr: 0.0007854209717842232
[batch_idx--50] train_loss: 0.001072613097836866, acc: 0.8826593137254902, lr: 0.0007710501494462701
[batch_idx--100] train_loss: 0.001089789509879296, acc: 0.8811107673267327, lr: 0.0007568099557912517
[batch_idx--150] train_loss: 0.0010943998396088252, acc: 0.8804842715231788, lr: 0.000742700467594179
[batch_idx--200] train_loss: 0.001091840886047564, acc: 0.8813549440298507, lr: 0.0007287217609253605
[batch_idx--250] train_loss: 0.001086876376307536, acc: 0.8820654880478087, lr: 0.0007148739111500131
[batch_idx--300] train_loss: 0.001084658588968106, acc: 0.8830071636212624, lr: 0.0007011569929278511
[batch_idx--350] train_loss: 0.0010835348475562606, acc: 0.8829460470085471, lr: 0.0006875710802126706
[batch_idx--400] train_loss: 0.001080993038632366, acc: 0.8832800810473815, lr: 0.0006741162462519713
[batch_idx--450] train_loss: 0.0010859725249582509, acc: 0.8832228277849133, lr: 0.0006607925635865458
total time of one epoch: 233.8396987915039 s
train_loss:  0.0010859725249582509  acc:  0.8832228277849133
->>lr:0.000661
test_loss:  0.0011514233332115776  test_acc:  0.8797617570418166
best acc:  88.24916242710013

------Epoch: 139------
[batch_idx--0] train_loss: 0.000873362529091537, acc: 0.90234375, lr: 0.0006605274281709927
[batch_idx--50] train_loss: 0.001073632512570304, acc: 0.8826593137254902, lr: 0.0006473375938249676
[batch_idx--100] train_loss: 0.001065389443382547, acc: 0.8844368811881188, lr: 0.0006342790551494393
[batch_idx--150] train_loss: 0.0010741764416652947, acc: 0.8834592301324503, lr: 0.0006213518825486042
[batch_idx--200] train_loss: 0.0010723918853026459, acc: 0.8835121268656716, lr: 0.0006085561457184031
[batch_idx--250] train_loss: 0.0010757456274807038, acc: 0.8840263944223108, lr: 0.0005958919136461599
[batch_idx--300] train_loss: 0.0010805610432738184, acc: 0.8836171096345515, lr: 0.000583359254610194
[batch_idx--350] train_loss: 0.001078215591706325, acc: 0.8838920049857549, lr: 0.0005709582361794502
[batch_idx--400] train_loss: 0.0010788590750921787, acc: 0.8836502493765586, lr: 0.0005586889252131494
[batch_idx--450] train_loss: 0.0010849356076612846, acc: 0.8833443260318673, lr: 0.0005465513878604278
total time of one epoch: 233.61226344108582 s
train_loss:  0.0010849356076612846  acc:  0.8833443260318673
->>lr:0.000547
test_loss:  0.0011482664725667772  test_acc:  0.8808785209083013
best acc:  88.24916242710013

------Epoch: 140------
[batch_idx--0] train_loss: 0.0010673957876861095, acc: 0.890625, lr: 0.0005463099816548578
[batch_idx--50] train_loss: 0.0010789136479919155, acc: 0.8825061274509803, lr: 0.0005343069207980278
[batch_idx--100] train_loss: 0.0010758576036366348, acc: 0.8825804455445545, lr: 0.0005224357650086414
[batch_idx--150] train_loss: 0.001092588936444372, acc: 0.8812603476821192, lr: 0.0005106965782891965
[batch_idx--200] train_loss: 0.0010869641355655865, acc: 0.8822489116915423, lr: 0.0004990894239306987
[batch_idx--250] train_loss: 0.0010900348322874164, acc: 0.8820966135458167, lr: 0.0004876143645123038
[batch_idx--300] train_loss: 0.001089479504857039, acc: 0.8819170473421927, lr: 0.00047627146190098725
[batch_idx--350] train_loss: 0.0010860316197326848, acc: 0.8827791132478633, lr: 0.00046506077725121944
[batch_idx--400] train_loss: 0.0010845565847922441, acc: 0.8829488778054863, lr: 0.00045398237100461594
[batch_idx--450] train_loss: 0.0010881232683624335, acc: 0.8831881140000695, lr: 0.0004430363028896239
total time of one epoch: 236.53398275375366 s
train_loss:  0.0010881232683624335  acc:  0.8831881140000695
->>lr:0.000443
test_loss:  0.0011457837623466494  test_acc:  0.8805062662861397
best acc:  88.24916242710013

------Epoch: 141------
[batch_idx--0] train_loss: 0.0011071838671341538, acc: 0.875, lr: 0.00044281873178278475
[batch_idx--50] train_loss: 0.001091475530034479, acc: 0.8808210784313726, lr: 0.0004320077093543484
[batch_idx--100] train_loss: 0.00108370266100945, acc: 0.881149443069307, lr: 0.0004213291435323757
[batch_idx--150] train_loss: 0.0010912124285727294, acc: 0.8804842715231788, lr: 0.0004107830918895994
[batch_idx--200] train_loss: 0.0010829473731562087, acc: 0.8822683457711443, lr: 0.00040036961128431806
[batch_idx--250] train_loss: 0.0010870630250857823, acc: 0.8817697958167331, lr: 0.00039008875786008537
[batch_idx--300] train_loss: 0.0010855254538100448, acc: 0.8818781146179402, lr: 0.00037994058704539927
[batch_idx--350] train_loss: 0.0010822709418297281, acc: 0.8822337962962963, lr: 0.0003699251535534104
[batch_idx--400] train_loss: 0.0010805230817358077, acc: 0.8826663809226932, lr: 0.0003600425113816253
[batch_idx--450] train_loss: 0.001084324068030294, acc: 0.8823636616100253, lr: 0.0003502927138116147
total time of one epoch: 237.22536325454712 s
train_loss:  0.001084324068030294  acc:  0.8823636616100253
->>lr:0.000350
test_loss:  0.0011446657999083427  test_acc:  0.8816230301526244
best acc:  88.24916242710013

------Epoch: 142------
[batch_idx--0] train_loss: 0.0009811314521357417, acc: 0.890625, lr: 0.00035009907323737546
[batch_idx--50] train_loss: 0.0010792000102810562, acc: 0.8825061274509803, lr: 0.00034048483130907914
[batch_idx--100] train_loss: 0.0010651761624445714, acc: 0.8851717202970297, lr: 0.00033100353942642217
[batch_idx--150] train_loss: 0.0010675814604873936, acc: 0.8852183360927153, lr: 0.0003216552487071145
[batch_idx--200] train_loss: 0.0010733707904681303, acc: 0.8847947761194029, lr: 0.00031244000955181765
[batch_idx--250] train_loss: 0.0010831654862597199, acc: 0.8832638197211156, lr: 0.00030335787164384453
[batch_idx--300] train_loss: 0.001082502658621244, acc: 0.8833964908637874, lr: 0.00029440888394890454
[batch_idx--350] train_loss: 0.0010876585853795528, acc: 0.8829905626780626, lr: 0.00028559309471483943
[batch_idx--400] train_loss: 0.001089486521825501, acc: 0.8823936253117207, lr: 0.00027691055147135437
[batch_idx--450] train_loss: 0.0010929568484955752, acc: 0.8820685944388517, lr: 0.0002683613010297709
total time of one epoch: 237.48402500152588 s
train_loss:  0.0010929568484955752  acc:  0.8820685944388517
->>lr:0.000268
test_loss:  0.0011497769555171024  test_acc:  0.8791413326715474
best acc:  88.24916242710013

------Epoch: 143------
[batch_idx--0] train_loss: 0.0011721786577254534, acc: 0.87890625, lr: 0.0002681916759252945
[batch_idx--50] train_loss: 0.0010868503264717612, acc: 0.8806678921568627, lr: 0.00025977843162139916
[batch_idx--100] train_loss: 0.001088553654043797, acc: 0.8809173886138614, lr: 0.0002514985724860308
[batch_idx--150] train_loss: 0.0010858139128035662, acc: 0.8815449089403974, lr: 0.00024335214315946986
[batch_idx--200] train_loss: 0.0010875680420746963, acc: 0.8818602300995025, lr: 0.00023533918756261376
[batch_idx--250] train_loss: 0.0010875095232979828, acc: 0.8822211155378487, lr: 0.00022745974889675503
[batch_idx--300] train_loss: 0.0010860701028932121, acc: 0.8821506436877077, lr: 0.0002197138696433315
[batch_idx--350] train_loss: 0.001084219007135934, acc: 0.881866542022792, lr: 0.0002121015915637098
[batch_idx--400] train_loss: 0.0010841619731403163, acc: 0.88215983478803, lr: 0.0002046229556989493
[batch_idx--450] train_loss: 0.001087079639413213, acc: 0.8821900926858055, lr: 0.00019727800236959416
total time of one epoch: 237.58842968940735 s
train_loss:  0.001087079639413213  acc:  0.8821900926858055
->>lr:0.000197
test_loss:  0.0011463965182861157  test_acc:  0.8813748604045167
best acc:  88.24916242710013

------Epoch: 144------
[batch_idx--0] train_loss: 0.0009050652151927352, acc: 0.89453125, lr: 0.0001971324671380531
[batch_idx--50] train_loss: 0.001078251264213274, acc: 0.8846507352941176, lr: 0.00018992391078557493
[batch_idx--100] train_loss: 0.0010850761721998747, acc: 0.8827351485148515, lr: 0.00018284911621737067
[batch_idx--150] train_loss: 0.0010896311669659781, acc: 0.8821916390728477, lr: 0.00017590812157669555
[batch_idx--200] train_loss: 0.0010956164984616326, acc: 0.8812383395522388, lr: 0.00016910096428543743
[batch_idx--250] train_loss: 0.0010931816316614173, acc: 0.8816452938247012, lr: 0.00016242768104390848
[batch_idx--300] train_loss: 0.001086103147440327, acc: 0.8823323297342193, lr: 0.00015588830783064834
[batch_idx--350] train_loss: 0.0010841596596993697, acc: 0.8823562143874644, lr: 0.0001494828799022241
[batch_idx--400] train_loss: 0.0010846243250100152, acc: 0.882228023690773, lr: 0.00014321143179305552
[batch_idx--450] train_loss: 0.0010880696059223033, acc: 0.8822161280244385, lr: 0.00013707399731520964
total time of one epoch: 236.05791401863098 s
train_loss:  0.0010880696059223033  acc:  0.8822161280244385
->>lr:0.000137
test_loss:  0.0011479850959683162  test_acc:  0.8806303511601936
best acc:  88.24916242710013

------Epoch: 145------
[batch_idx--0] train_loss: 0.000953919836319983, acc: 0.8984375, lr: 0.00013695261579316776
[batch_idx--50] train_loss: 0.0011045886352019129, acc: 0.8785998774509803, lr: 0.0001309519093031647
[batch_idx--100] train_loss: 0.0010898688861104373, acc: 0.8814201732673267, lr: 0.0001250852825408405
[batch_idx--150] train_loss: 0.0010972418760671126, acc: 0.8797599337748344, lr: 0.0001193527671357053
[batch_idx--200] train_loss: 0.0010947133536075256, acc: 0.8805775808457711, lr: 0.00011375439399421428
[batch_idx--250] train_loss: 0.0010869798551506522, acc: 0.8821121762948207, lr: 0.00010829019329959833
[batch_idx--300] train_loss: 0.0010846676018732627, acc: 0.882124688538206, lr: 0.00010296019451171701
[batch_idx--350] train_loss: 0.0010832377496849416, acc: 0.8823450854700855, lr: 9.776442636688366e-05
[batch_idx--400] train_loss: 0.0010821335080098313, acc: 0.882510520573566, lr: 9.270291687771548e-05
[batch_idx--450] train_loss: 0.0010865311017645002, acc: 0.8822334849168605, lr: 8.77756933329893e-05
total time of one epoch: 230.9375352859497 s
train_loss:  0.0010865311017645002  acc:  0.8822334849168605
->>lr:0.000088
test_loss:  0.0011480622772898888  test_acc:  0.8803821814120859
best acc:  88.24916242710013

------Epoch: 146------
[batch_idx--0] train_loss: 0.0013092681765556335, acc: 0.84375, lr: 8.767851876239075e-05
[batch_idx--50] train_loss: 0.0010796854267919472, acc: 0.8816636029411765, lr: 8.288829424305533e-05
[batch_idx--100] train_loss: 0.0011096575267446956, acc: 0.8784808168316832, lr: 7.82324085830094e-05
[batch_idx--150] train_loss: 0.0011002825833672028, acc: 0.8804584023178808, lr: 7.371088688413186e-05
[batch_idx--200] train_loss: 0.0010917766650429747, acc: 0.8813355099502488, lr: 6.93237535238922e-05
[batch_idx--250] train_loss: 0.0010939425131606599, acc: 0.88082046812749, lr: 6.507103215520893e-05
[batch_idx--300] train_loss: 0.0010964783100779493, acc: 0.8806452450166113, lr: 6.09527457063358e-05
[batch_idx--350] train_loss: 0.001090865097993035, acc: 0.8812433226495726, lr: 5.6968916380720215e-05
[batch_idx--400] train_loss: 0.001087060010645938, acc: 0.8813902743142145, lr: 5.311956565690057e-05
[batch_idx--450] train_loss: 0.0010907301029361317, acc: 0.8813829971881835, lr: 4.9404714288381335e-05
total time of one epoch: 230.2343201637268 s
train_loss:  0.0010907301029361317  acc:  0.8813829971881835
->>lr:0.000049
test_loss:  0.00114883194750452  test_acc:  0.8812507755304628
best acc:  88.24916242710013

------Epoch: 147------
[batch_idx--0] train_loss: 0.0010851543629541993, acc: 0.89453125, lr: 4.933178929321103e-05
[batch_idx--50] train_loss: 0.0010903220915911243, acc: 0.8814338235294118, lr: 4.57541478953355e-05
[batch_idx--100] train_loss: 0.0010953611961685786, acc: 0.8810334158415841, lr: 4.231104556289278e-05
[batch_idx--150] train_loss: 0.0010882797554622571, acc: 0.8819329470198676, lr: 3.9002500859128264e-05
[batch_idx--200] train_loss: 0.001083743693341793, acc: 0.8826181592039801, lr: 3.582853162182598e-05
[batch_idx--250] train_loss: 0.0010802093438759624, acc: 0.8830926294820717, lr: 3.2789154963222546e-05
[batch_idx--300] train_loss: 0.0010815420570130462, acc: 0.8834873338870431, lr: 2.9884387269901725e-05
[batch_idx--350] train_loss: 0.0010820715582035376, acc: 0.8832131410256411, lr: 2.7114244202716688e-05
[batch_idx--400] train_loss: 0.001079364655657841, acc: 0.8833580112219451, lr: 2.4478740696695647e-05
[batch_idx--450] train_loss: 0.0010807089650865173, acc: 0.8832575415697573, lr: 2.1977890960975244e-05
total time of one epoch: 229.8963475227356 s
train_loss:  0.0010807089650865173  acc:  0.8832575415697573
->>lr:0.000022
test_loss:  0.0011496307377573249  test_acc:  0.8807544360342474
best acc:  88.24916242710013

------Epoch: 148------
[batch_idx--0] train_loss: 0.001059256843291223, acc: 0.890625, lr: 2.192924752854042e-05
[batch_idx--50] train_loss: 0.0011104099034770008, acc: 0.8806678921568627, lr: 1.9565758523884538e-05
[batch_idx--100] train_loss: 0.001104050770051556, acc: 0.8806466584158416, lr: 1.7336949777524425e-05
[batch_idx--150] train_loss: 0.0010940209590052778, acc: 0.8826055463576159, lr: 1.524283330592846e-05
[batch_idx--200] train_loss: 0.0010945141244220978, acc: 0.8822683457711443, lr: 1.3283420399376467e-05
[batch_idx--250] train_loss: 0.0010934890963534168, acc: 0.8822211155378487, lr: 1.14587216219042e-05
[batch_idx--300] train_loss: 0.0010891474605123342, acc: 0.8828125, lr: 9.768746811253394e-06
[batch_idx--350] train_loss: 0.0010884839200953345, acc: 0.8826566951566952, lr: 8.213505078799587e-06
[batch_idx--400] train_loss: 0.0010859946699399603, acc: 0.8829196539900249, lr: 6.793004809518832e-06
[batch_idx--450] train_loss: 0.0010935819773472562, acc: 0.8823029124865485, lr: 5.507253661940492e-06
total time of one epoch: 229.5401268005371 s
train_loss:  0.0010935819773472562  acc:  0.8823029124865485
->>lr:0.000006
test_loss:  0.0011481659512082582  test_acc:  0.880258096538032
best acc:  88.24916242710013

------Epoch: 149------
[batch_idx--0] train_loss: 0.0010546226985752583, acc: 0.88671875, lr: 5.482913128862511e-06
[batch_idx--50] train_loss: 0.0011040166890084306, acc: 0.8788296568627451, lr: 4.334613221818051e-06
[batch_idx--100] train_loss: 0.0010892280203400936, acc: 0.8799118193069307, lr: 3.321075690718156e-06
[batch_idx--150] train_loss: 0.0010864941375515122, acc: 0.8801479718543046, lr: 2.4423059999861833e-06
[batch_idx--200] train_loss: 0.001093999036142964, acc: 0.8796253109452736, lr: 1.6983088874406029e-06
[batch_idx--250] train_loss: 0.0010901141486898717, acc: 0.8801357071713147, lr: 1.089088364294999e-06
[batch_idx--300] train_loss: 0.001086482303828137, acc: 0.8808009759136213, lr: 6.146477151164343e-07
[batch_idx--350] train_loss: 0.0010873046648911494, acc: 0.880798165954416, lr: 2.749894978198997e-07
[batch_idx--400] train_loss: 0.001087409358801427, acc: 0.8807376091022444, lr: 7.011554364610984e-08
[batch_idx--450] train_loss: 0.001093241379229318, acc: 0.8807060783837262, lr: 2.6957161503027296e-11
total time of one epoch: 231.75956916809082 s
train_loss:  0.001093241379229318  acc:  0.8807060783837262
->>lr:0.000000
test_loss:  0.0011485607275109032  test_acc:  0.8807544360342474
best acc:  88.24916242710013