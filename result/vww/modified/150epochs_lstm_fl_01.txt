Model: mobilenet_lstm_fl
Batch size: 256
Number of dataloader workers: 32

loading annotations into memory...
Done (t=2.00s)
creating index...
index created!
Len of trainloader: 451

loading annotations into memory...
Done (t=0.21s)
creating index...
index created!
Len of testloader: 32

use 4 GPUs!
DataParallel device_ids: [0, 1, 2, 3]

------Epoch: 0------
[batch_idx--0] train_loss: 0.00270115677267313, acc: 0.54296875, lr: 0.05
[batch_idx--50] train_loss: 0.0028787012549811135, acc: 0.5269607843137255, lr: 0.04999993260712715
[batch_idx--100] train_loss: 0.0027484070177715603, acc: 0.5644337871287128, lr: 0.04999973042887193
[batch_idx--150] train_loss: 0.0026733820443812584, acc: 0.5861444536423841, lr: 0.049999393466324364
[batch_idx--200] train_loss: 0.0026248617442927104, acc: 0.6010183457711443, lr: 0.04999892172130118
[batch_idx--250] train_loss: 0.0025965813807104212, acc: 0.6096706922310757, lr: 0.04999831519634575
[batch_idx--300] train_loss: 0.0025708843981754343, acc: 0.6178882890365448, lr: 0.0499975738947281
[batch_idx--350] train_loss: 0.0025538188654748973, acc: 0.6229745370370371, lr: 0.04999669782044491
[batch_idx--400] train_loss: 0.0025336056253280575, acc: 0.628604270573566, lr: 0.049995686978219496
[batch_idx--450] train_loss: 0.002517974677319106, acc: 0.6339171034817926, lr: 0.04999454137350172
total time of one epoch: 519.8014328479767 s
train_loss:  0.002517974677319106  acc:  0.6339171034817926
->>lr:0.049995
test_loss:  0.003375138053380462  test_acc:  0.5284774785953592
best acc:  0
Saving..
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(

------Epoch: 1------
[batch_idx--0] train_loss: 0.0022118401248008013, acc: 0.6953125, lr: 0.04999451708687114
[batch_idx--50] train_loss: 0.0023505929537920977, acc: 0.682827818627451, lr: 0.04999323403077913
[batch_idx--100] train_loss: 0.002323991367777828, acc: 0.6877320544554455, lr: 0.04999181622541965
[batch_idx--150] train_loss: 0.0023102024924750164, acc: 0.6917166804635762, lr: 0.0499902636784367
[batch_idx--200] train_loss: 0.0022952502167121096, acc: 0.6940881529850746, lr: 0.04998857639820074
[batch_idx--250] train_loss: 0.002277297042941014, acc: 0.6974912848605578, lr: 0.04998675439380862
[batch_idx--300] train_loss: 0.00226329339774901, acc: 0.7000752699335548, lr: 0.04998479767508354
[batch_idx--350] train_loss: 0.0022485423710414784, acc: 0.7025796830484331, lr: 0.04998270625257502
[batch_idx--400] train_loss: 0.0022378320979335323, acc: 0.7045959320448878, lr: 0.04998048013755882
[batch_idx--450] train_loss: 0.0022264363273725284, acc: 0.7072933661957164, lr: 0.049978119342036866
total time of one epoch: 505.03835248947144 s
train_loss:  0.0022264363273725284  acc:  0.7072933661957164
->>lr:0.049978
test_loss:  0.002781948324083498  test_acc:  0.5823303139347313
best acc:  52.84774785953592
Saving..

------Epoch: 2------
[batch_idx--0] train_loss: 0.0022696175146847963, acc: 0.71875, lr: 0.04997807075247146
[batch_idx--50] train_loss: 0.0020998257518216384, acc: 0.7279411764705882, lr: 0.04997557259595109
[batch_idx--100] train_loss: 0.0020965797144292604, acc: 0.7311649133663366, lr: 0.04997293978538365
[batch_idx--150] train_loss: 0.0020833392704633492, acc: 0.7339352235099338, lr: 0.04997017233496374
[batch_idx--200] train_loss: 0.002081621698896164, acc: 0.7337919776119403, lr: 0.04996727025961189
[batch_idx--250] train_loss: 0.002071880850017041, acc: 0.7352620766932271, lr: 0.04996423357497442
[batch_idx--300] train_loss: 0.002063159570577508, acc: 0.7366590531561462, lr: 0.04996106229742341
[batch_idx--350] train_loss: 0.002058853292797939, acc: 0.7367565883190883, lr: 0.04995775644405658
[batch_idx--400] train_loss: 0.0020513280249546814, acc: 0.737911081670823, lr: 0.049954316032697205
[batch_idx--450] train_loss: 0.0020441833077737715, acc: 0.7395771861006005, lr: 0.049950741081894026
total time of one epoch: 501.05386114120483 s
train_loss:  0.0020441833077737715  acc:  0.7395771861006005
->>lr:0.049951
test_loss:  0.004091637249042621  test_acc:  0.45898994912520164
best acc:  58.233031393473134

------Epoch: 3------
[batch_idx--0] train_loss: 0.0018108756048604846, acc: 0.75, lr: 0.04995066821070679
[batch_idx--50] train_loss: 0.0019737990783052703, acc: 0.7511488970588235, lr: 0.04994695604953209
[batch_idx--100] train_loss: 0.0019848105523016047, acc: 0.7484916460396039, lr: 0.0499431093885944
[batch_idx--150] train_loss: 0.0019838542658959005, acc: 0.7481632864238411, lr: 0.04993912824863275
[batch_idx--200] train_loss: 0.001973825617489493, acc: 0.750174906716418, lr: 0.049935012651111166
[batch_idx--250] train_loss: 0.0019666472736530865, acc: 0.751058266932271, lr: 0.0499307626182186
[batch_idx--300] train_loss: 0.001964563602485703, acc: 0.7521672549833887, lr: 0.0499263781728688
[batch_idx--350] train_loss: 0.0019581759457298663, acc: 0.7528601317663818, lr: 0.04992185933870021
[batch_idx--400] train_loss: 0.0019532069616121916, acc: 0.7537601309226932, lr: 0.049917206140075804
[batch_idx--450] train_loss: 0.0019539991274000676, acc: 0.7543045093206512, lr: 0.04991241860208297
total time of one epoch: 501.50708389282227 s
train_loss:  0.0019539991274000676  acc:  0.7543045093206512
->>lr:0.049912
test_loss:  0.003333585021779531  test_acc:  0.5379079290234521
best acc:  58.233031393473134

------Epoch: 4------
[batch_idx--0] train_loss: 0.0016764424508437514, acc: 0.796875, lr: 0.049912321481237615
[batch_idx--50] train_loss: 0.0019161568580231831, acc: 0.7607230392156863, lr: 0.04990739694368515
[batch_idx--100] train_loss: 0.001903683476214583, acc: 0.7624922648514851, lr: 0.04990233811964985
[batch_idx--150] train_loss: 0.0018933596558227445, acc: 0.7645643625827815, lr: 0.049897145036406014
[batch_idx--200] train_loss: 0.0018885780747896477, acc: 0.7651974502487562, lr: 0.04989181772195179
[batch_idx--250] train_loss: 0.0018875149474757542, acc: 0.7660763197211156, lr: 0.04988635620500901
[batch_idx--300] train_loss: 0.0018872067756158766, acc: 0.7656898878737541, lr: 0.049880760515023076
[batch_idx--350] train_loss: 0.001884546576656847, acc: 0.7662482193732194, lr: 0.04987503068216274
[batch_idx--400] train_loss: 0.001884888363200846, acc: 0.7659562032418953, lr: 0.04986916673732
[batch_idx--450] train_loss: 0.0018885094136673172, acc: 0.7660377685979103, lr: 0.049863168712109905
total time of one epoch: 476.88763093948364 s
train_loss:  0.0018885094136673172  acc:  0.7660377685979103
->>lr:0.049863
test_loss:  0.0024374591045424605  test_acc:  0.6610001240848741
best acc:  58.233031393473134
Saving..

------Epoch: 5------
[batch_idx--0] train_loss: 0.0017375200986862183, acc: 0.7890625, lr: 0.049863047384206834
[batch_idx--50] train_loss: 0.0018512742027786432, acc: 0.7725949754901961, lr: 0.04985691263034154
[batch_idx--100] train_loss: 0.0018425434677963061, acc: 0.773746905940594, lr: 0.049850643862176046
[batch_idx--150] train_loss: 0.0018463674940427902, acc: 0.7749896523178808, lr: 0.04984424111350797
[batch_idx--200] train_loss: 0.0018458145853613888, acc: 0.7744092039800995, lr: 0.0498377044188573
[batch_idx--250] train_loss: 0.0018436608059643452, acc: 0.7747758964143426, lr: 0.04983103381346615
[batch_idx--300] train_loss: 0.001846984536634554, acc: 0.7736451411960132, lr: 0.049824229333298636
[batch_idx--350] train_loss: 0.0018461316019997129, acc: 0.7740607193732194, lr: 0.049817291015040614
[batch_idx--400] train_loss: 0.0018500029332959036, acc: 0.7728919887780549, lr: 0.04981021889609956
[batch_idx--450] train_loss: 0.0018483723329211588, acc: 0.7737355503870587, lr: 0.0498030130146043
total time of one epoch: 471.78733563423157 s
train_loss:  0.0018483723329211588  acc:  0.7737355503870587
->>lr:0.049803
test_loss:  0.002966834743230895  test_acc:  0.643380071969227
best acc:  66.1000124084874

------Epoch: 6------
[batch_idx--0] train_loss: 0.0018086372874677181, acc: 0.7734375, lr: 0.04980286753286195
[batch_idx--50] train_loss: 0.0018521546838147676, acc: 0.7697610294117647, lr: 0.04979552525358963
[batch_idx--100] train_loss: 0.0018492457272466457, acc: 0.7718517945544554, lr: 0.04978804929098283
[batch_idx--150] train_loss: 0.0018314672495232315, acc: 0.7760244205298014, lr: 0.049780439685347705
[batch_idx--200] train_loss: 0.0018298142660288742, acc: 0.7757890236318408, lr: 0.0497726964777109
[batch_idx--250] train_loss: 0.0018189698420613412, acc: 0.7780440737051793, lr: 0.049764819709819365
[batch_idx--300] train_loss: 0.0018155400005426022, acc: 0.7780834717607974, lr: 0.04975680942414015
[batch_idx--350] train_loss: 0.001811884103828452, acc: 0.7785679309116809, lr: 0.04974866566386016
[batch_idx--400] train_loss: 0.0018055462702281978, acc: 0.7795257948877805, lr: 0.049740388472885894
[batch_idx--450] train_loss: 0.0018107888605013052, acc: 0.7797236782726421, lr: 0.04973197789584324
total time of one epoch: 477.83120369911194 s
train_loss:  0.0018107888605013052  acc:  0.7797236782726421
->>lr:0.049732
test_loss:  0.003261752046653008  test_acc:  0.5638416677007073
best acc:  66.1000124084874

------Epoch: 7------
[batch_idx--0] train_loss: 0.0018514225957915187, acc: 0.77734375, lr: 0.049731808324074714
[batch_idx--50] train_loss: 0.0018266405654596347, acc: 0.7757352941176471, lr: 0.04972326173996171
[batch_idx--100] train_loss: 0.0018058620084372193, acc: 0.7790454826732673, lr: 0.049714581862117906
[batch_idx--150] train_loss: 0.0018104451372356013, acc: 0.7790511175496688, lr: 0.049705768737340256
[batch_idx--200] train_loss: 0.001805343914230294, acc: 0.7800256529850746, lr: 0.04969682241314409
[batch_idx--250] train_loss: 0.0017984007337720567, acc: 0.7812033117529881, lr: 0.0496877429377629
[batch_idx--300] train_loss: 0.0017955239782530654, acc: 0.7818988787375415, lr: 0.04967853036014805
[batch_idx--350] train_loss: 0.0017911670092716175, acc: 0.7821625712250713, lr: 0.04966918472996849
[batch_idx--400] train_loss: 0.001785489509318795, acc: 0.7831105829177057, lr: 0.04965970609761053
[batch_idx--450] train_loss: 0.0017887884283151042, acc: 0.7834814454820009, lr: 0.04965009451417756
total time of one epoch: 475.1081395149231 s
train_loss:  0.0017887884283151042  acc:  0.7834814454820009
->>lr:0.049650
test_loss:  0.002981463612006074  test_acc:  0.6139719568184638
best acc:  66.1000124084874

------Epoch: 8------
[batch_idx--0] train_loss: 0.0017063842387869954, acc: 0.7890625, lr: 0.04964990092676263
[batch_idx--50] train_loss: 0.0017860756556996528, acc: 0.7870710784313726, lr: 0.0496401537866232
[batch_idx--100] train_loss: 0.001760826597110101, acc: 0.7887917698019802, lr: 0.04963027380082368
[batch_idx--150] train_loss: 0.0017577352723883873, acc: 0.7887779387417219, lr: 0.04962026102263131
[batch_idx--200] train_loss: 0.0017627278743636103, acc: 0.787099657960199, lr: 0.04961011550602926
[batch_idx--250] train_loss: 0.001761903936243746, acc: 0.7868837151394422, lr: 0.04959983730571641
[batch_idx--300] train_loss: 0.001760026836842051, acc: 0.787219684385382, lr: 0.04958942647710693
[batch_idx--350] train_loss: 0.0017594397134357198, acc: 0.7868144586894587, lr: 0.04957888307633007
[batch_idx--400] train_loss: 0.0017553985942192283, acc: 0.7872311408977556, lr: 0.04956820716022985
[batch_idx--450] train_loss: 0.0017589295369151003, acc: 0.787030929982296, lr: 0.049557398786364705
total time of one epoch: 478.81066846847534 s
train_loss:  0.0017589295369151003  acc:  0.787030929982296
->>lr:0.049557
test_loss:  0.0021536626159323847  test_acc:  0.7174587417793771
best acc:  66.1000124084874
Saving..

------Epoch: 9------
[batch_idx--0] train_loss: 0.0017086232546716928, acc: 0.8046875, lr: 0.049557181268217225
[batch_idx--50] train_loss: 0.0017370584229116932, acc: 0.7927389705882353, lr: 0.04954623784746919
[batch_idx--100] train_loss: 0.001734595964801046, acc: 0.7909189356435643, lr: 0.04953516208740226
[batch_idx--150] train_loss: 0.001728024188003546, acc: 0.7918305049668874, lr: 0.049523954047730606
[batch_idx--200] train_loss: 0.0017283702806676206, acc: 0.7919970460199005, lr: 0.04951261378888158
[batch_idx--250] train_loss: 0.001733250468895136, acc: 0.7914902888446215, lr: 0.049501141371995405
[batch_idx--300] train_loss: 0.001728315088136796, acc: 0.7927611088039868, lr: 0.0494895368589248
[batch_idx--350] train_loss: 0.001726846066714819, acc: 0.7932803596866097, lr: 0.0494778003122347
[batch_idx--400] train_loss: 0.001729837192589431, acc: 0.7928518547381546, lr: 0.049465931795201847
[batch_idx--450] train_loss: 0.0017355987660220343, acc: 0.7926285277883848, lr: 0.049453931371814544
total time of one epoch: 472.28115797042847 s
train_loss:  0.0017355987660220343  acc:  0.7926285277883848
->>lr:0.049454
test_loss:  0.002637280492158959  test_acc:  0.6538032013897506
best acc:  71.74587417793771

------Epoch: 10------
[batch_idx--0] train_loss: 0.0016438710736110806, acc: 0.80078125, lr: 0.049453690018345146
[batch_idx--50] train_loss: 0.001717442226614438, acc: 0.7917432598039216, lr: 0.04944155511713453
[batch_idx--100] train_loss: 0.0017279411002182135, acc: 0.7905321782178217, lr: 0.04942928844099462
[batch_idx--150] train_loss: 0.0017240407417176773, acc: 0.7913907284768212, lr: 0.0494168900560603
[batch_idx--200] train_loss: 0.0017287839512197087, acc: 0.7913557213930348, lr: 0.04940436002917662
[batch_idx--250] train_loss: 0.0017241743950737248, acc: 0.791941608565737, lr: 0.04939169842789834
[batch_idx--300] train_loss: 0.0017166738425446458, acc: 0.7934878529900332, lr: 0.04937890532048959
[batch_idx--350] train_loss: 0.0017165244229275871, acc: 0.7933026175213675, lr: 0.04936598077592351
[batch_idx--400] train_loss: 0.0017128240638191897, acc: 0.7935142612219451, lr: 0.049352924863881875
[batch_idx--450] train_loss: 0.0017129018870190257, acc: 0.7941038636442531, lr: 0.04933973765475472
total time of one epoch: 476.40314745903015 s
train_loss:  0.0017129018870190257  acc:  0.7941038636442531
->>lr:0.049340
test_loss:  0.002656139989011059  test_acc:  0.6885469661248294
best acc:  71.74587417793771

------Epoch: 11------
[batch_idx--0] train_loss: 0.0015412243083119392, acc: 0.80859375, lr: 0.04933947257182901
[batch_idx--50] train_loss: 0.0016971789734145882, acc: 0.79296875, lr: 0.04932615151292455
[batch_idx--100] train_loss: 0.0017017760869613525, acc: 0.7945544554455446, lr: 0.04931269930128121
[batch_idx--150] train_loss: 0.001696532940652394, acc: 0.7952711092715232, lr: 0.04929911600942565
[batch_idx--200] train_loss: 0.0016962728499022512, acc: 0.7959421641791045, lr: 0.04928540171059123
[batch_idx--250] train_loss: 0.0016950659488190515, acc: 0.796906125498008, lr: 0.04927155647871764
[batch_idx--300] train_loss: 0.0016968752051768608, acc: 0.7959406146179402, lr: 0.04925758038845046
[batch_idx--350] train_loss: 0.0016965028674652178, acc: 0.7964966168091168, lr: 0.04924347351514081
[batch_idx--400] train_loss: 0.0016939826594187211, acc: 0.7969139650872819, lr: 0.049229235934844906
[batch_idx--450] train_loss: 0.0016987638207713795, acc: 0.7967334328461833, lr: 0.04921486772432365
total time of one epoch: 475.64605832099915 s
train_loss:  0.0016987638207713795  acc:  0.7967334328461833
->>lr:0.049215
test_loss:  0.002346661054166497  test_acc:  0.7232907308599081
best acc:  71.74587417793771
Saving..

------Epoch: 12------
[batch_idx--0] train_loss: 0.0016255824593827128, acc: 0.80078125, lr: 0.04921457902821578
[batch_idx--50] train_loss: 0.0016951206432399796, acc: 0.7960324754901961, lr: 0.04920007765467417
[batch_idx--100] train_loss: 0.001688297230538239, acc: 0.7978032178217822, lr: 0.049185445808112044
[batch_idx--150] train_loss: 0.0016929180783817903, acc: 0.7976510761589404, lr: 0.049170683567415975
[batch_idx--200] train_loss: 0.001690942276296998, acc: 0.7967778296019901, lr: 0.04915579101217554
[batch_idx--250] train_loss: 0.0016881109899896905, acc: 0.7970150647410359, lr: 0.04914076822268292
[batch_idx--300] train_loss: 0.0016900030706554305, acc: 0.7969269102990033, lr: 0.04912561527993242
[batch_idx--350] train_loss: 0.0016883168053784092, acc: 0.7977987001424501, lr: 0.049110332265620074
[batch_idx--400] train_loss: 0.001682955083353654, acc: 0.7990180798004988, lr: 0.049094919262143176
[batch_idx--450] train_loss: 0.0016874469451746714, acc: 0.7992154684625264, lr: 0.049079376352599846
total time of one epoch: 475.98565125465393 s
train_loss:  0.0016874469451746714  acc:  0.7992154684625264
->>lr:0.049079
test_loss:  0.002534361967807935  test_acc:  0.6881747115026678
best acc:  72.32907308599081

------Epoch: 13------
[batch_idx--0] train_loss: 0.0017790787387639284, acc: 0.77734375, lr: 0.049079064169941455
[batch_idx--50] train_loss: 0.0016882787983608888, acc: 0.7987898284313726, lr: 0.04906338884254441
[batch_idx--100] train_loss: 0.001664393276003844, acc: 0.8022122524752475, lr: 0.04904758377907498
[batch_idx--150] train_loss: 0.001658183231869626, acc: 0.8028507864238411, lr: 0.04903164906474507
[batch_idx--200] train_loss: 0.001660646869573946, acc: 0.8021610696517413, lr: 0.04901558478546556
[batch_idx--250] train_loss: 0.0016567388696009776, acc: 0.8021818974103586, lr: 0.04899939102784589
[batch_idx--300] train_loss: 0.0016566576699933587, acc: 0.8027927740863787, lr: 0.04898306787919357
[batch_idx--350] train_loss: 0.0016616307918056632, acc: 0.8018051103988604, lr: 0.04896661542751371
[batch_idx--400] train_loss: 0.0016628349042541702, acc: 0.8016579644638404, lr: 0.04895003376150854
[batch_idx--450] train_loss: 0.0016687580303134104, acc: 0.801463186031173, lr: 0.04893332297057697
total time of one epoch: 488.16423201560974 s
train_loss:  0.0016687580303134104  acc:  0.801463186031173
->>lr:0.048933
test_loss:  0.0017992333881256524  test_acc:  0.7864499317533192
best acc:  72.32907308599081
Saving..

------Epoch: 14------
[batch_idx--0] train_loss: 0.0017666001804172993, acc: 0.796875, lr: 0.048932987438301684
[batch_idx--50] train_loss: 0.0016695125275017584, acc: 0.8023897058823529, lr: 0.04891614503276587
[batch_idx--100] train_loss: 0.0016854731746405215, acc: 0.7990795173267327, lr: 0.04889917368501234
[batch_idx--150] train_loss: 0.0016688138951195886, acc: 0.8023851407284768, lr: 0.04888207348654094
[batch_idx--200] train_loss: 0.0016607096921467217, acc: 0.8034825870646766, lr: 0.048864844529546175
[batch_idx--250] train_loss: 0.0016574997907556385, acc: 0.8033802290836654, lr: 0.04884748690691675
[batch_idx--300] train_loss: 0.0016532957482699342, acc: 0.8041813745847176, lr: 0.048830000712235096
[batch_idx--350] train_loss: 0.001651879954563077, acc: 0.8039752492877493, lr: 0.048812386039776785
[batch_idx--400] train_loss: 0.0016509527503106361, acc: 0.804385520573566, lr: 0.0487946429845101
[batch_idx--450] train_loss: 0.0016530429425245191, acc: 0.8046221404519734, lr: 0.048776771642095464
total time of one epoch: 492.46140813827515 s
train_loss:  0.0016530429425245191  acc:  0.8046221404519734
->>lr:0.048777
test_loss:  0.005262253819631427  test_acc:  0.5716590147661
best acc:  78.64499317533193

------Epoch: 15------
[batch_idx--0] train_loss: 0.0015050421934574842, acc: 0.83203125, lr: 0.048776412907378844
[batch_idx--50] train_loss: 0.0016627398104972992, acc: 0.80078125, lr: 0.04875841081133997
[batch_idx--100] train_loss: 0.0016461908771186183, acc: 0.8046101485148515, lr: 0.04874028062349638
[batch_idx--150] train_loss: 0.00163629406828754, acc: 0.8064466059602649, lr: 0.0487220224415957
[batch_idx--200] train_loss: 0.0016378722135070248, acc: 0.8058535447761194, lr: 0.04870363636407563
[batch_idx--250] train_loss: 0.0016368947546572918, acc: 0.8063371513944223, lr: 0.04868512249006343
[batch_idx--300] train_loss: 0.001632424815947753, acc: 0.8067249792358804, lr: 0.048666480919375345
[batch_idx--350] train_loss: 0.0016312403342370846, acc: 0.80643474002849, lr: 0.0486477117525161
[batch_idx--400] train_loss: 0.0016334335934579782, acc: 0.8059733478802993, lr: 0.04862881509067834
[batch_idx--450] train_loss: 0.0016379249147851229, acc: 0.8060106918457319, lr: 0.04860979103574209
total time of one epoch: 485.063289642334 s
train_loss:  0.0016379249147851229  acc:  0.8060106918457319
->>lr:0.048610
test_loss:  0.0018205242611690645  test_acc:  0.7840923191462961
best acc:  78.64499317533193

------Epoch: 16------
[batch_idx--0] train_loss: 0.0017301178304478526, acc: 0.796875, lr: 0.04860940925593703
[batch_idx--50] train_loss: 0.001684615244705449, acc: 0.7970281862745098, lr: 0.048590255365709406
[batch_idx--100] train_loss: 0.0016447746374708887, acc: 0.8045714727722773, lr: 0.04857097429027534
[batch_idx--150] train_loss: 0.0016290434907554397, acc: 0.8070674668874173, lr: 0.0485515661335874
[batch_idx--200] train_loss: 0.0016264568716611953, acc: 0.8082633706467661, lr: 0.048532031000283304
[batch_idx--250] train_loss: 0.0016244664139845278, acc: 0.8080490537848606, lr: 0.048512368995685354
[batch_idx--300] train_loss: 0.0016306328410870608, acc: 0.8066990240863787, lr: 0.04849258022579986
[batch_idx--350] train_loss: 0.0016303111625267485, acc: 0.8066907051282052, lr: 0.04847266479731658
[batch_idx--400] train_loss: 0.0016276341705627163, acc: 0.8070156639650873, lr: 0.048452622817608176
[batch_idx--450] train_loss: 0.0016300809842940069, acc: 0.8067049675426111, lr: 0.04843245439472954
total time of one epoch: 488.8647918701172 s
train_loss:  0.0016300809842940069  acc:  0.8067049675426111
->>lr:0.048432
test_loss:  0.002646393753160154  test_acc:  0.6659635190470282
best acc:  78.64499317533193

------Epoch: 17------
[batch_idx--0] train_loss: 0.0017309137620031834, acc: 0.80078125, lr: 0.04843204973729729
[batch_idx--50] train_loss: 0.0016216879674032622, acc: 0.8101256127450981, lr: 0.048411752454410206
[batch_idx--100] train_loss: 0.0016223368808940643, acc: 0.8076655321782178, lr: 0.0483913289487026
[batch_idx--150] train_loss: 0.0016246216305352698, acc: 0.8081281043046358, lr: 0.04837077933028638
[batch_idx--200] train_loss: 0.0016235089449638232, acc: 0.8086909203980099, lr: 0.04835010370995336
[batch_idx--250] train_loss: 0.0016236893969042547, acc: 0.8083603087649402, lr: 0.0483293021991747
[batch_idx--300] train_loss: 0.0016307806324653105, acc: 0.8064264950166113, lr: 0.04830837491010029
[batch_idx--350] train_loss: 0.0016280958884026845, acc: 0.8068687678062678, lr: 0.04828732195555814
[batch_idx--400] train_loss: 0.001620727407448737, acc: 0.807921602244389, lr: 0.04826614344905377
[batch_idx--450] train_loss: 0.0016241582436989806, acc: 0.8076682750720311, lr: 0.04824483950476961
total time of one epoch: 482.5030438899994 s
train_loss:  0.0016241582436989806  acc:  0.8076682750720311
->>lr:0.048245
test_loss:  0.0018875178738731444  test_acc:  0.77230425611118
best acc:  78.64499317533193

------Epoch: 18------
[batch_idx--0] train_loss: 0.0014567718608304858, acc: 0.84375, lr: 0.04824441214720629
[batch_idx--50] train_loss: 0.00162456846823368, acc: 0.8082107843137255, lr: 0.04822298037471885
[batch_idx--100] train_loss: 0.0016237729134517583, acc: 0.8090578589108911, lr: 0.04820142339716232
[batch_idx--150] train_loss: 0.001619279351461654, acc: 0.808542011589404, lr: 0.04817974133075961
[batch_idx--200] train_loss: 0.001619674928546582, acc: 0.8084382773631841, lr: 0.04815793429240808
[batch_idx--250] train_loss: 0.0016170934726673352, acc: 0.8092785109561753, lr: 0.04813600239967885
[batch_idx--300] train_loss: 0.001614442162843811, acc: 0.8101770141196013, lr: 0.04811394577081616
[batch_idx--350] train_loss: 0.001613946018297427, acc: 0.8100627670940171, lr: 0.04809176452473679
[batch_idx--400] train_loss: 0.0016111225256129652, acc: 0.8102302836658354, lr: 0.048069458781029376
[batch_idx--450] train_loss: 0.001613788166014113, acc: 0.8102891658277502, lr: 0.048047028659953764
total time of one epoch: 485.5219120979309 s
train_loss:  0.001613788166014113  acc:  0.8102891658277502
->>lr:0.048047
test_loss:  0.0023833410159162026  test_acc:  0.6804814493113289
best acc:  78.64499317533193

------Epoch: 19------
[batch_idx--0] train_loss: 0.0013652151683345437, acc: 0.82421875, lr: 0.04804657878971252
[batch_idx--50] train_loss: 0.0016427533335837663, acc: 0.8034620098039216, lr: 0.04802402192830846
[batch_idx--100] train_loss: 0.0016241989116931317, acc: 0.8055770420792079, lr: 0.04800134093450581
[batch_idx--150] train_loss: 0.0016099432528031287, acc: 0.8087748344370861, lr: 0.04797853593058756
[batch_idx--200] train_loss: 0.0016055514917834037, acc: 0.8103039490049752, lr: 0.04795560703950527
[batch_idx--250] train_loss: 0.0016052312374419248, acc: 0.8099943974103586, lr: 0.047932554384878465
[batch_idx--300] train_loss: 0.0016017213043759877, acc: 0.8100342607973422, lr: 0.0479093780909939
[batch_idx--350] train_loss: 0.0015993096777490018, acc: 0.8105635683760684, lr: 0.047886078282804945
[batch_idx--400] train_loss: 0.0015977447285802286, acc: 0.8109121726932669, lr: 0.047862655085930884
[batch_idx--450] train_loss: 0.001601674526771569, acc: 0.8111917242336932, lr: 0.04783910862665624
total time of one epoch: 483.99866700172424 s
train_loss:  0.001601674526771569  acc:  0.8111917242336932
->>lr:0.047839
test_loss:  0.0018538651017874076  test_acc:  0.7744136989700956
best acc:  78.64499317533193

------Epoch: 20------
[batch_idx--0] train_loss: 0.0017472432227805257, acc: 0.7578125, lr: 0.04783863644106502
[batch_idx--50] train_loss: 0.0016041119724475577, acc: 0.8095128676470589, lr: 0.047814964384929284
[batch_idx--100] train_loss: 0.0015839358704109298, acc: 0.8148205445544554, lr: 0.047791169323514016
[batch_idx--150] train_loss: 0.0015778059304833707, acc: 0.8153197433774835, lr: 0.047767251385108636
[batch_idx--200] train_loss: 0.0015705991403167298, acc: 0.8157066231343284, lr: 0.04774321069866503
[batch_idx--250] train_loss: 0.0015745268873981685, acc: 0.8149433515936255, lr: 0.04771904739379687
[batch_idx--300] train_loss: 0.0015766928123273078, acc: 0.8148619186046512, lr: 0.0476947616007789
[batch_idx--350] train_loss: 0.0015782187719354432, acc: 0.8144809472934473, lr: 0.0476703534505463
[batch_idx--400] train_loss: 0.0015783467140754782, acc: 0.8143411003740648, lr: 0.047645823074693894
[batch_idx--450] train_loss: 0.0015852329676735674, acc: 0.8138733641128892, lr: 0.047621170605475466
total time of one epoch: 484.0064015388489 s
train_loss:  0.0015852329676735674  acc:  0.8138733641128892
->>lr:0.047621
test_loss:  0.0023397547218873254  test_acc:  0.7215535426231542
best acc:  78.64499317533193

------Epoch: 21------
[batch_idx--0] train_loss: 0.0016132767777889967, acc: 0.81640625, lr: 0.04762067631165049
[batch_idx--50] train_loss: 0.0015912942620286462, acc: 0.8134191176470589, lr: 0.047595899444129244
[batch_idx--100] train_loss: 0.0015802961326951144, acc: 0.8154006806930693, lr: 0.04757100075240174
[batch_idx--150] train_loss: 0.0015844842372770538, acc: 0.8141556291390728, lr: 0.04754598037070751
[batch_idx--200] train_loss: 0.0015733889217224362, acc: 0.8155900186567164, lr: 0.047520838433942204
[batch_idx--250] train_loss: 0.0015691603516298995, acc: 0.8163906872509961, lr: 0.04749557507765681
[batch_idx--300] train_loss: 0.0015697568474009485, acc: 0.8162894518272426, lr: 0.047470190438056926
[batch_idx--350] train_loss: 0.0015688243310797716, acc: 0.8163394764957265, lr: 0.047444684652002064
[batch_idx--400] train_loss: 0.0015702344755296064, acc: 0.8160750467581047, lr: 0.04741905785700488
[batch_idx--450] train_loss: 0.001571710753067177, acc: 0.8162859721595446, lr: 0.04739331019123044
total time of one epoch: 485.4851927757263 s
train_loss:  0.001571710753067177  acc:  0.8162859721595446
->>lr:0.047393
test_loss:  0.0021138487212458827  test_acc:  0.7598957687057948
best acc:  78.64499317533193

------Epoch: 22------
[batch_idx--0] train_loss: 0.0016097252955660224, acc: 0.80859375, lr: 0.047392794005985325
[batch_idx--50] train_loss: 0.001579967815903764, acc: 0.8147212009803921, lr: 0.04736692319503155
[batch_idx--100] train_loss: 0.0015653287484725512, acc: 0.8153233292079208, lr: 0.047340931794380904
[batch_idx--150] train_loss: 0.0015713017293566603, acc: 0.8150351821192053, lr: 0.04731481994416418
[batch_idx--200] train_loss: 0.001574875708711125, acc: 0.8141130286069652, lr: 0.04728858778516159
[batch_idx--250] train_loss: 0.001572417364311052, acc: 0.8147877241035857, lr: 0.04726223545880198
[batch_idx--300] train_loss: 0.001575251887676204, acc: 0.8139405107973422, lr: 0.04723576310716207
[batch_idx--350] train_loss: 0.0015799555144116197, acc: 0.8131343482905983, lr: 0.047209170872965694
[batch_idx--400] train_loss: 0.0015782896630196575, acc: 0.8133474906483791, lr: 0.047182458899583
[batch_idx--450] train_loss: 0.001577926623457924, acc: 0.8139775054674211, lr: 0.04715562733102973
total time of one epoch: 487.56182646751404 s
train_loss:  0.001577926623457924  acc:  0.8139775054674211
->>lr:0.047156
test_loss:  0.0016276171528711732  test_acc:  0.8164784712743517
best acc:  78.64499317533193
Saving..

------Epoch: 23------
[batch_idx--0] train_loss: 0.001557700103148818, acc: 0.79296875, lr: 0.04715508948078037
[batch_idx--50] train_loss: 0.0015830140282381692, acc: 0.8148743872549019, lr: 0.047128136074186804
[batch_idx--100] train_loss: 0.0015761991824475255, acc: 0.816715655940594, lr: 0.04710106336530035
[batch_idx--150] train_loss: 0.0015757084471044063, acc: 0.8157595198675497, lr: 0.04707387150008163
[batch_idx--200] train_loss: 0.0015684920890182627, acc: 0.81640625, lr: 0.04704656062513368
[batch_idx--250] train_loss: 0.0015628973381089201, acc: 0.817402265936255, lr: 0.04701913088770116
[batch_idx--300] train_loss: 0.0015622590354448834, acc: 0.8171849044850499, lr: 0.04699158243566958
[batch_idx--350] train_loss: 0.0015610463444960762, acc: 0.8174189814814815, lr: 0.04696391541756448
[batch_idx--400] train_loss: 0.0015619603000776355, acc: 0.8174680486284289, lr: 0.046936129982550645
[batch_idx--450] train_loss: 0.0015650747769551064, acc: 0.8173620994897074, lr: 0.0469082262804313
total time of one epoch: 487.0822422504425 s
train_loss:  0.0015650747769551064  acc:  0.8173620994897074
->>lr:0.046908
test_loss:  0.0017818386131073143  test_acc:  0.7929023452041196
best acc:  81.64784712743517

------Epoch: 24------
[batch_idx--0] train_loss: 0.001547681400552392, acc: 0.81640625, lr: 0.04690766700109659
[batch_idx--50] train_loss: 0.0015860207209947939, acc: 0.813265931372549, lr: 0.04687964282151817
[batch_idx--100] train_loss: 0.0015589286109875186, acc: 0.8171410891089109, lr: 0.046851500679380806
[batch_idx--150] train_loss: 0.0015522377297208206, acc: 0.8171047185430463, lr: 0.046823240726410885
[batch_idx--200] train_loss: 0.0015466210811134818, acc: 0.8180581467661692, lr: 0.046794863114969956
[batch_idx--250] train_loss: 0.0015490924813357958, acc: 0.8182737798804781, lr: 0.04676636799805392
[batch_idx--300] train_loss: 0.0015458865756435053, acc: 0.8191315406976745, lr: 0.046737755529292206
[batch_idx--350] train_loss: 0.0015483903386855652, acc: 0.8188657407407407, lr: 0.046709025862946923
[batch_idx--400] train_loss: 0.0015490406214322273, acc: 0.8190266521197007, lr: 0.046680179153912066
[batch_idx--450] train_loss: 0.0015531704559124061, acc: 0.8185163328357691, lr: 0.04665121555771262
total time of one epoch: 483.4983322620392 s
train_loss:  0.0015531704559124061  acc:  0.8185163328357691
->>lr:0.046651
test_loss:  0.0016115557165236993  test_acc:  0.819580593125698
best acc:  81.64784712743517
Saving..

------Epoch: 25------
[batch_idx--0] train_loss: 0.0013446819502860308, acc: 0.8671875, lr: 0.046650635094610975
[batch_idx--50] train_loss: 0.0015546637518769678, acc: 0.8191636029411765, lr: 0.04662155243437907
[batch_idx--100] train_loss: 0.00155275527129669, acc: 0.8185334158415841, lr: 0.04659235320306443
[batch_idx--150] train_loss: 0.0015353108039249154, acc: 0.8211920529801324, lr: 0.046563037558092685
[batch_idx--200] train_loss: 0.0015403023528268755, acc: 0.8205068407960199, lr: 0.04653360565751704
[batch_idx--250] train_loss: 0.0015456327158341785, acc: 0.8191297310756972, lr: 0.04650405766001754
[batch_idx--300] train_loss: 0.0015431175807466193, acc: 0.8196117109634552, lr: 0.04647439372490014
[batch_idx--350] train_loss: 0.0015433016684214104, acc: 0.8194333155270656, lr: 0.046444614012095875
[batch_idx--400] train_loss: 0.0015419153609844923, acc: 0.8192214775561097, lr: 0.046414718682159954
[batch_idx--450] train_loss: 0.001546053549180852, acc: 0.8194275696879231, lr: 0.04638470789627097
total time of one epoch: 484.9353220462799 s
train_loss:  0.001546053549180852  acc:  0.8194275696879231
->>lr:0.046385
test_loss:  0.0017113802798082195  test_acc:  0.79935475865492
best acc:  81.9580593125698

------Epoch: 26------
[batch_idx--0] train_loss: 0.001515173353254795, acc: 0.8046875, lr: 0.04638410650401267
[batch_idx--50] train_loss: 0.0015341365372068157, acc: 0.815640318627451, lr: 0.04635397811974326
[batch_idx--100] train_loss: 0.0015409906858135716, acc: 0.8183013613861386, lr: 0.04632373460699926
[batch_idx--150] train_loss: 0.0015419760028159383, acc: 0.8193036009933775, lr: 0.04629337612883644
[batch_idx--200] train_loss: 0.0015330435140568077, acc: 0.8205845771144279, lr: 0.046262902848930414
[batch_idx--250] train_loss: 0.0015343696104392292, acc: 0.8197678037848606, lr: 0.04623231493157573
[batch_idx--300] train_loss: 0.0015375246030844723, acc: 0.819313226744186, lr: 0.046201612541685
[batch_idx--350] train_loss: 0.0015347340761782055, acc: 0.820045405982906, lr: 0.046170795844788
[batch_idx--400] train_loss: 0.001534413866828802, acc: 0.820224828553616, lr: 0.04613986500703078
[batch_idx--450] train_loss: 0.001535374308998468, acc: 0.8205904814801958, lr: 0.0461088201951748
total time of one epoch: 486.85928988456726 s
train_loss:  0.001535374308998468  acc:  0.8205904814801958
->>lr:0.046109
test_loss:  0.001770933925225371  test_acc:  0.7874426107457501
best acc:  81.9580593125698

------Epoch: 27------
[batch_idx--0] train_loss: 0.0017222656169906259, acc: 0.76953125, lr: 0.04610819813755038
[batch_idx--50] train_loss: 0.001552349376473941, acc: 0.8162530637254902, lr: 0.04607703724454855
[batch_idx--100] train_loss: 0.001541332149241894, acc: 0.8185720915841584, lr: 0.046045762716179425
[batch_idx--150] train_loss: 0.0015355931542542398, acc: 0.820390107615894, lr: 0.04601437472105743
[batch_idx--200] train_loss: 0.0015265128867172483, acc: 0.8213813743781094, lr: 0.04598287342840873
[batch_idx--250] train_loss: 0.0015233616095103057, acc: 0.8217909611553785, lr: 0.04595125900807036
[batch_idx--300] train_loss: 0.001528620800742898, acc: 0.8208964908637874, lr: 0.045919531630489216
[batch_idx--350] train_loss: 0.001524201542221307, acc: 0.8217592592592593, lr: 0.045887691466721246
[batch_idx--400] train_loss: 0.001522531432733683, acc: 0.8218613622194514, lr: 0.04585573868843045
[batch_idx--450] train_loss: 0.0015255706076029087, acc: 0.8222220293678619, lr: 0.04582367346788801
total time of one epoch: 485.5712900161743 s
train_loss:  0.0015255706076029087  acc:  0.8222220293678619
->>lr:0.045824
test_loss:  0.0020874334093151383  test_acc:  0.7530711006328329
best acc:  81.9580593125698

------Epoch: 28------
[batch_idx--0] train_loss: 0.001535857212729752, acc: 0.8203125, lr: 0.04582303101775249
[batch_idx--50] train_loss: 0.0015424737414600803, acc: 0.8193167892156863, lr: 0.04579085128421578
[batch_idx--100] train_loss: 0.0015342457192295258, acc: 0.8212407178217822, lr: 0.04575855945826332
[batch_idx--150] train_loss: 0.0015241763506713786, acc: 0.8217611754966887, lr: 0.04572615571399419
[batch_idx--200] train_loss: 0.0015202735056081295, acc: 0.8225668532338308, lr: 0.045693640226110915
[batch_idx--250] train_loss: 0.0015154631365001557, acc: 0.8230048555776892, lr: 0.045661013169918455
[batch_idx--300] train_loss: 0.0015154542951408365, acc: 0.8235049833887044, lr: 0.04562827472132332
[batch_idx--350] train_loss: 0.001516769769829711, acc: 0.8235064992877493, lr: 0.045595425056832534
[batch_idx--400] train_loss: 0.0015224050797238724, acc: 0.8226016988778054, lr: 0.04556246435355277
[batch_idx--450] train_loss: 0.0015285530455052784, acc: 0.822195994029229, lr: 0.04552939278918935
total time of one epoch: 486.93804121017456 s
train_loss:  0.0015285530455052784  acc:  0.822195994029229
->>lr:0.045529
test_loss:  0.0015652045332064535  test_acc:  0.8218141208586673
best acc:  81.9580593125698
Saving..

------Epoch: 29------
[batch_idx--0] train_loss: 0.0015840218402445316, acc: 0.80078125, lr: 0.045528730228342605
[batch_idx--50] train_loss: 0.0015464108642738532, acc: 0.8161764705882353, lr: 0.04549554576936571
[batch_idx--100] train_loss: 0.0015247200009422285, acc: 0.820621905940594, lr: 0.04546225081009201
[batch_idx--150] train_loss: 0.0015218751273728562, acc: 0.8219681291390728, lr: 0.04542884553002893
[batch_idx--200] train_loss: 0.0015172223196786583, acc: 0.8230138370646766, lr: 0.04539533010927871
[batch_idx--250] train_loss: 0.0015161604489722991, acc: 0.8235962400398407, lr: 0.04536170472853737
[batch_idx--300] train_loss: 0.001514789075946491, acc: 0.8234271179401993, lr: 0.045327969569093796
[batch_idx--350] train_loss: 0.0015133872772155705, acc: 0.8234285968660968, lr: 0.04529412481282874
[batch_idx--400] train_loss: 0.0015124526969911972, acc: 0.8235271197007481, lr: 0.04526017064221382
[batch_idx--450] train_loss: 0.0015167870882127957, acc: 0.8236105807616204, lr: 0.04522610724031057
total time of one epoch: 478.7067623138428 s
train_loss:  0.0015167870882127957  acc:  0.8236105807616204
->>lr:0.045226
test_loss:  0.0017179783860334526  test_acc:  0.791785581337635
best acc:  82.18141208586674

------Epoch: 30------
[batch_idx--0] train_loss: 0.001448801951482892, acc: 0.828125, lr: 0.04522542485937369
[batch_idx--50] train_loss: 0.0014949064934626222, acc: 0.8291973039215687, lr: 0.04519125023075707
[batch_idx--100] train_loss: 0.001504736977841447, acc: 0.8268487004950495, lr: 0.045156966742431685
[batch_idx--150] train_loss: 0.0015056040639131768, acc: 0.8256415562913907, lr: 0.04512257457923455
[batch_idx--200] train_loss: 0.0015180545131587863, acc: 0.8231498756218906, lr: 0.04508807392658861
[batch_idx--250] train_loss: 0.0015177795824880501, acc: 0.8230982320717132, lr: 0.0450534649705017
[batch_idx--300] train_loss: 0.0015136634797922202, acc: 0.8235698712624585, lr: 0.04501874789756559
[batch_idx--350] train_loss: 0.0015095127073177627, acc: 0.823951655982906, lr: 0.04498392289495493
[batch_idx--400] train_loss: 0.001507948911017239, acc: 0.8244233167082294, lr: 0.04494899015042629
[batch_idx--450] train_loss: 0.0015115618085535943, acc: 0.8244089978130316, lr: 0.04491394985231711
total time of one epoch: 479.930775642395 s
train_loss:  0.0015115618085535943  acc:  0.8244089978130316
->>lr:0.044914
test_loss:  0.0018199499627617574  test_acc:  0.7838441493981884
best acc:  82.18141208586674

------Epoch: 31------
[batch_idx--0] train_loss: 0.0013626188738271594, acc: 0.8671875, lr: 0.04491324795060491
[batch_idx--50] train_loss: 0.0015151958008680273, acc: 0.8246783088235294, lr: 0.04487809814247016
[batch_idx--100] train_loss: 0.0015056326900064797, acc: 0.8266939975247525, lr: 0.044842841162964144
[batch_idx--150] train_loss: 0.0014913636992148907, acc: 0.8283060844370861, lr: 0.04480747720217241
[batch_idx--200] train_loss: 0.0014960216624727149, acc: 0.8270949937810945, lr: 0.04477200645075726
[batch_idx--250] train_loss: 0.001496914106762534, acc: 0.827160109561753, lr: 0.04473642909995676
[batch_idx--300] train_loss: 0.0015024081536992593, acc: 0.8260096553156147, lr: 0.044700745341583706
[batch_idx--350] train_loss: 0.001502041365656779, acc: 0.8259993767806267, lr: 0.044664955368024575
[batch_idx--400] train_loss: 0.0014988094439934427, acc: 0.8262936408977556, lr: 0.044629059372238496
[batch_idx--450] train_loss: 0.001504306432547579, acc: 0.8261794008400736, lr: 0.044593057547756214
total time of one epoch: 487.5423140525818 s
train_loss:  0.001504306432547579  acc:  0.8261794008400736
->>lr:0.044593
test_loss:  0.0015998008729269878  test_acc:  0.8170988956446209
best acc:  82.18141208586674

------Epoch: 32------
[batch_idx--0] train_loss: 0.0016189548186957836, acc: 0.79296875, lr: 0.044592336433146
[batch_idx--50] train_loss: 0.0015220189439680647, acc: 0.8214613970588235, lr: 0.04455622686336067
[batch_idx--100] train_loss: 0.00151486030208076, acc: 0.8237933168316832, lr: 0.0445200118575505
[batch_idx--150] train_loss: 0.0015121685581540826, acc: 0.8231581125827815, lr: 0.04448369161096615
[batch_idx--200] train_loss: 0.001509928120188971, acc: 0.8233636504975125, lr: 0.044447266319425686
[batch_idx--250] train_loss: 0.0015054228887206827, acc: 0.8235962400398407, lr: 0.044410736179313494
[batch_idx--300] train_loss: 0.0014991275215849428, acc: 0.8246470099667774, lr: 0.04437410138757928
[batch_idx--350] train_loss: 0.0014985773239438649, acc: 0.8245192307692307, lr: 0.04433736214173695
[batch_idx--400] train_loss: 0.001497700635664295, acc: 0.8248811564837906, lr: 0.04430051863986356
[batch_idx--450] train_loss: 0.0015018490522445028, acc: 0.8246867080917832, lr: 0.04426357108059828
total time of one epoch: 491.57369017601013 s
train_loss:  0.0015018490522445028  acc:  0.8246867080917832
->>lr:0.044264
test_loss:  0.0018294755822894206  test_acc:  0.7826033006576498
best acc:  82.18141208586674

------Epoch: 33------
[batch_idx--0] train_loss: 0.0016719279810786247, acc: 0.80078125, lr: 0.044262831069394735
[batch_idx--50] train_loss: 0.0015035285865522775, acc: 0.8214613970588235, lr: 0.04422577757680957
[batch_idx--100] train_loss: 0.0015000365778232122, acc: 0.823019801980198, lr: 0.04418862042979371
[batch_idx--150] train_loss: 0.0014945253373635625, acc: 0.8245809188741722, lr: 0.044151359828677295
[batch_idx--200] train_loss: 0.0014891813141965674, acc: 0.826220460199005, lr: 0.04411399597434825
[batch_idx--250] train_loss: 0.0014858815148361473, acc: 0.8275336155378487, lr: 0.04407652906825116
[batch_idx--300] train_loss: 0.001484013273940728, acc: 0.828125, lr: 0.04403895931238623
[batch_idx--350] train_loss: 0.0014831556413227166, acc: 0.8279469373219374, lr: 0.044001286909308164
[batch_idx--400] train_loss: 0.0014829438030510731, acc: 0.8279496571072319, lr: 0.04396351206212508
[batch_idx--450] train_loss: 0.0014895151032106892, acc: 0.8279237685284827, lr: 0.043925634974497405
total time of one epoch: 481.238055229187 s
train_loss:  0.0014895151032106892  acc:  0.8279237685284827
->>lr:0.043926
test_loss:  0.001929074041392848  test_acc:  0.764735078793895
best acc:  82.18141208586674

------Epoch: 34------
[batch_idx--0] train_loss: 0.0013868140522390604, acc: 0.828125, lr: 0.043924876391293916
[batch_idx--50] train_loss: 0.0014957383083289161, acc: 0.8252910539215687, lr: 0.0438868952287954
[batch_idx--100] train_loss: 0.00147991944657694, acc: 0.8287824876237624, lr: 0.04384881223892658
[batch_idx--150] train_loss: 0.0014771429138776186, acc: 0.8292891142384106, lr: 0.04381062762700922
[batch_idx--200] train_loss: 0.0014750755725623068, acc: 0.8298740671641791, lr: 0.043772341598912995
[batch_idx--250] train_loss: 0.0014700513065002295, acc: 0.8299769671314741, lr: 0.04373395436105431
[batch_idx--300] train_loss: 0.0014701466284153914, acc: 0.8301235465116279, lr: 0.04369546612039528
[batch_idx--350] train_loss: 0.001475138251770532, acc: 0.8289040242165242, lr: 0.04365687708444255
[batch_idx--400] train_loss: 0.0014752772903218493, acc: 0.8290309382793017, lr: 0.04361818746124621
[batch_idx--450] train_loss: 0.0014770147395998029, acc: 0.8289998958586454, lr: 0.04357939745939863
total time of one epoch: 488.8059685230255 s
train_loss:  0.0014770147395998029  acc:  0.8289998958586454
->>lr:0.043579
test_loss:  0.002700178051338049  test_acc:  0.6850725896513215
best acc:  82.18141208586674

------Epoch: 35------
[batch_idx--0] train_loss: 0.0015890463255345821, acc: 0.81640625, lr: 0.04357862063693486
[batch_idx--50] train_loss: 0.001494057976421626, acc: 0.8258272058823529, lr: 0.04353972846431615
[batch_idx--100] train_loss: 0.0014792138786691397, acc: 0.8284730816831684, lr: 0.043500736336052385
[batch_idx--150] train_loss: 0.001475277262746005, acc: 0.8297806291390728, lr: 0.04346164446236689
[batch_idx--200] train_loss: 0.0014788059857141096, acc: 0.828299906716418, lr: 0.04342245305402075
[batch_idx--250] train_loss: 0.0014711103079269132, acc: 0.8294633964143426, lr: 0.04338316232231171
[batch_idx--300] train_loss: 0.0014670025534073874, acc: 0.8306166943521595, lr: 0.043343772479072985
[batch_idx--350] train_loss: 0.0014701073652961189, acc: 0.8302061075498576, lr: 0.043304283736672146
[batch_idx--400] train_loss: 0.0014741483798826535, acc: 0.8299661003740648, lr: 0.04326469630800999
[batch_idx--450] train_loss: 0.0014801720513474646, acc: 0.8296594577706807, lr: 0.04322501040651934
total time of one epoch: 487.2584013938904 s
train_loss:  0.0014801720513474646  acc:  0.8296594577706807
->>lr:0.043225
test_loss:  0.0015925106605534992  test_acc:  0.8206973569921826
best acc:  82.18141208586674

------Epoch: 36------
[batch_idx--0] train_loss: 0.0014274443965405226, acc: 0.82421875, lr: 0.04322421568553529
[batch_idx--50] train_loss: 0.0014987315379959695, acc: 0.8261335784313726, lr: 0.04318442956218869
[batch_idx--100] train_loss: 0.0014788936235766747, acc: 0.8278929455445545, lr: 0.04314454539876614
[batch_idx--150] train_loss: 0.0014845128602884857, acc: 0.8276334850993378, lr: 0.043104563410300306
[batch_idx--200] train_loss: 0.0014746970177363994, acc: 0.8290772699004975, lr: 0.043064483812351256
[batch_idx--250] train_loss: 0.001468535802100759, acc: 0.8304749750996016, lr: 0.04302430682100536
[batch_idx--300] train_loss: 0.0014776285220265536, acc: 0.829124273255814, lr: 0.042984032652874024
[batch_idx--350] train_loss: 0.0014768112507221578, acc: 0.8295717592592593, lr: 0.04294366152509261
[batch_idx--400] train_loss: 0.0014742942337652766, acc: 0.8297907574812967, lr: 0.04290319365531922
[batch_idx--450] train_loss: 0.0014776871933590125, acc: 0.8296334224320477, lr: 0.04286262926173353
total time of one epoch: 488.27900862693787 s
train_loss:  0.0014776871933590125  acc:  0.8296334224320477
->>lr:0.042863
test_loss:  0.0021160804081945326  test_acc:  0.7451296686933863
best acc:  82.18141208586674

------Epoch: 37------
[batch_idx--0] train_loss: 0.001558300107717514, acc: 0.8203125, lr: 0.04286181699082009
[batch_idx--50] train_loss: 0.0014655652442289626, acc: 0.8279718137254902, lr: 0.04282115436825425
[batch_idx--100] train_loss: 0.0014542676623689361, acc: 0.8291305693069307, lr: 0.04278039566418517
[batch_idx--150] train_loss: 0.0014586916782381321, acc: 0.8301686672185431, lr: 0.04273954109836054
[batch_idx--200] train_loss: 0.0014563517289384459, acc: 0.8314287935323383, lr: 0.0426985908910449
[batch_idx--250] train_loss: 0.001460965228382038, acc: 0.8313464890438247, lr: 0.042657545263018404
[batch_idx--300] train_loss: 0.001459140683666639, acc: 0.8317587209302325, lr: 0.042616404435575676
[batch_idx--350] train_loss: 0.0014556615329493485, acc: 0.8322538283475783, lr: 0.04257516863052461
[batch_idx--400] train_loss: 0.0014543710311321991, acc: 0.832420900872818, lr: 0.04253383807018514
[batch_idx--450] train_loss: 0.001455589451008811, acc: 0.8328270906376922, lr: 0.042492412977388094
total time of one epoch: 487.773264169693 s
train_loss:  0.001455589451008811  acc:  0.8328270906376922
->>lr:0.042492
test_loss:  0.0018715497237131071  test_acc:  0.7718079166149646
best acc:  82.18141208586674

------Epoch: 38------
[batch_idx--0] train_loss: 0.0013208910822868347, acc: 0.84375, lr: 0.042491583512834136
[batch_idx--50] train_loss: 0.0014738441335366054, acc: 0.8275888480392157, lr: 0.04245006222701923
[batch_idx--100] train_loss: 0.0014740669359867968, acc: 0.8295946782178217, lr: 0.04240844686041831
[batch_idx--150] train_loss: 0.001464793943516318, acc: 0.8305567052980133, lr: 0.042366737637397726
[batch_idx--200] train_loss: 0.001458473308984913, acc: 0.8317591728855721, lr: 0.04232493478282982
[batch_idx--250] train_loss: 0.0014552186536361496, acc: 0.8321713147410359, lr: 0.042283038522091754
[batch_idx--300] train_loss: 0.0014574533240232258, acc: 0.8314861918604651, lr: 0.04224104908106427
[batch_idx--350] train_loss: 0.001454758906254062, acc: 0.8315972222222222, lr: 0.0421989666861305
[batch_idx--400] train_loss: 0.0014563813756807635, acc: 0.8311447942643392, lr: 0.04215679156417471
[batch_idx--450] train_loss: 0.0014581103250940403, acc: 0.8311521505189711, lr: 0.04211452394258114
total time of one epoch: 481.933940410614 s
train_loss:  0.0014581103250940403  acc:  0.8311521505189711
->>lr:0.042115
test_loss:  0.0018613252380613448  test_acc:  0.7829755552798114
best acc:  82.18141208586674

------Epoch: 39------
[batch_idx--0] train_loss: 0.0013719290727749467, acc: 0.84375, lr: 0.04211367764821722
[batch_idx--50] train_loss: 0.0014269318929234264, acc: 0.8352481617647058, lr: 0.04207131591176148
[batch_idx--100] train_loss: 0.0014592460898387402, acc: 0.8309483292079208, lr: 0.042028862136503926
[batch_idx--150] train_loss: 0.0014554359256259061, acc: 0.832005380794702, lr: 0.0419863165513311
[batch_idx--200] train_loss: 0.0014533747794959156, acc: 0.8315648320895522, lr: 0.041943679385624544
[batch_idx--250] train_loss: 0.001452206299117065, acc: 0.8314243027888446, lr: 0.04190095086925955
[batch_idx--300] train_loss: 0.0014479462949998454, acc: 0.8318106312292359, lr: 0.041858131232603915
[batch_idx--350] train_loss: 0.0014427192263740335, acc: 0.8324652777777778, lr: 0.04181522070651669
[batch_idx--400] train_loss: 0.0014445006422364058, acc: 0.8327521041147132, lr: 0.04177221952234698
[batch_idx--450] train_loss: 0.001448296160762824, acc: 0.8326014510362065, lr: 0.041729127911932645
total time of one epoch: 485.7335557937622 s
train_loss:  0.001448296160762824  acc:  0.8326014510362065
->>lr:0.041729
test_loss:  0.002102972289915046  test_acc:  0.7276337014517931
best acc:  82.18141208586674

------Epoch: 40------
[batch_idx--0] train_loss: 0.0014779489720240235, acc: 0.83203125, lr: 0.04172826515897146
[batch_idx--50] train_loss: 0.0014563400353140691, acc: 0.8287377450980392, lr: 0.04168508155313258
[batch_idx--100] train_loss: 0.0014322584075392177, acc: 0.8359761757425742, lr: 0.04164180799084732
[batch_idx--150] train_loss: 0.0014350704373853492, acc: 0.8346957781456954, lr: 0.04159844470542206
[batch_idx--200] train_loss: 0.001441204420578161, acc: 0.8334305037313433, lr: 0.041554991930646906
[batch_idx--250] train_loss: 0.0014418742630586206, acc: 0.8334474601593626, lr: 0.041511449900794445
[batch_idx--300] train_loss: 0.0014440550072817905, acc: 0.8334717607973422, lr: 0.04146781885061848
[batch_idx--350] train_loss: 0.0014458018503658622, acc: 0.8331663995726496, lr: 0.04142409901535277
[batch_idx--400] train_loss: 0.001442021263259326, acc: 0.8338820916458853, lr: 0.04138029063070971
[batch_idx--450] train_loss: 0.001445657711461992, acc: 0.8339639670913319, lr: 0.041336393932879134
total time of one epoch: 484.4396924972534 s
train_loss:  0.001445657711461992  acc:  0.8339639670913319
->>lr:0.041336
test_loss:  0.0017205037880156854  test_acc:  0.7989825040327584
best acc:  82.18141208586674

------Epoch: 41------
[batch_idx--0] train_loss: 0.001551852561533451, acc: 0.83984375, lr: 0.04133551509975264
[batch_idx--50] train_loss: 0.0014602933261616557, acc: 0.8291973039215687, lr: 0.041291528566287365
[batch_idx--100] train_loss: 0.001447436399757862, acc: 0.8320699257425742, lr: 0.041247454198189024
[batch_idx--150] train_loss: 0.0014534539370396674, acc: 0.8307119205298014, lr: 0.04120329223308148
[batch_idx--200] train_loss: 0.0014450159728925545, acc: 0.8324004975124378, lr: 0.041159042909060875
[batch_idx--250] train_loss: 0.0014434525742199257, acc: 0.8328560756972112, lr: 0.04111470646469433
[batch_idx--300] train_loss: 0.0014413773388512112, acc: 0.8333030523255814, lr: 0.04107028313901867
[batch_idx--350] train_loss: 0.0014401721606227408, acc: 0.8337673611111112, lr: 0.04102577317153916
[batch_idx--400] train_loss: 0.001437507039679219, acc: 0.8344568266832918, lr: 0.04098117680222813
[batch_idx--450] train_loss: 0.0014413866061954831, acc: 0.8343111049397716, lr: 0.04093649427152381
total time of one epoch: 489.8167173862457 s
train_loss:  0.0014413866061954831  acc:  0.8343111049397716
->>lr:0.040936
test_loss:  0.0017912648262287105  test_acc:  0.7912892418414196
best acc:  82.18141208586674

------Epoch: 42------
[batch_idx--0] train_loss: 0.0014265173813328147, acc: 0.83203125, lr: 0.040935599743717244
[batch_idx--50] train_loss: 0.0014101554475286428, acc: 0.8384650735294118, lr: 0.04089082957657292
[batch_idx--100] train_loss: 0.001420948974843515, acc: 0.8366723391089109, lr: 0.04084597373513602
[batch_idx--150] train_loss: 0.0014263985451890638, acc: 0.8348768625827815, lr: 0.04080103246124366
[batch_idx--200] train_loss: 0.001434241901661515, acc: 0.8344799440298507, lr: 0.04075600599719357
[batch_idx--250] train_loss: 0.0014367398492383411, acc: 0.8341166583665338, lr: 0.04071089458574278
[batch_idx--300] train_loss: 0.0014326349067102586, acc: 0.8347305855481728, lr: 0.04066569847010627
[batch_idx--350] train_loss: 0.0014310876770539374, acc: 0.8351250890313391, lr: 0.040620417893955756
[batch_idx--400] train_loss: 0.001428550968301991, acc: 0.8357134507481296, lr: 0.04057505310141827
[batch_idx--450] train_loss: 0.001431431722569814, acc: 0.8353264831464574, lr: 0.04052960433707492
total time of one epoch: 485.329626083374 s
train_loss:  0.001431431722569814  acc:  0.8353264831464574
->>lr:0.040530
test_loss:  0.001974124143845184  test_acc:  0.7658518426603796
best acc:  82.18141208586674

------Epoch: 43------
[batch_idx--0] train_loss: 0.0012916079722344875, acc: 0.8671875, lr: 0.040528694506957764
[batch_idx--50] train_loss: 0.0014135640744558152, acc: 0.8365502450980392, lr: 0.04048316034380937
[batch_idx--100] train_loss: 0.0014424615027844021, acc: 0.8332688737623762, lr: 0.040437542704288454
[batch_idx--150] train_loss: 0.001440880550318305, acc: 0.8336868791390728, lr: 0.04039184183433934
[batch_idx--200] train_loss: 0.001433886088945194, acc: 0.8349657960199005, lr: 0.04034605798035504
[batch_idx--250] train_loss: 0.0014359093478981005, acc: 0.8347080428286853, lr: 0.04030019138917598
[batch_idx--300] train_loss: 0.0014307057771961703, acc: 0.8359375, lr: 0.040254242308088696
[batch_idx--350] train_loss: 0.001435358817238053, acc: 0.8351473468660968, lr: 0.040208210984824425
[batch_idx--400] train_loss: 0.0014333287579125894, acc: 0.8353140586034913, lr: 0.04016209766755781
[batch_idx--450] train_loss: 0.001433602974274499, acc: 0.8355868365327872, lr: 0.040115902604905565
total time of one epoch: 485.811940908432 s
train_loss:  0.001433602974274499  acc:  0.8355868365327872
->>lr:0.040116
test_loss:  0.0016478267330170152  test_acc:  0.8138726889192207
best acc:  82.18141208586674

------Epoch: 44------
[batch_idx--0] train_loss: 0.001374071347527206, acc: 0.83984375, lr: 0.040114977871559376
[batch_idx--50] train_loss: 0.0014105925961927163, acc: 0.8391544117647058, lr: 0.04006869968519579
[batch_idx--100] train_loss: 0.0014084107369313587, acc: 0.8379873143564357, lr: 0.04002234025699524
[batch_idx--150] train_loss: 0.0014203583763061178, acc: 0.8357564155629139, lr: 0.039975899836901335
[batch_idx--200] train_loss: 0.001425745261054653, acc: 0.8361707089552238, lr: 0.03992937867529435
[batch_idx--250] train_loss: 0.001424021848228823, acc: 0.8367156374501992, lr: 0.03988277702298985
[batch_idx--300] train_loss: 0.0014252354885200874, acc: 0.836703176910299, lr: 0.03983609513123738
[batch_idx--350] train_loss: 0.0014283199230092245, acc: 0.8363270121082621, lr: 0.03978933325171908
[batch_idx--400] train_loss: 0.001428401966270366, acc: 0.8363466334164589, lr: 0.03974249163654834
[batch_idx--450] train_loss: 0.0014298095676888777, acc: 0.8361422570902906, lr: 0.03969557053826845
total time of one epoch: 487.3884449005127 s
train_loss:  0.0014298095676888777  acc:  0.8361422570902906
->>lr:0.039696
test_loss:  0.0019900462019160985  test_acc:  0.776523141829011
best acc:  82.18141208586674

------Epoch: 45------
[batch_idx--0] train_loss: 0.0014785879757255316, acc: 0.83203125, lr: 0.03969463130731183
[batch_idx--50] train_loss: 0.001407330456262856, acc: 0.8396139705882353, lr: 0.0396476293968751
[batch_idx--100] train_loss: 0.0014104878698189807, acc: 0.8386834777227723, lr: 0.03960054851477232
[batch_idx--150] train_loss: 0.001412348475597108, acc: 0.8375672599337748, lr: 0.039553388914836764
[batch_idx--200] train_loss: 0.0014130421074348227, acc: 0.8372784514925373, lr: 0.039506150851326104
[batch_idx--250] train_loss: 0.001411693341347326, acc: 0.8378361553784861, lr: 0.039458834578921055
[batch_idx--300] train_loss: 0.001415614455248356, acc: 0.8371833471760798, lr: 0.03941144035272397
[batch_idx--350] train_loss: 0.0014131116207179606, acc: 0.8370949074074074, lr: 0.03936396842825749
[batch_idx--400] train_loss: 0.0014173400607494233, acc: 0.8364830112219451, lr: 0.03931641906146319
[batch_idx--450] train_loss: 0.0014203191349253699, acc: 0.8367844621099039, lr: 0.03926879250870011
total time of one epoch: 485.97737860679626 s
train_loss:  0.0014203191349253699  acc:  0.8367844621099039
->>lr:0.039269
test_loss:  0.0015034867673169325  test_acc:  0.830500062042437
best acc:  82.18141208586674
Saving..

------Epoch: 46------
[batch_idx--0] train_loss: 0.001514240400865674, acc: 0.81640625, lr: 0.0392678391921108
[batch_idx--50] train_loss: 0.0013831611905320018, acc: 0.8426011029411765, lr: 0.03922013417419226
[batch_idx--100] train_loss: 0.0013974426800643306, acc: 0.8412360767326733, lr: 0.03917235248941817
[batch_idx--150] train_loss: 0.0014087938000478886, acc: 0.8397144039735099, lr: 0.03912449439540013
[batch_idx--200] train_loss: 0.0014106245284010448, acc: 0.8386194029850746, lr: 0.0390765601501617
[batch_idx--250] train_loss: 0.0014053679329242958, acc: 0.8397348107569721, lr: 0.03902855001213699
[batch_idx--300] train_loss: 0.0014065809399384597, acc: 0.8392727367109635, lr: 0.0389804642401693
[batch_idx--350] train_loss: 0.0014074336156312726, acc: 0.8392873041310541, lr: 0.03893230309350968
[batch_idx--400] train_loss: 0.0014077533312847935, acc: 0.8392105673316709, lr: 0.03888406683181559
[batch_idx--450] train_loss: 0.001410704502196323, acc: 0.8391016072482382, lr: 0.03883575571514944
total time of one epoch: 479.7124533653259 s
train_loss:  0.001410704502196323  acc:  0.8391016072482382
->>lr:0.038836
test_loss:  0.001731017088827949  test_acc:  0.7981139099143815
best acc:  83.0500062042437

------Epoch: 47------
[batch_idx--0] train_loss: 0.0013234148500487208, acc: 0.8515625, lr: 0.038834788731083605
[batch_idx--50] train_loss: 0.0013804088264484616, acc: 0.8404564950980392, lr: 0.038786401530680796
[batch_idx--100] train_loss: 0.0013890839331681924, acc: 0.8411200495049505, lr: 0.03873794000186154
[batch_idx--150] train_loss: 0.0013894641244574296, acc: 0.8408009105960265, lr: 0.03868940440590278
[batch_idx--200] train_loss: 0.0013919700526711138, acc: 0.8402324315920398, lr: 0.03864079500448077
[batch_idx--250] train_loss: 0.0013913965604984131, acc: 0.8406685756972112, lr: 0.03859211205966969
[batch_idx--300] train_loss: 0.0013896173892691236, acc: 0.8413231935215947, lr: 0.038543355833940224
[batch_idx--350] train_loss: 0.0013908142291282721, acc: 0.8411792200854701, lr: 0.03849452659015813
[batch_idx--400] train_loss: 0.001394004807917824, acc: 0.8409347724438903, lr: 0.03844562459158286
[batch_idx--450] train_loss: 0.0014041020412823217, acc: 0.840195091470823, lr: 0.0383966501018661
total time of one epoch: 491.5580153465271 s
train_loss:  0.0014041020412823217  acc:  0.840195091470823
->>lr:0.038397
test_loss:  0.001441420396721264  test_acc:  0.8421640402034992
best acc:  83.0500062042437
Saving..

------Epoch: 48------
[batch_idx--0] train_loss: 0.0012892552185803652, acc: 0.84765625, lr: 0.03839566987447492
[batch_idx--50] train_loss: 0.0013996997355099987, acc: 0.8382352941176471, lr: 0.038346621715813135
[batch_idx--100] train_loss: 0.0014049550622129941, acc: 0.8374071782178217, lr: 0.038297501599776934
[batch_idx--150] train_loss: 0.0013984413694170927, acc: 0.8372309602649006, lr: 0.03824830979119395
[batch_idx--200] train_loss: 0.0013992018541274824, acc: 0.8366759950248757, lr: 0.038199046555278386
[batch_idx--250] train_loss: 0.0013933706392285478, acc: 0.8376805278884463, lr: 0.038149712157629516
[batch_idx--300] train_loss: 0.0013918874110791374, acc: 0.8388834094684385, lr: 0.038100306864230285
[batch_idx--350] train_loss: 0.0013923911640468317, acc: 0.8390202101139601, lr: 0.038050830941445866
[batch_idx--400] train_loss: 0.0013889600064122395, acc: 0.840145729426434, lr: 0.03800128465602222
[batch_idx--450] train_loss: 0.0013974369243141694, acc: 0.8398305967299615, lr: 0.03795166827508467
total time of one epoch: 485.72259736061096 s
train_loss:  0.0013974369243141694  acc:  0.8398305967299615
->>lr:0.037952
test_loss:  0.001561391847662305  test_acc:  0.8221863754808288
best acc:  84.21640402034991

------Epoch: 49------
[batch_idx--0] train_loss: 0.0016278285766020417, acc: 0.82421875, lr: 0.03795067523432826
[batch_idx--50] train_loss: 0.0013985865425281956, acc: 0.8431372549019608, lr: 0.037900987631550954
[batch_idx--100] train_loss: 0.001391750658945282, acc: 0.844794245049505, lr: 0.03785123047400412
[batch_idx--150] train_loss: 0.0013879288869928445, acc: 0.8449141142384106, lr: 0.03780140402994997
[batch_idx--200] train_loss: 0.0013977017471409258, acc: 0.8428171641791045, lr: 0.03775150856802428
[batch_idx--250] train_loss: 0.0014040949684846033, acc: 0.8412132719123506, lr: 0.03770154435723495
[batch_idx--300] train_loss: 0.0013991388967229778, acc: 0.8410506644518272, lr: 0.037651511666960506
[batch_idx--350] train_loss: 0.001402348361874896, acc: 0.8403890669515669, lr: 0.03760141076694869
[batch_idx--400] train_loss: 0.001402494690945358, acc: 0.84071072319202, lr: 0.037551241927314974
[batch_idx--450] train_loss: 0.0014026442247631029, acc: 0.8413753601555177, lr: 0.03750100541854115
total time of one epoch: 485.82042503356934 s
train_loss:  0.0014026442247631029  acc:  0.8413753601555177
->>lr:0.037501
test_loss:  0.001690127932710289  test_acc:  0.8045663233651817
best acc:  84.21640402034991

------Epoch: 50------
[batch_idx--0] train_loss: 0.0014243262121453881, acc: 0.83984375, lr: 0.037500000000000006
[batch_idx--50] train_loss: 0.0013383100672131952, acc: 0.8472732843137255, lr: 0.037449694747731944
[batch_idx--100] train_loss: 0.0013654792201843592, acc: 0.8455677599009901, lr: 0.03739932237380827
[batch_idx--150] train_loss: 0.0013735841039185788, acc: 0.8446295529801324, lr: 0.03734888314980809
[batch_idx--200] train_loss: 0.0013683535788782794, acc: 0.8442747201492538, lr: 0.037298377347670955
[batch_idx--250] train_loss: 0.0013726597500638479, acc: 0.8436099352589641, lr: 0.03724780523969534
[batch_idx--300] train_loss: 0.0013764155166149387, acc: 0.843217919435216, lr: 0.03719716709853723
[batch_idx--350] train_loss: 0.0013815799888563037, acc: 0.8425592058404558, lr: 0.037146463197208594
[batch_idx--400] train_loss: 0.001382530583568066, acc: 0.8425031172069826, lr: 0.03709569380907597
[batch_idx--450] train_loss: 0.001386910601692562, acc: 0.8423560245773597, lr: 0.03704485920785895
total time of one epoch: 478.8073990345001 s
train_loss:  0.001386910601692562  acc:  0.8423560245773597
->>lr:0.037045
test_loss:  0.001807641892060998  test_acc:  0.7873185258716963
best acc:  84.21640402034991

------Epoch: 51------
[batch_idx--0] train_loss: 0.0013734818203374743, acc: 0.84765625, lr: 0.037043841852542884
[batch_idx--50] train_loss: 0.001394988311564221, acc: 0.8388480392156863, lr: 0.03699294101633032
[batch_idx--100] train_loss: 0.0013920848562133195, acc: 0.8396116955445545, lr: 0.036941975521017835
[batch_idx--150] train_loss: 0.0013857767554863497, acc: 0.8404904801324503, lr: 0.0368909456413823
[batch_idx--200] train_loss: 0.0013900731536165918, acc: 0.8409126243781094, lr: 0.03683985165254776
[batch_idx--250] train_loss: 0.0013890773919689287, acc: 0.8416334661354582, lr: 0.03678869382998386
[batch_idx--300] train_loss: 0.0013865940218661414, acc: 0.8414659468438538, lr: 0.03673747244950439
[batch_idx--350] train_loss: 0.0013863651511097524, acc: 0.8415798611111112, lr: 0.03668618778726586
[batch_idx--400] train_loss: 0.0013878190358102024, acc: 0.8414315773067331, lr: 0.0366348401197659
[batch_idx--450] train_loss: 0.001391206186643787, acc: 0.8410716145381331, lr: 0.036583429723841876
total time of one epoch: 483.14761424064636 s
train_loss:  0.001391206186643787  acc:  0.8410716145381331
->>lr:0.036583
test_loss:  0.0014381813032630952  test_acc:  0.838937833478099
best acc:  84.21640402034991

------Epoch: 52------
[batch_idx--0] train_loss: 0.0012155771255493164, acc: 0.87890625, lr: 0.036582400877996545
[batch_idx--50] train_loss: 0.0013558520392204325, acc: 0.8444393382352942, lr: 0.03653092678462853
[batch_idx--100] train_loss: 0.0013554567150716292, acc: 0.845413056930693, lr: 0.036479390523077894
[batch_idx--150] train_loss: 0.0013512333358533138, acc: 0.8462334437086093, lr: 0.036427792371198774
[batch_idx--200] train_loss: 0.0013623050441826457, acc: 0.8444301927860697, lr: 0.036376132607179
[batch_idx--250] train_loss: 0.0013754377721352466, acc: 0.8428940488047809, lr: 0.03632441150953856
[batch_idx--300] train_loss: 0.001374474890024225, acc: 0.8433217400332226, lr: 0.036272629357128106
[batch_idx--350] train_loss: 0.0013774290680553648, acc: 0.8427038817663818, lr: 0.0362207864291275
[batch_idx--400] train_loss: 0.0013780007070624861, acc: 0.8423862219451371, lr: 0.03616888300504424
[batch_idx--450] train_loss: 0.001383394362033086, acc: 0.8419221022668102, lr: 0.03611691936471199
total time of one epoch: 487.25642347335815 s
train_loss:  0.001383394362033086  acc:  0.8419221022668102
->>lr:0.036117
test_loss:  0.0024131515405065355  test_acc:  0.7088968854696612
best acc:  84.21640402034991

------Epoch: 53------
[batch_idx--0] train_loss: 0.0014501208206638694, acc: 0.82421875, lr: 0.036115879479623185
[batch_idx--50] train_loss: 0.0013781102424414427, acc: 0.8426776960784313, lr: 0.0360638547073383
[batch_idx--100] train_loss: 0.0013741654237861385, acc: 0.8437886757425742, lr: 0.036011770285057136
[batch_idx--150] train_loss: 0.001371923751592488, acc: 0.8449399834437086, lr: 0.03595962649358918
[batch_idx--200] train_loss: 0.0013698636697818392, acc: 0.8448188743781094, lr: 0.03590742361406404
[batch_idx--250] train_loss: 0.001374466611866457, acc: 0.8438433764940239, lr: 0.03585516192792988
[batch_idx--300] train_loss: 0.0013761973457930739, acc: 0.8430751661129569, lr: 0.03580284171695191
[batch_idx--350] train_loss: 0.0013731368167320547, acc: 0.8437277421652422, lr: 0.03575046326321087
[batch_idx--400] train_loss: 0.0013729611634070104, acc: 0.8435746571072319, lr: 0.035698026849101526
[batch_idx--450] train_loss: 0.0013773866484289088, acc: 0.8436230777241642, lr: 0.03564553275733112
total time of one epoch: 485.89528799057007 s
train_loss:  0.0013773866484289088  acc:  0.8436230777241642
->>lr:0.035646
test_loss:  0.001538469146773957  test_acc:  0.8242958183397444
best acc:  84.21640402034991

------Epoch: 54------
[batch_idx--0] train_loss: 0.0013501080684363842, acc: 0.84375, lr: 0.03564448228912682
[batch_idx--50] train_loss: 0.0014043922978909868, acc: 0.8374693627450981, lr: 0.035591929657709624
[batch_idx--100] train_loss: 0.001383699379898239, acc: 0.8407719678217822, lr: 0.03553931992064693
[batch_idx--150] train_loss: 0.0013715040188480095, acc: 0.8439569536423841, lr: 0.035486653361580446
[batch_idx--200] train_loss: 0.0013729738643791397, acc: 0.8438277363184079, lr: 0.03543393026445823
[batch_idx--250] train_loss: 0.0013741047146629943, acc: 0.8432675547808764, lr: 0.03538115091353316
[batch_idx--300] train_loss: 0.0013744785342879122, acc: 0.8433217400332226, lr: 0.035328315593361394
[batch_idx--350] train_loss: 0.001372268733547263, acc: 0.8437611289173789, lr: 0.03527542458880086
[batch_idx--400] train_loss: 0.001373356731929015, acc: 0.8432921602244389, lr: 0.035222478185009704
[batch_idx--450] train_loss: 0.0013761443071129147, acc: 0.8435449717082654, lr: 0.035169476667444736
total time of one epoch: 484.324907541275 s
train_loss:  0.0013761443071129147  acc:  0.8435449717082654
->>lr:0.035169
test_loss:  0.0016712256608906921  test_acc:  0.8173470653927286
best acc:  84.21640402034991

------Epoch: 55------
[batch_idx--0] train_loss: 0.00126330042257905, acc: 0.8671875, lr: 0.035168416076895005
[batch_idx--50] train_loss: 0.0014008332600853608, acc: 0.8416053921568627, lr: 0.03511535863766653
[batch_idx--100] train_loss: 0.0013896776582252713, acc: 0.8417775371287128, lr: 0.03506224666219176
[batch_idx--150] train_loss: 0.001386978512395494, acc: 0.8420943708609272, lr: 0.03500908043682018
[batch_idx--200] train_loss: 0.0013793964606167665, acc: 0.8422924440298507, lr: 0.034955860248193804
[batch_idx--250] train_loss: 0.0013777900230235965, acc: 0.8435632470119522, lr: 0.034902586383245504
[batch_idx--300] train_loss: 0.0013748243922194422, acc: 0.844515676910299, lr: 0.03484925912919761
[batch_idx--350] train_loss: 0.0013755378625130126, acc: 0.8444066061253561, lr: 0.03479587877356025
[batch_idx--400] train_loss: 0.0013729651337210786, acc: 0.8446072319201995, lr: 0.034742445604129875
[batch_idx--450] train_loss: 0.0013745176402946537, acc: 0.8448467386399139, lr: 0.034688959908987675
total time of one epoch: 481.2831211090088 s
train_loss:  0.0013745176402946537  acc:  0.8448467386399139
->>lr:0.034689
test_loss:  0.0017720579413181942  test_acc:  0.8029532200024817
best acc:  84.21640402034991

------Epoch: 56------
[batch_idx--0] train_loss: 0.0014221807941794395, acc: 0.83203125, lr: 0.034687889661302575
[batch_idx--50] train_loss: 0.0013826056018325628, acc: 0.8431372549019608, lr: 0.034634350687009215
[batch_idx--100] train_loss: 0.0013520119557304696, acc: 0.8462639232673267, lr: 0.034580759769790186
[batch_idx--150] train_loss: 0.0013671360157479513, acc: 0.8430774006622517, lr: 0.034527117198577144
[batch_idx--200] train_loss: 0.0013690878415888, acc: 0.843691697761194, lr: 0.034473423262580266
[batch_idx--250] train_loss: 0.0013691149216026543, acc: 0.8439678784860558, lr: 0.03441967825128663
[batch_idx--300] train_loss: 0.0013652069047805032, acc: 0.8444897217607974, lr: 0.0343658824544587
[batch_idx--350] train_loss: 0.0013672939940830666, acc: 0.8442508012820513, lr: 0.034312036162132735
[batch_idx--400] train_loss: 0.0013656985854260866, acc: 0.8445682668329177, lr: 0.034258139664617236
[batch_idx--450] train_loss: 0.0013695761031703418, acc: 0.8441698198354567, lr: 0.0342041932524914
total time of one epoch: 486.15486693382263 s
train_loss:  0.0013695761031703418  acc:  0.8441698198354567
->>lr:0.034204
test_loss:  0.0025618046074680394  test_acc:  0.7162178930388385
best acc:  84.21640402034991

------Epoch: 57------
[batch_idx--0] train_loss: 0.0013112525921314955, acc: 0.84375, lr: 0.03420311381711696
[batch_idx--50] train_loss: 0.0013333374027199314, acc: 0.8497242647058824, lr: 0.03414911679172232
[batch_idx--100] train_loss: 0.0013570301995455925, acc: 0.8466506806930693, lr: 0.034095070439506506
[batch_idx--150] train_loss: 0.0013694441723113029, acc: 0.8439310844370861, lr: 0.03404097505185664
[batch_idx--200] train_loss: 0.0013646285654281946, acc: 0.8444690609452736, lr: 0.0339868309204242
[batch_idx--250] train_loss: 0.0013619343164855563, acc: 0.8446370766932271, lr: 0.03393263833712346
[batch_idx--300] train_loss: 0.0013641494088821682, acc: 0.8442691029900332, lr: 0.03387839759412996
[batch_idx--350] train_loss: 0.001361482263280031, acc: 0.8442953169515669, lr: 0.03382410898387883
[batch_idx--400] train_loss: 0.0013609684706477453, acc: 0.8449384351620948, lr: 0.033769772799063326
[batch_idx--450] train_loss: 0.0013625877629871788, acc: 0.8449595584406567, lr: 0.03371538933263315
total time of one epoch: 488.9189467430115 s
train_loss:  0.0013625877629871788  acc:  0.8449595584406567
->>lr:0.033715
test_loss:  0.0015633834482259971  test_acc:  0.8169748107705671
best acc:  84.21640402034991

------Epoch: 58------
[batch_idx--0] train_loss: 0.0014382891822606325, acc: 0.828125, lr: 0.03371430118304538
[batch_idx--50] train_loss: 0.0013432546025689911, acc: 0.8462775735294118, lr: 0.03365986979142943
[batch_idx--100] train_loss: 0.0013485472156011527, acc: 0.8452583539603961, lr: 0.03360539171073317
[batch_idx--150] train_loss: 0.0013442585693474933, acc: 0.8460264900662252, lr: 0.03355086723467137
[batch_idx--200] train_loss: 0.0013444628618629788, acc: 0.8470732276119403, lr: 0.03349629665720888
[batch_idx--250] train_loss: 0.0013452816863110163, acc: 0.8468469870517928, lr: 0.03344168027255918
[batch_idx--300] train_loss: 0.0013451879040378323, acc: 0.8466180440199336, lr: 0.033387018375182646
[batch_idx--350] train_loss: 0.0013443338787554632, acc: 0.8466657763532763, lr: 0.03333231125978507
[batch_idx--400] train_loss: 0.0013437096141000044, acc: 0.8467990180798005, lr: 0.03327755922131603
[batch_idx--450] train_loss: 0.0013483000212042285, acc: 0.8464782865275801, lr: 0.033222762554967304
total time of one epoch: 487.76087737083435 s
train_loss:  0.0013483000212042285  acc:  0.8464782865275801
->>lr:0.033223
test_loss:  0.0015387130495128922  test_acc:  0.8234272242213674
best acc:  84.21640402034991

------Epoch: 59------
[batch_idx--0] train_loss: 0.0014361380599439144, acc: 0.83203125, lr: 0.03322166616846458
[batch_idx--50] train_loss: 0.0013478233401353161, acc: 0.8449754901960784, lr: 0.033166824286034645
[batch_idx--100] train_loss: 0.0013619975427783435, acc: 0.842705754950495, lr: 0.03311193837274467
[batch_idx--150] train_loss: 0.0013648943589315656, acc: 0.8431291390728477, lr: 0.03305700872450816
[batch_idx--200] train_loss: 0.0013634700786243586, acc: 0.8435945273631841, lr: 0.03300203563747449
[batch_idx--250] train_loss: 0.0013625429360199705, acc: 0.8432519920318725, lr: 0.0329470194080272
[batch_idx--300] train_loss: 0.001356117237255633, acc: 0.8448011835548173, lr: 0.032891960332782424
[batch_idx--350] train_loss: 0.0013543315581046045, acc: 0.8453080484330484, lr: 0.03283685870858731
[batch_idx--400] train_loss: 0.0013540559960703395, acc: 0.8451137780548629, lr: 0.03278171483251839
[batch_idx--450] train_loss: 0.0013583115731591413, acc: 0.8451938764883535, lr: 0.03272652900188
total time of one epoch: 485.0526566505432 s
train_loss:  0.0013583115731591413  acc:  0.8451938764883535
->>lr:0.032727
test_loss:  0.002209491126367806  test_acc:  0.7592753443355255
best acc:  84.21640402034991

------Epoch: 60------
[batch_idx--0] train_loss: 0.0011565007735043764, acc: 0.890625, lr: 0.032725424859373686
[batch_idx--50] train_loss: 0.0013560423166399786, acc: 0.8467371323529411, lr: 0.032670196541591943
[batch_idx--100] train_loss: 0.0013647115349050352, acc: 0.8455290841584159, lr: 0.03261492687048379
[batch_idx--150] train_loss: 0.0013499231284348579, acc: 0.8473975579470199, lr: 0.03255961614403176
[batch_idx--200] train_loss: 0.0013548866069565217, acc: 0.8462764303482587, lr: 0.03250426466043975
[batch_idx--250] train_loss: 0.0013487171986978873, acc: 0.8469714890438247, lr: 0.03244887271813142
[batch_idx--300] train_loss: 0.0013519124802050377, acc: 0.8472279900332226, lr: 0.032393440615748524
[batch_idx--350] train_loss: 0.0013540299459058058, acc: 0.8466991631054132, lr: 0.03233796865214936
[batch_idx--400] train_loss: 0.0013497340384907928, acc: 0.847373753117207, lr: 0.03228245712640712
[batch_idx--450] train_loss: 0.001350753819890333, acc: 0.8476932689971187, lr: 0.0322269063378083
total time of one epoch: 485.84362864494324 s
train_loss:  0.001350753819890333  acc:  0.8476932689971187
->>lr:0.032227
test_loss:  0.0014747792466844425  test_acc:  0.8314927410348678
best acc:  84.21640402034991

------Epoch: 61------
[batch_idx--0] train_loss: 0.0012371812481433153, acc: 0.8671875, lr: 0.03222579492361179
[batch_idx--50] train_loss: 0.0013290358223386255, acc: 0.8475030637254902, lr: 0.032170204395443734
[batch_idx--100] train_loss: 0.0013224564326724203, acc: 0.8497447400990099, lr: 0.03211457520962184
[batch_idx--150] train_loss: 0.001338511204273002, acc: 0.8484581953642384, lr: 0.032058907666066935
[batch_idx--200] train_loss: 0.0013446623131642072, acc: 0.8477922885572139, lr: 0.03200320206490668
[batch_idx--250] train_loss: 0.0013462710569972596, acc: 0.8474539342629482, lr: 0.03194745870647391
[batch_idx--300] train_loss: 0.001347923145839864, acc: 0.8474096760797342, lr: 0.03189167789130505
[batch_idx--350] train_loss: 0.0013461984489033492, acc: 0.8474448005698005, lr: 0.031835859920138446
[batch_idx--400] train_loss: 0.0013458522970316714, acc: 0.8477926278054863, lr: 0.03178000509391275
[batch_idx--450] train_loss: 0.0013497468938507052, acc: 0.8476759121046967, lr: 0.03172411371376536
total time of one epoch: 483.50253319740295 s
train_loss:  0.0013497468938507052  acc:  0.8476759121046967
->>lr:0.031724
test_loss:  0.0017909728085851238  test_acc:  0.7884352897381809
best acc:  84.21640402034991

------Epoch: 62------
[batch_idx--0] train_loss: 0.0015886258333921432, acc: 0.8125, lr: 0.031722995515381644
[batch_idx--50] train_loss: 0.0013494007974205649, acc: 0.8502604166666666, lr: 0.03166706716067022
[batch_idx--100] train_loss: 0.0013478824195664117, acc: 0.8475788985148515, lr: 0.03161110286093404
[batch_idx--150] train_loss: 0.001343779443201936, acc: 0.847604511589404, lr: 0.031555102917900694
[batch_idx--200] train_loss: 0.0013459122001856047, acc: 0.8472287002487562, lr: 0.03149906763348994
[batch_idx--250] train_loss: 0.0013516741699030794, acc: 0.8461155378486056, lr: 0.0314429973098121
[batch_idx--300] train_loss: 0.0013502268770406412, acc: 0.8459561877076412, lr: 0.031386892249166375
[batch_idx--350] train_loss: 0.0013468810546203938, acc: 0.8463875534188035, lr: 0.03133075275403927
[batch_idx--400] train_loss: 0.001341783159419411, acc: 0.8474224594763092, lr: 0.03127457912710293
[batch_idx--450] train_loss: 0.0013422717495117631, acc: 0.847406880272156, lr: 0.031218371671213524
total time of one epoch: 490.65609407424927 s
train_loss:  0.0013422717495117631  acc:  0.847406880272156
->>lr:0.031218
test_loss:  0.0015821478468621246  test_acc:  0.8179674897629979
best acc:  84.21640402034991

------Epoch: 63------
[batch_idx--0] train_loss: 0.0011186390183866024, acc: 0.875, lr: 0.031217247179121367
[batch_idx--50] train_loss: 0.001337365514379652, acc: 0.8491881127450981, lr: 0.0311610055298914
[batch_idx--100] train_loss: 0.0013332268578175566, acc: 0.8495513613861386, lr: 0.031104730664032437
[batch_idx--150] train_loss: 0.0013357380918529354, acc: 0.8497257864238411, lr: 0.031048422884946483
[batch_idx--200] train_loss: 0.001338720840022005, acc: 0.8486279539800995, lr: 0.030992082496212964
[batch_idx--250] train_loss: 0.0013344087600856427, acc: 0.8492747758964143, lr: 0.030935709801587143
[batch_idx--300] train_loss: 0.0013389892306061232, acc: 0.8485906353820598, lr: 0.03087930510499845
[batch_idx--350] train_loss: 0.0013391983584551263, acc: 0.8484018874643875, lr: 0.030822868710548842
[batch_idx--400] train_loss: 0.0013354176131687929, acc: 0.8488739089775561, lr: 0.030766400922511174
[batch_idx--450] train_loss: 0.0013378714572246566, acc: 0.8490818203908772, lr: 0.030709902045327583
total time of one epoch: 491.306681394577 s
train_loss:  0.0013378714572246566  acc:  0.8490818203908772
->>lr:0.030710
test_loss:  0.0017299294982067127  test_acc:  0.7987343342846507
best acc:  84.21640402034991

------Epoch: 64------
[batch_idx--0] train_loss: 0.0014474530471488833, acc: 0.84375, lr: 0.030708771752766397
[batch_idx--50] train_loss: 0.0013251831576995114, acc: 0.852328431372549, lr: 0.030652241478464032
[batch_idx--100] train_loss: 0.0013276613836112146, acc: 0.8507116336633663, lr: 0.03059568073049836
[batch_idx--150] train_loss: 0.0013208368562612164, acc: 0.8523385761589404, lr: 0.030539089813812693
[batch_idx--200] train_loss: 0.0013291335700019564, acc: 0.8509211753731343, lr: 0.03048246903351297
[batch_idx--250] train_loss: 0.0013285763740290952, acc: 0.8502085408366534, lr: 0.030425818694866172
[batch_idx--300] train_loss: 0.0013308028724938754, acc: 0.8501738995016611, lr: 0.030369139103298623
[batch_idx--350] train_loss: 0.0013283424083066525, acc: 0.8506833155270656, lr: 0.030312430564394355
[batch_idx--400] train_loss: 0.0013271473344366653, acc: 0.8507831982543641, lr: 0.03025569338389348
[batch_idx--450] train_loss: 0.0013329541476131558, acc: 0.8507133682785434, lr: 0.03019892786769053
total time of one epoch: 484.80289220809937 s
train_loss:  0.0013329541476131558  acc:  0.8507133682785434
->>lr:0.030199
test_loss:  0.0028948507262808705  test_acc:  0.7039334905075071
best acc:  84.21640402034991

------Epoch: 65------
[batch_idx--0] train_loss: 0.0015308676520362496, acc: 0.83203125, lr: 0.03019779227044398
[batch_idx--50] train_loss: 0.0013459615783729389, acc: 0.8470435049019608, lr: 0.03014099816711588
[batch_idx--100] train_loss: 0.0013491618320216785, acc: 0.8471921410891089, lr: 0.030084176346456905
[batch_idx--150] train_loss: 0.0013243799515697636, acc: 0.8500103476821192, lr: 0.030027327114817932
[batch_idx--200] train_loss: 0.0013273448778307112, acc: 0.8501438121890548, lr: 0.029970450778697578
[batch_idx--250] train_loss: 0.0013297696489343546, acc: 0.849586030876494, lr: 0.02991354764474065
[batch_idx--300] train_loss: 0.001331585442780384, acc: 0.8488631644518272, lr: 0.02985661801973638
[batch_idx--350] train_loss: 0.001332392303493309, acc: 0.8489138176638177, lr: 0.02979966221061685
[batch_idx--400] train_loss: 0.001332429139538113, acc: 0.8488739089775561, lr: 0.029742680524455323
[batch_idx--450] train_loss: 0.0013397983169797336, acc: 0.848387544693998, lr: 0.02968567326846454
total time of one epoch: 485.591835975647 s
train_loss:  0.0013397983169797336  acc:  0.848387544693998
->>lr:0.029686
test_loss:  0.0018846849447622654  test_acc:  0.7806179426727882
best acc:  84.21640402034991

------Epoch: 66------
[batch_idx--0] train_loss: 0.0012098145671188831, acc: 0.86328125, lr: 0.02968453286464312
[batch_idx--50] train_loss: 0.0013168971487960103, acc: 0.8516390931372549, lr: 0.029627499844060053
[batch_idx--100] train_loss: 0.001322653462723045, acc: 0.8507116336633663, lr: 0.029570441874636297
[batch_idx--150] train_loss: 0.0013281124002540742, acc: 0.8499586092715232, lr: 0.029513359263995894
[batch_idx--200] train_loss: 0.0013221236772890856, acc: 0.8509600435323383, lr: 0.029456252319895716
[batch_idx--250] train_loss: 0.001316141941495596, acc: 0.8518893177290837, lr: 0.029399121350223874
[batch_idx--300] train_loss: 0.001318690637389563, acc: 0.8516533430232558, lr: 0.029341966662997956
[batch_idx--350] train_loss: 0.001320433910031328, acc: 0.8511618589743589, lr: 0.02928478856636346
[batch_idx--400] train_loss: 0.0013163433344326356, acc: 0.8516599127182045, lr: 0.02922758736859208
[batch_idx--450] train_loss: 0.0013203909241414913, acc: 0.8517634602700732, lr: 0.02917036337808005
total time of one epoch: 488.58487129211426 s
train_loss:  0.0013203909241414913  acc:  0.8517634602700732
->>lr:0.029170
test_loss:  0.0016351513234538584  test_acc:  0.8106464821938206
best acc:  84.21640402034991

------Epoch: 67------
[batch_idx--0] train_loss: 0.0014669926604256034, acc: 0.8359375, lr: 0.02916921866790256
[batch_idx--50] train_loss: 0.0013280955951332169, acc: 0.8504136029411765, lr: 0.029111971746632322
[batch_idx--100] train_loss: 0.0013564865572820647, acc: 0.8466893564356436, lr: 0.02905470265595496
[batch_idx--150] train_loss: 0.0013420614120951354, acc: 0.8490531870860927, lr: 0.028997411704632756
[batch_idx--200] train_loss: 0.0013484328618013667, acc: 0.8480449315920398, lr: 0.02894009920154584
[batch_idx--250] train_loss: 0.0013476333528037268, acc: 0.847687375498008, lr: 0.02888276545569057
[batch_idx--300] train_loss: 0.0013431067515839127, acc: 0.8485127699335548, lr: 0.0288254107761778
[batch_idx--350] train_loss: 0.0013351343874620576, acc: 0.8491697827635327, lr: 0.028768035472231265
[batch_idx--400] train_loss: 0.0013328249815345145, acc: 0.8495557980049875, lr: 0.0287106398531859
[batch_idx--450] train_loss: 0.0013308753668289455, acc: 0.8500017356892422, lr: 0.02865322422848614
total time of one epoch: 486.7838122844696 s
train_loss:  0.0013308753668289455  acc:  0.8500017356892422
->>lr:0.028653
test_loss:  0.0014694770182136093  test_acc:  0.8324854200272986
best acc:  84.21640402034991

------Epoch: 68------
[batch_idx--0] train_loss: 0.0013706909958273172, acc: 0.8203125, lr: 0.028652075714060296
[batch_idx--50] train_loss: 0.001295855784715683, acc: 0.8542432598039216, lr: 0.028594640002494582
[batch_idx--100] train_loss: 0.0012796595001058413, acc: 0.8569384282178217, lr: 0.028537184910679542
[batch_idx--150] train_loss: 0.001284458531091446, acc: 0.8578487168874173, lr: 0.028479710748380266
[batch_idx--200] train_loss: 0.0012940900169767032, acc: 0.8564598880597015, lr: 0.028422217825464665
[batch_idx--250] train_loss: 0.0013000584560895405, acc: 0.8552819970119522, lr: 0.028364706451901797
[batch_idx--300] train_loss: 0.0013036401466655226, acc: 0.8544954318936877, lr: 0.028307176937760206
[batch_idx--350] train_loss: 0.0013063088138362238, acc: 0.8537660256410257, lr: 0.028249629593206222
[batch_idx--400] train_loss: 0.0013060865376813527, acc: 0.8533354114713217, lr: 0.02819206472850232
[batch_idx--450] train_loss: 0.0013110603475457291, acc: 0.8530652272017218, lr: 0.02813448265400542
total time of one epoch: 486.7568027973175 s
train_loss:  0.0013110603475457291  acc:  0.8530652272017218
->>lr:0.028134
test_loss:  0.0015385510467657573  test_acc:  0.8242958183397444
best acc:  84.21640402034991

------Epoch: 69------
[batch_idx--0] train_loss: 0.0012146236840635538, acc: 0.8671875, lr: 0.028133330839107608
[batch_idx--50] train_loss: 0.001306559737570876, acc: 0.8544730392156863, lr: 0.028075731530447786
[batch_idx--100] train_loss: 0.001287939944442841, acc: 0.8572091584158416, lr: 0.028018115639197247
[batch_idx--150] train_loss: 0.0012864500958016081, acc: 0.8568656870860927, lr: 0.027960483475988025
[batch_idx--200] train_loss: 0.0012941827855086816, acc: 0.855352145522388, lr: 0.02790283535153988
[batch_idx--250] train_loss: 0.0012979801770659587, acc: 0.854472734063745, lr: 0.027845171576658636
[batch_idx--300] train_loss: 0.0012970136177255787, acc: 0.8544175664451827, lr: 0.027787492462234484
[batch_idx--350] train_loss: 0.0013001964029861334, acc: 0.8537660256410257, lr: 0.02772979831924033
[batch_idx--400] train_loss: 0.0012997120525629871, acc: 0.8543874688279302, lr: 0.02767208945873009
[batch_idx--450] train_loss: 0.0013056017204197865, acc: 0.8535251848509043, lr: 0.027614366191837037
total time of one epoch: 487.9701507091522 s
train_loss:  0.0013056017204197865  acc:  0.8535251848509043
->>lr:0.027614
test_loss:  0.001835821480028593  test_acc:  0.7832237250279191
best acc:  84.21640402034991

------Epoch: 70------
[batch_idx--0] train_loss: 0.0011358886258676648, acc: 0.8828125, lr: 0.02761321158169134
[batch_idx--50] train_loss: 0.0013282294248175971, acc: 0.8488817401960784, lr: 0.027555473940897853
[batch_idx--100] train_loss: 0.001314074150286615, acc: 0.8510210396039604, lr: 0.027497722522445946
[batch_idx--150] train_loss: 0.001302853527722498, acc: 0.8531922599337748, lr: 0.027439957637698322
[batch_idx--200] train_loss: 0.0012963787543666156, acc: 0.8544193097014925, lr: 0.027382179598090313
[batch_idx--250] train_loss: 0.0012970383277170331, acc: 0.8548773655378487, lr: 0.027324388715128153
[batch_idx--300] train_loss: 0.0012999041736175452, acc: 0.8548328488372093, lr: 0.027266585300387343
[batch_idx--350] train_loss: 0.0012966118065741157, acc: 0.8552684294871795, lr: 0.027208769665510946
[batch_idx--400] train_loss: 0.0013006079571549211, acc: 0.8547673784289277, lr: 0.027150942122207884
[batch_idx--450] train_loss: 0.0013015678549903697, acc: 0.8548356302287639, lr: 0.027093102982251305
total time of one epoch: 488.39828395843506 s
train_loss:  0.0013015678549903697  acc:  0.8548356302287639
->>lr:0.027093
test_loss:  0.0017102566557052428  test_acc:  0.8030773048765355
best acc:  84.21640402034991

------Epoch: 71------
[batch_idx--0] train_loss: 0.0013930922141298652, acc: 0.828125, lr: 0.02709194608330789
[batch_idx--50] train_loss: 0.001298889679852508, acc: 0.8543198529411765, lr: 0.027034095436018247
[batch_idx--100] train_loss: 0.001305872814194991, acc: 0.852606745049505, lr: 0.026976233822045795
[batch_idx--150] train_loss: 0.001315593472774455, acc: 0.8517953228476821, lr: 0.026918361553347366
[batch_idx--200] train_loss: 0.0013141965236403604, acc: 0.8514070273631841, lr: 0.026860478941937244
[batch_idx--250] train_loss: 0.001307504928756164, acc: 0.8520449452191236, lr: 0.026802586299885446
[batch_idx--300] train_loss: 0.001306366887248347, acc: 0.8523022217607974, lr: 0.026744683939316106
[batch_idx--350] train_loss: 0.0013035079930309322, acc: 0.8528423254985755, lr: 0.026686772172405743
[batch_idx--400] train_loss: 0.0012986441324302402, acc: 0.8541731608478803, lr: 0.02662885131138157
[batch_idx--450] train_loss: 0.0013034412857259776, acc: 0.8535078279584823, lr: 0.026570921668519862
total time of one epoch: 490.31568908691406 s
train_loss:  0.0013034412857259776  acc:  0.8535078279584823
->>lr:0.026571
test_loss:  0.0018708198201288018  test_acc:  0.7953840426851967
best acc:  84.21640402034991

------Epoch: 72------
[batch_idx--0] train_loss: 0.0012622993672266603, acc: 0.86328125, lr: 0.026569762988232833
[batch_idx--50] train_loss: 0.0012818868751363719, acc: 0.8549325980392157, lr: 0.026511824709652916
[batch_idx--100] train_loss: 0.0012878026366049406, acc: 0.8558941831683168, lr: 0.02645387828017616
[batch_idx--150] train_loss: 0.0012894772927566672, acc: 0.8551841887417219, lr: 0.026395924012216673
[batch_idx--200] train_loss: 0.0012964022725783474, acc: 0.8541277985074627, lr: 0.02633796221823084
[batch_idx--250] train_loss: 0.0012929776833722909, acc: 0.8546283615537849, lr: 0.026279993210715575
[batch_idx--300] train_loss: 0.0012925160372710208, acc: 0.8547549833887044, lr: 0.026222017302206753
[batch_idx--350] train_loss: 0.0012950717161099117, acc: 0.8543447293447294, lr: 0.02616403480527739
[batch_idx--400] train_loss: 0.0012940295393917792, acc: 0.8544653990024937, lr: 0.02610604603253605
[batch_idx--450] train_loss: 0.001297616480164002, acc: 0.8543843510257924, lr: 0.026048051296625147
total time of one epoch: 490.8780438899994 s
train_loss:  0.001297616480164002  acc:  0.8543843510257924
->>lr:0.026048
test_loss:  0.0017218559791793567  test_acc:  0.7986102494105969
best acc:  84.21640402034991

------Epoch: 73------
[batch_idx--0] train_loss: 0.001296399743296206, acc: 0.85546875, lr: 0.02604689134322999
[batch_idx--50] train_loss: 0.0013174640229337063, acc: 0.8494944852941176, lr: 0.025988890847003655
[batch_idx--100] train_loss: 0.0013157797442509395, acc: 0.8490872524752475, lr: 0.025930885019241706
[batch_idx--150] train_loss: 0.0013051826748935295, acc: 0.8520540149006622, lr: 0.025872874172678507
[batch_idx--200] train_loss: 0.0013014509948433854, acc: 0.8529034514925373, lr: 0.02581485862007545
[batch_idx--250] train_loss: 0.0013074648767835888, acc: 0.8524651394422311, lr: 0.02575683867421932
[batch_idx--300] train_loss: 0.0013054076290574927, acc: 0.8530549210963455, lr: 0.02569881464792059
[batch_idx--350] train_loss: 0.0013048062014772936, acc: 0.8529758725071225, lr: 0.02564078685401172
[batch_idx--400] train_loss: 0.001305285088446205, acc: 0.8533646352867831, lr: 0.025582755605345495
[batch_idx--450] train_loss: 0.0013065614846230512, acc: 0.8535859339743812, lr: 0.02552472121479332
total time of one epoch: 485.06314849853516 s
train_loss:  0.0013065614846230512  acc:  0.8535859339743812
->>lr:0.025525
test_loss:  0.00145149808957154  test_acc:  0.8374488149894528
best acc:  84.21640402034991

------Epoch: 74------
[batch_idx--0] train_loss: 0.0010688264155760407, acc: 0.88671875, lr: 0.025523560497083927
[batch_idx--50] train_loss: 0.0013006856920672399, acc: 0.8524816176470589, lr: 0.025465523224145754
[batch_idx--100] train_loss: 0.0012889018531261694, acc: 0.8554300742574258, lr: 0.02540748344137178
[batch_idx--150] train_loss: 0.0012869080301182998, acc: 0.8559602649006622, lr: 0.02534944146167944
[batch_idx--200] train_loss: 0.001282773366654338, acc: 0.8568485696517413, lr: 0.025291397597997967
[batch_idx--250] train_loss: 0.0012905074854425908, acc: 0.8559511952191236, lr: 0.025233352163266793
[batch_idx--300] train_loss: 0.0012883830676706156, acc: 0.8560138081395349, lr: 0.025175305470433812
[batch_idx--350] train_loss: 0.0012874524415858047, acc: 0.8566929309116809, lr: 0.025117257832453683
[batch_idx--400] train_loss: 0.0012878338895457103, acc: 0.8567838216957606, lr: 0.025059209562286185
[batch_idx--450] train_loss: 0.001290597386905708, acc: 0.85646717811643, lr: 0.02500116097289448
total time of one epoch: 487.7789430618286 s
train_loss:  0.001290597386905708  acc:  0.85646717811643
->>lr:0.025001
test_loss:  0.0013442172433472343  test_acc:  0.8543243578607768
best acc:  84.21640402034991
Saving..

------Epoch: 75------
[batch_idx--0] train_loss: 0.0011735167354345322, acc: 0.8828125, lr: 0.025
[batch_idx--50] train_loss: 0.0012943060434076423, acc: 0.8542432598039216, lr: 0.024941951407416053
[batch_idx--100] train_loss: 0.0012961390006383604, acc: 0.8516785272277227, lr: 0.024883903127797022
[batch_idx--150] train_loss: 0.0012866079534360807, acc: 0.8538131208609272, lr: 0.02482585547410613
[batch_idx--200] train_loss: 0.0012857216255118449, acc: 0.8541277985074627, lr: 0.024767808759303227
[batch_idx--250] train_loss: 0.0012896371053613396, acc: 0.8533210906374502, lr: 0.024709763296343102
[batch_idx--300] train_loss: 0.001283836019599804, acc: 0.8545084094684385, lr: 0.024651719398173802
[batch_idx--350] train_loss: 0.0012857779111591118, acc: 0.8544671474358975, lr: 0.024593677377734924
[batch_idx--400] train_loss: 0.0012860788822643217, acc: 0.8546504831670823, lr: 0.02453563754795596
[batch_idx--450] train_loss: 0.0012881775542234485, acc: 0.8550178775991947, lr: 0.024477600221754565
total time of one epoch: 482.3163962364197 s
train_loss:  0.0012881775542234485  acc:  0.8550178775991947
->>lr:0.024478
test_loss:  0.0018514807015113817  test_acc:  0.7880630351160194
best acc:  85.43243578607768

------Epoch: 76------
[batch_idx--0] train_loss: 0.001449601142667234, acc: 0.84375, lr: 0.02447643950291608
[batch_idx--50] train_loss: 0.001303366148004345, acc: 0.8501838235294118, lr: 0.024418405052717584
[batch_idx--100] train_loss: 0.001281193960665513, acc: 0.8551206683168316, lr: 0.024360373738147447
[batch_idx--150] train_loss: 0.0012748978437627635, acc: 0.8567622102649006, lr: 0.024302345872077406
[batch_idx--200] train_loss: 0.0012856820857138442, acc: 0.8558962997512438, lr: 0.024244321767360646
[batch_idx--250] train_loss: 0.0012834910164212445, acc: 0.8560445717131474, lr: 0.024186301736830045
[batch_idx--300] train_loss: 0.0012831739157722936, acc: 0.8558970099667774, lr: 0.024128286093296536
[batch_idx--350] train_loss: 0.0012812345179906938, acc: 0.8564035790598291, lr: 0.02407027514954738
[batch_idx--400] train_loss: 0.0012845990284023217, acc: 0.8555953865336658, lr: 0.024012269218344526
[batch_idx--450] train_loss: 0.0012871566996302687, acc: 0.855581976602909, lr: 0.023954268612422863
total time of one epoch: 481.1745855808258 s
train_loss:  0.0012871566996302687  acc:  0.855581976602909
->>lr:0.023954
test_loss:  0.0016988169090788364  test_acc:  0.7997270132770815
best acc:  85.43243578607768

------Epoch: 77------
[batch_idx--0] train_loss: 0.0010982119711115956, acc: 0.89453125, lr: 0.02395310865677001
[batch_idx--50] train_loss: 0.0012561870252658777, acc: 0.8609834558823529, lr: 0.023895113804784887
[batch_idx--100] train_loss: 0.0012761420290225583, acc: 0.8579053217821783, lr: 0.02383712490971616
[batch_idx--150] train_loss: 0.0012736723897824472, acc: 0.8570209023178808, lr: 0.023779142284206876
[batch_idx--200] train_loss: 0.0012756772038170058, acc: 0.8567513992537313, lr: 0.023721166240866298
[batch_idx--250] train_loss: 0.001278007928972166, acc: 0.8561068227091634, lr: 0.0236631970922682
[batch_idx--300] train_loss: 0.0012816760160703447, acc: 0.8558840323920266, lr: 0.023605235150949158
[batch_idx--350] train_loss: 0.0012839041919609335, acc: 0.8556468126780626, lr: 0.02354728072940694
[batch_idx--400] train_loss: 0.001284237558828049, acc: 0.8555369389027432, lr: 0.02348933414009873
[batch_idx--450] train_loss: 0.0012855913215771549, acc: 0.855599333495331, lr: 0.02343139569543949
total time of one epoch: 484.9391613006592 s
train_loss:  0.0012855913215771549  acc:  0.855599333495331
->>lr:0.023431
test_loss:  0.0017156230928525393  test_acc:  0.8039458989949125
best acc:  85.43243578607768

------Epoch: 78------
[batch_idx--0] train_loss: 0.0012679446954280138, acc: 0.84375, lr: 0.023430237011767167
[batch_idx--50] train_loss: 0.0012678781789088366, acc: 0.8566942401960784, lr: 0.02337230719645424
[batch_idx--100] train_loss: 0.0012742128167854676, acc: 0.8568997524752475, lr: 0.023314386156732855
[batch_idx--150] train_loss: 0.0012766963513938107, acc: 0.8575124172185431, lr: 0.023256474204880216
[batch_idx--200] train_loss: 0.0012684062317903362, acc: 0.8582089552238806, lr: 0.023198571653124563
[batch_idx--250] train_loss: 0.001273252219295656, acc: 0.8575230328685259, lr: 0.02314067881364343
[batch_idx--300] train_loss: 0.0012721268700333652, acc: 0.8576360049833887, lr: 0.02308279599856199
[batch_idx--350] train_loss: 0.0012732175335704622, acc: 0.8574496972934473, lr: 0.023024923519951404
[batch_idx--400] train_loss: 0.0012717741780201358, acc: 0.8575436408977556, lr: 0.02296706168982706
[batch_idx--450] train_loss: 0.0012793321363294527, acc: 0.8567362099489707, lr: 0.022909210820146964
total time of one epoch: 483.11321330070496 s
train_loss:  0.0012793321363294527  acc:  0.8567362099489707
->>lr:0.022909
test_loss:  0.001461228538586079  test_acc:  0.8327335897754063
best acc:  85.43243578607768

------Epoch: 79------
[batch_idx--0] train_loss: 0.0011640620650723577, acc: 0.85546875, lr: 0.022908053916692112
[batch_idx--50] train_loss: 0.001275517735812886, acc: 0.8585324754901961, lr: 0.022850214547982983
[batch_idx--100] train_loss: 0.0012644494533317514, acc: 0.8600324876237624, lr: 0.022792386769691267
[batch_idx--150] train_loss: 0.0012675288961336807, acc: 0.8587541390728477, lr: 0.022734570893591363
[batch_idx--200] train_loss: 0.0012686182368333585, acc: 0.8586948072139303, lr: 0.022676767231393526
[batch_idx--250] train_loss: 0.0012644327712241575, acc: 0.8590014940239044, lr: 0.02261897609474213
[batch_idx--300] train_loss: 0.0012660240797028935, acc: 0.8587910091362126, lr: 0.022561197795214035
[batch_idx--350] train_loss: 0.001264217863206956, acc: 0.8590967770655271, lr: 0.022503432644316902
[batch_idx--400] train_loss: 0.001266699314797924, acc: 0.8589463840399002, lr: 0.022445680953487472
[batch_idx--450] train_loss: 0.0012723851911344709, acc: 0.8583937931752699, lr: 0.022387943034089947
total time of one epoch: 482.31664657592773 s
train_loss:  0.0012723851911344709  acc:  0.8583937931752699
->>lr:0.022388
test_loss:  0.0014661669524051162  test_acc:  0.8337262687678372
best acc:  85.43243578607768

------Epoch: 80------
[batch_idx--0] train_loss: 0.0014079944230616093, acc: 0.8125, lr: 0.022386788418308663
[batch_idx--50] train_loss: 0.0012624076494545328, acc: 0.8609834558823529, lr: 0.022329064866462054
[batch_idx--100] train_loss: 0.0012484724186176417, acc: 0.8625850866336634, lr: 0.022271355714774788
[batch_idx--150] train_loss: 0.001265850192589673, acc: 0.8598923841059603, lr: 0.022213661274381714
[batch_idx--200] train_loss: 0.0012661140621755625, acc: 0.8592972636815921, lr: 0.022155981856338363
[batch_idx--250] train_loss: 0.0012706102069608303, acc: 0.8588147410358565, lr: 0.022098317771619257
[batch_idx--300] train_loss: 0.001270458213226913, acc: 0.858375726744186, lr: 0.022040669331116272
[batch_idx--350] train_loss: 0.001273569314637118, acc: 0.8578725961538461, lr: 0.021983036845636923
[batch_idx--400] train_loss: 0.0012668511573924333, acc: 0.8589950903990025, lr: 0.02192542062590272
[batch_idx--450] train_loss: 0.0012692141321383914, acc: 0.8593050300274239, lr: 0.02186782098254747
total time of one epoch: 482.4193027019501 s
train_loss:  0.0012692141321383914  acc:  0.8593050300274239
->>lr:0.021868
test_loss:  0.001724247723717979  test_acc:  0.8077925300905819
best acc:  85.43243578607768

------Epoch: 81------
[batch_idx--0] train_loss: 0.001428895047865808, acc: 0.84765625, lr: 0.02186666916089239
[batch_idx--50] train_loss: 0.0012806719077714517, acc: 0.8549325980392157, lr: 0.021809086745365924
[batch_idx--100] train_loss: 0.0012747638358614674, acc: 0.8562035891089109, lr: 0.021751521533424346
[batch_idx--150] train_loss: 0.0012778863191314732, acc: 0.8564259105960265, lr: 0.021693973835426473
[batch_idx--200] train_loss: 0.001273566304731521, acc: 0.857295553482587, lr: 0.021636443961636685
[batch_idx--250] train_loss: 0.0012685377684150975, acc: 0.8578031623505976, lr: 0.021578932222223245
[batch_idx--300] train_loss: 0.0012676682167739122, acc: 0.8580512873754153, lr: 0.021521438927256664
[batch_idx--350] train_loss: 0.0012653301157550807, acc: 0.8584846866096866, lr: 0.021463964386708015
[batch_idx--400] train_loss: 0.0012618154673453912, acc: 0.8591704332917706, lr: 0.021406508910447243
[batch_idx--450] train_loss: 0.0012681417954221721, acc: 0.8588884646092964, lr: 0.021349072808241526
total time of one epoch: 480.8379786014557 s
train_loss:  0.0012681417954221721  acc:  0.8588884646092964
->>lr:0.021349
test_loss:  0.0014850567101337639  test_acc:  0.831368656160814
best acc:  85.43243578607768

------Epoch: 82------
[batch_idx--0] train_loss: 0.001363501069135964, acc: 0.8515625, lr: 0.021347924285939714
[batch_idx--50] train_loss: 0.0012685635341696587, acc: 0.8556985294117647, lr: 0.02129050826428394
[batch_idx--100] train_loss: 0.001254730602025543, acc: 0.8591429455445545, lr: 0.021233112242092567
[batch_idx--150] train_loss: 0.001257934946017895, acc: 0.8582367549668874, lr: 0.02117573652881221
[batch_idx--200] train_loss: 0.0012529611052361442, acc: 0.8595110385572139, lr: 0.02111838143378
[batch_idx--250] train_loss: 0.0012548880603357377, acc: 0.859312749003984, lr: 0.021061047266221912
[batch_idx--300] train_loss: 0.0012580529102851387, acc: 0.8590505606312292, lr: 0.021003734335251087
[batch_idx--350] train_loss: 0.0012573490479491397, acc: 0.8591190349002849, lr: 0.020946442949866164
[batch_idx--400] train_loss: 0.0012558736486251274, acc: 0.8594139650872819, lr: 0.020889173418949643
[batch_idx--450] train_loss: 0.001262306827591042, acc: 0.8590533550873052, lr: 0.020831926051266162
total time of one epoch: 485.8538091182709 s
train_loss:  0.001262306827591042  acc:  0.8590533550873052
->>lr:0.020832
test_loss:  0.0012838396241786477  test_acc:  0.8582950738305001
best acc:  85.43243578607768
Saving..

------Epoch: 83------
[batch_idx--0] train_loss: 0.0014256677823141217, acc: 0.8359375, lr: 0.020830781332097453
[batch_idx--50] train_loss: 0.0013038611847578602, acc: 0.8545496323529411, lr: 0.020773556888877096
[batch_idx--100] train_loss: 0.0012623292559960691, acc: 0.8601485148514851, lr: 0.020716355232228204
[batch_idx--150] train_loss: 0.0012623363310187462, acc: 0.8602545529801324, lr: 0.020659176670549492
[batch_idx--200] train_loss: 0.0012517854324032307, acc: 0.861454446517413, lr: 0.020602021512115154
[batch_idx--250] train_loss: 0.001251600725637504, acc: 0.8620984810756972, lr: 0.02054489006507322
[batch_idx--300] train_loss: 0.001249583145453474, acc: 0.8619705149501661, lr: 0.02048778263744388
[batch_idx--350] train_loss: 0.0012437300711798554, acc: 0.8626691595441596, lr: 0.02043069953711782
[batch_idx--400] train_loss: 0.0012474927206133537, acc: 0.8621512624688279, lr: 0.020373641071854572
[batch_idx--450] train_loss: 0.0012543442997475327, acc: 0.8615874613809144, lr: 0.020316607549280843
total time of one epoch: 480.6885509490967 s
train_loss:  0.0012543442997475327  acc:  0.8615874613809144
->>lr:0.020317
test_loss:  0.001647352255193926  test_acc:  0.815361707407867
best acc:  85.82950738305

------Epoch: 84------
[batch_idx--0] train_loss: 0.0013117212802171707, acc: 0.83984375, lr: 0.020315467135356893
[batch_idx--50] train_loss: 0.001271221496840464, acc: 0.8569240196078431, lr: 0.02025845937110404
[batch_idx--100] train_loss: 0.0012636264327378704, acc: 0.8586788366336634, lr: 0.020201477170534773
[batch_idx--150] train_loss: 0.001248843626763721, acc: 0.8610047599337748, lr: 0.020144520840864624
[batch_idx--200] train_loss: 0.001246830714641797, acc: 0.861435012437811, lr: 0.02008759068916964
[batch_idx--250] train_loss: 0.001253092197462011, acc: 0.8604177041832669, lr: 0.020030687022384752
[batch_idx--300] train_loss: 0.0012557179119014042, acc: 0.859984946013289, lr: 0.019973810147302068
[batch_idx--350] train_loss: 0.0012557737396942435, acc: 0.8596643518518519, lr: 0.01991696037056928
[batch_idx--400] train_loss: 0.0012571099982132434, acc: 0.8592288809226932, lr: 0.01986013799868798
[batch_idx--450] train_loss: 0.0012570377686906226, acc: 0.859235602457736, lr: 0.01980334333801198
total time of one epoch: 481.52328395843506 s
train_loss:  0.0012570377686906226  acc:  0.859235602457736
->>lr:0.019803
test_loss:  0.0013649428818240357  test_acc:  0.8502295570169996
best acc:  85.82950738305

------Epoch: 85------
[batch_idx--0] train_loss: 0.001302544609643519, acc: 0.83984375, lr: 0.019802207729556022
[batch_idx--50] train_loss: 0.0012530836724110094, acc: 0.8599877450980392, lr: 0.0197454416497602
[batch_idx--100] train_loss: 0.0012365971238924062, acc: 0.8623143564356436, lr: 0.019688703899547008
[batch_idx--150] train_loss: 0.0012458653358082652, acc: 0.8615738824503312, lr: 0.01963199478481404
[batch_idx--200] train_loss: 0.0012446994854447742, acc: 0.8608131218905473, lr: 0.019575314611304503
[batch_idx--250] train_loss: 0.0012364866591403744, acc: 0.8626587400398407, lr: 0.019518663684605593
[batch_idx--300] train_loss: 0.0012388609698200073, acc: 0.8628789451827242, lr: 0.01946204231014678
[batch_idx--350] train_loss: 0.0012394826604846727, acc: 0.8626357727920227, lr: 0.019405450793198248
[batch_idx--400] train_loss: 0.0012410555411991838, acc: 0.8617713528678305, lr: 0.01934888943886919
[batch_idx--450] train_loss: 0.0012459373262917425, acc: 0.8616482105043913, lr: 0.019292358552106172
total time of one epoch: 480.5964334011078 s
train_loss:  0.0012459373262917425  acc:  0.8616482105043913
->>lr:0.019292
test_loss:  0.0022015074913518604  test_acc:  0.753815609877156
best acc:  85.82950738305

------Epoch: 86------
[batch_idx--0] train_loss: 0.001209940412081778, acc: 0.8515625, lr: 0.019291228247233613
[batch_idx--50] train_loss: 0.0012297624306680233, acc: 0.8623621323529411, lr: 0.019234728751373553
[batch_idx--100] train_loss: 0.0012339428274680188, acc: 0.8625077351485149, lr: 0.01917826033856888
[batch_idx--150] train_loss: 0.001243753475137055, acc: 0.8614962748344371, lr: 0.019121823313265066
[batch_idx--200] train_loss: 0.0012354673968340776, acc: 0.8620763370646766, lr: 0.01906541797973838
[batch_idx--250] train_loss: 0.0012336763269472052, acc: 0.8622385458167331, lr: 0.01900904464209422
[batch_idx--300] train_loss: 0.0012301688016379915, acc: 0.8628270348837209, lr: 0.018952703604265476
[batch_idx--350] train_loss: 0.0012352059336917798, acc: 0.8628472222222222, lr: 0.018896395170010898
[batch_idx--400] train_loss: 0.0012378823629027682, acc: 0.8621902275561097, lr: 0.01884011964291346
[batch_idx--450] train_loss: 0.001242864766805825, acc: 0.8618217794286112, lr: 0.018783877326378724
total time of one epoch: 482.99097633361816 s
train_loss:  0.001242864766805825  acc:  0.8618217794286112
->>lr:0.018784
test_loss:  0.0013398574546158854  test_acc:  0.8496091326467303
best acc:  85.82950738305

------Epoch: 87------
[batch_idx--0] train_loss: 0.0013111073058098555, acc: 0.86328125, lr: 0.018782752820878636
[batch_idx--50] train_loss: 0.0012373500275334307, acc: 0.8627450980392157, lr: 0.018726544691500546
[batch_idx--100] train_loss: 0.0012382667968141856, acc: 0.8622756806930693, lr: 0.01867037038501655
[batch_idx--150] train_loss: 0.0012483397800944105, acc: 0.8598147764900662, lr: 0.018614230204286455
[batch_idx--200] train_loss: 0.0012340881046259877, acc: 0.861376710199005, lr: 0.018558124451986114
[batch_idx--250] train_loss: 0.0012328559502614179, acc: 0.8620673555776892, lr: 0.018502053430605753
[batch_idx--300] train_loss: 0.001236964226390956, acc: 0.8616330980066446, lr: 0.01844601744244835
[batch_idx--350] train_loss: 0.0012371010452832635, acc: 0.8619791666666666, lr: 0.018390016789628004
[batch_idx--400] train_loss: 0.0012368811748775554, acc: 0.8618200592269327, lr: 0.018334051774068303
[batch_idx--450] train_loss: 0.0012426374642229563, acc: 0.8608497934529802, lr: 0.0182781226975007
total time of one epoch: 483.77803468704224 s
train_loss:  0.0012426374642229563  acc:  0.8608497934529802
->>lr:0.018278
test_loss:  0.0015027272611031802  test_acc:  0.8322372502791909
best acc:  85.82950738305

------Epoch: 88------
[batch_idx--0] train_loss: 0.0008763476507738233, acc: 0.9140625, lr: 0.01827700448461836
[batch_idx--50] train_loss: 0.0012347733866715548, acc: 0.8628216911764706, lr: 0.018221112376465492
[batch_idx--100] train_loss: 0.0012303482174025018, acc: 0.8660272277227723, lr: 0.018165256816209563
[batch_idx--150] train_loss: 0.0012299915897468758, acc: 0.8653507864238411, lr: 0.018109438104991903
[batch_idx--200] train_loss: 0.001232719473397146, acc: 0.865360696517413, lr: 0.01805365654375518
[batch_idx--250] train_loss: 0.0012323922972543632, acc: 0.8645885209163346, lr: 0.017997912433241763
[batch_idx--300] train_loss: 0.0012298532557809892, acc: 0.8648255813953488, lr: 0.017942206073992117
[batch_idx--350] train_loss: 0.001233406947160198, acc: 0.8642383368945868, lr: 0.017886537766343167
[batch_idx--400] train_loss: 0.001232667961546877, acc: 0.8640995168329177, lr: 0.017830907810426684
[batch_idx--450] train_loss: 0.0012366789361670137, acc: 0.8638612142881938, lr: 0.017775316506167683
total time of one epoch: 484.3742165565491 s
train_loss:  0.0012366789361670137  acc:  0.8638612142881938
->>lr:0.017775
test_loss:  0.0014587673600723792  test_acc:  0.8358357116267527
best acc:  85.82950738305

------Epoch: 89------
[batch_idx--0] train_loss: 0.0013475921005010605, acc: 0.83984375, lr: 0.017774205076388213
[batch_idx--50] train_loss: 0.0012490140552650771, acc: 0.8595281862745098, lr: 0.017718653505586445
[batch_idx--100] train_loss: 0.0012451188989204935, acc: 0.8602258663366337, lr: 0.01766314119165336
[batch_idx--150] train_loss: 0.0012382372122085252, acc: 0.8618843129139073, lr: 0.017607668433879703
[batch_idx--200] train_loss: 0.0012303652796101993, acc: 0.863397854477612, lr: 0.017552235531342955
[batch_idx--250] train_loss: 0.0012296677559643866, acc: 0.8629233067729084, lr: 0.017496842782905715
[batch_idx--300] train_loss: 0.0012297052333125245, acc: 0.8624636627906976, lr: 0.017441490487214106
[batch_idx--350] train_loss: 0.001229277579113841, acc: 0.8625356125356125, lr: 0.017386178942696135
[batch_idx--400] train_loss: 0.001227275636354856, acc: 0.8632520261845387, lr: 0.01733090844756013
[batch_idx--450] train_loss: 0.0012306699536855357, acc: 0.8631409032526817, lr: 0.017275679299793074
total time of one epoch: 485.07332396507263 s
train_loss:  0.0012306699536855357  acc:  0.8631409032526817
->>lr:0.017276
test_loss:  0.0017024852683991175  test_acc:  0.8121355006824668
best acc:  85.82950738305

------Epoch: 90------
[batch_idx--0] train_loss: 0.0013281620340421796, acc: 0.8515625, lr: 0.017274575140626316
[batch_idx--50] train_loss: 0.0012117167740749817, acc: 0.8634344362745098, lr: 0.017219388473930602
[batch_idx--100] train_loss: 0.0012220131454638915, acc: 0.8631652227722773, lr: 0.017164243755855953
[batch_idx--150] train_loss: 0.0012306660422993613, acc: 0.8623758278145696, lr: 0.017109141283711254
[batch_idx--200] train_loss: 0.0012276396537616626, acc: 0.8630480410447762, lr: 0.0170540813545776
[batch_idx--250] train_loss: 0.0012244230884858277, acc: 0.8626276145418327, lr: 0.016999064265306747
[batch_idx--300] train_loss: 0.001221958969787778, acc: 0.8625674833887044, lr: 0.016944090312519478
[batch_idx--350] train_loss: 0.0012207192554870923, acc: 0.8627915776353277, lr: 0.01688915979260398
[batch_idx--400] train_loss: 0.001224632205835258, acc: 0.8622486751870324, lr: 0.016834273001714316
[batch_idx--450] train_loss: 0.001225951494812059, acc: 0.8624900197868574, lr: 0.016779430235768767
total time of one epoch: 481.71413135528564 s
train_loss:  0.001225951494812059  acc:  0.8624900197868574
->>lr:0.016779
test_loss:  0.0014788352913589658  test_acc:  0.8359597965008065
best acc:  85.82950738305

------Epoch: 91------
[batch_idx--0] train_loss: 0.0009470483055338264, acc: 0.90625, lr: 0.01677833383153542
[batch_idx--50] train_loss: 0.0012100049347032373, acc: 0.8667279411764706, lr: 0.016723536275641708
[batch_idx--100] train_loss: 0.0012064869665439325, acc: 0.8663366336633663, lr: 0.01666878334172139
[batch_idx--150] train_loss: 0.0012069340650337618, acc: 0.8658681705298014, lr: 0.01661407532497108
[batch_idx--200] train_loss: 0.0012171648472283426, acc: 0.8640974813432836, lr: 0.016559412520345193
[batch_idx--250] train_loss: 0.0012164856546068661, acc: 0.8639971364541833, lr: 0.016504795222554415
[batch_idx--300] train_loss: 0.0012196509186503325, acc: 0.8634759136212624, lr: 0.01645022372606408
[batch_idx--350] train_loss: 0.0012213343709967287, acc: 0.8630252849002849, lr: 0.01639569832509256
[batch_idx--400] train_loss: 0.0012186534322178144, acc: 0.8637877961346634, lr: 0.016341219313609757
[batch_idx--450] train_loss: 0.0012236465888938004, acc: 0.863687645363974, lr: 0.01628678698533542
total time of one epoch: 483.6167962551117 s
train_loss:  0.0012236465888938004  acc:  0.863687645363974
->>lr:0.016287
test_loss:  0.0017001301860051971  test_acc:  0.8101501426976052
best acc:  85.82950738305

------Epoch: 92------
[batch_idx--0] train_loss: 0.001299979630857706, acc: 0.83984375, lr: 0.016285698816954627
[batch_idx--50] train_loss: 0.0012343143633402446, acc: 0.8608302696078431, lr: 0.016231314407882003
[batch_idx--100] train_loss: 0.0012264487715115272, acc: 0.8637453589108911, lr: 0.016176977274562434
[batch_idx--150] train_loss: 0.0012204223809708279, acc: 0.8638762417218543, lr: 0.016122687709950775
[batch_idx--200] train_loss: 0.0012239394625486685, acc: 0.8627565298507462, lr: 0.01606844600674539
[batch_idx--250] train_loss: 0.001220705472554388, acc: 0.864261703187251, lr: 0.016014252457386614
[batch_idx--300] train_loss: 0.0012240584185919368, acc: 0.8638782184385382, lr: 0.015960107354055172
[batch_idx--350] train_loss: 0.0012251542195574278, acc: 0.8635817307692307, lr: 0.01590601098867059
[batch_idx--400] train_loss: 0.0012247689076155851, acc: 0.863670900872818, lr: 0.015851963652889624
[batch_idx--450] train_loss: 0.0012332353670193104, acc: 0.8631061894678377, lr: 0.015797965638104688
total time of one epoch: 483.18591046333313 s
train_loss:  0.0012332353670193104  acc:  0.8631061894678377
->>lr:0.015798
test_loss:  0.0019119251475527648  test_acc:  0.7778880754436034
best acc:  85.82950738305

------Epoch: 93------
[batch_idx--0] train_loss: 0.0012506769271567464, acc: 0.8515625, lr: 0.01579688618288306
[batch_idx--50] train_loss: 0.0011997509978291597, acc: 0.8677236519607843, lr: 0.01574293877543077
[batch_idx--100] train_loss: 0.001211949526724212, acc: 0.8654084158415841, lr: 0.015689041276774486
[batch_idx--150] train_loss: 0.0012157143715041264, acc: 0.8662562086092715, lr: 0.015635193977498796
[batch_idx--200] train_loss: 0.0012160075801790724, acc: 0.8655744713930348, lr: 0.015581397167917649
[batch_idx--250] train_loss: 0.0012128721056246306, acc: 0.866191484063745, lr: 0.01552765113807274
[batch_idx--300] train_loss: 0.0012144950981193108, acc: 0.8660714285714286, lr: 0.015473956177732033
[batch_idx--350] train_loss: 0.001215039289913318, acc: 0.8661413817663818, lr: 0.01542031257638813
[batch_idx--400] train_loss: 0.0012167208715390758, acc: 0.8660769950124688, lr: 0.015366720623256752
[batch_idx--450] train_loss: 0.0012194227890076623, acc: 0.8660481827333634, lr: 0.015313180607275165
total time of one epoch: 482.69710993766785 s
train_loss:  0.0012194227890076623  acc:  0.8660481827333634
->>lr:0.015313
test_loss:  0.0013701499307225131  test_acc:  0.8483682839061918
best acc:  85.82950738305

------Epoch: 94------
[batch_idx--0] train_loss: 0.001178699778392911, acc: 0.87890625, lr: 0.015312110338697428
[batch_idx--50] train_loss: 0.0011904872143549809, acc: 0.8733149509803921, lr: 0.015258623595981367
[batch_idx--100] train_loss: 0.0011924479293895166, acc: 0.871403155940594, lr: 0.015205189373212608
[batch_idx--150] train_loss: 0.0012148701649819136, acc: 0.8670581539735099, lr: 0.015151807958478031
[batch_idx--200] train_loss: 0.0012085873165065932, acc: 0.8674595771144279, lr: 0.015098479639579785
[batch_idx--250] train_loss: 0.0012080885170294767, acc: 0.8670629980079682, lr: 0.015045204704033754
[batch_idx--300] train_loss: 0.0012072606566841668, acc: 0.8667981727574751, lr: 0.01499198343906803
[batch_idx--350] train_loss: 0.0012092626629731595, acc: 0.8667646011396012, lr: 0.014938816131621303
[batch_idx--400] train_loss: 0.0012133896639431245, acc: 0.8658821695760599, lr: 0.014885703068341395
[batch_idx--450] train_loss: 0.0012184682423057819, acc: 0.8657878293470337, lr: 0.014832644535583656
total time of one epoch: 485.53991413116455 s
train_loss:  0.0012184682423057819  acc:  0.8657878293470337
->>lr:0.014833
test_loss:  0.0015563684201207997  test_acc:  0.8259089217024445
best acc:  85.82950738305

------Epoch: 95------
[batch_idx--0] train_loss: 0.0012019367422908545, acc: 0.87109375, lr: 0.014831583923105
[batch_idx--50] train_loss: 0.0011861794673855982, acc: 0.8651194852941176, lr: 0.014778581306178257
[batch_idx--100] train_loss: 0.0012018912936339506, acc: 0.8639387376237624, lr: 0.014725633797313148
[batch_idx--150] train_loss: 0.0011929136782650226, acc: 0.8666701158940397, lr: 0.014672741681972468
[batch_idx--200] train_loss: 0.0011948382175546047, acc: 0.8661769278606966, lr: 0.01461990524532032
[batch_idx--250] train_loss: 0.001199750486432957, acc: 0.8654755976095617, lr: 0.014567124772220653
[batch_idx--300] train_loss: 0.0011975862456337113, acc: 0.8657210340531561, lr: 0.014514400547235684
[batch_idx--350] train_loss: 0.0012041264776793173, acc: 0.8652733262108262, lr: 0.014461732854624376
[batch_idx--400] train_loss: 0.0012048594641993913, acc: 0.865190539276808, lr: 0.014409121978340905
[batch_idx--450] train_loss: 0.0012060363560404959, acc: 0.8653105148054292, lr: 0.014356568202033099
total time of one epoch: 485.4115197658539 s
train_loss:  0.0012060363560404959  acc:  0.8653105148054292
->>lr:0.014357
test_loss:  0.001367054523731198  test_acc:  0.8478719444099764
best acc:  85.82950738305

------Epoch: 96------
[batch_idx--0] train_loss: 0.0010632651392370462, acc: 0.87890625, lr: 0.014355517710873192
[batch_idx--50] train_loss: 0.0012437509938928427, acc: 0.8645067401960784, lr: 0.014303022468435317
[batch_idx--100] train_loss: 0.0012252964730614263, acc: 0.8639387376237624, lr: 0.014250584898001182
[batch_idx--150] train_loss: 0.0012030671686026582, acc: 0.8677566225165563, lr: 0.014198205282284266
[batch_idx--200] train_loss: 0.001204168414453795, acc: 0.8672846703980099, lr: 0.014145883903685591
[batch_idx--250] train_loss: 0.0011980826433087546, acc: 0.8680434511952191, lr: 0.014093621044292189
[batch_idx--300] train_loss: 0.0012040509619174581, acc: 0.8668890157807309, lr: 0.014041416985875627
[batch_idx--350] train_loss: 0.001200663468281757, acc: 0.8670539529914529, lr: 0.013989272009890398
[batch_idx--400] train_loss: 0.0012034794662328916, acc: 0.8667004364089775, lr: 0.013937186397472484
[batch_idx--450] train_loss: 0.0012079429352256992, acc: 0.866386642135592, lr: 0.01388516042943782
total time of one epoch: 480.8527648448944 s
train_loss:  0.0012079429352256992  acc:  0.866386642135592
->>lr:0.013885
test_loss:  0.0013192615869663863  test_acc:  0.857550564586177
best acc:  85.82950738305

------Epoch: 97------
[batch_idx--0] train_loss: 0.0014607366174459457, acc: 0.83203125, lr: 0.01388412052037681
[batch_idx--50] train_loss: 0.0011914698155962077, acc: 0.8695618872549019, lr: 0.01383215567857612
[batch_idx--100] train_loss: 0.0011834071950276963, acc: 0.8702815594059405, lr: 0.013780251047424422
[batch_idx--150] train_loss: 0.0011941338438287822, acc: 0.8688431291390728, lr: 0.013728406906761904
[batch_idx--200] train_loss: 0.001199974752881504, acc: 0.8680814676616916, lr: 0.013676623536102595
[batch_idx--250] train_loss: 0.0012001363204354309, acc: 0.8680745766932271, lr: 0.013624901214632912
[batch_idx--300] train_loss: 0.0011968178004707114, acc: 0.8683165490033222, lr: 0.01357324022121012
[batch_idx--350] train_loss: 0.0011977911870422484, acc: 0.8675102386039886, lr: 0.013521640834360844
[batch_idx--400] train_loss: 0.001200240734207474, acc: 0.8671387936408977, lr: 0.013470103332279566
[batch_idx--450] train_loss: 0.0012045739326638607, acc: 0.8666556739681327, lr: 0.013418627992827087
total time of one epoch: 486.04520630836487 s
train_loss:  0.0012045739326638607  acc:  0.8666556739681327
->>lr:0.013419
test_loss:  0.0013352696942046465  test_acc:  0.8484923687802457
best acc:  85.82950738305

------Epoch: 98------
[batch_idx--0] train_loss: 0.001107697724364698, acc: 0.87109375, lr: 0.013417599122003463
[batch_idx--50] train_loss: 0.0012027421594122607, acc: 0.8638939950980392, lr: 0.013366187474337023
[batch_idx--100] train_loss: 0.0011848392740749561, acc: 0.8670327970297029, lr: 0.013314838549554453
[batch_idx--150] train_loss: 0.0011912238809576147, acc: 0.8662044701986755, lr: 0.013263552624499875
[batch_idx--200] train_loss: 0.0011911059582643026, acc: 0.8667405161691543, lr: 0.01321232997567776
[batch_idx--250] train_loss: 0.0011862430044828332, acc: 0.867249750996016, lr: 0.01316117087925142
[batch_idx--300] train_loss: 0.0011886121383001811, acc: 0.8671615448504983, lr: 0.013110075611041534
[batch_idx--350] train_loss: 0.0011931847354086738, acc: 0.866653311965812, lr: 0.01305904444652466
[batch_idx--400] train_loss: 0.0011919715772429364, acc: 0.8670121571072319, lr: 0.013008077660831736
[batch_idx--450] train_loss: 0.0011974166497186235, acc: 0.8665949248446558, lr: 0.01295717552874661
total time of one epoch: 483.5651376247406 s
train_loss:  0.0011974166497186235  acc:  0.8665949248446558
->>lr:0.012957
test_loss:  0.0013208752168675985  test_acc:  0.8534557637423998
best acc:  85.82950738305

------Epoch: 99------
[batch_idx--0] train_loss: 0.0013238944811746478, acc: 0.81640625, lr: 0.012956158147457115
[batch_idx--50] train_loss: 0.0012077939486605865, acc: 0.8638174019607843, lr: 0.012905322244772761
[batch_idx--100] train_loss: 0.0011991933460743858, acc: 0.8646735767326733, lr: 0.012854551549694835
[batch_idx--150] train_loss: 0.001206736534445343, acc: 0.8646264486754967, lr: 0.012803846335949954
[batch_idx--200] train_loss: 0.001203808608286509, acc: 0.8655550373134329, lr: 0.012753206876911727
[batch_idx--250] train_loss: 0.0012001316220800122, acc: 0.8668451195219123, lr: 0.012702633445599246
[batch_idx--300] train_loss: 0.0012005987862183827, acc: 0.8667462624584718, lr: 0.012652126314675622
[batch_idx--350] train_loss: 0.001197081383256682, acc: 0.8675881410256411, lr: 0.012601685756446507
[batch_idx--400] train_loss: 0.0011946378287945193, acc: 0.8683759351620948, lr: 0.012551312042858621
[batch_idx--450] train_loss: 0.00119665864179101, acc: 0.8685302183497067, lr: 0.012501005445498313
total time of one epoch: 488.83635544776917 s
train_loss:  0.00119665864179101  acc:  0.8685302183497067
->>lr:0.012501
test_loss:  0.002003876162101915  test_acc:  0.7854572527608884
best acc:  85.82950738305

------Epoch: 100------
[batch_idx--0] train_loss: 0.0010393518023192883, acc: 0.90234375, lr: 0.012500000000000006
[batch_idx--50] train_loss: 0.0011342070464903087, acc: 0.8766084558823529, lr: 0.012449762140604802
[batch_idx--100] train_loss: 0.0011693200316639746, acc: 0.8719059405940595, lr: 0.012399591944936346
[batch_idx--150] train_loss: 0.0011700588368675025, acc: 0.871119619205298, lr: 0.012349489683483728
[batch_idx--200] train_loss: 0.0011786336979286661, acc: 0.8700248756218906, lr: 0.012299455626369788
[batch_idx--250] train_loss: 0.0011787171912958393, acc: 0.8700043575697212, lr: 0.012249490043349598
[batch_idx--300] train_loss: 0.0011847515629551859, acc: 0.868796719269103, lr: 0.01219959320380913
[batch_idx--350] train_loss: 0.0011842381330193724, acc: 0.8692129629629629, lr: 0.012149765376763677
[batch_idx--400] train_loss: 0.0011909509317466335, acc: 0.8682590399002493, lr: 0.012100006830856476
[batch_idx--450] train_loss: 0.0011964598855851206, acc: 0.8680529038081022, lr: 0.01205031783435723
total time of one epoch: 485.76331996917725 s
train_loss:  0.0011964598855851206  acc:  0.8680529038081022
->>lr:0.012050
test_loss:  0.0014472703644382936  test_acc:  0.8375728998635067
best acc:  85.82950738305

------Epoch: 101------
[batch_idx--0] train_loss: 0.00108446239028126, acc: 0.875, lr: 0.012049324765671741
[batch_idx--50] train_loss: 0.0012074060573735658, acc: 0.8669577205882353, lr: 0.01199970698555119
[batch_idx--100] train_loss: 0.0011903034300672461, acc: 0.8677676361386139, lr: 0.011950159295598187
[batch_idx--150] train_loss: 0.0011880763282919216, acc: 0.8680670529801324, lr: 0.011900681962945607
[batch_idx--200] train_loss: 0.0011886114298611582, acc: 0.8677316542288557, lr: 0.011851275254347019
[batch_idx--250] train_loss: 0.00119078016711911, acc: 0.8680278884462151, lr: 0.011801939436175232
[batch_idx--300] train_loss: 0.0011900875566951139, acc: 0.8679661544850499, lr: 0.01175267477442085
[batch_idx--350] train_loss: 0.0011931230505448144, acc: 0.8672987891737892, lr: 0.011703481534690844
[batch_idx--400] train_loss: 0.0011938252427355104, acc: 0.8673043952618454, lr: 0.011654359982207095
[batch_idx--450] train_loss: 0.001192905501110028, acc: 0.8677057659596625, lr: 0.011605310381805019
total time of one epoch: 485.97208523750305 s
train_loss:  0.001192905501110028  acc:  0.8677057659596625
->>lr:0.011605
test_loss:  0.001314461686087832  test_acc:  0.8590395830748232
best acc:  85.82950738305
Saving..

------Epoch: 102------
[batch_idx--0] train_loss: 0.001297817099839449, acc: 0.859375, lr: 0.01160433012552509
[batch_idx--50] train_loss: 0.0012059119363388448, acc: 0.8644301470588235, lr: 0.011555354188677439
[batch_idx--100] train_loss: 0.0011909428008804374, acc: 0.866878094059406, lr: 0.011506450737694249
[batch_idx--150] train_loss: 0.0012029967253830358, acc: 0.8656870860927153, lr: 0.011457620036235043
[batch_idx--200] train_loss: 0.0011973819534400877, acc: 0.8667016480099502, lr: 0.011408862347567132
[batch_idx--250] train_loss: 0.0011945009953713422, acc: 0.8670629980079682, lr: 0.011360177934564142
[batch_idx--300] train_loss: 0.0011882882354861477, acc: 0.8676287375415282, lr: 0.011311567059704701
[batch_idx--350] train_loss: 0.0011902928328807558, acc: 0.8675324964387464, lr: 0.01126302998507092
[batch_idx--400] train_loss: 0.0011863026376337537, acc: 0.8683369700748129, lr: 0.011214566972347026
[batch_idx--450] train_loss: 0.0011867478303139265, acc: 0.8684607907800187, lr: 0.01116617828281797
total time of one epoch: 477.94007444381714 s
train_loss:  0.0011867478303139265  acc:  0.8684607907800187
->>lr:0.011166
test_loss:  0.0014735577249663065  test_acc:  0.8337262687678372
best acc:  85.90395830748231

------Epoch: 103------
[batch_idx--0] train_loss: 0.0011161940637975931, acc: 0.8671875, lr: 0.011165211268916392
[batch_idx--50] train_loss: 0.0011588003607375511, acc: 0.8731617647058824, lr: 0.011116898657806221
[batch_idx--100] train_loss: 0.0011750630133019963, acc: 0.8689279084158416, lr: 0.01106866089646273
[batch_idx--150] train_loss: 0.0011759307146818679, acc: 0.8687396523178808, lr: 0.011020498244956429
[batch_idx--200] train_loss: 0.0011770874768639197, acc: 0.8694807213930348, lr: 0.010972410962952879
[batch_idx--250] train_loss: 0.001179597666811762, acc: 0.8687749003984063, lr: 0.010924399309711284
[batch_idx--300] train_loss: 0.001181856302298494, acc: 0.8686928986710963, lr: 0.010876463544083113
[batch_idx--350] train_loss: 0.0011819068074128206, acc: 0.8687789351851852, lr: 0.010828603924510663
[batch_idx--400] train_loss: 0.0011804259185937054, acc: 0.8693500623441397, lr: 0.010780820709025727
[batch_idx--450] train_loss: 0.0011791109343797417, acc: 0.8697104870344013, lr: 0.010733114155248157
total time of one epoch: 482.0822033882141 s
train_loss:  0.0011791109343797417  acc:  0.8697104870344013
->>lr:0.010733
test_loss:  0.0013529791742034432  test_acc:  0.8502295570169996
best acc:  85.90395830748231

------Epoch: 104------
[batch_idx--0] train_loss: 0.0010940867941826582, acc: 0.8671875, lr: 0.010732160807889211
[batch_idx--50] train_loss: 0.0011580162647399394, acc: 0.8740042892156863, lr: 0.010684532714024482
[batch_idx--100] train_loss: 0.0011794744964255628, acc: 0.8713258044554455, lr: 0.010636981800997085
[batch_idx--150] train_loss: 0.0011726333991013812, acc: 0.871145488410596, lr: 0.01058950832517444
[batch_idx--200] train_loss: 0.001170361376904989, acc: 0.8712492226368159, lr: 0.010542112542506449
[batch_idx--250] train_loss: 0.0011714521426321619, acc: 0.8714050049800797, lr: 0.01049479470852415
[batch_idx--300] train_loss: 0.0011729140281739128, acc: 0.8708212209302325, lr: 0.010447555078338317
[batch_idx--350] train_loss: 0.0011729234733361422, acc: 0.8703258547008547, lr: 0.010400393906638123
[batch_idx--400] train_loss: 0.001174161770523867, acc: 0.8701488466334164, lr: 0.010353311447689712
[batch_idx--450] train_loss: 0.0011741980657094752, acc: 0.8705262609782345, lr: 0.01030630795533484
total time of one epoch: 483.01221776008606 s
train_loss:  0.0011741980657094752  acc:  0.8705262609782345
->>lr:0.010306
test_loss:  0.0013324708534183448  test_acc:  0.855813376349423
best acc:  85.90395830748231

------Epoch: 105------
[batch_idx--0] train_loss: 0.0014599644346162677, acc: 0.83984375, lr: 0.010305368692688175
[batch_idx--50] train_loss: 0.001174095297898805, acc: 0.8710171568627451, lr: 0.010258446007324987
[batch_idx--100] train_loss: 0.0011702467471886757, acc: 0.8707069925742574, lr: 0.010211602800015714
[batch_idx--150] train_loss: 0.0011756047012827155, acc: 0.8700848509933775, lr: 0.010164839323312217
[batch_idx--200] train_loss: 0.0011749499734023132, acc: 0.8702775186567164, lr: 0.010118155829336504
[batch_idx--250] train_loss: 0.0011706935880479376, acc: 0.8703623007968128, lr: 0.010071552569779364
[batch_idx--300] train_loss: 0.001172224876735409, acc: 0.8700814991694352, lr: 0.010025029795898983
[batch_idx--350] train_loss: 0.0011711964271617708, acc: 0.8705373041310541, lr: 0.00997858775851964
[batch_idx--400] train_loss: 0.0011732019974671287, acc: 0.8703534133416458, lr: 0.00993222670803032
[batch_idx--450] train_loss: 0.0011746558448789302, acc: 0.8705956885479224, lr: 0.009885946894383374
total time of one epoch: 486.863561630249 s
train_loss:  0.0011746558448789302  acc:  0.8705956885479224
->>lr:0.009886
test_loss:  0.0013546682177739014  test_acc:  0.8494850477726765
best acc:  85.90395830748231

------Epoch: 106------
[batch_idx--0] train_loss: 0.001041288604028523, acc: 0.88671875, lr: 0.00988502212844063
[batch_idx--50] train_loss: 0.0011210809244920372, acc: 0.8769148284313726, lr: 0.009838825433419594
[batch_idx--100] train_loss: 0.0011363082281820992, acc: 0.8760829207920792, lr: 0.009792710478807351
[batch_idx--150] train_loss: 0.001143919801669479, acc: 0.875025869205298, lr: 0.009746677513229449
[batch_idx--200] train_loss: 0.001152576173803959, acc: 0.873056592039801, lr: 0.00970072678486938
[batch_idx--250] train_loss: 0.0011544279217074415, acc: 0.8727900896414342, lr: 0.009654858541467274
[batch_idx--300] train_loss: 0.0011559879912784404, acc: 0.8725602159468439, lr: 0.009609073030318542
[batch_idx--350] train_loss: 0.0011548808702211985, acc: 0.8728966346153846, lr: 0.009563370498272567
[batch_idx--400] train_loss: 0.0011551889423699003, acc: 0.8732757948877805, lr: 0.009517751191731351
[batch_idx--450] train_loss: 0.0011618652929606117, acc: 0.8726177665150832, lr: 0.00947221535664816
total time of one epoch: 483.4611201286316 s
train_loss:  0.0011618652929606117  acc:  0.8726177665150832
->>lr:0.009472
test_loss:  0.00127134510313759  test_acc:  0.8648715721553543
best acc:  85.90395830748231
Saving..

------Epoch: 107------
[batch_idx--0] train_loss: 0.0012427136534824967, acc: 0.8515625, lr: 0.009471305493042243
[batch_idx--50] train_loss: 0.0011133794220821822, acc: 0.8799019607843137, lr: 0.00942585505176061
[batch_idx--100] train_loss: 0.0011313459772552077, acc: 0.8767404084158416, lr: 0.009380488577388602
[batch_idx--150] train_loss: 0.0011398040216157076, acc: 0.8743791390728477, lr: 0.009335206314516387
[batch_idx--200] train_loss: 0.0011512355618897028, acc: 0.8730177238805971, lr: 0.0092900085072801
[batch_idx--250] train_loss: 0.0011528433081174484, acc: 0.8727122758964143, lr: 0.009244895399360565
[batch_idx--300] train_loss: 0.001160012023791089, acc: 0.8723395971760798, lr: 0.009199867233981912
[batch_idx--350] train_loss: 0.0011643168831209619, acc: 0.8718060007122507, lr: 0.009154924253910346
[batch_idx--400] train_loss: 0.0011612749056126505, acc: 0.8719314993765586, lr: 0.009110066701452797
[batch_idx--450] train_loss: 0.0011613647917968171, acc: 0.8720102752803138, lr: 0.0090652948184556
total time of one epoch: 484.7182228565216 s
train_loss:  0.0011613647917968171  acc:  0.8720102752803138
->>lr:0.009065
test_loss:  0.0013392347380664985  test_acc:  0.8533316788683459
best acc:  86.48715721553543

------Epoch: 108------
[batch_idx--0] train_loss: 0.001092558610253036, acc: 0.875, lr: 0.009064400256282757
[batch_idx--50] train_loss: 0.0011259764250294835, acc: 0.8733149509803921, lr: 0.009019716004806225
[batch_idx--100] train_loss: 0.0011345341203429986, acc: 0.8743038366336634, lr: 0.0089751179099095
[batch_idx--150] train_loss: 0.0011391968902706212, acc: 0.8741980546357616, lr: 0.008930606212040063
[batch_idx--200] train_loss: 0.0011417675457561195, acc: 0.8743975435323383, lr: 0.00888618115117962
[batch_idx--250] train_loss: 0.0011512856161503856, acc: 0.8728834661354582, lr: 0.00884184296684277
[batch_idx--300] train_loss: 0.0011559516031749892, acc: 0.8720021802325582, lr: 0.00879759189807571
[batch_idx--350] train_loss: 0.0011603368901942149, acc: 0.8716501958689459, lr: 0.008753428183455004
[batch_idx--400] train_loss: 0.0011586678040764315, acc: 0.8722432200748129, lr: 0.008709352061086187
[batch_idx--450] train_loss: 0.0011593573687433034, acc: 0.8725223036067622, lr: 0.008665363768602597
total time of one epoch: 481.2319920063019 s
train_loss:  0.0011593573687433034  acc:  0.8725223036067622
->>lr:0.008665
test_loss:  0.001981736124412403  test_acc:  0.7859535922571038
best acc:  86.48715721553543

------Epoch: 109------
[batch_idx--0] train_loss: 0.0011601190781220794, acc: 0.88671875, lr: 0.008664484900247363
[batch_idx--50] train_loss: 0.0011667353991309509, acc: 0.8678002450980392, lr: 0.00862058643856546
[batch_idx--100] train_loss: 0.001153153563287146, acc: 0.8717512376237624, lr: 0.0085767762853424
[batch_idx--150] train_loss: 0.0011480323066749912, acc: 0.8730080711920529, lr: 0.008533054676777554
[batch_idx--200] train_loss: 0.0011482402894863702, acc: 0.873037157960199, lr: 0.008489421848592919
[batch_idx--250] train_loss: 0.0011497743938403925, acc: 0.873039093625498, lr: 0.008445878036031801
[batch_idx--300] train_loss: 0.0011540500606113172, acc: 0.8728976328903655, lr: 0.008402423473857626
[batch_idx--350] train_loss: 0.0011550452741940222, acc: 0.8728187321937322, lr: 0.008359058396352615
[batch_idx--400] train_loss: 0.0011550808823876492, acc: 0.8726620947630923, lr: 0.008315783037316537
[batch_idx--450] train_loss: 0.0011631465462120909, acc: 0.8721317735272677, lr: 0.008272597630065468
total time of one epoch: 486.9102144241333 s
train_loss:  0.0011631465462120909  acc:  0.8721317735272677
->>lr:0.008273
test_loss:  0.0014040847616909248  test_acc:  0.8462588410472763
best acc:  86.48715721553543

------Epoch: 110------
[batch_idx--0] train_loss: 0.0012940941378474236, acc: 0.8671875, lr: 0.008271734841028545
[batch_idx--50] train_loss: 0.0011642408139510628, acc: 0.8697916666666666, lr: 0.008228641424457422
[batch_idx--100] train_loss: 0.0011569692823565612, acc: 0.87109375, lr: 0.00818563842948918
[batch_idx--150] train_loss: 0.0011542563373685524, acc: 0.8707057119205298, lr: 0.008142726087971458
[batch_idx--200] train_loss: 0.0011535164571728612, acc: 0.8713075248756219, lr: 0.00809990463126313
[batch_idx--250] train_loss: 0.0011504437459959275, acc: 0.8719652639442231, lr: 0.008057174290233077
[batch_idx--300] train_loss: 0.0011530175133673258, acc: 0.8718983596345515, lr: 0.008014535295258926
[batch_idx--350] train_loss: 0.0011544274166226387, acc: 0.8721509971509972, lr: 0.00797198787622585
[batch_idx--400] train_loss: 0.0011567196438897244, acc: 0.8719120168329177, lr: 0.007929532262525246
[batch_idx--450] train_loss: 0.0011592122544158347, acc: 0.8720623459575798, lr: 0.007887168683053591
total time of one epoch: 481.77884340286255 s
train_loss:  0.0011592122544158347  acc:  0.8720623459575798
->>lr:0.007887
test_loss:  0.001370281317583428  test_acc:  0.847375604913761
best acc:  86.48715721553543

------Epoch: 111------
[batch_idx--0] train_loss: 0.0012238789349794388, acc: 0.87109375, lr: 0.00788632235178279
[batch_idx--50] train_loss: 0.0011360417736475082, acc: 0.8740042892156863, lr: 0.00784405288251919
[batch_idx--100] train_loss: 0.001146066169102335, acc: 0.8736076732673267, lr: 0.007801875908340622
[batch_idx--150] train_loss: 0.0011527849641159817, acc: 0.8729045943708609, lr: 0.007759791656641275
[batch_idx--200] train_loss: 0.001153323810665743, acc: 0.8734452736318408, lr: 0.007717800354315446
[batch_idx--250] train_loss: 0.0011532450877723703, acc: 0.873070219123506, lr: 0.007675902227756282
[batch_idx--300] train_loss: 0.0011563677947188532, acc: 0.872936565614618, lr: 0.007634097502854598
[batch_idx--350] train_loss: 0.0011567773053321744, acc: 0.8729967948717948, lr: 0.007592386404997634
[batch_idx--400] train_loss: 0.0011582316428961747, acc: 0.872720542394015, lr: 0.007550769159067847
[batch_idx--450] train_loss: 0.0011611538201898464, acc: 0.872704550977193, lr: 0.00750924598944171
total time of one epoch: 483.77782130241394 s
train_loss:  0.0011611538201898464  acc:  0.872704550977193
->>lr:0.007509
test_loss:  0.001216354062368178  test_acc:  0.8714480704802084
best acc:  86.48715721553543
Saving..

------Epoch: 112------
[batch_idx--0] train_loss: 0.0012579495087265968, acc: 0.859375, lr: 0.007508416487165862
[batch_idx--50] train_loss: 0.0011529638740124509, acc: 0.87109375, lr: 0.007466989505996053
[batch_idx--100] train_loss: 0.0011650216650439076, acc: 0.8705909653465347, lr: 0.007425657052821996
[batch_idx--150] train_loss: 0.001166151207794639, acc: 0.8698520281456954, lr: 0.007384419350484717
[batch_idx--200] train_loss: 0.0011594474399045332, acc: 0.87109375, lr: 0.0073432766213143985
[batch_idx--250] train_loss: 0.001151339115252147, acc: 0.8725877739043825, lr: 0.007302229087129178
[batch_idx--300] train_loss: 0.0011492723369339723, acc: 0.8730793189368771, lr: 0.007261276969233954
[batch_idx--350] train_loss: 0.0011472016131171049, acc: 0.8731414707977208, lr: 0.007220420488419194
[batch_idx--400] train_loss: 0.0011452496302328038, acc: 0.8731686408977556, lr: 0.007179659864959754
[batch_idx--450] train_loss: 0.0011529247769028425, acc: 0.8728781199014128, lr: 0.007138995318613667
total time of one epoch: 482.26412177085876 s
train_loss:  0.0011529247769028425  acc:  0.8728781199014128
->>lr:0.007139
test_loss:  0.001283408065545735  test_acc:  0.8595359225710386
best acc:  87.14480704802085

------Epoch: 113------
[batch_idx--0] train_loss: 0.0011368074920028448, acc: 0.87109375, lr: 0.007138183009179922
[batch_idx--50] train_loss: 0.0011282375586840014, acc: 0.8764552696078431, lr: 0.007097616687346986
[batch_idx--100] train_loss: 0.001137329283340991, acc: 0.8752707301980198, lr: 0.00705714688495745
[batch_idx--150] train_loss: 0.0011345743173147421, acc: 0.8752586920529801, lr: 0.007016773820201414
[batch_idx--200] train_loss: 0.001136660791611512, acc: 0.8745141480099502, lr: 0.00697649771074741
[batch_idx--250] train_loss: 0.001134167795915498, acc: 0.8749221862549801, lr: 0.006936318773741257
[batch_idx--300] train_loss: 0.0011315923365934496, acc: 0.8755969684385382, lr: 0.00689623722580488
[batch_idx--350] train_loss: 0.0011379440801624113, acc: 0.8742543625356125, lr: 0.006856253283035133
[batch_idx--400] train_loss: 0.0011393100744986587, acc: 0.8740356140897756, lr: 0.00681636716100264
[batch_idx--450] train_loss: 0.0011421287375477298, acc: 0.8742493144027493, lr: 0.006776579074750619
total time of one epoch: 482.6696608066559 s
train_loss:  0.0011421287375477298  acc:  0.8742493144027493
->>lr:0.006777
test_loss:  0.0014261592779077894  test_acc:  0.8474996897878149
best acc:  87.14480704802085

------Epoch: 114------
[batch_idx--0] train_loss: 0.0011485567083582282, acc: 0.86328125, lr: 0.006775784314464717
[batch_idx--50] train_loss: 0.001136303913560422, acc: 0.8756127450980392, lr: 0.006736096445698165
[batch_idx--100] train_loss: 0.0011421176950714672, acc: 0.8750386757425742, lr: 0.0066965070454860194
[batch_idx--150] train_loss: 0.001140450785824696, acc: 0.8740169701986755, lr: 0.006657016327271753
[batch_idx--200] train_loss: 0.0011392932979445627, acc: 0.8745530161691543, lr: 0.006617624503966805
[batch_idx--250] train_loss: 0.0011433841710709837, acc: 0.8738172310756972, lr: 0.006578331787949427
[batch_idx--300] train_loss: 0.0011442295920360598, acc: 0.8738190406976745, lr: 0.006539138391063526
[batch_idx--350] train_loss: 0.0011409323278116727, acc: 0.8742766203703703, lr: 0.006500044524617568
[batch_idx--400] train_loss: 0.0011372730862279597, acc: 0.8747077618453866, lr: 0.0064610503993833834
[batch_idx--450] train_loss: 0.001140050713408555, acc: 0.8750303745617385, lr: 0.006422156225595066
total time of one epoch: 480.82901263237 s
train_loss:  0.001140050713408555  acc:  0.8750303745617385
->>lr:0.006422
test_loss:  0.0012755650901693848  test_acc:  0.864251147785085
best acc:  87.14480704802085

------Epoch: 115------
[batch_idx--0] train_loss: 0.0012417570687830448, acc: 0.84765625, lr: 0.00642137936306515
[batch_idx--50] train_loss: 0.001148873272434096, acc: 0.8754595588235294, lr: 0.006382587355775901
[batch_idx--100] train_loss: 0.0011371808906897238, acc: 0.8771271658415841, lr: 0.006343895722960522
[batch_idx--150] train_loss: 0.001141630614635886, acc: 0.8764228062913907, lr: 0.006305304673222229
[batch_idx--200] train_loss: 0.001135288163456621, acc: 0.8763409514925373, lr: 0.0062668144146219495
[batch_idx--250] train_loss: 0.0011307442624797206, acc: 0.8768519671314741, lr: 0.006228425154677217
[batch_idx--300] train_loss: 0.0011321404837443187, acc: 0.8771153446843853, lr: 0.0061901371003610295
[batch_idx--350] train_loss: 0.0011315469912311694, acc: 0.8769920762108262, lr: 0.00615195045810075
[batch_idx--400] train_loss: 0.0011307584441747711, acc: 0.8769287718204489, lr: 0.006113865433776986
[batch_idx--450] train_loss: 0.0011305928909985919, acc: 0.8770177387440553, lr: 0.006075882232722457
total time of one epoch: 482.7099406719208 s
train_loss:  0.0011305928909985919  acc:  0.8770177387440553
->>lr:0.006076
test_loss:  0.0012385866669807383  test_acc:  0.8653679116515697
best acc:  87.14480704802085

------Epoch: 116------
[batch_idx--0] train_loss: 0.0012464867904782295, acc: 0.86328125, lr: 0.006075123608706093
[batch_idx--50] train_loss: 0.0011315095653830498, acc: 0.8740042892156863, lr: 0.006037244478350651
[batch_idx--100] train_loss: 0.0011371945608453363, acc: 0.8739170792079208, lr: 0.00599946758436096
[batch_idx--150] train_loss: 0.001135980829115439, acc: 0.8742239238410596, lr: 0.005961793130408489
[batch_idx--200] train_loss: 0.0011377759122600157, acc: 0.8747862251243781, lr: 0.005924221319612417
[batch_idx--250] train_loss: 0.0011299837151527465, acc: 0.8758559511952191, lr: 0.005886752354538527
[batch_idx--300] train_loss: 0.00113703631966118, acc: 0.8744549418604651, lr: 0.0058493864371981065
[batch_idx--350] train_loss: 0.0011362848828939398, acc: 0.8744880698005698, lr: 0.005812123769046874
[batch_idx--400] train_loss: 0.0011335925799748046, acc: 0.8747954332917706, lr: 0.005774964550983902
[batch_idx--450] train_loss: 0.0011384112579830735, acc: 0.8747353073905648, lr: 0.005737908983350504
total time of one epoch: 483.76275396347046 s
train_loss:  0.0011384112579830735  acc:  0.8747353073905648
->>lr:0.005738
test_loss:  0.0014595784647231924  test_acc:  0.8407991065889068
best acc:  87.14480704802085

------Epoch: 117------
[batch_idx--0] train_loss: 0.001175728626549244, acc: 0.88671875, lr: 0.005737168930605272
[batch_idx--50] train_loss: 0.0011386211708133273, acc: 0.8736213235294118, lr: 0.005700219292222111
[batch_idx--100] train_loss: 0.0011247731215034676, acc: 0.8755414603960396, lr: 0.005663373707252357
[batch_idx--150] train_loss: 0.0011248646565367598, acc: 0.8754915149006622, lr: 0.005626632374346372
[batch_idx--200] train_loss: 0.0011240382660273, acc: 0.8753498134328358, lr: 0.005589995491592479
[batch_idx--250] train_loss: 0.001123496026785829, acc: 0.8761360806772909, lr: 0.005553463256515865
[batch_idx--300] train_loss: 0.001127432977263986, acc: 0.8755710132890365, lr: 0.005517035866077508
[batch_idx--350] train_loss: 0.0011327074413808684, acc: 0.8754340277777778, lr: 0.0054807135166731365
[batch_idx--400] train_loss: 0.0011354191266487997, acc: 0.8750584476309227, lr: 0.005444496404132135
[batch_idx--450] train_loss: 0.0011340900396929936, acc: 0.875455618426077, lr: 0.005408384723716528
total time of one epoch: 481.4818344116211 s
train_loss:  0.0011340900396929936  acc:  0.875455618426077
->>lr:0.005408
test_loss:  0.0014131380963198288  test_acc:  0.8497332175207842
best acc:  87.14480704802085

------Epoch: 118------
[batch_idx--0] train_loss: 0.0011353668523952365, acc: 0.8828125, lr: 0.005407663566854007
[batch_idx--50] train_loss: 0.0011364483941054227, acc: 0.8758425245098039, lr: 0.005371659627775735
[batch_idx--100] train_loss: 0.0011213475401457952, acc: 0.8779006806930693, lr: 0.005335761513517229
[batch_idx--150] train_loss: 0.001111267540073454, acc: 0.8777421357615894, lr: 0.0052999694176206515
[batch_idx--200] train_loss: 0.001116648986495438, acc: 0.877021144278607, lr: 0.005264283533056586
[batch_idx--250] train_loss: 0.001113246691522682, acc: 0.8774744770916335, lr: 0.0052287040522229575
[batch_idx--300] train_loss: 0.0011153734344029893, acc: 0.8775436046511628, lr: 0.005193231166944048
[batch_idx--350] train_loss: 0.0011171426504991014, acc: 0.8778044871794872, lr: 0.005157865068469426
[batch_idx--400] train_loss: 0.0011185872086330766, acc: 0.8775229894014963, lr: 0.005122605947472936
[batch_idx--450] train_loss: 0.001126323208498906, acc: 0.8765838164335057, lr: 0.0050874539940516635
total time of one epoch: 480.2881877422333 s
train_loss:  0.001126323208498906  acc:  0.8765838164335057
->>lr:0.005087
test_loss:  0.00121953210525676  test_acc:  0.8678496091326467
best acc:  87.14480704802085

------Epoch: 119------
[batch_idx--0] train_loss: 0.0010047639952972531, acc: 0.890625, lr: 0.005086752049395094
[batch_idx--50] train_loss: 0.0011027587997708835, acc: 0.8795189950980392, lr: 0.005051709602139323
[batch_idx--100] train_loss: 0.0011077852404473515, acc: 0.8796797648514851, lr: 0.005016774704691432
[batch_idx--150] train_loss: 0.0011144926947300995, acc: 0.8783371274834437, lr: 0.004981947545400465
[batch_idx--200] train_loss: 0.0011162861879910366, acc: 0.8777596393034826, lr: 0.004947228312034608
[batch_idx--250] train_loss: 0.0011264696316997636, acc: 0.8764628984063745, lr: 0.004912617191780173
[batch_idx--300] train_loss: 0.001129173764771785, acc: 0.8758954526578073, lr: 0.004878114371240583
[batch_idx--350] train_loss: 0.0011281485288228807, acc: 0.8763354700854701, lr: 0.004843720036435387
[batch_idx--400] train_loss: 0.0011325266486279983, acc: 0.8756818890274314, lr: 0.004809434372799207
[batch_idx--450] train_loss: 0.001137129959599289, acc: 0.8753948693026, lr: 0.004775257565180805
total time of one epoch: 480.446106672287 s
train_loss:  0.001137129959599289  acc:  0.8753948693026
->>lr:0.004775
test_loss:  0.001209179756954684  test_acc:  0.8718203251023701
best acc:  87.14480704802085
Saving..

------Epoch: 120------
[batch_idx--0] train_loss: 0.0011475099017843604, acc: 0.87109375, lr: 0.004774575140626317
[batch_idx--50] train_loss: 0.0010892505250761613, acc: 0.8821997549019608, lr: 0.004740509555968578
[batch_idx--100] train_loss: 0.001107588837425787, acc: 0.8794477103960396, lr: 0.004706553198931926
[batch_idx--150] train_loss: 0.0011080419814325129, acc: 0.8790355960264901, lr: 0.004672706252589681
[batch_idx--200] train_loss: 0.001112185307403109, acc: 0.8777596393034826, lr: 0.004638968899425284
[batch_idx--250] train_loss: 0.001115131897358335, acc: 0.8776301045816733, lr: 0.004605341321331294
[batch_idx--300] train_loss: 0.001117166508440906, acc: 0.8776604028239202, lr: 0.004571823699608443
[batch_idx--350] train_loss: 0.0011215850265107604, acc: 0.8773036858974359, lr: 0.0045384162149646355
[batch_idx--400] train_loss: 0.001124784743333203, acc: 0.8767436876558603, lr: 0.004505119047513989
[batch_idx--450] train_loss: 0.0011277275561684269, acc: 0.8766706008956157, lr: 0.0044719323767758445
total time of one epoch: 482.2004997730255 s
train_loss:  0.0011277275561684269  acc:  0.8766706008956157
->>lr:0.004472
test_loss:  0.0012349965798971686  test_acc:  0.8632584687926542
best acc:  87.18203251023701

------Epoch: 121------
[batch_idx--0] train_loss: 0.0010813222033903003, acc: 0.87890625, lr: 0.004471269771657399
[batch_idx--50] train_loss: 0.0011157592046348488, acc: 0.8760723039215687, lr: 0.004438195991889007
[batch_idx--100] train_loss: 0.0011265300661509874, acc: 0.8759282178217822, lr: 0.004405233069644058
[batch_idx--150] train_loss: 0.0011180433011397917, acc: 0.8767849751655629, lr: 0.004372381182639854
[batch_idx--200] train_loss: 0.0011147488185450137, acc: 0.8777402052238806, lr: 0.004339640507995033
[batch_idx--250] train_loss: 0.0011097687652308597, acc: 0.8787039342629482, lr: 0.00430701122222864
[batch_idx--300] train_loss: 0.001113765719470466, acc: 0.878828384551495, lr: 0.004274493501259191
[batch_idx--350] train_loss: 0.0011207489683186672, acc: 0.878104967948718, lr: 0.004242087520403681
[batch_idx--400] train_loss: 0.0011207650976192828, acc: 0.8779028990024937, lr: 0.004209793454376692
[batch_idx--450] train_loss: 0.0011218130482748613, acc: 0.8779376540424202, lr: 0.0041776114772894115
total time of one epoch: 481.13036465644836 s
train_loss:  0.0011218130482748613  acc:  0.8779376540424202
->>lr:0.004178
test_loss:  0.0012896599374939866  test_acc:  0.8592877528229309
best acc:  87.18203251023701

------Epoch: 122------
[batch_idx--0] train_loss: 0.0011534163495525718, acc: 0.86328125, lr: 0.004176968982247515
[batch_idx--50] train_loss: 0.0011225494615477965, acc: 0.8750765931372549, lr: 0.004144901514621361
[batch_idx--100] train_loss: 0.0011142126928858165, acc: 0.8769724628712872, lr: 0.0041129464857952575
[batch_idx--150] train_loss: 0.001118463193088005, acc: 0.8774834437086093, lr: 0.004081104068052505
[batch_idx--200] train_loss: 0.0011115262327734288, acc: 0.8777985074626866, lr: 0.00404937443306925
[batch_idx--250] train_loss: 0.0011156320108557157, acc: 0.8772565986055777, lr: 0.004017757751913604
[batch_idx--300] train_loss: 0.0011196134828937634, acc: 0.877063434385382, lr: 0.003986254195044678
[batch_idx--350] train_loss: 0.0011213325487086257, acc: 0.8770699786324786, lr: 0.003954863932311695
[batch_idx--400] train_loss: 0.0011175227072206036, acc: 0.877581437032419, lr: 0.003923587132953052
[batch_idx--450] train_loss: 0.001119120606253362, acc: 0.8776425868712465, lr: 0.003892423965595415
total time of one epoch: 483.11613154411316 s
train_loss:  0.001119120606253362  acc:  0.8776425868712465
->>lr:0.003892
test_loss:  0.0012079881244623448  test_acc:  0.8695867973694007
best acc:  87.18203251023701

------Epoch: 123------
[batch_idx--0] train_loss: 0.0010302199516445398, acc: 0.88671875, lr: 0.003891801862449629
[batch_idx--50] train_loss: 0.0011192770028833812, acc: 0.8778339460784313, lr: 0.003860754772816863
[batch_idx--100] train_loss: 0.0011343162894101426, acc: 0.8760829207920792, lr: 0.0038298216539413596
[batch_idx--150] train_loss: 0.0011136674677601566, acc: 0.8783629966887417, lr: 0.0037990026725968685
[batch_idx--200] train_loss: 0.0011036211085524317, acc: 0.8794504042288557, lr: 0.003768297994941761
[batch_idx--250] train_loss: 0.0011122976436717547, acc: 0.8778168575697212, lr: 0.0037377077865181603
[batch_idx--300] train_loss: 0.001110722161551003, acc: 0.8785169227574751, lr: 0.003707232212251013
[batch_idx--350] train_loss: 0.0011135583635329394, acc: 0.8781606125356125, lr: 0.003676871436447249
[batch_idx--400] train_loss: 0.0011115086153428305, acc: 0.8784191864089775, lr: 0.0036466256227948553
[batch_idx--450] train_loss: 0.001116442878268571, acc: 0.87811122296664, lr: 0.003616494934362016
total time of one epoch: 482.71415519714355 s
train_loss:  0.001116442878268571  acc:  0.87811122296664
->>lr:0.003616
test_loss:  0.001520245524017224  test_acc:  0.8340985233899988
best acc:  87.18203251023701

------Epoch: 124------
[batch_idx--0] train_loss: 0.001143353059887886, acc: 0.8828125, lr: 0.003615893495987335
[batch_idx--50] train_loss: 0.0011048893108690048, acc: 0.8782169117647058, lr: 0.003585880402627581
[batch_idx--100] train_loss: 0.0010955116139853944, acc: 0.8801438737623762, lr: 0.0035559827619909834
[batch_idx--150] train_loss: 0.001098889231123647, acc: 0.8791649420529801, lr: 0.0035262007352685563
[batch_idx--200] train_loss: 0.0011024914446764102, acc: 0.8794504042288557, lr: 0.003496534483028016
[batch_idx--250] train_loss: 0.0011051265470427554, acc: 0.8786728087649402, lr: 0.0034669841652128805
[batch_idx--300] train_loss: 0.0011063305111106893, acc: 0.8786856312292359, lr: 0.00343754994114161
[batch_idx--350] train_loss: 0.0011025592489061914, acc: 0.87931801994302, lr: 0.0034082319695067616
[batch_idx--400] train_loss: 0.0011025681321513827, acc: 0.8793251246882793, lr: 0.003379030408374123
[batch_idx--450] train_loss: 0.0011086220045660297, acc: 0.8787794633248863, lr: 0.00334994541518186
total time of one epoch: 483.8219540119171 s
train_loss:  0.0011086220045660297  acc:  0.8787794633248863
->>lr:0.003350
test_loss:  0.0012141857649851325  test_acc:  0.8683459486288622
best acc:  87.18203251023701

------Epoch: 125------
[batch_idx--0] train_loss: 0.0010751772206276655, acc: 0.87890625, lr: 0.003349364905389038
[batch_idx--50] train_loss: 0.0011277417321324203, acc: 0.8761488970588235, lr: 0.003320398973036992
[batch_idx--100] train_loss: 0.0011323131592068268, acc: 0.8742264851485149, lr: 0.0032915499247325843
[batch_idx--150] train_loss: 0.0011204804690085992, acc: 0.8761899834437086, lr: 0.003262817916013447
[batch_idx--200] train_loss: 0.0011163935567998322, acc: 0.8773320895522388, lr: 0.0032342031017861847
[batch_idx--250] train_loss: 0.001111093312557564, acc: 0.8778635458167331, lr: 0.003205705636325565
[batch_idx--300] train_loss: 0.0011128204558709903, acc: 0.8777382682724253, lr: 0.0031773256732736594
[batch_idx--350] train_loss: 0.0011127569765433606, acc: 0.8776486823361823, lr: 0.0031490633656390573
[batch_idx--400] train_loss: 0.001111225656145473, acc: 0.8779028990024937, lr: 0.0031209188657960046
[batch_idx--450] train_loss: 0.0011111894929512897, acc: 0.878224042767383, lr: 0.0030928923254835983
total time of one epoch: 485.2469291687012 s
train_loss:  0.0011111894929512897  acc:  0.878224042767383
->>lr:0.003093
test_loss:  0.0012460693204827456  test_acc:  0.8635066385407619
best acc:  87.18203251023701

------Epoch: 126------
[batch_idx--0] train_loss: 0.0011445390991866589, acc: 0.8671875, lr: 0.0030923329989034107
[batch_idx--50] train_loss: 0.0011126429798976316, acc: 0.8755361519607843, lr: 0.003064426932974329
[batch_idx--100] train_loss: 0.0010948240443473996, acc: 0.8779006806930693, lr: 0.003036639131148192
[batch_idx--150] train_loss: 0.0010885302172449498, acc: 0.8803549254966887, lr: 0.003008969743240972
[batch_idx--200] train_loss: 0.0010923821903621564, acc: 0.8803055037313433, lr: 0.002981418918430234
[batch_idx--250] train_loss: 0.0010900142332687381, acc: 0.8810072211155379, lr: 0.002953986805254319
[batch_idx--300] train_loss: 0.0010915100545486269, acc: 0.8812162583056479, lr: 0.002926673551611542
[batch_idx--350] train_loss: 0.0010878640305625005, acc: 0.8814325142450142, lr: 0.002899479304759398
[batch_idx--400] train_loss: 0.0010908883938245345, acc: 0.8812636377805486, lr: 0.0028724042113137424
[batch_idx--450] train_loss: 0.0010929186930758068, acc: 0.8815392092199813, lr: 0.002845448417248059
total time of one epoch: 481.587459564209 s
train_loss:  0.0010929186930758068  acc:  0.8815392092199813
->>lr:0.002845
test_loss:  0.0012125078154669343  test_acc:  0.8723166645985855
best acc:  87.18203251023701
Saving..

------Epoch: 127------
[batch_idx--0] train_loss: 0.0011310952249914408, acc: 0.87890625, lr: 0.0028449105192196373
[batch_idx--50] train_loss: 0.0011208442019243888, acc: 0.8794424019607843, lr: 0.0028180765602363435
[batch_idx--100] train_loss: 0.0010992869680590633, acc: 0.8805306311881188, lr: 0.0027913621935367313
[batch_idx--150] train_loss: 0.0011036777876576546, acc: 0.8801221026490066, lr: 0.002764767563149445
[batch_idx--200] train_loss: 0.0011026976637041835, acc: 0.8801500310945274, lr: 0.002738292812457563
[batch_idx--250] train_loss: 0.0011040745752926664, acc: 0.8797933266932271, lr: 0.00271193808419784
[batch_idx--300] train_loss: 0.0011047331788004732, acc: 0.879827657807309, lr: 0.002685703520459948
[batch_idx--350] train_loss: 0.001103011249469068, acc: 0.8799301103988604, lr: 0.0026595892626856965
[batch_idx--400] train_loss: 0.0011010851083669412, acc: 0.880162874064838, lr: 0.0026335954516682747
[batch_idx--450] train_loss: 0.0011035209680648886, acc: 0.879898982886104, lr: 0.0026077222275514957
total time of one epoch: 485.1409890651703 s
train_loss:  0.0011035209680648886  acc:  0.879898982886104
->>lr:0.002608
test_loss:  0.0012316326099377527  test_acc:  0.8678496091326467
best acc:  87.23166645985854

------Epoch: 128------
[batch_idx--0] train_loss: 0.0009375030058436096, acc: 0.88671875, lr: 0.0026072059940146775
[batch_idx--50] train_loss: 0.0011119657132190233, acc: 0.8745404411764706, lr: 0.002581455912238459
[batch_idx--100] train_loss: 0.001094887710273229, acc: 0.8780167079207921, lr: 0.0025558266984695406
[batch_idx--150] train_loss: 0.001101795533079876, acc: 0.8781043046357616, lr: 0.002530318490886033
[batch_idx--200] train_loss: 0.0011021215517875455, acc: 0.8785564365671642, lr: 0.0025049314270136516
[batch_idx--250] train_loss: 0.0010978848039380376, acc: 0.878843999003984, lr: 0.0024796656437249655
[batch_idx--300] train_loss: 0.0010938423711255787, acc: 0.8792696220930233, lr: 0.0024545212772386807
[batch_idx--350] train_loss: 0.0010979470199549788, acc: 0.8791288283475783, lr: 0.0024294984631188735
[batch_idx--400] train_loss: 0.001098013695641804, acc: 0.8791205579800498, lr: 0.0024045973362742893
[batch_idx--450] train_loss: 0.001099362684250267, acc: 0.8795692019300865, lr: 0.0023798180309576172
total time of one epoch: 484.2106261253357 s
train_loss:  0.001099362684250267  acc:  0.8795692019300865
->>lr:0.002380
test_loss:  0.0012448908991576394  test_acc:  0.8677255242585928
best acc:  87.23166645985854

------Epoch: 129------
[batch_idx--0] train_loss: 0.0010890249395743012, acc: 0.87890625, lr: 0.0023793236883495163
[batch_idx--50] train_loss: 0.0011147665186310369, acc: 0.8809742647058824, lr: 0.002354668778617275
[batch_idx--100] train_loss: 0.0010990677874000503, acc: 0.880569306930693, lr: 0.0023301359595992556
[batch_idx--150] train_loss: 0.0010965737423224264, acc: 0.8808205711920529, lr: 0.0023057253635624278
[batch_idx--200] train_loss: 0.001101736660724719, acc: 0.8796253109452736, lr: 0.0022814371221148186
[batch_idx--250] train_loss: 0.0010947665388406482, acc: 0.8804936503984063, lr: 0.0022572713662047635
[batch_idx--300] train_loss: 0.0010933545897668382, acc: 0.8805673795681063, lr: 0.0022332282261202457
[batch_idx--350] train_loss: 0.0010926425505092532, acc: 0.8804531695156695, lr: 0.0022093078314881667
[batch_idx--400] train_loss: 0.0010950080044463072, acc: 0.880162874064838, lr: 0.002185510311273653
[batch_idx--450] train_loss: 0.0010979549186815344, acc: 0.8797080570694623, lr: 0.0021618357937793764
total time of one epoch: 482.79827904701233 s
train_loss:  0.0010979549186815344  acc:  0.8797080570694623
->>lr:0.002162
test_loss:  0.001200837538132583  test_acc:  0.8723166645985855
best acc:  87.23166645985854

------Epoch: 130------
[batch_idx--0] train_loss: 0.0009124574135057628, acc: 0.90625, lr: 0.0021613635589349755
[batch_idx--50] train_loss: 0.0010935686181719397, acc: 0.8816636029411765, lr: 0.0021378146357049848
[batch_idx--100] train_loss: 0.0010812666704002214, acc: 0.8825804455445545, lr: 0.0021143889723431067
[batch_idx--150] train_loss: 0.0010834559381920968, acc: 0.882734892384106, lr: 0.0020910866951471623
[batch_idx--200] train_loss: 0.001091514594461398, acc: 0.8822877798507462, lr: 0.0020679079297497515
[batch_idx--250] train_loss: 0.0010940855326301666, acc: 0.8812562250996016, lr: 0.0020448528011175527
[batch_idx--300] train_loss: 0.0010953825007755916, acc: 0.8811383928571429, lr: 0.0020219214335506857
[batch_idx--350] train_loss: 0.001099079208212382, acc: 0.880798165954416, lr: 0.0019991139506819965
[batch_idx--400] train_loss: 0.0010978264593057092, acc: 0.8808057980049875, lr: 0.001976430475476429
[batch_idx--450] train_loss: 0.0011025751659087778, acc: 0.8807755059534141, lr: 0.0019538711302303584
total time of one epoch: 486.83298420906067 s
train_loss:  0.0011025751659087778  acc:  0.8807755059534141
->>lr:0.001954
test_loss:  0.001184185750284182  test_acc:  0.873557513339124
best acc:  87.23166645985854
Saving..

------Epoch: 131------
[batch_idx--0] train_loss: 0.0010232318891212344, acc: 0.89453125, lr: 0.00195342121028749
[batch_idx--50] train_loss: 0.001121092225908868, acc: 0.8756127450980392, lr: 0.001930988602895767
[batch_idx--100] train_loss: 0.0011169322700663885, acc: 0.8762376237623762, lr: 0.001908680370460203
[batch_idx--150] train_loss: 0.001103484534754091, acc: 0.878880380794702, lr: 0.0018864966332540673
[batch_idx--200] train_loss: 0.001098609341781086, acc: 0.8796447450248757, lr: 0.0018644375108794243
[batch_idx--250] train_loss: 0.0010967425579034476, acc: 0.8801979581673307, lr: 0.0018425031222664813
[batch_idx--300] train_loss: 0.0010915878489907473, acc: 0.8807360880398671, lr: 0.0018206935856729584
[batch_idx--350] train_loss: 0.0010959623499900803, acc: 0.8801638176638177, lr: 0.0017990090186834396
[batch_idx--400] train_loss: 0.0010919261088262677, acc: 0.8806889027431422, lr: 0.0017774495382087503
[batch_idx--450] train_loss: 0.0010972974485889933, acc: 0.8802461207345437, lr: 0.001756015260485311
total time of one epoch: 483.5261232852936 s
train_loss:  0.0010972974485889933  acc:  0.8802461207345437
->>lr:0.001756
test_loss:  0.0011903933347758118  test_acc:  0.872688919220747
best acc:  87.3557513339124

------Epoch: 132------
[batch_idx--0] train_loss: 0.0009583295322954655, acc: 0.89453125, lr: 0.0017555878527937164
[batch_idx--50] train_loss: 0.0010625509552054985, acc: 0.8863357843137255, lr: 0.0017342814009232738
[batch_idx--100] train_loss: 0.0010720130544856633, acc: 0.8846302599009901, lr: 0.0017131003845420657
[batch_idx--150] train_loss: 0.0010843101826447082, acc: 0.8825279387417219, lr: 0.0016920449178460556
[batch_idx--200] train_loss: 0.0010786501746346702, acc: 0.882987406716418, lr: 0.0016711151143543159
[batch_idx--250] train_loss: 0.001075718685218404, acc: 0.8836684511952191, lr: 0.0016503110869084154
[batch_idx--300] train_loss: 0.0010782141130931205, acc: 0.8833575581395349, lr: 0.0016296329476718054
[batch_idx--350] train_loss: 0.0010808436687574044, acc: 0.8828570156695157, lr: 0.0016090808081292208
[batch_idx--400] train_loss: 0.0010836584185205977, acc: 0.8825202618453866, lr: 0.0015886547790860768
[batch_idx--450] train_loss: 0.0010847109676257812, acc: 0.8825025167494012, lr: 0.0015683549706678873
total time of one epoch: 482.0072913169861 s
train_loss:  0.0010847109676257812  acc:  0.8825025167494012
->>lr:0.001568
test_loss:  0.0011858570304279633  test_acc:  0.876907804938578
best acc:  87.3557513339124
Saving..

------Epoch: 133------
[batch_idx--0] train_loss: 0.0012597473105415702, acc: 0.81640625, lr: 0.0015679502627027138
[batch_idx--50] train_loss: 0.0011031458670200378, acc: 0.8774509803921569, lr: 0.0015477793120675237
[batch_idx--100] train_loss: 0.0010856706902642947, acc: 0.8800278465346535, lr: 0.0015277348024344995
[batch_idx--150] train_loss: 0.0010943494969207967, acc: 0.8801997102649006, lr: 0.001507816841872195
[batch_idx--200] train_loss: 0.0010969149975676034, acc: 0.8799362562189055, lr: 0.0014880255377669072
[batch_idx--250] train_loss: 0.001088579083269692, acc: 0.8814585408366534, lr: 0.0014683609968220602
[batch_idx--300] train_loss: 0.0010835635032972006, acc: 0.881891092192691, lr: 0.0014488233250576467
[batch_idx--350] train_loss: 0.0010826130658971873, acc: 0.8820557336182336, lr: 0.0014294126278096538
[batch_idx--400] train_loss: 0.0010836184482923953, acc: 0.8819065617206983, lr: 0.0014101290097294967
[batch_idx--450] train_loss: 0.0010890480499857768, acc: 0.8818603117297878, lr: 0.0013909725747834447
total time of one epoch: 480.463152885437 s
train_loss:  0.0010890480499857768  acc:  0.8818603117297878
->>lr:0.001391
test_loss:  0.0011818050720626891  test_acc:  0.8728130040948009
best acc:  87.6907804938578

------Epoch: 134------
[batch_idx--0] train_loss: 0.0009660805808380246, acc: 0.88671875, lr: 0.001390590744062975
[batch_idx--50] train_loss: 0.0011089896582359192, acc: 0.8792892156862745, lr: 0.0013715641423086456
[batch_idx--100] train_loss: 0.0011066724263860078, acc: 0.8796797648514851, lr: 0.0013526649316081968
[batch_idx--150] train_loss: 0.0011031963971955393, acc: 0.8803807947019867, lr: 0.0013338932138554
[batch_idx--200] train_loss: 0.0010975084043992915, acc: 0.880907960199005, lr: 0.0013152490902566538
[batch_idx--250] train_loss: 0.0010904250341834893, acc: 0.8818942978087649, lr: 0.0012967326613304436
[batch_idx--300] train_loss: 0.001089052913479965, acc: 0.8817742940199336, lr: 0.0012783440269067943
[batch_idx--350] train_loss: 0.0010890815703216887, acc: 0.8813100961538461, lr: 0.0012600832861267342
[batch_idx--400] train_loss: 0.0010899111044713925, acc: 0.881205190149626, lr: 0.0012419505374417718
[batch_idx--450] train_loss: 0.0010899693185311792, acc: 0.8820078453153747, lr: 0.0012239458786133446
total time of one epoch: 479.7851228713989 s
train_loss:  0.0010899693185311792  acc:  0.8820078453153747
->>lr:0.001224
test_loss:  0.0011644034760512198  test_acc:  0.8764114654423626
best acc:  87.6907804938578

------Epoch: 135------
[batch_idx--0] train_loss: 0.0008488236926496029, acc: 0.9296875, lr: 0.0012235870926211618
[batch_idx--50] train_loss: 0.001111704732894021, acc: 0.8782935049019608, lr: 0.0012057131854440546
[batch_idx--100] train_loss: 0.0010875553644197707, acc: 0.881458849009901, lr: 0.0011879675634946297
[batch_idx--150] train_loss: 0.001085447649385114, acc: 0.8817777317880795, lr: 0.0011703503224471529
[batch_idx--200] train_loss: 0.001085763503808936, acc: 0.8821711753731343, lr: 0.001152861557283752
[batch_idx--250] train_loss: 0.0010936541540318158, acc: 0.8810539093625498, lr: 0.0011355013622938726
[batch_idx--300] train_loss: 0.0010862706922941479, acc: 0.881670473421927, lr: 0.0011182698310737928
[batch_idx--350] train_loss: 0.0010875669837679895, acc: 0.8816439636752137, lr: 0.0011011670565261005
[batch_idx--400] train_loss: 0.001085976565470385, acc: 0.8819163029925187, lr: 0.0010841931308592041
[batch_idx--450] train_loss: 0.0010867759571931387, acc: 0.8821293435623286, lr: 0.00106734814558683
total time of one epoch: 483.9984414577484 s
train_loss:  0.0010867759571931387  acc:  0.8821293435623286
->>lr:0.001067
test_loss:  0.0011845479026771476  test_acc:  0.874302022583447
best acc:  87.6907804938578

------Epoch: 136------
[batch_idx--0] train_loss: 0.0008606915944255888, acc: 0.91015625, lr: 0.001067012561698319
[batch_idx--50] train_loss: 0.0010732956157595503, acc: 0.8836550245098039, lr: 0.0010502991891848613
[batch_idx--100] train_loss: 0.0010892402923592173, acc: 0.8800278465346535, lr: 0.0010337149398027378
[batch_idx--150] train_loss: 0.001086421521374376, acc: 0.8817259933774835, lr: 0.001017259902964765
[batch_idx--200] train_loss: 0.0010890620378360375, acc: 0.880927394278607, lr: 0.0010009341673871241
[batch_idx--250] train_loss: 0.0010876950781896295, acc: 0.8813029133466136, lr: 0.000984737821088863
[batch_idx--300] train_loss: 0.0010833289656800487, acc: 0.8821506436877077, lr: 0.000968670951391451
[batch_idx--350] train_loss: 0.0010823744660617514, acc: 0.8823896011396012, lr: 0.0009527336449182884
[batch_idx--400] train_loss: 0.001083781550658119, acc: 0.8823059538653366, lr: 0.0009369259875942449
[batch_idx--450] train_loss: 0.0010865328690369417, acc: 0.8822421633630715, lr: 0.0009212480646451971
total time of one epoch: 484.1412441730499 s
train_loss:  0.0010865328690369417  acc:  0.8822421633630715
->>lr:0.000921
test_loss:  0.0011695043900007349  test_acc:  0.8757910410720933
best acc:  87.6907804938578

------Epoch: 137------
[batch_idx--0] train_loss: 0.0013021340128034353, acc: 0.859375, lr: 0.0009209358300585474
[batch_idx--50] train_loss: 0.001053516472251538, acc: 0.8844209558823529, lr: 0.0009053903232463079
[batch_idx--100] train_loss: 0.0010689240229076308, acc: 0.8822323638613861, lr: 0.0008899747208313852
[batch_idx--150] train_loss: 0.0010706676221884392, acc: 0.8828125, lr: 0.0008746891059259105
[batch_idx--200] train_loss: 0.0010744892147633788, acc: 0.8827347636815921, lr: 0.0008595335609412142
[batch_idx--250] train_loss: 0.001072701253414347, acc: 0.8832015687250996, lr: 0.0008445081675873518
[batch_idx--300] train_loss: 0.0010752391841330649, acc: 0.8828384551495017, lr: 0.0008296130068726787
[batch_idx--350] train_loss: 0.0010802720735072452, acc: 0.8819221866096866, lr: 0.0008148481591034013
[batch_idx--400] train_loss: 0.0010750979606638153, acc: 0.8828806889027432, lr: 0.0008002137038831625
[batch_idx--450] train_loss: 0.001075963367601889, acc: 0.8833096122470233, lr: 0.000785709720112604
total time of one epoch: 485.1252796649933 s
train_loss:  0.001075963367601889  acc:  0.8833096122470233
->>lr:0.000786
test_loss:  0.0011924410305657477  test_acc:  0.8724407494726393
best acc:  87.6907804938578

------Epoch: 138------
[batch_idx--0] train_loss: 0.001006626756861806, acc: 0.87890625, lr: 0.0007854209717842232
[batch_idx--50] train_loss: 0.0010717327035415698, acc: 0.8805912990196079, lr: 0.0007710501494462701
[batch_idx--100] train_loss: 0.0010615969774091967, acc: 0.8826577970297029, lr: 0.0007568099557912517
[batch_idx--150] train_loss: 0.0010680824376346654, acc: 0.8814414321192053, lr: 0.000742700467594179
[batch_idx--200] train_loss: 0.0010739502578681864, acc: 0.8815298507462687, lr: 0.0007287217609253605
[batch_idx--250] train_loss: 0.0010700675645431289, acc: 0.8820499252988048, lr: 0.0007148739111500131
[batch_idx--300] train_loss: 0.0010724255828298257, acc: 0.8820987333887044, lr: 0.0007011569929278511
[batch_idx--350] train_loss: 0.0010744949049539226, acc: 0.8818776709401709, lr: 0.0006875710802126706
[batch_idx--400] train_loss: 0.0010772081108838135, acc: 0.8818383728179551, lr: 0.0006741162462519713
[batch_idx--450] train_loss: 0.0010803102551814844, acc: 0.8816259936820912, lr: 0.0006607925635865458
total time of one epoch: 481.790372133255 s
train_loss:  0.0010803102551814844  acc:  0.8816259936820912
->>lr:0.000661
test_loss:  0.00117450223280872  test_acc:  0.8731852587169624
best acc:  87.6907804938578

------Epoch: 139------
[batch_idx--0] train_loss: 0.0010656107915565372, acc: 0.8984375, lr: 0.0006605274281709927
[batch_idx--50] train_loss: 0.0010768004508195993, acc: 0.8813572303921569, lr: 0.0006473375938249676
[batch_idx--100] train_loss: 0.001085064796348204, acc: 0.8804919554455446, lr: 0.0006342790551494393
[batch_idx--150] train_loss: 0.001081129770019764, acc: 0.8814155629139073, lr: 0.0006213518825486042
[batch_idx--200] train_loss: 0.0010804221916142203, acc: 0.8812966417910447, lr: 0.0006085561457184031
[batch_idx--250] train_loss: 0.0010761053809725432, acc: 0.8824856822709163, lr: 0.0005958919136461599
[batch_idx--300] train_loss: 0.0010781934369971165, acc: 0.8823842400332226, lr: 0.000583359254610194
[batch_idx--350] train_loss: 0.0010804598437929977, acc: 0.8821447649572649, lr: 0.0005709582361794502
[batch_idx--400] train_loss: 0.0010748344704048925, acc: 0.8826858634663342, lr: 0.0005586889252131494
[batch_idx--450] train_loss: 0.0010750034570095998, acc: 0.8831100079841705, lr: 0.0005465513878604278
total time of one epoch: 484.09801030158997 s
train_loss:  0.0010750034570095998  acc:  0.8831100079841705
->>lr:0.000547
test_loss:  0.0011903554633794138  test_acc:  0.8718203251023701
best acc:  87.6907804938578

------Epoch: 140------
[batch_idx--0] train_loss: 0.0011398049537092447, acc: 0.87890625, lr: 0.0005463099816548578
[batch_idx--50] train_loss: 0.0010801296471161586, acc: 0.8804381127450981, lr: 0.0005343069207980278
[batch_idx--100] train_loss: 0.0010778702141966043, acc: 0.8820003094059405, lr: 0.0005224357650086414
[batch_idx--150] train_loss: 0.001079110029332389, acc: 0.8824762003311258, lr: 0.0005106965782891965
[batch_idx--200] train_loss: 0.0010802562861698703, acc: 0.8830068407960199, lr: 0.0004990894239306987
[batch_idx--250] train_loss: 0.001084609390598206, acc: 0.8822366782868526, lr: 0.0004876143645123038
[batch_idx--300] train_loss: 0.0010798180124264496, acc: 0.8824361503322259, lr: 0.00047627146190098725
[batch_idx--350] train_loss: 0.0010753125541026246, acc: 0.8829460470085471, lr: 0.00046506077725121944
[batch_idx--400] train_loss: 0.0010801135021508057, acc: 0.882442331670823, lr: 0.00045398237100461594
[batch_idx--450] train_loss: 0.0010836305073532743, acc: 0.8821467004547506, lr: 0.0004430363028896239
total time of one epoch: 486.28343081474304 s
train_loss:  0.0010836305073532743  acc:  0.8821467004547506
->>lr:0.000443
test_loss:  0.0011729343399869581  test_acc:  0.8756669561980395
best acc:  87.6907804938578

------Epoch: 141------
[batch_idx--0] train_loss: 0.0009173194994218647, acc: 0.91015625, lr: 0.00044281873178278475
[batch_idx--50] train_loss: 0.0010705284189944173, acc: 0.8846507352941176, lr: 0.0004320077093543484
[batch_idx--100] train_loss: 0.001072995210213974, acc: 0.8828125, lr: 0.0004213291435323757
[batch_idx--150] train_loss: 0.0010737419099121398, acc: 0.882890107615894, lr: 0.0004107830918895994
[batch_idx--200] train_loss: 0.001066613017433133, acc: 0.8840174129353234, lr: 0.00040036961128431806
[batch_idx--250] train_loss: 0.0010664166638672174, acc: 0.8836995766932271, lr: 0.00039008875786008537
[batch_idx--300] train_loss: 0.0010693973573110379, acc: 0.8833835132890365, lr: 0.00037994058704539927
[batch_idx--350] train_loss: 0.001072415374909286, acc: 0.8829349180911681, lr: 0.0003699251535534104
[batch_idx--400] train_loss: 0.0010721791631999678, acc: 0.8829196539900249, lr: 0.0003600425113816253
[batch_idx--450] train_loss: 0.001074994119795193, acc: 0.882745513243309, lr: 0.0003502927138116147
total time of one epoch: 485.0149257183075 s
train_loss:  0.001074994119795193  acc:  0.882745513243309
->>lr:0.000350
test_loss:  0.0011720903507162375  test_acc:  0.8745501923315547
best acc:  87.6907804938578

------Epoch: 142------
[batch_idx--0] train_loss: 0.0010747495107352734, acc: 0.88671875, lr: 0.00035009907323737546
[batch_idx--50] train_loss: 0.0010929731218436477, acc: 0.8806678921568627, lr: 0.00034048483130907914
[batch_idx--100] train_loss: 0.001080042661264502, acc: 0.8821936881188119, lr: 0.00033100353942642217
[batch_idx--150] train_loss: 0.0010782296777801551, acc: 0.8813638245033113, lr: 0.0003216552487071145
[batch_idx--200] train_loss: 0.0010746678155592055, acc: 0.8824238184079602, lr: 0.00031244000955181765
[batch_idx--250] train_loss: 0.0010782559284016461, acc: 0.8815986055776892, lr: 0.00030335787164384453
[batch_idx--300] train_loss: 0.001078670513560915, acc: 0.8816834509966778, lr: 0.00029440888394890454
[batch_idx--350] train_loss: 0.0010807938022045498, acc: 0.8819333155270656, lr: 0.00028559309471483943
[batch_idx--400] train_loss: 0.00108169543236364, acc: 0.8817019950124688, lr: 0.00027691055147135437
[batch_idx--450] train_loss: 0.0010857361440574646, acc: 0.8814350678654493, lr: 0.0002683613010297709
total time of one epoch: 481.41310143470764 s
train_loss:  0.0010857361440574646  acc:  0.8814350678654493
->>lr:0.000268
test_loss:  0.0011668010764004264  test_acc:  0.8756669561980395
best acc:  87.6907804938578

------Epoch: 143------
[batch_idx--0] train_loss: 0.0011308405082672834, acc: 0.88671875, lr: 0.0002681916759252945
[batch_idx--50] train_loss: 0.0010595480836106137, acc: 0.8868719362745098, lr: 0.00025977843162139916
[batch_idx--100] train_loss: 0.0010670988070133078, acc: 0.8847462871287128, lr: 0.0002514985724860308
[batch_idx--150] train_loss: 0.0010683415064415493, acc: 0.8840024834437086, lr: 0.00024335214315946986
[batch_idx--200] train_loss: 0.0010659625314741363, acc: 0.8841923196517413, lr: 0.00023533918756261376
[batch_idx--250] train_loss: 0.0010650817966237072, acc: 0.8842598356573705, lr: 0.00022745974889675503
[batch_idx--300] train_loss: 0.0010668049696786483, acc: 0.8841362126245847, lr: 0.0002197138696433315
[batch_idx--350] train_loss: 0.0010672802000407373, acc: 0.884292646011396, lr: 0.0002121015915637098
[batch_idx--400] train_loss: 0.0010718614929309232, acc: 0.88367947319202, lr: 0.0002046229556989493
[batch_idx--450] train_loss: 0.0010740585984936914, acc: 0.8839518172666366, lr: 0.00019727800236959416
total time of one epoch: 484.2786567211151 s
train_loss:  0.0010740585984936914  acc:  0.8839518172666366
->>lr:0.000197
test_loss:  0.0011656470952724491  test_acc:  0.8757910410720933
best acc:  87.6907804938578

------Epoch: 144------
[batch_idx--0] train_loss: 0.001097835716791451, acc: 0.890625, lr: 0.0001971324671380531
[batch_idx--50] train_loss: 0.0010995527834394107, acc: 0.8793658088235294, lr: 0.00018992391078557493
[batch_idx--100] train_loss: 0.001080103137871564, acc: 0.8822323638613861, lr: 0.00018284911621737067
[batch_idx--150] train_loss: 0.0010810499399474865, acc: 0.8814155629139073, lr: 0.00017590812157669555
[batch_idx--200] train_loss: 0.001074468173707525, acc: 0.8818213619402985, lr: 0.00016910096428543743
[batch_idx--250] train_loss: 0.0010739533224632866, acc: 0.8822989292828686, lr: 0.00016242768104390848
[batch_idx--300] train_loss: 0.0010750003884611435, acc: 0.8825659260797342, lr: 0.00015588830783064834
[batch_idx--350] train_loss: 0.0010735642060801982, acc: 0.8824452457264957, lr: 0.0001494828799022241
[batch_idx--400] train_loss: 0.001074690641161807, acc: 0.8820331982543641, lr: 0.00014321143179305552
[batch_idx--450] train_loss: 0.001077678701424419, acc: 0.881816919498733, lr: 0.00013707399731520964
total time of one epoch: 480.1380412578583 s
train_loss:  0.001077678701424419  acc:  0.881816919498733
->>lr:0.000137
test_loss:  0.001169695337130216  test_acc:  0.8752947015758779
best acc:  87.6907804938578

------Epoch: 145------
[batch_idx--0] train_loss: 0.0010976498015224934, acc: 0.88671875, lr: 0.00013695261579316776
[batch_idx--50] train_loss: 0.001107146723798531, acc: 0.8768382352941176, lr: 0.0001309519093031647
[batch_idx--100] train_loss: 0.0010807650869177415, acc: 0.8821550123762376, lr: 0.0001250852825408405
[batch_idx--150] train_loss: 0.0010775267790281368, acc: 0.8825538079470199, lr: 0.0001193527671357053
[batch_idx--200] train_loss: 0.0010691795866491635, acc: 0.8833566542288557, lr: 0.00011375439399421428
[batch_idx--250] train_loss: 0.001066769828993931, acc: 0.8838863296812749, lr: 0.00010829019329959833
[batch_idx--300] train_loss: 0.0010710275380801026, acc: 0.8832667151162791, lr: 0.00010296019451171701
[batch_idx--350] train_loss: 0.0010693194551932017, acc: 0.8835803952991453, lr: 9.776442636688366e-05
[batch_idx--400] train_loss: 0.0010682889973068902, acc: 0.8836697319201995, lr: 9.270291687771548e-05
[batch_idx--450] train_loss: 0.001074167835742228, acc: 0.883613357864408, lr: 8.77756933329893e-05
total time of one epoch: 484.61558508872986 s
train_loss:  0.001074167835742228  acc:  0.883613357864408
->>lr:0.000088
test_loss:  0.0011681440742927918  test_acc:  0.8756669561980395
best acc:  87.6907804938578

------Epoch: 146------
[batch_idx--0] train_loss: 0.0009536248981021345, acc: 0.890625, lr: 8.767851876239075e-05
[batch_idx--50] train_loss: 0.0010974319667701482, acc: 0.8779871323529411, lr: 8.288829424305533e-05
[batch_idx--100] train_loss: 0.0010803673280366133, acc: 0.8806079826732673, lr: 7.82324085830094e-05
[batch_idx--150] train_loss: 0.0010826945349586424, acc: 0.8802773178807947, lr: 7.371088688413186e-05
[batch_idx--200] train_loss: 0.0010832709205841915, acc: 0.8802083333333334, lr: 6.93237535238922e-05
[batch_idx--250] train_loss: 0.0010833443901724223, acc: 0.8806959661354582, lr: 6.507103215520893e-05
[batch_idx--300] train_loss: 0.0010855681739787748, acc: 0.8807360880398671, lr: 6.09527457063358e-05
[batch_idx--350] train_loss: 0.0010827139696236328, acc: 0.8812321937321937, lr: 5.6968916380720215e-05
[batch_idx--400] train_loss: 0.0010838269537948816, acc: 0.8809324345386533, lr: 5.311956565690057e-05
[batch_idx--450] train_loss: 0.001083974321244943, acc: 0.8814958169889263, lr: 4.9404714288381335e-05
total time of one epoch: 488.2538993358612 s
train_loss:  0.001083974321244943  acc:  0.8814958169889263
->>lr:0.000049
test_loss:  0.0011657371549396868  test_acc:  0.8745501923315547
best acc:  87.6907804938578

------Epoch: 147------
[batch_idx--0] train_loss: 0.00121110281907022, acc: 0.85546875, lr: 4.933178929321103e-05
[batch_idx--50] train_loss: 0.0010945198295053606, acc: 0.8802083333333334, lr: 4.57541478953355e-05
[batch_idx--100] train_loss: 0.0010808693840961424, acc: 0.8811107673267327, lr: 4.231104556289278e-05
[batch_idx--150] train_loss: 0.001064951218192817, acc: 0.8836144453642384, lr: 3.9002500859128264e-05
[batch_idx--200] train_loss: 0.0010699104982201213, acc: 0.882870802238806, lr: 3.582853162182598e-05
[batch_idx--250] train_loss: 0.00106737718210589, acc: 0.8834194472111554, lr: 3.2789154963222546e-05
[batch_idx--300] train_loss: 0.00106829388954358, acc: 0.8839026162790697, lr: 2.9884387269901725e-05
[batch_idx--350] train_loss: 0.0010675524172049408, acc: 0.8838363603988604, lr: 2.7114244202716688e-05
[batch_idx--400] train_loss: 0.0010664842641352678, acc: 0.8838645573566085, lr: 2.4478740696695647e-05
[batch_idx--450] train_loss: 0.0010718855584375803, acc: 0.8836741069878848, lr: 2.1977890960975244e-05
total time of one epoch: 486.7636408805847 s
train_loss:  0.0010718855584375803  acc:  0.8836741069878848
->>lr:0.000022
test_loss:  0.0011684384771576146  test_acc:  0.8746742772056086
best acc:  87.6907804938578

------Epoch: 148------
[batch_idx--0] train_loss: 0.0010593346087262034, acc: 0.89453125, lr: 2.192924752854042e-05
[batch_idx--50] train_loss: 0.0010599637525064835, acc: 0.8867953431372549, lr: 1.9565758523884538e-05
[batch_idx--100] train_loss: 0.0010521741449086013, acc: 0.8867574257425742, lr: 1.7336949777524425e-05
[batch_idx--150] train_loss: 0.0010645434928021782, acc: 0.8845974751655629, lr: 1.524283330592846e-05
[batch_idx--200] train_loss: 0.0010645043971341344, acc: 0.8845226990049752, lr: 1.3283420399376467e-05
[batch_idx--250] train_loss: 0.0010706422325461153, acc: 0.8837307021912351, lr: 1.14587216219042e-05
[batch_idx--300] train_loss: 0.0010695898355421087, acc: 0.8841232350498339, lr: 9.768746811253394e-06
[batch_idx--350] train_loss: 0.0010729161098777208, acc: 0.8838474893162394, lr: 8.213505078799587e-06
[batch_idx--400] train_loss: 0.0010725826801885469, acc: 0.8836502493765586, lr: 6.793004809518832e-06
[batch_idx--450] train_loss: 0.0010763339075773358, acc: 0.8837001423265178, lr: 5.507253661940492e-06
total time of one epoch: 483.8414349555969 s
train_loss:  0.0010763339075773358  acc:  0.8837001423265178
->>lr:0.000006
test_loss:  0.0011686763743162598  test_acc:  0.8754187864499318
best acc:  87.6907804938578

------Epoch: 149------
[batch_idx--0] train_loss: 0.0010666934540495276, acc: 0.86328125, lr: 5.482913128862511e-06
[batch_idx--50] train_loss: 0.0010806219709361448, acc: 0.8828125, lr: 4.334613221818051e-06
[batch_idx--100] train_loss: 0.0010767329557992444, acc: 0.8831992574257426, lr: 3.321075690718156e-06
[batch_idx--150] train_loss: 0.0010679896068235008, acc: 0.8837955298013245, lr: 2.4423059999861833e-06
[batch_idx--200] train_loss: 0.0010632167223363707, acc: 0.884717039800995, lr: 1.6983088874406029e-06
[batch_idx--250] train_loss: 0.0010618816410002125, acc: 0.8848979083665338, lr: 1.089088364294999e-06
[batch_idx--300] train_loss: 0.0010689176337490248, acc: 0.8843308762458472, lr: 6.146477151164343e-07
[batch_idx--350] train_loss: 0.001065938534849241, acc: 0.8845819978632479, lr: 2.749894978198997e-07
[batch_idx--400] train_loss: 0.0010631849829332806, acc: 0.8847120480049875, lr: 7.011554364610984e-08
[batch_idx--450] train_loss: 0.0010657884257102611, acc: 0.8847936265491027, lr: 2.6957161503027296e-11
total time of one epoch: 481.80502676963806 s
train_loss:  0.0010657884257102611  acc:  0.8847936265491027
->>lr:0.000000
test_loss:  0.001167529983369037  test_acc:  0.876039210820201
best acc:  87.6907804938578