Model: mobilenet_gru_last
Batch size: 256
Number of dataloader workers: 32

loading annotations into memory...
Done (t=2.65s)
creating index...
index created!
Len of trainloader: 451

loading annotations into memory...
Done (t=0.79s)
creating index...
index created!
Len of testloader: 32

use 4 GPUs!
DataParallel device_ids: [0, 1, 2, 3]

------Epoch: 0------
[batch_idx--0] train_loss: 0.0027360308449715376, acc: 0.4921875, lr: 0.05
[batch_idx--50] train_loss: 0.0028325783307938013, acc: 0.5212162990196079, lr: 0.04999993260712715
[batch_idx--100] train_loss: 0.0027343554394596284, acc: 0.551980198019802, lr: 0.04999973042887193
[batch_idx--150] train_loss: 0.0026747494371644905, acc: 0.5750206953642384, lr: 0.049999393466324364
[batch_idx--200] train_loss: 0.0026274299647529326, acc: 0.591689987562189, lr: 0.04999892172130118
[batch_idx--250] train_loss: 0.002588402226648898, acc: 0.6049707420318725, lr: 0.04999831519634575
[batch_idx--300] train_loss: 0.0025482839638633387, acc: 0.6180440199335548, lr: 0.0499975738947281
[batch_idx--350] train_loss: 0.002513389980707031, acc: 0.6283609330484331, lr: 0.04999669782044491
[batch_idx--400] train_loss: 0.002484958066124274, acc: 0.6367869389027432, lr: 0.049995686978219496
[batch_idx--450] train_loss: 0.0024630016902263854, acc: 0.6442184191342382, lr: 0.04999454137350172
total time of one epoch: 211.714586019516 s
train_loss:  0.0024630016902263854  acc:  0.6442184191342382
->>lr:0.049995
test_loss:  0.003486466320502668  test_acc:  0.5286015634694131
best acc:  0
Saving..
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(

------Epoch: 1------
[batch_idx--0] train_loss: 0.0023216635454446077, acc: 0.71484375, lr: 0.04999451708687114
[batch_idx--50] train_loss: 0.002219455919283278, acc: 0.7074142156862745, lr: 0.04999323403077913
[batch_idx--100] train_loss: 0.0022017169780660386, acc: 0.7106667698019802, lr: 0.04999181622541965
[batch_idx--150] train_loss: 0.0021887079485698254, acc: 0.7138348509933775, lr: 0.0499902636784367
[batch_idx--200] train_loss: 0.0021773933673935445, acc: 0.7159320584577115, lr: 0.04998857639820074
[batch_idx--250] train_loss: 0.002162814808200555, acc: 0.7182831175298805, lr: 0.04998675439380862
[batch_idx--300] train_loss: 0.002147529691541289, acc: 0.7215791112956811, lr: 0.04998479767508354
[batch_idx--350] train_loss: 0.0021364049371756463, acc: 0.7237246260683761, lr: 0.04998270625257502
[batch_idx--400] train_loss: 0.002124105321482623, acc: 0.7259195760598504, lr: 0.04998048013755882
[batch_idx--450] train_loss: 0.0021189744911277605, acc: 0.7268632624014997, lr: 0.049978119342036866
total time of one epoch: 199.7313199043274 s
train_loss:  0.0021189744911277605  acc:  0.7268632624014997
->>lr:0.049978
test_loss:  0.0020855764387736385  test_acc:  0.7415312073458246
best acc:  52.86015634694131
Saving..

------Epoch: 2------
[batch_idx--0] train_loss: 0.002121712313964963, acc: 0.73046875, lr: 0.04997807075247146
[batch_idx--50] train_loss: 0.0020134973125167043, acc: 0.7438725490196079, lr: 0.04997557259595109
[batch_idx--100] train_loss: 0.0020172187233214625, acc: 0.7427289603960396, lr: 0.04997293978538365
[batch_idx--150] train_loss: 0.0020100511286703757, acc: 0.7455763658940397, lr: 0.04997017233496374
[batch_idx--200] train_loss: 0.002003498497622931, acc: 0.7475901741293532, lr: 0.04996727025961189
[batch_idx--250] train_loss: 0.001992908221079534, acc: 0.7493930527888446, lr: 0.04996423357497442
[batch_idx--300] train_loss: 0.001991533068630634, acc: 0.7498312915282392, lr: 0.04996106229742341
[batch_idx--350] train_loss: 0.0019823052758547316, acc: 0.7513243411680912, lr: 0.04995775644405658
[batch_idx--400] train_loss: 0.0019774245980202667, acc: 0.7523476465087282, lr: 0.049954316032697205
[batch_idx--450] train_loss: 0.001977246304470327, acc: 0.7533325233450203, lr: 0.049950741081894026
total time of one epoch: 200.26454877853394 s
train_loss:  0.001977246304470327  acc:  0.7533325233450203
->>lr:0.049951
test_loss:  0.002093592793847716  test_acc:  0.736071472887455
best acc:  74.15312073458246

------Epoch: 3------
[batch_idx--0] train_loss: 0.0018176459707319736, acc: 0.78515625, lr: 0.04995066821070679
[batch_idx--50] train_loss: 0.001928474849966519, acc: 0.7617953431372549, lr: 0.04994695604953209
[batch_idx--100] train_loss: 0.0019319931248036942, acc: 0.7610225866336634, lr: 0.0499431093885944
[batch_idx--150] train_loss: 0.0019209079817554217, acc: 0.7615894039735099, lr: 0.04993912824863275
[batch_idx--200] train_loss: 0.001918525215520973, acc: 0.7619713930348259, lr: 0.049935012651111166
[batch_idx--250] train_loss: 0.0019078748514022366, acc: 0.763741907370518, lr: 0.0499307626182186
[batch_idx--300] train_loss: 0.0019036570352740413, acc: 0.7643791528239202, lr: 0.0499263781728688
[batch_idx--350] train_loss: 0.0019016964606505598, acc: 0.7646345263532763, lr: 0.04992185933870021
[batch_idx--400] train_loss: 0.0018987513906171458, acc: 0.7653132793017456, lr: 0.049917206140075804
[batch_idx--450] train_loss: 0.0019023906533040353, acc: 0.7654563127017738, lr: 0.04991241860208297
total time of one epoch: 203.76848363876343 s
train_loss:  0.0019023906533040353  acc:  0.7654563127017738
->>lr:0.049912
test_loss:  0.0022399830439499284  test_acc:  0.7250279190966621
best acc:  74.15312073458246

------Epoch: 4------
[batch_idx--0] train_loss: 0.0016977748600766063, acc: 0.84375, lr: 0.049912321481237615
[batch_idx--50] train_loss: 0.0018421054461642222, acc: 0.7772671568627451, lr: 0.04990739694368515
[batch_idx--100] train_loss: 0.0018539035307833611, acc: 0.7732827970297029, lr: 0.04990233811964985
[batch_idx--150] train_loss: 0.0018482589099667226, acc: 0.7760502897350994, lr: 0.049897145036406014
[batch_idx--200] train_loss: 0.0018513427018674452, acc: 0.7739427860696517, lr: 0.04989181772195179
[batch_idx--250] train_loss: 0.0018466926482227813, acc: 0.7737020667330677, lr: 0.04988635620500901
[batch_idx--300] train_loss: 0.0018509204516441026, acc: 0.7734245224252492, lr: 0.049880760515023076
[batch_idx--350] train_loss: 0.0018455214606746607, acc: 0.774238782051282, lr: 0.04987503068216274
[batch_idx--400] train_loss: 0.0018449689849788448, acc: 0.774109647755611, lr: 0.04986916673732
[batch_idx--450] train_loss: 0.0018444701997674393, acc: 0.7749158190717534, lr: 0.049863168712109905
total time of one epoch: 202.24098086357117 s
train_loss:  0.0018444701997674393  acc:  0.7749158190717534
->>lr:0.049863
test_loss:  0.0017869100076327742  test_acc:  0.7896761384787194
best acc:  74.15312073458246
Saving..

------Epoch: 5------
[batch_idx--0] train_loss: 0.0017053344054147601, acc: 0.79296875, lr: 0.049863047384206834
[batch_idx--50] train_loss: 0.0017903489037873405, acc: 0.7836243872549019, lr: 0.04985691263034154
[batch_idx--100] train_loss: 0.0018025601794482162, acc: 0.7813660272277227, lr: 0.049850643862176046
[batch_idx--150] train_loss: 0.0018099009341541801, acc: 0.7803445778145696, lr: 0.04984424111350797
[batch_idx--200] train_loss: 0.001809746355388258, acc: 0.7804532027363185, lr: 0.0498377044188573
[batch_idx--250] train_loss: 0.001803135300385376, acc: 0.7817480079681275, lr: 0.04983103381346615
[batch_idx--300] train_loss: 0.0017950827730788643, acc: 0.7826126453488372, lr: 0.049824229333298636
[batch_idx--350] train_loss: 0.0017902523181679794, acc: 0.7834312678062678, lr: 0.049817291015040614
[batch_idx--400] train_loss: 0.0017906314907641964, acc: 0.7834904925187033, lr: 0.04981021889609956
[batch_idx--450] train_loss: 0.001789984734679856, acc: 0.784305897872045, lr: 0.0498030130146043
total time of one epoch: 202.82805705070496 s
train_loss:  0.001789984734679856  acc:  0.784305897872045
->>lr:0.049803
test_loss:  0.0017297772027553052  test_acc:  0.7992306737808661
best acc:  78.96761384787195
Saving..

------Epoch: 6------
[batch_idx--0] train_loss: 0.0015933462418615818, acc: 0.828125, lr: 0.04980286753286195
[batch_idx--50] train_loss: 0.0017663263419058686, acc: 0.7899050245098039, lr: 0.04979552525358963
[batch_idx--100] train_loss: 0.001757960738890832, acc: 0.7881729579207921, lr: 0.04978804929098283
[batch_idx--150] train_loss: 0.0017566196682141317, acc: 0.7890625, lr: 0.049780439685347705
[batch_idx--200] train_loss: 0.001750719547619237, acc: 0.7909864738805971, lr: 0.0497726964777109
[batch_idx--250] train_loss: 0.0017489580571117154, acc: 0.790945592629482, lr: 0.049764819709819365
[batch_idx--300] train_loss: 0.0017505675210830974, acc: 0.7904251453488372, lr: 0.04975680942414015
[batch_idx--350] train_loss: 0.0017425932465757951, acc: 0.7914329594017094, lr: 0.04974866566386016
[batch_idx--400] train_loss: 0.0017439687869597476, acc: 0.7916634195760599, lr: 0.049740388472885894
[batch_idx--450] train_loss: 0.0017408924385815777, acc: 0.792428923525532, lr: 0.04973197789584324
total time of one epoch: 204.95933747291565 s
train_loss:  0.0017408924385815777  acc:  0.792428923525532
->>lr:0.049732
test_loss:  0.0018385926892287325  test_acc:  0.7842164040203499
best acc:  79.92306737808661

------Epoch: 7------
[batch_idx--0] train_loss: 0.0015623783692717552, acc: 0.83984375, lr: 0.049731808324074714
[batch_idx--50] train_loss: 0.0017499430196396277, acc: 0.7912071078431373, lr: 0.04972326173996171
[batch_idx--100] train_loss: 0.0017311690077831102, acc: 0.7934715346534653, lr: 0.049714581862117906
[batch_idx--150] train_loss: 0.0017268645510829935, acc: 0.7949606788079471, lr: 0.049705768737340256
[batch_idx--200] train_loss: 0.0017193123496679673, acc: 0.795048196517413, lr: 0.04969682241314409
[batch_idx--250] train_loss: 0.0017183000125376828, acc: 0.7950697211155379, lr: 0.0496877429377629
[batch_idx--300] train_loss: 0.0017145193047338842, acc: 0.7956940406976745, lr: 0.04967853036014805
[batch_idx--350] train_loss: 0.0017162848557836438, acc: 0.7950943732193733, lr: 0.04966918472996849
[batch_idx--400] train_loss: 0.001717708657084595, acc: 0.7949364869077307, lr: 0.04965970609761053
[batch_idx--450] train_loss: 0.0017186653175601304, acc: 0.7946939979866005, lr: 0.04965009451417756
total time of one epoch: 202.11353158950806 s
train_loss:  0.0017186653175601304  acc:  0.7946939979866005
->>lr:0.049650
test_loss:  0.0018974839087854412  test_acc:  0.7718079166149646
best acc:  79.92306737808661

------Epoch: 8------
[batch_idx--0] train_loss: 0.0016837919829413295, acc: 0.7890625, lr: 0.04964990092676263
[batch_idx--50] train_loss: 0.0017001186771427885, acc: 0.7984068627450981, lr: 0.0496401537866232
[batch_idx--100] train_loss: 0.0016951641692586317, acc: 0.7969910272277227, lr: 0.04963027380082368
[batch_idx--150] train_loss: 0.0016873615935740882, acc: 0.7986599751655629, lr: 0.04962026102263131
[batch_idx--200] train_loss: 0.00169184313512486, acc: 0.7979438743781094, lr: 0.04961011550602926
[batch_idx--250] train_loss: 0.001686333216711938, acc: 0.7990382221115537, lr: 0.04959983730571641
[batch_idx--300] train_loss: 0.0016854997748273898, acc: 0.7994056270764119, lr: 0.04958942647710693
[batch_idx--350] train_loss: 0.0016855577894478526, acc: 0.799568198005698, lr: 0.04957888307633007
[batch_idx--400] train_loss: 0.0016823403904228436, acc: 0.8001578086034913, lr: 0.04956820716022985
[batch_idx--450] train_loss: 0.001686530221413601, acc: 0.8002395251154233, lr: 0.049557398786364705
total time of one epoch: 206.36529397964478 s
train_loss:  0.001686530221413601  acc:  0.8002395251154233
->>lr:0.049557
test_loss:  0.0021158041145210157  test_acc:  0.7498448939074327
best acc:  79.92306737808661

------Epoch: 9------
[batch_idx--0] train_loss: 0.001627551857382059, acc: 0.80859375, lr: 0.049557181268217225
[batch_idx--50] train_loss: 0.0016868797441323598, acc: 0.8001685049019608, lr: 0.04954623784746919
[batch_idx--100] train_loss: 0.0016642419902589357, acc: 0.8015160891089109, lr: 0.04953516208740226
[batch_idx--150] train_loss: 0.001663965785209805, acc: 0.8017384105960265, lr: 0.049523954047730606
[batch_idx--200] train_loss: 0.001650845630219512, acc: 0.8041433457711443, lr: 0.04951261378888158
[batch_idx--250] train_loss: 0.0016504669630625452, acc: 0.8043295567729084, lr: 0.049501141371995405
[batch_idx--300] train_loss: 0.0016494464470333484, acc: 0.804765365448505, lr: 0.0494895368589248
[batch_idx--350] train_loss: 0.0016463594716785216, acc: 0.8051883012820513, lr: 0.0494778003122347
[batch_idx--400] train_loss: 0.0016456244625453083, acc: 0.8055155081047382, lr: 0.049465931795201847
[batch_idx--450] train_loss: 0.0016492370438599747, acc: 0.8052209532405318, lr: 0.049453931371814544
total time of one epoch: 204.84555220603943 s
train_loss:  0.0016492370438599747  acc:  0.8052209532405318
->>lr:0.049454
test_loss:  0.001690525920741063  test_acc:  0.802705050254374
best acc:  79.92306737808661
Saving..

------Epoch: 10------
[batch_idx--0] train_loss: 0.001778692938387394, acc: 0.8046875, lr: 0.049453690018345146
[batch_idx--50] train_loss: 0.0016645835803858206, acc: 0.8009344362745098, lr: 0.04944155511713453
[batch_idx--100] train_loss: 0.0016410836205347488, acc: 0.8048808787128713, lr: 0.04942928844099462
[batch_idx--150] train_loss: 0.0016372995165836633, acc: 0.8046875, lr: 0.0494168900560603
[batch_idx--200] train_loss: 0.0016277339819132984, acc: 0.8060284514925373, lr: 0.04940436002917662
[batch_idx--250] train_loss: 0.0016277226460800762, acc: 0.8065861553784861, lr: 0.04939169842789834
[batch_idx--300] train_loss: 0.0016287032667968262, acc: 0.806984530730897, lr: 0.04937890532048959
[batch_idx--350] train_loss: 0.0016295649078104145, acc: 0.8071469907407407, lr: 0.04936598077592351
[batch_idx--400] train_loss: 0.0016291600967318451, acc: 0.8071715243142145, lr: 0.049352924863881875
[batch_idx--450] train_loss: 0.0016307588929841488, acc: 0.8081021973825806, lr: 0.04933973765475472
total time of one epoch: 205.43006038665771 s
train_loss:  0.0016307588929841488  acc:  0.8081021973825806
->>lr:0.049340
test_loss:  0.0015593585667442722  test_acc:  0.8197046779997519
best acc:  80.2705050254374
Saving..

------Epoch: 11------
[batch_idx--0] train_loss: 0.0014978117542341352, acc: 0.8046875, lr: 0.04933947257182901
[batch_idx--50] train_loss: 0.0016173871334496082, acc: 0.8127297794117647, lr: 0.04932615151292455
[batch_idx--100] train_loss: 0.001601865652275484, acc: 0.8154393564356436, lr: 0.04931269930128121
[batch_idx--150] train_loss: 0.0016098607089432167, acc: 0.8135606374172185, lr: 0.04929911600942565
[batch_idx--200] train_loss: 0.0016077236875900952, acc: 0.8128886815920398, lr: 0.04928540171059123
[batch_idx--250] train_loss: 0.001609765519146841, acc: 0.8127956922310757, lr: 0.04927155647871764
[batch_idx--300] train_loss: 0.0016089590796984213, acc: 0.8123312915282392, lr: 0.04925758038845046
[batch_idx--350] train_loss: 0.0016033477425187869, acc: 0.8130898326210826, lr: 0.04924347351514081
[batch_idx--400] train_loss: 0.0016063405862751597, acc: 0.8121687967581047, lr: 0.049229235934844906
[batch_idx--450] train_loss: 0.001611693077078795, acc: 0.8118339292533064, lr: 0.04921486772432365
total time of one epoch: 207.91335487365723 s
train_loss:  0.001611693077078795  acc:  0.8118339292533064
->>lr:0.049215
test_loss:  0.001836649584465486  test_acc:  0.7859535922571038
best acc:  81.97046779997518

------Epoch: 12------
[batch_idx--0] train_loss: 0.0019217743538320065, acc: 0.7890625, lr: 0.04921457902821578
[batch_idx--50] train_loss: 0.0016141890310773662, acc: 0.8098958333333334, lr: 0.04920007765467417
[batch_idx--100] train_loss: 0.00161343690879311, acc: 0.8093285891089109, lr: 0.049185445808112044
[batch_idx--150] train_loss: 0.001608137799186373, acc: 0.8123447847682119, lr: 0.049170683567415975
[batch_idx--200] train_loss: 0.0015955583791280935, acc: 0.8142685012437811, lr: 0.04915579101217554
[batch_idx--250] train_loss: 0.0015961632788351985, acc: 0.8136516434262948, lr: 0.04914076822268292
[batch_idx--300] train_loss: 0.0015938320422260418, acc: 0.8137977574750831, lr: 0.04912561527993242
[batch_idx--350] train_loss: 0.0015951131299360949, acc: 0.8139912749287749, lr: 0.049110332265620074
[batch_idx--400] train_loss: 0.0015929069467576365, acc: 0.8140975685785536, lr: 0.049094919262143176
[batch_idx--450] train_loss: 0.001593806723230818, acc: 0.8141944666226959, lr: 0.049079376352599846
total time of one epoch: 204.9618043899536 s
train_loss:  0.001593806723230818  acc:  0.8141944666226959
->>lr:0.049079
test_loss:  0.0015798020058137368  test_acc:  0.8202010174959672
best acc:  81.97046779997518
Saving..

------Epoch: 13------
[batch_idx--0] train_loss: 0.0015513170510530472, acc: 0.8046875, lr: 0.049079064169941455
[batch_idx--50] train_loss: 0.0015758842951161605, acc: 0.8145680147058824, lr: 0.04906338884254441
[batch_idx--100] train_loss: 0.0015921213267610806, acc: 0.8119972153465347, lr: 0.04904758377907498
[batch_idx--150] train_loss: 0.0015845958471902653, acc: 0.8146212748344371, lr: 0.04903164906474507
[batch_idx--200] train_loss: 0.0015857180120627309, acc: 0.8138603855721394, lr: 0.04901558478546556
[batch_idx--250] train_loss: 0.0015881092373867967, acc: 0.813464890438247, lr: 0.04899939102784589
[batch_idx--300] train_loss: 0.001584116810781145, acc: 0.8146932101328903, lr: 0.04898306787919357
[batch_idx--350] train_loss: 0.0015810309422396103, acc: 0.8153044871794872, lr: 0.04896661542751371
[batch_idx--400] train_loss: 0.0015831456262446438, acc: 0.8151788497506235, lr: 0.04895003376150854
[batch_idx--450] train_loss: 0.0015825006517130934, acc: 0.8159388343111049, lr: 0.04893332297057697
total time of one epoch: 205.4245536327362 s
train_loss:  0.0015825006517130934  acc:  0.8159388343111049
->>lr:0.048933
test_loss:  0.0015649403542380043  test_acc:  0.8204491872440749
best acc:  82.02010174959672
Saving..

------Epoch: 14------
[batch_idx--0] train_loss: 0.0016759303398430347, acc: 0.8203125, lr: 0.048932987438301684
[batch_idx--50] train_loss: 0.0015532281021496245, acc: 0.8159466911764706, lr: 0.04891614503276587
[batch_idx--100] train_loss: 0.0015489599877267634, acc: 0.8175665222772277, lr: 0.04889917368501234
[batch_idx--150] train_loss: 0.001550119203694214, acc: 0.8177773178807947, lr: 0.04888207348654094
[batch_idx--200] train_loss: 0.0015501609658220069, acc: 0.8174362562189055, lr: 0.048864844529546175
[batch_idx--250] train_loss: 0.0015471878988423432, acc: 0.818429407370518, lr: 0.04884748690691675
[batch_idx--300] train_loss: 0.0015506316162026998, acc: 0.8184567068106312, lr: 0.048830000712235096
[batch_idx--350] train_loss: 0.0015497665512017333, acc: 0.8188991274928775, lr: 0.048812386039776785
[batch_idx--400] train_loss: 0.0015493362983502912, acc: 0.8192896664588528, lr: 0.0487946429845101
[batch_idx--450] train_loss: 0.0015554480997199388, acc: 0.8191758947478044, lr: 0.048776771642095464
total time of one epoch: 206.46789288520813 s
train_loss:  0.0015554480997199388  acc:  0.8191758947478044
->>lr:0.048777
test_loss:  0.0016840440727874798  test_acc:  0.8022087107581586
best acc:  82.0449187244075

------Epoch: 15------
[batch_idx--0] train_loss: 0.001652000704780221, acc: 0.81640625, lr: 0.048776412907378844
[batch_idx--50] train_loss: 0.0015723755076418027, acc: 0.8147977941176471, lr: 0.04875841081133997
[batch_idx--100] train_loss: 0.0015689317323728511, acc: 0.8165996287128713, lr: 0.04874028062349638
[batch_idx--150] train_loss: 0.001559919706200379, acc: 0.8183723096026491, lr: 0.0487220224415957
[batch_idx--200] train_loss: 0.0015530247769471425, acc: 0.8194962686567164, lr: 0.04870363636407563
[batch_idx--250] train_loss: 0.0015488588812378832, acc: 0.8202658117529881, lr: 0.04868512249006343
[batch_idx--300] train_loss: 0.0015507539648383212, acc: 0.8208964908637874, lr: 0.048666480919375345
[batch_idx--350] train_loss: 0.001543204866262137, acc: 0.8218705484330484, lr: 0.0486477117525161
[batch_idx--400] train_loss: 0.0015414948827770546, acc: 0.8220464463840399, lr: 0.04862881509067834
[batch_idx--450] train_loss: 0.00154605070442312, acc: 0.8219182837504773, lr: 0.04860979103574209
total time of one epoch: 204.5904402732849 s
train_loss:  0.00154605070442312  acc:  0.8219182837504773
->>lr:0.048610
test_loss:  0.0014495662822515117  test_acc:  0.8367043057451297
best acc:  82.0449187244075
Saving..

------Epoch: 16------
[batch_idx--0] train_loss: 0.0015759868547320366, acc: 0.796875, lr: 0.04860940925593703
[batch_idx--50] train_loss: 0.001552126580374498, acc: 0.8193167892156863, lr: 0.048590255365709406
[batch_idx--100] train_loss: 0.0015360765680117478, acc: 0.8223236386138614, lr: 0.04857097429027534
[batch_idx--150] train_loss: 0.0015278952620269744, acc: 0.8235720198675497, lr: 0.0485515661335874
[batch_idx--200] train_loss: 0.0015279281194048439, acc: 0.8237912002487562, lr: 0.048532031000283304
[batch_idx--250] train_loss: 0.0015282603861964438, acc: 0.8239386205179283, lr: 0.048512368995685354
[batch_idx--300] train_loss: 0.0015320347902826048, acc: 0.8235179609634552, lr: 0.04849258022579986
[batch_idx--350] train_loss: 0.0015354571844772183, acc: 0.8228944088319088, lr: 0.04847266479731658
[batch_idx--400] train_loss: 0.0015273578012097357, acc: 0.8237316864089775, lr: 0.048452622817608176
[batch_idx--450] train_loss: 0.001531128540025241, acc: 0.8234283333911896, lr: 0.04843245439472954
total time of one epoch: 206.3585181236267 s
train_loss:  0.001531128540025241  acc:  0.8234283333911896
->>lr:0.048432
test_loss:  0.0014760602732008837  test_acc:  0.8354634570045911
best acc:  83.67043057451296

------Epoch: 17------
[batch_idx--0] train_loss: 0.0014696106081828475, acc: 0.84765625, lr: 0.04843204973729729
[batch_idx--50] train_loss: 0.0015093541895861134, acc: 0.8232996323529411, lr: 0.048411752454410206
[batch_idx--100] train_loss: 0.0015215470782932964, acc: 0.8232131806930693, lr: 0.0483913289487026
[batch_idx--150] train_loss: 0.0015168155401649064, acc: 0.824192880794702, lr: 0.04837077933028638
[batch_idx--200] train_loss: 0.0015236043726877119, acc: 0.8232859141791045, lr: 0.04835010370995336
[batch_idx--250] train_loss: 0.0015139631065261732, acc: 0.8247011952191236, lr: 0.0483293021991747
[batch_idx--300] train_loss: 0.0015151852794437115, acc: 0.8243615033222591, lr: 0.04830837491010029
[batch_idx--350] train_loss: 0.001512017352785119, acc: 0.8251869658119658, lr: 0.04828732195555814
[batch_idx--400] train_loss: 0.001506594205368078, acc: 0.8259721789276808, lr: 0.04826614344905377
[batch_idx--450] train_loss: 0.0015117116806536658, acc: 0.8257715138681571, lr: 0.04824483950476961
total time of one epoch: 204.6314799785614 s
train_loss:  0.0015117116806536658  acc:  0.8257715138681571
->>lr:0.048245
test_loss:  0.0017701294548178091  test_acc:  0.7987343342846507
best acc:  83.67043057451296

------Epoch: 18------
[batch_idx--0] train_loss: 0.001292551402002573, acc: 0.8515625, lr: 0.04824441214720629
[batch_idx--50] train_loss: 0.0015160477692809176, acc: 0.8253676470588235, lr: 0.04822298037471885
[batch_idx--100] train_loss: 0.0015059784642595909, acc: 0.8251856435643564, lr: 0.04820142339716232
[batch_idx--150] train_loss: 0.0014959143957320527, acc: 0.8276852235099338, lr: 0.04817974133075961
[batch_idx--200] train_loss: 0.0014919782241583981, acc: 0.828163868159204, lr: 0.04815793429240808
[batch_idx--250] train_loss: 0.0014948868716833186, acc: 0.8283273157370518, lr: 0.04813600239967885
[batch_idx--300] train_loss: 0.001493541756644845, acc: 0.8280990448504983, lr: 0.04811394577081616
[batch_idx--350] train_loss: 0.001491876543589743, acc: 0.8285478988603988, lr: 0.04809176452473679
[batch_idx--400] train_loss: 0.0014903394437448454, acc: 0.8282516365336658, lr: 0.048069458781029376
[batch_idx--450] train_loss: 0.0014924324649845287, acc: 0.8281841219148124, lr: 0.048047028659953764
total time of one epoch: 207.70458555221558 s
train_loss:  0.0014924324649845287  acc:  0.8281841219148124
->>lr:0.048047
test_loss:  0.0015565455107790082  test_acc:  0.8267775158208215
best acc:  83.67043057451296

------Epoch: 19------
[batch_idx--0] train_loss: 0.0014020383823662996, acc: 0.83984375, lr: 0.04804657878971252
[batch_idx--50] train_loss: 0.001507056924952742, acc: 0.8277420343137255, lr: 0.04802402192830846
[batch_idx--100] train_loss: 0.0014938590460281708, acc: 0.8277382425742574, lr: 0.04800134093450581
[batch_idx--150] train_loss: 0.0014922113708275933, acc: 0.8276593543046358, lr: 0.04797853593058756
[batch_idx--200] train_loss: 0.0014888643112209677, acc: 0.8292327425373134, lr: 0.04795560703950527
[batch_idx--250] train_loss: 0.001486295422787715, acc: 0.8298057768924303, lr: 0.047932554384878465
[batch_idx--300] train_loss: 0.0014833260367800825, acc: 0.8303960755813954, lr: 0.0479093780909939
[batch_idx--350] train_loss: 0.0014765386478285546, acc: 0.8312967414529915, lr: 0.047886078282804945
[batch_idx--400] train_loss: 0.0014777901002375451, acc: 0.8309986751870324, lr: 0.047862655085930884
[batch_idx--450] train_loss: 0.0014813439084174472, acc: 0.8308917971326414, lr: 0.04783910862665624
total time of one epoch: 206.34684872627258 s
train_loss:  0.0014813439084174472  acc:  0.8308917971326414
->>lr:0.047839
test_loss:  0.0014358474068109739  test_acc:  0.8396823427224221
best acc:  83.67043057451296
Saving..

------Epoch: 20------
[batch_idx--0] train_loss: 0.0016616301145404577, acc: 0.796875, lr: 0.04783863644106502
[batch_idx--50] train_loss: 0.001507550457437687, acc: 0.8260569852941176, lr: 0.047814964384929284
[batch_idx--100] train_loss: 0.0014987038609820722, acc: 0.8265006188118812, lr: 0.047791169323514016
[batch_idx--150] train_loss: 0.0014815344398113473, acc: 0.8293667218543046, lr: 0.047767251385108636
[batch_idx--200] train_loss: 0.0014866969950117208, acc: 0.8293493470149254, lr: 0.04774321069866503
[batch_idx--250] train_loss: 0.0014902526304956926, acc: 0.8290432021912351, lr: 0.04771904739379687
[batch_idx--300] train_loss: 0.0014796191625346576, acc: 0.8303830980066446, lr: 0.0476947616007789
[batch_idx--350] train_loss: 0.001477341470441269, acc: 0.8306957799145299, lr: 0.0476703534505463
[batch_idx--400] train_loss: 0.0014728235964549523, acc: 0.831271430798005, lr: 0.047645823074693894
[batch_idx--450] train_loss: 0.0014759095653166861, acc: 0.8315340021522547, lr: 0.047621170605475466
total time of one epoch: 207.0215232372284 s
train_loss:  0.0014759095653166861  acc:  0.8315340021522547
->>lr:0.047621
test_loss:  0.0015189737129601936  test_acc:  0.8308723166645986
best acc:  83.96823427224221

------Epoch: 21------
[batch_idx--0] train_loss: 0.0012953485129401088, acc: 0.87109375, lr: 0.04762067631165049
[batch_idx--50] train_loss: 0.0014615446949998538, acc: 0.8330269607843137, lr: 0.047595899444129244
[batch_idx--100] train_loss: 0.0014575104929949387, acc: 0.8323019801980198, lr: 0.04757100075240174
[batch_idx--150] train_loss: 0.0014624414720344327, acc: 0.8329366721854304, lr: 0.04754598037070751
[batch_idx--200] train_loss: 0.0014600820088786865, acc: 0.8340135261194029, lr: 0.047520838433942204
[batch_idx--250] train_loss: 0.001464708218447478, acc: 0.8333229581673307, lr: 0.04749557507765681
[batch_idx--300] train_loss: 0.0014628844689175587, acc: 0.8333549626245847, lr: 0.047470190438056926
[batch_idx--350] train_loss: 0.001470947240484597, acc: 0.8319422186609686, lr: 0.047444684652002064
[batch_idx--400] train_loss: 0.0014641107930372147, acc: 0.8330833073566085, lr: 0.04741905785700488
[batch_idx--450] train_loss: 0.0014691623868256808, acc: 0.8327750199604262, lr: 0.04739331019123044
total time of one epoch: 204.78153467178345 s
train_loss:  0.0014691623868256808  acc:  0.8327750199604262
->>lr:0.047393
test_loss:  0.001534326365100848  test_acc:  0.8247921578359598
best acc:  83.96823427224221

------Epoch: 22------
[batch_idx--0] train_loss: 0.0013515331083908677, acc: 0.84765625, lr: 0.047392794005985325
[batch_idx--50] train_loss: 0.0014653787194915553, acc: 0.8291207107843137, lr: 0.04736692319503155
[batch_idx--100] train_loss: 0.0014567204271581503, acc: 0.8309483292079208, lr: 0.047340931794380904
[batch_idx--150] train_loss: 0.001450020771331789, acc: 0.8317984271523179, lr: 0.04731481994416418
[batch_idx--200] train_loss: 0.0014489823471597251, acc: 0.8334693718905473, lr: 0.04728858778516159
[batch_idx--250] train_loss: 0.0014488874114604584, acc: 0.8333385209163346, lr: 0.04726223545880198
[batch_idx--300] train_loss: 0.001447426475061605, acc: 0.8345099667774086, lr: 0.04723576310716207
[batch_idx--350] train_loss: 0.0014475907349661842, acc: 0.8346354166666666, lr: 0.047209170872965694
[batch_idx--400] train_loss: 0.0014444227310645387, acc: 0.8354309538653366, lr: 0.047182458899583
[batch_idx--450] train_loss: 0.0014458571711628383, acc: 0.8355521227479432, lr: 0.04715562733102973
total time of one epoch: 208.40447783470154 s
train_loss:  0.0014458571711628383  acc:  0.8355521227479432
->>lr:0.047156
test_loss:  0.0015015053363011453  test_acc:  0.8291351284278446
best acc:  83.96823427224221

------Epoch: 23------
[batch_idx--0] train_loss: 0.0014054602943360806, acc: 0.8359375, lr: 0.04715508948078037
[batch_idx--50] train_loss: 0.0014516975269561598, acc: 0.8346354166666666, lr: 0.047128136074186804
[batch_idx--100] train_loss: 0.0014523397981290622, acc: 0.8345451732673267, lr: 0.04710106336530035
[batch_idx--150] train_loss: 0.0014380319961439202, acc: 0.8365066225165563, lr: 0.04707387150008163
[batch_idx--200] train_loss: 0.0014382428617045208, acc: 0.8364622201492538, lr: 0.04704656062513368
[batch_idx--250] train_loss: 0.0014379694640443501, acc: 0.8367623256972112, lr: 0.04701913088770116
[batch_idx--300] train_loss: 0.0014360835679042528, acc: 0.8374299210963455, lr: 0.04699158243566958
[batch_idx--350] train_loss: 0.0014365457852060597, acc: 0.8375066773504274, lr: 0.04696391541756448
[batch_idx--400] train_loss: 0.0014407296065227164, acc: 0.8367655081047382, lr: 0.046936129982550645
[batch_idx--450] train_loss: 0.0014383107515340149, acc: 0.837487416252994, lr: 0.0469082262804313
total time of one epoch: 206.37644743919373 s
train_loss:  0.0014383107515340149  acc:  0.837487416252994
->>lr:0.046908
test_loss:  0.0017112472251414484  test_acc:  0.8033254746246432
best acc:  83.96823427224221

------Epoch: 24------
[batch_idx--0] train_loss: 0.0015953467227518559, acc: 0.80859375, lr: 0.04690766700109659
[batch_idx--50] train_loss: 0.0014507627667055703, acc: 0.8363204656862745, lr: 0.04687964282151817
[batch_idx--100] train_loss: 0.0014290992437981734, acc: 0.8375232054455446, lr: 0.046851500679380806
[batch_idx--150] train_loss: 0.0014359430920345005, acc: 0.8373861754966887, lr: 0.046823240726410885
[batch_idx--200] train_loss: 0.0014325741444487327, acc: 0.8383861940298507, lr: 0.046794863114969956
[batch_idx--250] train_loss: 0.0014337036991491914, acc: 0.8371358316733067, lr: 0.04676636799805392
[batch_idx--300] train_loss: 0.0014293650157464995, acc: 0.8375596968438538, lr: 0.046737755529292206
[batch_idx--350] train_loss: 0.0014239417835459791, acc: 0.8383524750712251, lr: 0.046709025862946923
[batch_idx--400] train_loss: 0.0014214240957488146, acc: 0.8387137624688279, lr: 0.046680179153912066
[batch_idx--450] train_loss: 0.0014244297966575716, acc: 0.8389627521088624, lr: 0.04665121555771262
total time of one epoch: 209.6879644393921 s
train_loss:  0.0014244297966575716  acc:  0.8389627521088624
->>lr:0.046651
test_loss:  0.001552214855028894  test_acc:  0.8259089217024445
best acc:  83.96823427224221

------Epoch: 25------
[batch_idx--0] train_loss: 0.0014819602947682142, acc: 0.8125, lr: 0.046650635094610975
[batch_idx--50] train_loss: 0.001439723843599067, acc: 0.8328737745098039, lr: 0.04662155243437907
[batch_idx--100] train_loss: 0.0014291339378693316, acc: 0.8367496905940595, lr: 0.04659235320306443
[batch_idx--150] train_loss: 0.0014184733177381044, acc: 0.8387831125827815, lr: 0.046563037558092685
[batch_idx--200] train_loss: 0.0014199138872686829, acc: 0.8388914800995025, lr: 0.04653360565751704
[batch_idx--250] train_loss: 0.0014145132325834547, acc: 0.8399682519920318, lr: 0.04650405766001754
[batch_idx--300] train_loss: 0.0014103061865328307, acc: 0.8406613372093024, lr: 0.04647439372490014
[batch_idx--350] train_loss: 0.0014080859739280325, acc: 0.840789707977208, lr: 0.046444614012095875
[batch_idx--400] train_loss: 0.0014055463946436037, acc: 0.8413731296758105, lr: 0.046414718682159954
[batch_idx--450] train_loss: 0.0014139092020884678, acc: 0.8406290137813726, lr: 0.04638470789627097
total time of one epoch: 206.23967027664185 s
train_loss:  0.0014139092020884678  acc:  0.8406290137813726
->>lr:0.046385
test_loss:  0.0013841196094024919  test_acc:  0.8476237746618687
best acc:  83.96823427224221
Saving..

------Epoch: 26------
[batch_idx--0] train_loss: 0.001374876475892961, acc: 0.84765625, lr: 0.04638410650401267
[batch_idx--50] train_loss: 0.0014127608269964363, acc: 0.8420649509803921, lr: 0.04635397811974326
[batch_idx--100] train_loss: 0.0013905324924755656, acc: 0.8434019183168316, lr: 0.04632373460699926
[batch_idx--150] train_loss: 0.0013915392537817161, acc: 0.843698261589404, lr: 0.04629337612883644
[batch_idx--200] train_loss: 0.0013976491760666395, acc: 0.8430698072139303, lr: 0.046262902848930414
[batch_idx--250] train_loss: 0.0014064782470709597, acc: 0.84183578187251, lr: 0.04623231493157573
[batch_idx--300] train_loss: 0.0014056175981224375, acc: 0.841686565614618, lr: 0.046201612541685
[batch_idx--350] train_loss: 0.001406287047759951, acc: 0.8413127670940171, lr: 0.046170795844788
[batch_idx--400] train_loss: 0.001404519235840685, acc: 0.8411490804239401, lr: 0.04613986500703078
[batch_idx--450] train_loss: 0.0014062228536917856, acc: 0.8412885756934079, lr: 0.0461088201951748
total time of one epoch: 206.63246417045593 s
train_loss:  0.0014062228536917856  acc:  0.8412885756934079
->>lr:0.046109
test_loss:  0.0014769850216250309  test_acc:  0.8375728998635067
best acc:  84.76237746618688

------Epoch: 27------
[batch_idx--0] train_loss: 0.001231638714671135, acc: 0.87109375, lr: 0.04610819813755038
[batch_idx--50] train_loss: 0.0013563751640236553, acc: 0.8473498774509803, lr: 0.04607703724454855
[batch_idx--100] train_loss: 0.0013813047962595183, acc: 0.8426670792079208, lr: 0.046045762716179425
[batch_idx--150] train_loss: 0.0013743349287769948, acc: 0.8434654387417219, lr: 0.04601437472105743
[batch_idx--200] train_loss: 0.0013776113532844986, acc: 0.8435167910447762, lr: 0.04598287342840873
[batch_idx--250] train_loss: 0.0013824760486219688, acc: 0.842691733067729, lr: 0.04595125900807036
[batch_idx--300] train_loss: 0.001385449559468021, acc: 0.8424133098006644, lr: 0.045919531630489216
[batch_idx--350] train_loss: 0.0013866789816106614, acc: 0.8426037215099715, lr: 0.045887691466721246
[batch_idx--400] train_loss: 0.0013847735268005782, acc: 0.8427271664588528, lr: 0.04585573868843045
[batch_idx--450] train_loss: 0.0013931063350574432, acc: 0.8423907383622037, lr: 0.04582367346788801
total time of one epoch: 203.37235856056213 s
train_loss:  0.0013931063350574432  acc:  0.8423907383622037
->>lr:0.045824
test_loss:  0.001340036863931016  test_acc:  0.8507258965132151
best acc:  84.76237746618688
Saving..

------Epoch: 28------
[batch_idx--0] train_loss: 0.0015348054002970457, acc: 0.828125, lr: 0.04582303101775249
[batch_idx--50] train_loss: 0.0013809830530126597, acc: 0.8439797794117647, lr: 0.04579085128421578
[batch_idx--100] train_loss: 0.0013770822822900101, acc: 0.8432472153465347, lr: 0.04575855945826332
[batch_idx--150] train_loss: 0.001384525500478482, acc: 0.8423013245033113, lr: 0.04572615571399419
[batch_idx--200] train_loss: 0.0013765320975324185, acc: 0.8435362251243781, lr: 0.045693640226110915
[batch_idx--250] train_loss: 0.0013740897406842485, acc: 0.8439678784860558, lr: 0.045661013169918455
[batch_idx--300] train_loss: 0.0013772231020788318, acc: 0.8438019102990033, lr: 0.04562827472132332
[batch_idx--350] train_loss: 0.0013770972311555108, acc: 0.8439058048433048, lr: 0.045595425056832534
[batch_idx--400] train_loss: 0.0013786164658757256, acc: 0.8432629364089775, lr: 0.04556246435355277
[batch_idx--450] train_loss: 0.0013831969555288262, acc: 0.8435449717082654, lr: 0.04552939278918935
total time of one epoch: 204.79350233078003 s
train_loss:  0.0013831969555288262  acc:  0.8435449717082654
->>lr:0.045529
test_loss:  0.00166891365300368  test_acc:  0.8075443603424742
best acc:  85.07258965132151

------Epoch: 29------
[batch_idx--0] train_loss: 0.0015475278487429023, acc: 0.8359375, lr: 0.045528730228342605
[batch_idx--50] train_loss: 0.0014182888701850293, acc: 0.8363970588235294, lr: 0.04549554576936571
[batch_idx--100] train_loss: 0.0013900398608702835, acc: 0.8411587252475248, lr: 0.04546225081009201
[batch_idx--150] train_loss: 0.0013828895753249526, acc: 0.8428704470198676, lr: 0.04542884553002893
[batch_idx--200] train_loss: 0.0013735092735029202, acc: 0.8447800062189055, lr: 0.04539533010927871
[batch_idx--250] train_loss: 0.0013739083257255208, acc: 0.8441079432270916, lr: 0.04536170472853737
[batch_idx--300] train_loss: 0.0013706050024203881, acc: 0.8444767441860465, lr: 0.045327969569093796
[batch_idx--350] train_loss: 0.0013704819129143134, acc: 0.8448295049857549, lr: 0.04529412481282874
[batch_idx--400] train_loss: 0.0013680697309591825, acc: 0.845357309850374, lr: 0.04526017064221382
[batch_idx--450] train_loss: 0.0013733039141533073, acc: 0.8450810566876107, lr: 0.04522610724031057
total time of one epoch: 208.13456320762634 s
train_loss:  0.0013733039141533073  acc:  0.8450810566876107
->>lr:0.045226
test_loss:  0.0014075874091525988  test_acc:  0.8420399553294453
best acc:  85.07258965132151

------Epoch: 30------
[batch_idx--0] train_loss: 0.0013416301226243377, acc: 0.859375, lr: 0.04522542485937369
[batch_idx--50] train_loss: 0.001355440107028128, acc: 0.8494178921568627, lr: 0.04519125023075707
[batch_idx--100] train_loss: 0.0013635006265272157, acc: 0.8468053836633663, lr: 0.045156966742431685
[batch_idx--150] train_loss: 0.001360324937665206, acc: 0.8479666804635762, lr: 0.04512257457923455
[batch_idx--200] train_loss: 0.0013632906139805097, acc: 0.8466262437810945, lr: 0.04508807392658861
[batch_idx--250] train_loss: 0.0013636827619145234, acc: 0.8470493027888446, lr: 0.0450534649705017
[batch_idx--300] train_loss: 0.0013629732981472712, acc: 0.8473837209302325, lr: 0.04501874789756559
[batch_idx--350] train_loss: 0.0013618176044137389, acc: 0.8475115740740741, lr: 0.04498392289495493
[batch_idx--400] train_loss: 0.001363213430971669, acc: 0.8476367674563591, lr: 0.04494899015042629
[batch_idx--450] train_loss: 0.0013649312826314794, acc: 0.8475283785191099, lr: 0.04491394985231711
total time of one epoch: 206.6975326538086 s
train_loss:  0.0013649312826314794  acc:  0.8475283785191099
->>lr:0.044914
test_loss:  0.0013359213847205188  test_acc:  0.8514704057575382
best acc:  85.07258965132151
Saving..

------Epoch: 31------
[batch_idx--0] train_loss: 0.0015144271310418844, acc: 0.8359375, lr: 0.04491324795060491
[batch_idx--50] train_loss: 0.0013666735361695435, acc: 0.8448223039215687, lr: 0.04487809814247016
[batch_idx--100] train_loss: 0.0013456855200941094, acc: 0.8474628712871287, lr: 0.044842841162964144
[batch_idx--150] train_loss: 0.0013506311999590735, acc: 0.847682119205298, lr: 0.04480747720217241
[batch_idx--200] train_loss: 0.00135658414882668, acc: 0.8466651119402985, lr: 0.04477200645075726
[batch_idx--250] train_loss: 0.0013641885774436434, acc: 0.8458042828685259, lr: 0.04473642909995676
[batch_idx--300] train_loss: 0.0013642143394312267, acc: 0.8455409053156147, lr: 0.044700745341583706
[batch_idx--350] train_loss: 0.0013568400794393423, acc: 0.8465878739316239, lr: 0.044664955368024575
[batch_idx--400] train_loss: 0.0013578415090889388, acc: 0.8462437655860349, lr: 0.044629059372238496
[batch_idx--450] train_loss: 0.0013598311633894798, acc: 0.8464696080813691, lr: 0.044593057547756214
total time of one epoch: 207.40417528152466 s
train_loss:  0.0013598311633894798  acc:  0.8464696080813691
->>lr:0.044593
test_loss:  0.0013065361284354674  test_acc:  0.8479960292840303
best acc:  85.14704057575382

------Epoch: 32------
[batch_idx--0] train_loss: 0.001240510493516922, acc: 0.8828125, lr: 0.044592336433146
[batch_idx--50] train_loss: 0.001358259375681918, acc: 0.8475796568627451, lr: 0.04455622686336067
[batch_idx--100] train_loss: 0.001342507552973336, acc: 0.8489712252475248, lr: 0.0445200118575505
[batch_idx--150] train_loss: 0.0013461260461180612, acc: 0.8490531870860927, lr: 0.04448369161096615
[batch_idx--200] train_loss: 0.0013460762890296714, acc: 0.8486279539800995, lr: 0.044447266319425686
[batch_idx--250] train_loss: 0.0013459876276630596, acc: 0.8493681523904383, lr: 0.044410736179313494
[batch_idx--300] train_loss: 0.0013433265597621394, acc: 0.8498364825581395, lr: 0.04437410138757928
[batch_idx--350] train_loss: 0.0013399969004001735, acc: 0.8500378383190883, lr: 0.04433736214173695
[batch_idx--400] train_loss: 0.0013391769325948248, acc: 0.8501792394014963, lr: 0.04430051863986356
[batch_idx--450] train_loss: 0.0013453379084867618, acc: 0.8497760960877564, lr: 0.04426357108059828
total time of one epoch: 204.2087848186493 s
train_loss:  0.0013453379084867618  acc:  0.8497760960877564
->>lr:0.044264
test_loss:  0.0013946423845353857  test_acc:  0.8462588410472763
best acc:  85.14704057575382

------Epoch: 33------
[batch_idx--0] train_loss: 0.0011988888727501035, acc: 0.87109375, lr: 0.044262831069394735
[batch_idx--50] train_loss: 0.0013504709555383992, acc: 0.8475796568627451, lr: 0.04422577757680957
[batch_idx--100] train_loss: 0.0013424137406659745, acc: 0.8494353341584159, lr: 0.04418862042979371
[batch_idx--150] train_loss: 0.0013428191756151172, acc: 0.8498810016556292, lr: 0.044151359828677295
[batch_idx--200] train_loss: 0.0013440444032239973, acc: 0.8500272077114428, lr: 0.04411399597434825
[batch_idx--250] train_loss: 0.0013440119852107834, acc: 0.8502241035856574, lr: 0.04407652906825116
[batch_idx--300] train_loss: 0.0013425946506390044, acc: 0.8504723837209303, lr: 0.04403895931238623
[batch_idx--350] train_loss: 0.0013368741988583847, acc: 0.8509504095441596, lr: 0.044001286909308164
[batch_idx--400] train_loss: 0.0013374814675410193, acc: 0.8505104426433915, lr: 0.04396351206212508
[batch_idx--450] train_loss: 0.0013445019473692526, acc: 0.8500711632589302, lr: 0.043925634974497405
total time of one epoch: 207.31122732162476 s
train_loss:  0.0013445019473692526  acc:  0.8500711632589302
->>lr:0.043926
test_loss:  0.0013263142202107276  test_acc:  0.8566819704677999
best acc:  85.14704057575382
Saving..

------Epoch: 34------
[batch_idx--0] train_loss: 0.001251840847544372, acc: 0.8671875, lr: 0.043924876391293916
[batch_idx--50] train_loss: 0.0013680384110878495, acc: 0.8400735294117647, lr: 0.0438868952287954
[batch_idx--100] train_loss: 0.0013599635048833962, acc: 0.8434792698019802, lr: 0.04384881223892658
[batch_idx--150] train_loss: 0.0013393802315440793, acc: 0.847759726821192, lr: 0.04381062762700922
[batch_idx--200] train_loss: 0.0013373744493322586, acc: 0.8479866293532339, lr: 0.043772341598912995
[batch_idx--250] train_loss: 0.0013340467701209672, acc: 0.8488234561752988, lr: 0.04373395436105431
[batch_idx--300] train_loss: 0.001333897442176344, acc: 0.8494860880398671, lr: 0.04369546612039528
[batch_idx--350] train_loss: 0.001334894097282782, acc: 0.8491697827635327, lr: 0.04365687708444255
[batch_idx--400] train_loss: 0.0013366340995740675, acc: 0.8488544264339152, lr: 0.04361818746124621
[batch_idx--450] train_loss: 0.0013389629472376724, acc: 0.849220675530253, lr: 0.04357939745939863
total time of one epoch: 207.64346027374268 s
train_loss:  0.0013389629472376724  acc:  0.849220675530253
->>lr:0.043579
test_loss:  0.0013592642210659696  test_acc:  0.8501054721429457
best acc:  85.66819704678

------Epoch: 35------
[batch_idx--0] train_loss: 0.0013263692380860448, acc: 0.859375, lr: 0.04357862063693486
[batch_idx--50] train_loss: 0.0012980399826797201, acc: 0.856234681372549, lr: 0.04353972846431615
[batch_idx--100] train_loss: 0.0013090774605954343, acc: 0.8553527227722773, lr: 0.043500736336052385
[batch_idx--150] train_loss: 0.001314163946589788, acc: 0.8528042218543046, lr: 0.04346164446236689
[batch_idx--200] train_loss: 0.0013095064706108834, acc: 0.8544970460199005, lr: 0.04342245305402075
[batch_idx--250] train_loss: 0.0013068005249212194, acc: 0.8545972360557769, lr: 0.04338316232231171
[batch_idx--300] train_loss: 0.0013095489685714518, acc: 0.8535740240863787, lr: 0.043343772479072985
[batch_idx--350] train_loss: 0.0013120049705922583, acc: 0.8532874821937322, lr: 0.043304283736672146
[batch_idx--400] train_loss: 0.0013140181566941602, acc: 0.8530236907730673, lr: 0.04326469630800999
[batch_idx--450] train_loss: 0.0013185255330341876, acc: 0.8529697642934009, lr: 0.04322501040651934
total time of one epoch: 206.0517954826355 s
train_loss:  0.0013185255330341876  acc:  0.8529697642934009
->>lr:0.043225
test_loss:  0.0012989988145379753  test_acc:  0.857550564586177
best acc:  85.66819704678
Saving..

------Epoch: 36------
[batch_idx--0] train_loss: 0.0012582610361278057, acc: 0.87109375, lr: 0.04322421568553529
[batch_idx--50] train_loss: 0.0013303303310428472, acc: 0.8509497549019608, lr: 0.04318442956218869
[batch_idx--100] train_loss: 0.0013074268526997012, acc: 0.8549272896039604, lr: 0.04314454539876614
[batch_idx--150] train_loss: 0.0013128220765166823, acc: 0.8537613824503312, lr: 0.043104563410300306
[batch_idx--200] train_loss: 0.0013129831128406214, acc: 0.8539528917910447, lr: 0.043064483812351256
[batch_idx--250] train_loss: 0.0013129346010523784, acc: 0.8539747260956175, lr: 0.04302430682100536
[batch_idx--300] train_loss: 0.00131599191170916, acc: 0.8532236295681063, lr: 0.042984032652874024
[batch_idx--350] train_loss: 0.0013152956687301355, acc: 0.8529981303418803, lr: 0.04294366152509261
[batch_idx--400] train_loss: 0.0013127092262172602, acc: 0.8533548940149626, lr: 0.04290319365531922
[batch_idx--450] train_loss: 0.001315988943983764, acc: 0.853794216683445, lr: 0.04286262926173353
total time of one epoch: 206.51666474342346 s
train_loss:  0.001315988943983764  acc:  0.853794216683445
->>lr:0.042863
test_loss:  0.0013732046669182433  test_acc:  0.846631095669438
best acc:  85.75505645861769

------Epoch: 37------
[batch_idx--0] train_loss: 0.0012061767047271132, acc: 0.84765625, lr: 0.04286181699082009
[batch_idx--50] train_loss: 0.0013044441470365022, acc: 0.854702818627451, lr: 0.04282115436825425
[batch_idx--100] train_loss: 0.0012967571354526473, acc: 0.8566290222772277, lr: 0.04278039566418517
[batch_idx--150] train_loss: 0.0013103624747985887, acc: 0.8549513658940397, lr: 0.04273954109836054
[batch_idx--200] train_loss: 0.0013069724863909408, acc: 0.8557019589552238, lr: 0.0426985908910449
[batch_idx--250] train_loss: 0.001302753896331897, acc: 0.8557333167330677, lr: 0.042657545263018404
[batch_idx--300] train_loss: 0.001303921077528851, acc: 0.8553519518272426, lr: 0.042616404435575676
[batch_idx--350] train_loss: 0.0013029984332172684, acc: 0.8555355235042735, lr: 0.04257516863052461
[batch_idx--400] train_loss: 0.0013059722623982911, acc: 0.8550011689526185, lr: 0.04253383807018514
[batch_idx--450] train_loss: 0.0013120005200610387, acc: 0.854644704412122, lr: 0.042492412977388094
total time of one epoch: 204.8317186832428 s
train_loss:  0.0013120005200610387  acc:  0.854644704412122
->>lr:0.042492
test_loss:  0.0012951086111526687  test_acc:  0.8563097158456384
best acc:  85.75505645861769

------Epoch: 38------
[batch_idx--0] train_loss: 0.001249738154001534, acc: 0.84765625, lr: 0.042491583512834136
[batch_idx--50] train_loss: 0.0013173867014748062, acc: 0.8537837009803921, lr: 0.04245006222701923
[batch_idx--100] train_loss: 0.0013065470519733828, acc: 0.8532642326732673, lr: 0.04240844686041831
[batch_idx--150] train_loss: 0.0013038513612230339, acc: 0.8532181291390728, lr: 0.042366737637397726
[batch_idx--200] train_loss: 0.0013043723507571168, acc: 0.8533698694029851, lr: 0.04232493478282982
[batch_idx--250] train_loss: 0.0013010811841716449, acc: 0.8536012201195219, lr: 0.042283038522091754
[batch_idx--300] train_loss: 0.0013005000761898847, acc: 0.8537686877076412, lr: 0.04224104908106427
[batch_idx--350] train_loss: 0.0012954632646173367, acc: 0.8548232727920227, lr: 0.0421989666861305
[batch_idx--400] train_loss: 0.0012976813749607625, acc: 0.8543192799251871, lr: 0.04215679156417471
[batch_idx--450] train_loss: 0.001304799015345219, acc: 0.8538983580379769, lr: 0.04211452394258114
total time of one epoch: 208.19236850738525 s
train_loss:  0.001304799015345219  acc:  0.8538983580379769
->>lr:0.042115
test_loss:  0.0012439521352474705  test_acc:  0.8647474872813005
best acc:  85.75505645861769
Saving..

------Epoch: 39------
[batch_idx--0] train_loss: 0.0012972744880244136, acc: 0.87109375, lr: 0.04211367764821722
[batch_idx--50] train_loss: 0.0012810259450263546, acc: 0.858609068627451, lr: 0.04207131591176148
[batch_idx--100] train_loss: 0.0012906102110899174, acc: 0.8587175123762376, lr: 0.042028862136503926
[batch_idx--150] train_loss: 0.0012908388138902897, acc: 0.8584695778145696, lr: 0.0419863165513311
[batch_idx--200] train_loss: 0.0012902260621296085, acc: 0.8580923507462687, lr: 0.041943679385624544
[batch_idx--250] train_loss: 0.0012895801263226871, acc: 0.85746078187251, lr: 0.04190095086925955
[batch_idx--300] train_loss: 0.0012938691925047047, acc: 0.8571169019933554, lr: 0.041858131232603915
[batch_idx--350] train_loss: 0.0012912839641821096, acc: 0.8571380876068376, lr: 0.04181522070651669
[batch_idx--400] train_loss: 0.0012915843927610359, acc: 0.8568714931421446, lr: 0.04177221952234698
[batch_idx--450] train_loss: 0.0012953122702402025, acc: 0.8568316728572917, lr: 0.041729127911932645
total time of one epoch: 208.50315594673157 s
train_loss:  0.0012953122702402025  acc:  0.8568316728572917
->>lr:0.041729
test_loss:  0.001329235043799645  test_acc:  0.8546966124829384
best acc:  86.47474872813004

------Epoch: 40------
[batch_idx--0] train_loss: 0.001297701965086162, acc: 0.84765625, lr: 0.04172826515897146
[batch_idx--50] train_loss: 0.0013161294194230554, acc: 0.8535539215686274, lr: 0.04168508155313258
[batch_idx--100] train_loss: 0.0013170561080079266, acc: 0.855159344059406, lr: 0.04164180799084732
[batch_idx--150] train_loss: 0.0012965870204702365, acc: 0.8572019867549668, lr: 0.04159844470542206
[batch_idx--200] train_loss: 0.001295010770951393, acc: 0.8562849813432836, lr: 0.041554991930646906
[batch_idx--250] train_loss: 0.0012873043999561957, acc: 0.8572429033864541, lr: 0.041511449900794445
[batch_idx--300] train_loss: 0.0012902246404863102, acc: 0.8565718438538206, lr: 0.04146781885061848
[batch_idx--350] train_loss: 0.0012906296263273773, acc: 0.8563368055555556, lr: 0.04142409901535277
[batch_idx--400] train_loss: 0.0012914670044567873, acc: 0.8563064993765586, lr: 0.04138029063070971
[batch_idx--450] train_loss: 0.001295891480527674, acc: 0.8562155031763113, lr: 0.041336393932879134
total time of one epoch: 207.22841668128967 s
train_loss:  0.001295891480527674  acc:  0.8562155031763113
->>lr:0.041336
test_loss:  0.0012271976405122556  test_acc:  0.8680977788807545
best acc:  86.47474872813004
Saving..

------Epoch: 41------
[batch_idx--0] train_loss: 0.0012173393042758107, acc: 0.8671875, lr: 0.04133551509975264
[batch_idx--50] train_loss: 0.0012653215557756816, acc: 0.8589920343137255, lr: 0.041291528566287365
[batch_idx--100] train_loss: 0.0012704743755898337, acc: 0.858330754950495, lr: 0.041247454198189024
[batch_idx--150] train_loss: 0.0012759130354816502, acc: 0.8576676324503312, lr: 0.04120329223308148
[batch_idx--200] train_loss: 0.0012723656017356436, acc: 0.8581700870646766, lr: 0.041159042909060875
[batch_idx--250] train_loss: 0.0012765464591385567, acc: 0.8572273406374502, lr: 0.04111470646469433
[batch_idx--300] train_loss: 0.0012769570198618617, acc: 0.8577398255813954, lr: 0.04107028313901867
[batch_idx--350] train_loss: 0.0012801765250984017, acc: 0.8573495370370371, lr: 0.04102577317153916
[batch_idx--400] train_loss: 0.001276727222768994, acc: 0.8578358790523691, lr: 0.04098117680222813
[batch_idx--450] train_loss: 0.00128278633006147, acc: 0.8576561252473357, lr: 0.04093649427152381
total time of one epoch: 207.59817957878113 s
train_loss:  0.00128278633006147  acc:  0.8576561252473357
->>lr:0.040936
test_loss:  0.0012162954432450449  test_acc:  0.8688422881250776
best acc:  86.80977788807544
Saving..

------Epoch: 42------
[batch_idx--0] train_loss: 0.0012606978416442871, acc: 0.859375, lr: 0.040935599743717244
[batch_idx--50] train_loss: 0.0013245273924743135, acc: 0.8510263480392157, lr: 0.04089082957657292
[batch_idx--100] train_loss: 0.0012939317419313559, acc: 0.8560875618811881, lr: 0.04084597373513602
[batch_idx--150] train_loss: 0.001288991212530296, acc: 0.8560120033112583, lr: 0.04080103246124366
[batch_idx--200] train_loss: 0.001281735034073374, acc: 0.8566930970149254, lr: 0.04075600599719357
[batch_idx--250] train_loss: 0.0012758503047901528, acc: 0.8573362798804781, lr: 0.04071089458574278
[batch_idx--300] train_loss: 0.0012730502328553864, acc: 0.8574802740863787, lr: 0.04066569847010627
[batch_idx--350] train_loss: 0.0012719882953981007, acc: 0.8576166310541311, lr: 0.040620417893955756
[batch_idx--400] train_loss: 0.001274600925221296, acc: 0.8575144170822943, lr: 0.04057505310141827
[batch_idx--450] train_loss: 0.0012769772311882776, acc: 0.8578123372791335, lr: 0.04052960433707492
total time of one epoch: 208.7848539352417 s
train_loss:  0.0012769772311882776  acc:  0.8578123372791335
->>lr:0.040530
test_loss:  0.0012546636682835327  test_acc:  0.8616453654299541
best acc:  86.88422881250776

------Epoch: 43------
[batch_idx--0] train_loss: 0.0009513575350865722, acc: 0.92578125, lr: 0.040528694506957764
[batch_idx--50] train_loss: 0.0013109913127789018, acc: 0.8537071078431373, lr: 0.04048316034380937
[batch_idx--100] train_loss: 0.00127973739463504, acc: 0.8577506188118812, lr: 0.040437542704288454
[batch_idx--150] train_loss: 0.0012825095635955993, acc: 0.8576417632450332, lr: 0.04039184183433934
[batch_idx--200] train_loss: 0.0012832367763766527, acc: 0.8577425373134329, lr: 0.04034605798035504
[batch_idx--250] train_loss: 0.0012774499452327826, acc: 0.8587058017928287, lr: 0.04030019138917598
[batch_idx--300] train_loss: 0.0012764979567319971, acc: 0.8588688745847176, lr: 0.040254242308088696
[batch_idx--350] train_loss: 0.0012754415978804931, acc: 0.8589743589743589, lr: 0.040208210984824425
[batch_idx--400] train_loss: 0.001270903129841287, acc: 0.8596477556109726, lr: 0.04016209766755781
[batch_idx--450] train_loss: 0.001274584034454505, acc: 0.8598083799076613, lr: 0.040115902604905565
total time of one epoch: 205.74033904075623 s
train_loss:  0.001274584034454505  acc:  0.8598083799076613
->>lr:0.040116
test_loss:  0.0012503387777425764  test_acc:  0.8636307234148157
best acc:  86.88422881250776

------Epoch: 44------
[batch_idx--0] train_loss: 0.0010788722429424524, acc: 0.8984375, lr: 0.040114977871559376
[batch_idx--50] train_loss: 0.0012670424013562938, acc: 0.8587622549019608, lr: 0.04006869968519579
[batch_idx--100] train_loss: 0.0012667338435289146, acc: 0.8584467821782178, lr: 0.04002234025699524
[batch_idx--150] train_loss: 0.0012592419184781363, acc: 0.8597630380794702, lr: 0.039975899836901335
[batch_idx--200] train_loss: 0.0012611425910330383, acc: 0.8608325559701493, lr: 0.03992937867529435
[batch_idx--250] train_loss: 0.0012695008760830202, acc: 0.8598574452191236, lr: 0.03988277702298985
[batch_idx--300] train_loss: 0.0012670195384176938, acc: 0.8600109011627907, lr: 0.03983609513123738
[batch_idx--350] train_loss: 0.0012650180533740594, acc: 0.8601317663817664, lr: 0.03978933325171908
[batch_idx--400] train_loss: 0.0012651110550463015, acc: 0.8602517144638404, lr: 0.03974249163654834
[batch_idx--450] train_loss: 0.0012692442666810998, acc: 0.8602249453257889, lr: 0.03969557053826845
total time of one epoch: 208.35001230239868 s
train_loss:  0.0012692442666810998  acc:  0.8602249453257889
->>lr:0.039696
test_loss:  0.0011963185497513035  test_acc:  0.8714480704802084
best acc:  86.88422881250776
Saving..

------Epoch: 45------
[batch_idx--0] train_loss: 0.0010136286728084087, acc: 0.88671875, lr: 0.03969463130731183
[batch_idx--50] train_loss: 0.0012751728839551408, acc: 0.8591452205882353, lr: 0.0396476293968751
[batch_idx--100] train_loss: 0.0012578370025390668, acc: 0.8610767326732673, lr: 0.03960054851477232
[batch_idx--150] train_loss: 0.0012589027647959032, acc: 0.8614704056291391, lr: 0.039553388914836764
[batch_idx--200] train_loss: 0.0012555907903799778, acc: 0.8622706778606966, lr: 0.039506150851326104
[batch_idx--250] train_loss: 0.0012587500813572975, acc: 0.8616004731075697, lr: 0.039458834578921055
[batch_idx--300] train_loss: 0.001258320687377386, acc: 0.8613995016611296, lr: 0.03941144035272397
[batch_idx--350] train_loss: 0.0012592647562633956, acc: 0.8614115918803419, lr: 0.03936396842825749
[batch_idx--400] train_loss: 0.0012559383087721828, acc: 0.8615862687032418, lr: 0.03931641906146319
[batch_idx--450] train_loss: 0.0012586794865507127, acc: 0.8612750373173187, lr: 0.03926879250870011
total time of one epoch: 209.50575947761536 s
train_loss:  0.0012586794865507127  acc:  0.8612750373173187
->>lr:0.039269
test_loss:  0.0011778464738452  test_acc:  0.8721925797245316
best acc:  87.14480704802085
Saving..

------Epoch: 46------
[batch_idx--0] train_loss: 0.0011690001701936126, acc: 0.875, lr: 0.0392678391921108
[batch_idx--50] train_loss: 0.0012437196599100443, acc: 0.8626685049019608, lr: 0.03922013417419226
[batch_idx--100] train_loss: 0.001240929236547966, acc: 0.8634359529702971, lr: 0.03917235248941817
[batch_idx--150] train_loss: 0.001239376143777484, acc: 0.8638762417218543, lr: 0.03912449439540013
[batch_idx--200] train_loss: 0.0012489290098863567, acc: 0.8620957711442786, lr: 0.0390765601501617
[batch_idx--250] train_loss: 0.0012534279223212386, acc: 0.861258092629482, lr: 0.03902855001213699
[batch_idx--300] train_loss: 0.001249808690277086, acc: 0.8617369186046512, lr: 0.0389804642401693
[batch_idx--350] train_loss: 0.0012482187904396288, acc: 0.8618233618233618, lr: 0.03893230309350968
[batch_idx--400] train_loss: 0.0012488055732124428, acc: 0.8617713528678305, lr: 0.03888406683181559
[batch_idx--450] train_loss: 0.0012535082062074434, acc: 0.861951956121776, lr: 0.03883575571514944
total time of one epoch: 205.6823205947876 s
train_loss:  0.0012535082062074434  acc:  0.861951956121776
->>lr:0.038836
test_loss:  0.001169233591581104  test_acc:  0.8745501923315547
best acc:  87.21925797245316
Saving..

------Epoch: 47------
[batch_idx--0] train_loss: 0.0014070020988583565, acc: 0.84765625, lr: 0.038834788731083605
[batch_idx--50] train_loss: 0.0012825252899133107, acc: 0.8558517156862745, lr: 0.038786401530680796
[batch_idx--100] train_loss: 0.0012725902471165773, acc: 0.8579053217821783, lr: 0.03873794000186154
[batch_idx--150] train_loss: 0.0012512167735296666, acc: 0.8612117135761589, lr: 0.03868940440590278
[batch_idx--200] train_loss: 0.001245296987084051, acc: 0.8626010572139303, lr: 0.03864079500448077
[batch_idx--250] train_loss: 0.0012508861280410028, acc: 0.8619428535856574, lr: 0.03859211205966969
[batch_idx--300] train_loss: 0.001241235467613028, acc: 0.86328125, lr: 0.038543355833940224
[batch_idx--350] train_loss: 0.00124134714191148, acc: 0.8631365740740741, lr: 0.03849452659015813
[batch_idx--400] train_loss: 0.0012398116083576476, acc: 0.8633396976309227, lr: 0.03844562459158286
[batch_idx--450] train_loss: 0.0012432586303547908, acc: 0.8631929739299475, lr: 0.0383966501018661
total time of one epoch: 205.93590569496155 s
train_loss:  0.0012432586303547908  acc:  0.8631929739299475
->>lr:0.038397
test_loss:  0.0011854272265043164  test_acc:  0.8745501923315547
best acc:  87.45501923315548

------Epoch: 48------
[batch_idx--0] train_loss: 0.0010022677015513182, acc: 0.88671875, lr: 0.03839566987447492
[batch_idx--50] train_loss: 0.0012359081849674968, acc: 0.8644301470588235, lr: 0.038346621715813135
[batch_idx--100] train_loss: 0.0012359241914640337, acc: 0.8644415222772277, lr: 0.038297501599776934
[batch_idx--150] train_loss: 0.0012304907863564937, acc: 0.8657388245033113, lr: 0.03824830979119395
[batch_idx--200] train_loss: 0.0012361276697886376, acc: 0.8650303171641791, lr: 0.038199046555278386
[batch_idx--250] train_loss: 0.0012406344832555647, acc: 0.8644484561752988, lr: 0.038149712157629516
[batch_idx--300] train_loss: 0.0012407753726025035, acc: 0.8639301287375415, lr: 0.038100306864230285
[batch_idx--350] train_loss: 0.0012428609853639583, acc: 0.8636596331908832, lr: 0.038050830941445866
[batch_idx--400] train_loss: 0.001240870348227784, acc: 0.86414822319202, lr: 0.03800128465602222
[batch_idx--450] train_loss: 0.00124655693050959, acc: 0.863757072933662, lr: 0.03795166827508467
total time of one epoch: 210.99067449569702 s
train_loss:  0.00124655693050959  acc:  0.863757072933662
->>lr:0.037952
test_loss:  0.0012217752135322117  test_acc:  0.866732845266162
best acc:  87.45501923315548

------Epoch: 49------
[batch_idx--0] train_loss: 0.0010974600445479155, acc: 0.88671875, lr: 0.03795067523432826
[batch_idx--50] train_loss: 0.0012553824846833653, acc: 0.8618259803921569, lr: 0.037900987631550954
[batch_idx--100] train_loss: 0.0012478763525752296, acc: 0.8621209777227723, lr: 0.03785123047400412
[batch_idx--150] train_loss: 0.0012439769694260908, acc: 0.8624275662251656, lr: 0.03780140402994997
[batch_idx--200] train_loss: 0.0012404325239207428, acc: 0.8637476679104478, lr: 0.03775150856802428
[batch_idx--250] train_loss: 0.0012397787995651304, acc: 0.8644484561752988, lr: 0.03770154435723495
[batch_idx--300] train_loss: 0.0012368786990320762, acc: 0.8650332225913622, lr: 0.037651511666960506
[batch_idx--350] train_loss: 0.0012384944176168694, acc: 0.8642717236467237, lr: 0.03760141076694869
[batch_idx--400] train_loss: 0.0012350075142550981, acc: 0.8644404613466334, lr: 0.037551241927314974
[batch_idx--450] train_loss: 0.0012360082112725245, acc: 0.8647984864789808, lr: 0.03750100541854115
total time of one epoch: 208.1671576499939 s
train_loss:  0.0012360082112725245  acc:  0.8647984864789808
->>lr:0.037501
test_loss:  0.001165806183981857  test_acc:  0.8711999007321007
best acc:  87.45501923315548

------Epoch: 50------
[batch_idx--0] train_loss: 0.0011583769228309393, acc: 0.87890625, lr: 0.037500000000000006
[batch_idx--50] train_loss: 0.001241107535201545, acc: 0.8628982843137255, lr: 0.037449694747731944
[batch_idx--100] train_loss: 0.0012402442902889066, acc: 0.8639000618811881, lr: 0.03739932237380827
[batch_idx--150] train_loss: 0.001243980085270615, acc: 0.863203642384106, lr: 0.03734888314980809
[batch_idx--200] train_loss: 0.0012360397406010449, acc: 0.8643889925373134, lr: 0.037298377347670955
[batch_idx--250] train_loss: 0.0012411123572522217, acc: 0.8639037599601593, lr: 0.03724780523969534
[batch_idx--300] train_loss: 0.0012409218321662657, acc: 0.8638263081395349, lr: 0.03719716709853723
[batch_idx--350] train_loss: 0.0012420771749321361, acc: 0.8631922186609686, lr: 0.037146463197208594
[batch_idx--400] train_loss: 0.0012373072786159127, acc: 0.8635734881546134, lr: 0.03709569380907597
[batch_idx--450] train_loss: 0.0012394426635652703, acc: 0.8634533273162773, lr: 0.03704485920785895
total time of one epoch: 205.7109227180481 s
train_loss:  0.0012394426635652703  acc:  0.8634533273162773
->>lr:0.037045
test_loss:  0.001499311025214559  test_acc:  0.8296314679240601
best acc:  87.45501923315548

------Epoch: 51------
[batch_idx--0] train_loss: 0.001231341972015798, acc: 0.83203125, lr: 0.037043841852542884
[batch_idx--50] train_loss: 0.001245154309835212, acc: 0.8606770833333334, lr: 0.03699294101633032
[batch_idx--100] train_loss: 0.0012446064242659744, acc: 0.8613861386138614, lr: 0.036941975521017835
[batch_idx--150] train_loss: 0.0012451594249061647, acc: 0.8621171357615894, lr: 0.0368909456413823
[batch_idx--200] train_loss: 0.0012425748282112181, acc: 0.8626204912935324, lr: 0.03683985165254776
[batch_idx--250] train_loss: 0.0012392354199191578, acc: 0.8629388695219123, lr: 0.03678869382998386
[batch_idx--300] train_loss: 0.0012381421580007206, acc: 0.8634240033222591, lr: 0.03673747244950439
[batch_idx--350] train_loss: 0.0012324321026677674, acc: 0.8642160790598291, lr: 0.03668618778726586
[batch_idx--400] train_loss: 0.0012306101841415438, acc: 0.8645476153366584, lr: 0.0366348401197659
[batch_idx--450] train_loss: 0.0012323564017982249, acc: 0.864676988232027, lr: 0.036583429723841876
total time of one epoch: 207.94135403633118 s
train_loss:  0.0012323564017982249  acc:  0.864676988232027
->>lr:0.036583
test_loss:  0.0011487471741531842  test_acc:  0.8751706167018241
best acc:  87.45501923315548
Saving..

------Epoch: 52------
[batch_idx--0] train_loss: 0.0013024206273257732, acc: 0.8671875, lr: 0.036582400877996545
[batch_idx--50] train_loss: 0.0012169234618982848, acc: 0.8681066176470589, lr: 0.03653092678462853
[batch_idx--100] train_loss: 0.0012101926760157884, acc: 0.8677676361386139, lr: 0.036479390523077894
[batch_idx--150] train_loss: 0.0012163871726551592, acc: 0.8662820778145696, lr: 0.036427792371198774
[batch_idx--200] train_loss: 0.0012203641270579241, acc: 0.8658659825870647, lr: 0.036376132607179
[batch_idx--250] train_loss: 0.0012188876473040605, acc: 0.8666428037848606, lr: 0.03632441150953856
[batch_idx--300] train_loss: 0.0012196950098898793, acc: 0.866577553986711, lr: 0.036272629357128106
[batch_idx--350] train_loss: 0.0012179386035533902, acc: 0.8667200854700855, lr: 0.0362207864291275
[batch_idx--400] train_loss: 0.001216379541670323, acc: 0.8665056109725686, lr: 0.03616888300504424
[batch_idx--450] train_loss: 0.001221682053621489, acc: 0.8659180060401985, lr: 0.03611691936471199
total time of one epoch: 210.5926079750061 s
train_loss:  0.001221682053621489  acc:  0.8659180060401985
->>lr:0.036117
test_loss:  0.0011889870564093556  test_acc:  0.8704553914877776
best acc:  87.5170616701824

------Epoch: 53------
[batch_idx--0] train_loss: 0.0013730751816183329, acc: 0.8359375, lr: 0.036115879479623185
[batch_idx--50] train_loss: 0.0011994371672307013, acc: 0.8690257352941176, lr: 0.0360638547073383
[batch_idx--100] train_loss: 0.001216617835879252, acc: 0.8663753094059405, lr: 0.036011770285057136
[batch_idx--150] train_loss: 0.0012117965202408515, acc: 0.8668512003311258, lr: 0.03595962649358918
[batch_idx--200] train_loss: 0.001213161495748203, acc: 0.867012593283582, lr: 0.03590742361406404
[batch_idx--250] train_loss: 0.001218685020870748, acc: 0.8663159860557769, lr: 0.03585516192792988
[batch_idx--300] train_loss: 0.0012148621956588842, acc: 0.8668371054817275, lr: 0.03580284171695191
[batch_idx--350] train_loss: 0.0012138434450282712, acc: 0.8670984686609686, lr: 0.03575046326321087
[batch_idx--400] train_loss: 0.0012102102233152697, acc: 0.8677330112219451, lr: 0.035698026849101526
[batch_idx--450] train_loss: 0.0012133718978832293, acc: 0.8674106987884889, lr: 0.03564553275733112
total time of one epoch: 205.60375499725342 s
train_loss:  0.0012133718978832293  acc:  0.8674106987884889
->>lr:0.035646
test_loss:  0.0011484456156246538  test_acc:  0.8762873805683087
best acc:  87.5170616701824
Saving..

------Epoch: 54------
[batch_idx--0] train_loss: 0.0009747848380357027, acc: 0.89453125, lr: 0.03564448228912682
[batch_idx--50] train_loss: 0.001195388548213112, acc: 0.8683363970588235, lr: 0.035591929657709624
[batch_idx--100] train_loss: 0.0012082609383730532, acc: 0.8667233910891089, lr: 0.03553931992064693
[batch_idx--150] train_loss: 0.0012095152058897677, acc: 0.8669546771523179, lr: 0.035486653361580446
[batch_idx--200] train_loss: 0.001212940844406017, acc: 0.8671097636815921, lr: 0.03543393026445823
[batch_idx--250] train_loss: 0.0012108290440911256, acc: 0.8674520667330677, lr: 0.03538115091353316
[batch_idx--300] train_loss: 0.0012144508289693053, acc: 0.8664477782392026, lr: 0.035328315593361394
[batch_idx--350] train_loss: 0.0012150718120757247, acc: 0.8657296118233618, lr: 0.03527542458880086
[batch_idx--400] train_loss: 0.001214595963427114, acc: 0.8659698410224439, lr: 0.035222478185009704
[batch_idx--450] train_loss: 0.0012142685622097895, acc: 0.8662998576734822, lr: 0.035169476667444736
total time of one epoch: 207.02506017684937 s
train_loss:  0.0012142685622097895  acc:  0.8662998576734822
->>lr:0.035169
test_loss:  0.0011511237087461579  test_acc:  0.8752947015758779
best acc:  87.62873805683087

------Epoch: 55------
[batch_idx--0] train_loss: 0.0012232753215357661, acc: 0.87109375, lr: 0.035168416076895005
[batch_idx--50] train_loss: 0.001175565371180282, acc: 0.8694087009803921, lr: 0.03511535863766653
[batch_idx--100] train_loss: 0.0011994772063946297, acc: 0.8680770420792079, lr: 0.03506224666219176
[batch_idx--150] train_loss: 0.001201167285198728, acc: 0.8681705298013245, lr: 0.03500908043682018
[batch_idx--200] train_loss: 0.0011994430687584316, acc: 0.8686061878109452, lr: 0.034955860248193804
[batch_idx--250] train_loss: 0.0012014909221631182, acc: 0.8680278884462151, lr: 0.034902586383245504
[batch_idx--300] train_loss: 0.001205337142178857, acc: 0.8670058139534884, lr: 0.03484925912919761
[batch_idx--350] train_loss: 0.0012000637685155703, acc: 0.86759926994302, lr: 0.03479587877356025
[batch_idx--400] train_loss: 0.0011998893034950995, acc: 0.8678012001246883, lr: 0.034742445604129875
[batch_idx--450] train_loss: 0.0012064934412845947, acc: 0.8668899920158295, lr: 0.034688959908987675
total time of one epoch: 211.24054384231567 s
train_loss:  0.0012064934412845947  acc:  0.8668899920158295
->>lr:0.034689
test_loss:  0.0011627157785591023  test_acc:  0.8754187864499318
best acc:  87.62873805683087

------Epoch: 56------
[batch_idx--0] train_loss: 0.001188998925499618, acc: 0.8671875, lr: 0.034687889661302575
[batch_idx--50] train_loss: 0.0011948486675928329, acc: 0.8685661764705882, lr: 0.034634350687009215
[batch_idx--100] train_loss: 0.0011761576389100882, acc: 0.872137995049505, lr: 0.034580759769790186
[batch_idx--150] train_loss: 0.0011837094211149097, acc: 0.8713783112582781, lr: 0.034527117198577144
[batch_idx--200] train_loss: 0.0011839701322634791, acc: 0.871054881840796, lr: 0.034473423262580266
[batch_idx--250] train_loss: 0.0011828179321385385, acc: 0.8715295069721115, lr: 0.03441967825128663
[batch_idx--300] train_loss: 0.0011864049504031473, acc: 0.8710807724252492, lr: 0.0343658824544587
[batch_idx--350] train_loss: 0.0011882295235367943, acc: 0.8706040776353277, lr: 0.034312036162132735
[batch_idx--400] train_loss: 0.0011918323657108456, acc: 0.8702462593516209, lr: 0.034258139664617236
[batch_idx--450] train_loss: 0.00119770906968276, acc: 0.8697278439268233, lr: 0.0342041932524914
total time of one epoch: 208.0054533481598 s
train_loss:  0.00119770906968276  acc:  0.8697278439268233
->>lr:0.034204
test_loss:  0.0011271351800690899  test_acc:  0.8805062662861397
best acc:  87.62873805683087
Saving..

------Epoch: 57------
[batch_idx--0] train_loss: 0.0012728706933557987, acc: 0.84375, lr: 0.03420311381711696
[batch_idx--50] train_loss: 0.00120169049649335, acc: 0.8680300245098039, lr: 0.03414911679172232
[batch_idx--100] train_loss: 0.0011968576904884216, acc: 0.8679610148514851, lr: 0.034095070439506506
[batch_idx--150] train_loss: 0.001199836676958825, acc: 0.8674979304635762, lr: 0.03404097505185664
[batch_idx--200] train_loss: 0.0011964905320722332, acc: 0.8685673196517413, lr: 0.0339868309204242
[batch_idx--250] train_loss: 0.0011956255722501542, acc: 0.8689149651394422, lr: 0.03393263833712346
[batch_idx--300] train_loss: 0.0011919698532147835, acc: 0.8695883513289037, lr: 0.03387839759412996
[batch_idx--350] train_loss: 0.0011891294479704439, acc: 0.8696247329059829, lr: 0.03382410898387883
[batch_idx--400] train_loss: 0.0011882115802274752, acc: 0.8695351465087282, lr: 0.033769772799063326
[batch_idx--450] train_loss: 0.0011917105809148433, acc: 0.8697452008192453, lr: 0.03371538933263315
total time of one epoch: 208.9801049232483 s
train_loss:  0.0011917105809148433  acc:  0.8697452008192453
->>lr:0.033715
test_loss:  0.0011852577204798363  test_acc:  0.8741779377093932
best acc:  88.05062662861397

------Epoch: 58------
[batch_idx--0] train_loss: 0.0010215610964223742, acc: 0.90625, lr: 0.03371430118304538
[batch_idx--50] train_loss: 0.001189027322848857, acc: 0.8698682598039216, lr: 0.03365986979142943
[batch_idx--100] train_loss: 0.0011859583169323308, acc: 0.8703589108910891, lr: 0.03360539171073317
[batch_idx--150] train_loss: 0.0011918090502824018, acc: 0.8697485513245033, lr: 0.03355086723467137
[batch_idx--200] train_loss: 0.0011934659791883284, acc: 0.8695001554726368, lr: 0.03349629665720888
[batch_idx--250] train_loss: 0.0011939165925428984, acc: 0.8693351593625498, lr: 0.03344168027255918
[batch_idx--300] train_loss: 0.0011861092415622798, acc: 0.8706135797342193, lr: 0.033387018375182646
[batch_idx--350] train_loss: 0.0011890309251197469, acc: 0.870147792022792, lr: 0.03333231125978507
[batch_idx--400] train_loss: 0.0011868443420769976, acc: 0.8701001402743143, lr: 0.03327755922131603
[batch_idx--450] train_loss: 0.0011933262967478212, acc: 0.870066303329052, lr: 0.033222762554967304
total time of one epoch: 207.7315592765808 s
train_loss:  0.0011933262967478212  acc:  0.870066303329052
->>lr:0.033223
test_loss:  0.0012019594796376335  test_acc:  0.869338627621293
best acc:  88.05062662861397

------Epoch: 59------
[batch_idx--0] train_loss: 0.0010248408652842045, acc: 0.8828125, lr: 0.03322166616846458
[batch_idx--50] train_loss: 0.0012279837392270565, acc: 0.8653492647058824, lr: 0.033166824286034645
[batch_idx--100] train_loss: 0.0012053024907836157, acc: 0.8674582301980198, lr: 0.03311193837274467
[batch_idx--150] train_loss: 0.0011989038436833943, acc: 0.8682222682119205, lr: 0.03305700872450816
[batch_idx--200] train_loss: 0.0011960551610670576, acc: 0.8680814676616916, lr: 0.03300203563747449
[batch_idx--250] train_loss: 0.0011950380396583966, acc: 0.8679033864541833, lr: 0.0329470194080272
[batch_idx--300] train_loss: 0.0011952320008192124, acc: 0.8680699750830565, lr: 0.032891960332782424
[batch_idx--350] train_loss: 0.0011899775672542128, acc: 0.8690237713675214, lr: 0.03283685870858731
[batch_idx--400] train_loss: 0.001190235046466622, acc: 0.8692429083541147, lr: 0.03278171483251839
[batch_idx--450] train_loss: 0.0011913012565123724, acc: 0.8693720276321727, lr: 0.03272652900188
total time of one epoch: 208.8396511077881 s
train_loss:  0.0011913012565123724  acc:  0.8693720276321727
->>lr:0.032727
test_loss:  0.0011096960713689122  test_acc:  0.8838565578855937
best acc:  88.05062662861397
Saving..

------Epoch: 60------
[batch_idx--0] train_loss: 0.0009249290451407433, acc: 0.90234375, lr: 0.032725424859373686
[batch_idx--50] train_loss: 0.0011654318648153077, acc: 0.8739276960784313, lr: 0.032670196541591943
[batch_idx--100] train_loss: 0.001171947349701999, acc: 0.8712097772277227, lr: 0.03261492687048379
[batch_idx--150] train_loss: 0.00117544330030507, acc: 0.8717663493377483, lr: 0.03255961614403176
[batch_idx--200] train_loss: 0.0011760852449059264, acc: 0.8722209266169154, lr: 0.03250426466043975
[batch_idx--250] train_loss: 0.0011762474094001777, acc: 0.8717785109561753, lr: 0.03244887271813142
[batch_idx--300] train_loss: 0.0011770999042837078, acc: 0.8713273463455149, lr: 0.032393440615748524
[batch_idx--350] train_loss: 0.001179133424969215, acc: 0.8711493945868946, lr: 0.03233796865214936
[batch_idx--400] train_loss: 0.0011778354886896034, acc: 0.8716295199501247, lr: 0.03228245712640712
[batch_idx--450] train_loss: 0.0011784742940745524, acc: 0.8716978512167182, lr: 0.0322269063378083
total time of one epoch: 211.40352821350098 s
train_loss:  0.0011784742940745524  acc:  0.8716978512167182
->>lr:0.032227
test_loss:  0.0011030338988408867  test_acc:  0.8841047276337014
best acc:  88.38565578855938
Saving..

------Epoch: 61------
[batch_idx--0] train_loss: 0.0011633471585810184, acc: 0.859375, lr: 0.03222579492361179
[batch_idx--50] train_loss: 0.0011697063717863285, acc: 0.8731617647058824, lr: 0.032170204395443734
[batch_idx--100] train_loss: 0.0011731767646581083, acc: 0.8724860767326733, lr: 0.03211457520962184
[batch_idx--150] train_loss: 0.0011780317803376063, acc: 0.8718698261589404, lr: 0.032058907666066935
[batch_idx--200] train_loss: 0.0011759111967600364, acc: 0.8716184701492538, lr: 0.03200320206490668
[batch_idx--250] train_loss: 0.0011737685468775105, acc: 0.8717006972111554, lr: 0.03194745870647391
[batch_idx--300] train_loss: 0.0011700745762876572, acc: 0.8724174626245847, lr: 0.03189167789130505
[batch_idx--350] train_loss: 0.0011701666464116372, acc: 0.8723624465811965, lr: 0.031835859920138446
[batch_idx--400] train_loss: 0.0011685868584959678, acc: 0.8728374376558603, lr: 0.03178000509391275
[batch_idx--450] train_loss: 0.0011712382705164795, acc: 0.872782656993092, lr: 0.03172411371376536
total time of one epoch: 207.20849990844727 s
train_loss:  0.0011712382705164795  acc:  0.872782656993092
->>lr:0.031724
test_loss:  0.001293898309219385  test_acc:  0.8631343839186003
best acc:  88.41047276337015

------Epoch: 62------
[batch_idx--0] train_loss: 0.0011115182423964143, acc: 0.875, lr: 0.031722995515381644
[batch_idx--50] train_loss: 0.0011571420883924207, acc: 0.878140318627451, lr: 0.03166706716067022
[batch_idx--100] train_loss: 0.0011607250550273104, acc: 0.8754254331683168, lr: 0.03161110286093404
[batch_idx--150] train_loss: 0.0011705086055359747, acc: 0.8739134933774835, lr: 0.031555102917900694
[batch_idx--200] train_loss: 0.0011705555353633392, acc: 0.8738533893034826, lr: 0.03149906763348994
[batch_idx--250] train_loss: 0.0011761712468789513, acc: 0.8732102838645418, lr: 0.0314429973098121
[batch_idx--300] train_loss: 0.0011723813170758989, acc: 0.8735594892026578, lr: 0.031386892249166375
[batch_idx--350] train_loss: 0.0011706996380425776, acc: 0.8734975961538461, lr: 0.03133075275403927
[batch_idx--400] train_loss: 0.0011765801011319934, acc: 0.8722627026184538, lr: 0.03127457912710293
[batch_idx--450] train_loss: 0.001183856615792353, acc: 0.8714895685076544, lr: 0.031218371671213524
total time of one epoch: 209.45061540603638 s
train_loss:  0.001183856615792353  acc:  0.8714895685076544
->>lr:0.031218
test_loss:  0.0011407731780196438  test_acc:  0.8782727385531703
best acc:  88.41047276337015

------Epoch: 63------
[batch_idx--0] train_loss: 0.001257863943465054, acc: 0.8515625, lr: 0.031217247179121367
[batch_idx--50] train_loss: 0.0011694994561063747, acc: 0.8697916666666666, lr: 0.0311610055298914
[batch_idx--100] train_loss: 0.001160411122669973, acc: 0.8724860767326733, lr: 0.031104730664032437
[batch_idx--150] train_loss: 0.0011497304608292928, acc: 0.8743015314569537, lr: 0.031048422884946483
[batch_idx--200] train_loss: 0.0011637511582632749, acc: 0.873056592039801, lr: 0.030992082496212964
[batch_idx--250] train_loss: 0.001166429185119283, acc: 0.8728834661354582, lr: 0.030935709801587143
[batch_idx--300] train_loss: 0.0011653132969513535, acc: 0.8731312292358804, lr: 0.03087930510499845
[batch_idx--350] train_loss: 0.0011643462600796736, acc: 0.8732861467236467, lr: 0.030822868710548842
[batch_idx--400] train_loss: 0.001164690332726443, acc: 0.8730517456359103, lr: 0.030766400922511174
[batch_idx--450] train_loss: 0.0011687786006218202, acc: 0.8729475474711008, lr: 0.030709902045327583
total time of one epoch: 206.2787094116211 s
train_loss:  0.0011687786006218202  acc:  0.8729475474711008
->>lr:0.030710
test_loss:  0.0011039728772360658  test_acc:  0.8848492368780245
best acc:  88.41047276337015
Saving..

------Epoch: 64------
[batch_idx--0] train_loss: 0.0010540063958615065, acc: 0.90234375, lr: 0.030708771752766397
[batch_idx--50] train_loss: 0.001177324797026813, acc: 0.8739276960784313, lr: 0.030652241478464032
[batch_idx--100] train_loss: 0.0011622064912894575, acc: 0.8741104579207921, lr: 0.03059568073049836
[batch_idx--150] train_loss: 0.0011439552509059376, acc: 0.8758019453642384, lr: 0.030539089813812693
[batch_idx--200] train_loss: 0.0011481152032501996, acc: 0.875019434079602, lr: 0.03048246903351297
[batch_idx--250] train_loss: 0.0011491563200831888, acc: 0.8747354332669323, lr: 0.030425818694866172
[batch_idx--300] train_loss: 0.0011521390969153383, acc: 0.8741434800664452, lr: 0.030369139103298623
[batch_idx--350] train_loss: 0.0011549775050541762, acc: 0.8738203347578347, lr: 0.030312430564394355
[batch_idx--400] train_loss: 0.0011583324909347232, acc: 0.8738602711970075, lr: 0.03025569338389348
[batch_idx--450] train_loss: 0.0011583738805951251, acc: 0.8740844239247405, lr: 0.03019892786769053
total time of one epoch: 207.2508807182312 s
train_loss:  0.0011583738805951251  acc:  0.8740844239247405
->>lr:0.030199
test_loss:  0.0011031999583131311  test_acc:  0.884476982255863
best acc:  88.48492368780245

------Epoch: 65------
[batch_idx--0] train_loss: 0.001036953879520297, acc: 0.890625, lr: 0.03019779227044398
[batch_idx--50] train_loss: 0.001169547850640454, acc: 0.8727787990196079, lr: 0.03014099816711588
[batch_idx--100] train_loss: 0.0011709602843591998, acc: 0.8723313737623762, lr: 0.030084176346456905
[batch_idx--150] train_loss: 0.0011770082853537127, acc: 0.8707315811258278, lr: 0.030027327114817932
[batch_idx--200] train_loss: 0.0011727024041769554, acc: 0.8715796019900498, lr: 0.029970450778697578
[batch_idx--250] train_loss: 0.0011762260279406709, acc: 0.8712026892430279, lr: 0.02991354764474065
[batch_idx--300] train_loss: 0.0011719550507721735, acc: 0.871859426910299, lr: 0.02985661801973638
[batch_idx--350] train_loss: 0.0011699933464508875, acc: 0.8723958333333334, lr: 0.02979966221061685
[batch_idx--400] train_loss: 0.0011704036746199645, acc: 0.8722529613466334, lr: 0.029742680524455323
[batch_idx--450] train_loss: 0.0011728483873572415, acc: 0.8724789113757073, lr: 0.02968567326846454
total time of one epoch: 212.47019147872925 s
train_loss:  0.0011728483873572415  acc:  0.8724789113757073
->>lr:0.029686
test_loss:  0.0011794377399860652  test_acc:  0.8759151259461472
best acc:  88.48492368780245

------Epoch: 66------
[batch_idx--0] train_loss: 0.001109911478124559, acc: 0.87890625, lr: 0.02968453286464312
[batch_idx--50] train_loss: 0.0012224703666516672, acc: 0.8656556372549019, lr: 0.029627499844060053
[batch_idx--100] train_loss: 0.0011883430577132223, acc: 0.8698174504950495, lr: 0.029570441874636297
[batch_idx--150] train_loss: 0.0011862928382373901, acc: 0.8708867963576159, lr: 0.029513359263995894
[batch_idx--200] train_loss: 0.0011725788446611248, acc: 0.8722597947761194, lr: 0.029456252319895716
[batch_idx--250] train_loss: 0.0011726993041491485, acc: 0.872027514940239, lr: 0.029399121350223874
[batch_idx--300] train_loss: 0.0011756626472953842, acc: 0.8717426287375415, lr: 0.029341966662997956
[batch_idx--350] train_loss: 0.0011708646655504585, acc: 0.8724180911680912, lr: 0.02928478856636346
[batch_idx--400] train_loss: 0.001167061496113759, acc: 0.8729445916458853, lr: 0.02922758736859208
[batch_idx--450] train_loss: 0.001170276880903635, acc: 0.8734075051202833, lr: 0.02917036337808005
total time of one epoch: 211.64924120903015 s
train_loss:  0.001170276880903635  acc:  0.8734075051202833
->>lr:0.029170
test_loss:  0.001158532187414755  test_acc:  0.8791413326715474
best acc:  88.48492368780245

------Epoch: 67------
[batch_idx--0] train_loss: 0.0011864894768223166, acc: 0.87109375, lr: 0.02916921866790256
[batch_idx--50] train_loss: 0.0011722745382975713, acc: 0.8723958333333334, lr: 0.029111971746632322
[batch_idx--100] train_loss: 0.0011490990308638993, acc: 0.8750386757425742, lr: 0.02905470265595496
[batch_idx--150] train_loss: 0.001152867656000674, acc: 0.8739652317880795, lr: 0.028997411704632756
[batch_idx--200] train_loss: 0.0011604348784289439, acc: 0.8720654539800995, lr: 0.02894009920154584
[batch_idx--250] train_loss: 0.0011567974020634218, acc: 0.8726188994023905, lr: 0.02888276545569057
[batch_idx--300] train_loss: 0.001156057941029622, acc: 0.8732220722591362, lr: 0.0288254107761778
[batch_idx--350] train_loss: 0.0011556628088870132, acc: 0.8734642094017094, lr: 0.028768035472231265
[batch_idx--400] train_loss: 0.0011547896662666612, acc: 0.8736167394014963, lr: 0.0287106398531859
[batch_idx--450] train_loss: 0.0011511193127030778, acc: 0.8743881695421252, lr: 0.02865322422848614
total time of one epoch: 208.60076236724854 s
train_loss:  0.0011511193127030778  acc:  0.8743881695421252
->>lr:0.028653
test_loss:  0.001125937279437224  test_acc:  0.878520908301278
best acc:  88.48492368780245

------Epoch: 68------
[batch_idx--0] train_loss: 0.0011961535783484578, acc: 0.8515625, lr: 0.028652075714060296
[batch_idx--50] train_loss: 0.001172540532470699, acc: 0.8717064950980392, lr: 0.028594640002494582
[batch_idx--100] train_loss: 0.0011704627592762065, acc: 0.8732209158415841, lr: 0.028537184910679542
[batch_idx--150] train_loss: 0.0011652603376169522, acc: 0.8732408940397351, lr: 0.028479710748380266
[batch_idx--200] train_loss: 0.0011613957322693768, acc: 0.8737756529850746, lr: 0.028422217825464665
[batch_idx--250] train_loss: 0.0011554152131511039, acc: 0.8746420567729084, lr: 0.028364706451901797
[batch_idx--300] train_loss: 0.001154796282437466, acc: 0.8747793812292359, lr: 0.028307176937760206
[batch_idx--350] train_loss: 0.0011542036607357384, acc: 0.8745437143874644, lr: 0.028249629593206222
[batch_idx--400] train_loss: 0.0011565939950329389, acc: 0.8742791458852868, lr: 0.02819206472850232
[batch_idx--450] train_loss: 0.0011613631642534753, acc: 0.8740063179088416, lr: 0.02813448265400542
total time of one epoch: 211.47083139419556 s
train_loss:  0.0011613631642534753  acc:  0.8740063179088416
->>lr:0.028134
test_loss:  0.0010609135506895373  test_acc:  0.8915498200769326
best acc:  88.48492368780245
Saving..

------Epoch: 69------
[batch_idx--0] train_loss: 0.0010922795627266169, acc: 0.890625, lr: 0.028133330839107608
[batch_idx--50] train_loss: 0.001167091902792819, acc: 0.8726256127450981, lr: 0.028075731530447786
[batch_idx--100] train_loss: 0.0011641701267303733, acc: 0.8726407797029703, lr: 0.028018115639197247
[batch_idx--150] train_loss: 0.0011606391504659804, acc: 0.8732408940397351, lr: 0.027960483475988025
[batch_idx--200] train_loss: 0.0011558139442456932, acc: 0.8740671641791045, lr: 0.02790283535153988
[batch_idx--250] train_loss: 0.0011549850571455351, acc: 0.8745175547808764, lr: 0.027845171576658636
[batch_idx--300] train_loss: 0.001149809270698045, acc: 0.8749740448504983, lr: 0.027787492462234484
[batch_idx--350] train_loss: 0.00114808982421254, acc: 0.8754896723646723, lr: 0.02772979831924033
[batch_idx--400] train_loss: 0.001148708714979313, acc: 0.8749902587281796, lr: 0.02767208945873009
[batch_idx--450] train_loss: 0.0011533765719683204, acc: 0.8744575971118131, lr: 0.027614366191837037
total time of one epoch: 211.19199657440186 s
train_loss:  0.0011533765719683204  acc:  0.8744575971118131
->>lr:0.027614
test_loss:  0.001126566358425582  test_acc:  0.881995284774786
best acc:  89.15498200769326

------Epoch: 70------
[batch_idx--0] train_loss: 0.0013650135369971395, acc: 0.8203125, lr: 0.02761321158169134
[batch_idx--50] train_loss: 0.0011490101597326644, acc: 0.8743106617647058, lr: 0.027555473940897853
[batch_idx--100] train_loss: 0.0011529064544771642, acc: 0.8731822400990099, lr: 0.027497722522445946
[batch_idx--150] train_loss: 0.0011472689270794342, acc: 0.8748189155629139, lr: 0.027439957637698322
[batch_idx--200] train_loss: 0.0011485776854146142, acc: 0.8748445273631841, lr: 0.027382179598090313
[batch_idx--250] train_loss: 0.0011393844631901271, acc: 0.8756225099601593, lr: 0.027324388715128153
[batch_idx--300] train_loss: 0.0011437195074741429, acc: 0.8749091569767442, lr: 0.027266585300387343
[batch_idx--350] train_loss: 0.0011455325367979896, acc: 0.8748108084045584, lr: 0.027208769665510946
[batch_idx--400] train_loss: 0.0011481069856639162, acc: 0.874629831670823, lr: 0.027150942122207884
[batch_idx--450] train_loss: 0.0011548706585666872, acc: 0.874544381573923, lr: 0.027093102982251305
total time of one epoch: 208.90105199813843 s
train_loss:  0.0011548706585666872  acc:  0.874544381573923
->>lr:0.027093
test_loss:  0.0011050672481722416  test_acc:  0.8860900856185631
best acc:  89.15498200769326

------Epoch: 71------
[batch_idx--0] train_loss: 0.0012180169578641653, acc: 0.86328125, lr: 0.02709194608330789
[batch_idx--50] train_loss: 0.0011409723859590788, acc: 0.8775275735294118, lr: 0.027034095436018247
[batch_idx--100] train_loss: 0.0011307696879859829, acc: 0.8783647896039604, lr: 0.026976233822045795
[batch_idx--150] train_loss: 0.0011461888033656145, acc: 0.8760606374172185, lr: 0.026918361553347366
[batch_idx--200] train_loss: 0.0011440418792114737, acc: 0.8757190609452736, lr: 0.026860478941937244
[batch_idx--250] train_loss: 0.0011463325873733428, acc: 0.8755135707171314, lr: 0.026802586299885446
[batch_idx--300] train_loss: 0.0011393413142195942, acc: 0.8762977574750831, lr: 0.026744683939316106
[batch_idx--350] train_loss: 0.0011376562031474166, acc: 0.8770922364672364, lr: 0.026686772172405743
[batch_idx--400] train_loss: 0.0011346131954237614, acc: 0.8777372973815462, lr: 0.02662885131138157
[batch_idx--450] train_loss: 0.001139466389980072, acc: 0.877330162807651, lr: 0.026570921668519862
total time of one epoch: 212.55479764938354 s
train_loss:  0.001139466389980072  acc:  0.877330162807651
->>lr:0.026571
test_loss:  0.0010967033793071552  test_acc:  0.8834843032634322
best acc:  89.15498200769326

------Epoch: 72------
[batch_idx--0] train_loss: 0.0011875126510858536, acc: 0.84375, lr: 0.026569762988232833
[batch_idx--50] train_loss: 0.0011212364793298584, acc: 0.8756893382352942, lr: 0.026511824709652916
[batch_idx--100] train_loss: 0.0011195700366677034, acc: 0.8767017326732673, lr: 0.02645387828017616
[batch_idx--150] train_loss: 0.0011323882854352427, acc: 0.8753621688741722, lr: 0.026395924012216673
[batch_idx--200] train_loss: 0.0011263391164024893, acc: 0.8762826492537313, lr: 0.02633796221823084
[batch_idx--250] train_loss: 0.0011269412380531876, acc: 0.8757781374501992, lr: 0.026279993210715575
[batch_idx--300] train_loss: 0.0011326221005056685, acc: 0.8755580357142857, lr: 0.026222017302206753
[batch_idx--350] train_loss: 0.0011306408853429314, acc: 0.8758235398860399, lr: 0.02616403480527739
[batch_idx--400] train_loss: 0.0011338856072104686, acc: 0.8758474906483791, lr: 0.02610604603253605
[batch_idx--450] train_loss: 0.0011351982295641438, acc: 0.8758808622904155, lr: 0.026048051296625147
total time of one epoch: 209.75453734397888 s
train_loss:  0.0011351982295641438  acc:  0.8758808622904155
->>lr:0.026048
test_loss:  0.0011165191594269513  test_acc:  0.8775282293088472
best acc:  89.15498200769326

------Epoch: 73------
[batch_idx--0] train_loss: 0.0010394342243671417, acc: 0.8828125, lr: 0.02604689134322999
[batch_idx--50] train_loss: 0.0011273906794467977, acc: 0.8755361519607843, lr: 0.025988890847003655
[batch_idx--100] train_loss: 0.0011156337850930004, acc: 0.8782487623762376, lr: 0.025930885019241706
[batch_idx--150] train_loss: 0.0011214432148540406, acc: 0.8784147350993378, lr: 0.025872874172678507
[batch_idx--200] train_loss: 0.001124986437547822, acc: 0.8780122823383084, lr: 0.02581485862007545
[batch_idx--250] train_loss: 0.001125674156993405, acc: 0.8781125498007968, lr: 0.02575683867421932
[batch_idx--300] train_loss: 0.0011264640813541795, acc: 0.8783482142857143, lr: 0.02569881464792059
[batch_idx--350] train_loss: 0.0011296719196584191, acc: 0.8775485220797721, lr: 0.02564078685401172
[batch_idx--400] train_loss: 0.00113153664155415, acc: 0.8774937655860349, lr: 0.025582755605345495
[batch_idx--450] train_loss: 0.0011342333330806667, acc: 0.8775297670705037, lr: 0.02552472121479332
total time of one epoch: 210.57381010055542 s
train_loss:  0.0011342333330806667  acc:  0.8775297670705037
->>lr:0.025525
test_loss:  0.0011017322373872418  test_acc:  0.8865864251147785
best acc:  89.15498200769326

------Epoch: 74------
[batch_idx--0] train_loss: 0.001364715863019228, acc: 0.84375, lr: 0.025523560497083927
[batch_idx--50] train_loss: 0.0011164297625952052, acc: 0.8780637254901961, lr: 0.025465523224145754
[batch_idx--100] train_loss: 0.0011284918251152306, acc: 0.8787128712871287, lr: 0.02540748344137178
[batch_idx--150] train_loss: 0.001135026369188351, acc: 0.8773282284768212, lr: 0.02534944146167944
[batch_idx--200] train_loss: 0.0011291097764467904, acc: 0.8778179415422885, lr: 0.025291397597997967
[batch_idx--250] train_loss: 0.0011289464091822742, acc: 0.8778946713147411, lr: 0.025233352163266793
[batch_idx--300] train_loss: 0.0011302287813331746, acc: 0.8775955149501661, lr: 0.025175305470433812
[batch_idx--350] train_loss: 0.0011256970771975773, acc: 0.8782830306267806, lr: 0.025117257832453683
[batch_idx--400] train_loss: 0.0011257164601522248, acc: 0.8781756546134664, lr: 0.025059209562286185
[batch_idx--450] train_loss: 0.0011308876522818818, acc: 0.8780591522893741, lr: 0.02500116097289448
total time of one epoch: 210.31143021583557 s
train_loss:  0.0011308876522818818  acc:  0.8780591522893741
->>lr:0.025001
test_loss:  0.0011226932158436428  test_acc:  0.8838565578855937
best acc:  89.15498200769326

------Epoch: 75------
[batch_idx--0] train_loss: 0.0009447239572182298, acc: 0.90625, lr: 0.025
[batch_idx--50] train_loss: 0.0011497377851685765, acc: 0.8725490196078431, lr: 0.024941951407416053
[batch_idx--100] train_loss: 0.0011453166814972785, acc: 0.8754641089108911, lr: 0.024883903127797022
[batch_idx--150] train_loss: 0.0011371667138362514, acc: 0.8765521523178808, lr: 0.02482585547410613
[batch_idx--200] train_loss: 0.0011434012801567121, acc: 0.8755441542288557, lr: 0.024767808759303227
[batch_idx--250] train_loss: 0.0011383695667053005, acc: 0.8763228336653387, lr: 0.024709763296343102
[batch_idx--300] train_loss: 0.0011381752954554617, acc: 0.8758305647840532, lr: 0.024651719398173802
[batch_idx--350] train_loss: 0.0011383598117141896, acc: 0.8758569266381766, lr: 0.024593677377734924
[batch_idx--400] train_loss: 0.001132449652230892, acc: 0.8763637780548629, lr: 0.02453563754795596
[batch_idx--450] train_loss: 0.0011340986578941726, acc: 0.876349498385809, lr: 0.024477600221754565
total time of one epoch: 213.8055408000946 s
train_loss:  0.0011340986578941726  acc:  0.876349498385809
->>lr:0.024478
test_loss:  0.0010987718209748173  test_acc:  0.8843528973818091
best acc:  89.15498200769326

------Epoch: 76------
[batch_idx--0] train_loss: 0.000930790847633034, acc: 0.90234375, lr: 0.02447643950291608
[batch_idx--50] train_loss: 0.0010846853404598055, acc: 0.8832720588235294, lr: 0.024418405052717584
[batch_idx--100] train_loss: 0.001092677836831991, acc: 0.8830445544554455, lr: 0.024360373738147447
[batch_idx--150] train_loss: 0.0011097861890255517, acc: 0.8803031870860927, lr: 0.024302345872077406
[batch_idx--200] train_loss: 0.001111524566470539, acc: 0.8798002176616916, lr: 0.024244321767360646
[batch_idx--250] train_loss: 0.0011090286462419328, acc: 0.8801045816733067, lr: 0.024186301736830045
[batch_idx--300] train_loss: 0.001106315556189596, acc: 0.880515469269103, lr: 0.024128286093296536
[batch_idx--350] train_loss: 0.0011097589772038076, acc: 0.879852207977208, lr: 0.02407027514954738
[batch_idx--400] train_loss: 0.0011137580798655526, acc: 0.8794809850374065, lr: 0.024012269218344526
[batch_idx--450] train_loss: 0.001116720008856098, acc: 0.8796993786232513, lr: 0.023954268612422863
total time of one epoch: 209.77416348457336 s
train_loss:  0.001116720008856098  acc:  0.8796993786232513
->>lr:0.023954
test_loss:  0.0010740652833864757  test_acc:  0.8888199528477478
best acc:  89.15498200769326

------Epoch: 77------
[batch_idx--0] train_loss: 0.0010290107456967235, acc: 0.90625, lr: 0.02395310865677001
[batch_idx--50] train_loss: 0.0011161680483971449, acc: 0.8777573529411765, lr: 0.023895113804784887
[batch_idx--100] train_loss: 0.0011113882767921775, acc: 0.8780553836633663, lr: 0.02383712490971616
[batch_idx--150] train_loss: 0.001108295837762636, acc: 0.8794236341059603, lr: 0.023779142284206876
[batch_idx--200] train_loss: 0.0011185193770282453, acc: 0.8783037935323383, lr: 0.023721166240866298
[batch_idx--250] train_loss: 0.0011135496633253488, acc: 0.87890625, lr: 0.0236631970922682
[batch_idx--300] train_loss: 0.0011138686315818656, acc: 0.8789581602990033, lr: 0.023605235150949158
[batch_idx--350] train_loss: 0.0011133909438726124, acc: 0.8791399572649573, lr: 0.02354728072940694
[batch_idx--400] train_loss: 0.0011137564949043317, acc: 0.8791108167082294, lr: 0.02348933414009873
[batch_idx--450] train_loss: 0.001117447637957552, acc: 0.8786492866317215, lr: 0.02343139569543949
total time of one epoch: 212.83584022521973 s
train_loss:  0.001117447637957552  acc:  0.8786492866317215
->>lr:0.023431
test_loss:  0.0010739251266772493  test_acc:  0.8858419158704554
best acc:  89.15498200769326

------Epoch: 78------
[batch_idx--0] train_loss: 0.0010111596202477813, acc: 0.88671875, lr: 0.023430237011767167
[batch_idx--50] train_loss: 0.0011334366669567923, acc: 0.878140318627451, lr: 0.02337230719645424
[batch_idx--100] train_loss: 0.0011187310083907577, acc: 0.8798731435643564, lr: 0.023314386156732855
[batch_idx--150] train_loss: 0.001110538841450328, acc: 0.8802773178807947, lr: 0.023256474204880216
[batch_idx--200] train_loss: 0.0011100472088333274, acc: 0.8806358830845771, lr: 0.023198571653124563
[batch_idx--250] train_loss: 0.0011132847600286285, acc: 0.8802135209163346, lr: 0.02314067881364343
[batch_idx--300] train_loss: 0.0011171343838068907, acc: 0.880048276578073, lr: 0.02308279599856199
[batch_idx--350] train_loss: 0.0011139597383558622, acc: 0.8799523682336182, lr: 0.023024923519951404
[batch_idx--400] train_loss: 0.0011131060647922208, acc: 0.8803869233167082, lr: 0.02296706168982706
[batch_idx--450] train_loss: 0.0011159868882264557, acc: 0.8802547991807547, lr: 0.022909210820146964
total time of one epoch: 207.8646523952484 s
train_loss:  0.0011159868882264557  acc:  0.8802547991807547
->>lr:0.022909
test_loss:  0.001062276795227277  test_acc:  0.8858419158704554
best acc:  89.15498200769326

------Epoch: 79------
[batch_idx--0] train_loss: 0.0011630529770627618, acc: 0.875, lr: 0.022908053916692112
[batch_idx--50] train_loss: 0.0011096148690044442, acc: 0.8807444852941176, lr: 0.022850214547982983
[batch_idx--100] train_loss: 0.0011187075743322621, acc: 0.8786355198019802, lr: 0.022792386769691267
[batch_idx--150] train_loss: 0.0011134113182023858, acc: 0.8793201572847682, lr: 0.022734570893591363
[batch_idx--200] train_loss: 0.0011107998405495167, acc: 0.8798973880597015, lr: 0.022676767231393526
[batch_idx--250] train_loss: 0.0011116558450749107, acc: 0.8802135209163346, lr: 0.02261897609474213
[batch_idx--300] train_loss: 0.0011199007112071835, acc: 0.8790490033222591, lr: 0.022561197795214035
[batch_idx--350] train_loss: 0.0011140752304809704, acc: 0.8799078525641025, lr: 0.022503432644316902
[batch_idx--400] train_loss: 0.0011154789800704584, acc: 0.8795004675810474, lr: 0.022445680953487472
[batch_idx--450] train_loss: 0.0011156564808278355, acc: 0.879985767348214, lr: 0.022387943034089947
total time of one epoch: 206.75377440452576 s
train_loss:  0.0011156564808278355  acc:  0.879985767348214
->>lr:0.022388
test_loss:  0.0010656143779833925  test_acc:  0.8891922074699095
best acc:  89.15498200769326

------Epoch: 80------
[batch_idx--0] train_loss: 0.0011078565148636699, acc: 0.86328125, lr: 0.022386788418308663
[batch_idx--50] train_loss: 0.0011129928239182953, acc: 0.8811274509803921, lr: 0.022329064866462054
[batch_idx--100] train_loss: 0.0011097512969811733, acc: 0.882503094059406, lr: 0.022271355714774788
[batch_idx--150] train_loss: 0.0011056085033897334, acc: 0.8824762003311258, lr: 0.022213661274381714
[batch_idx--200] train_loss: 0.0011040153139993659, acc: 0.8824821206467661, lr: 0.022155981856338363
[batch_idx--250] train_loss: 0.0011051368027224216, acc: 0.8816608565737052, lr: 0.022098317771619257
[batch_idx--300] train_loss: 0.001103736517836411, acc: 0.8820857558139535, lr: 0.022040669331116272
[batch_idx--350] train_loss: 0.0011059336715505228, acc: 0.8817107371794872, lr: 0.021983036845636923
[batch_idx--400] train_loss: 0.0011013400791145564, acc: 0.882140352244389, lr: 0.02192542062590272
[batch_idx--450] train_loss: 0.0011048994298356928, acc: 0.8815652445586142, lr: 0.02186782098254747
total time of one epoch: 211.33087301254272 s
train_loss:  0.0011048994298356928  acc:  0.8815652445586142
->>lr:0.021868
test_loss:  0.0010591569313977548  test_acc:  0.8911775654547711
best acc:  89.15498200769326

------Epoch: 81------
[batch_idx--0] train_loss: 0.0009943529730662704, acc: 0.90625, lr: 0.02186666916089239
[batch_idx--50] train_loss: 0.0011134126928963645, acc: 0.879672181372549, lr: 0.021809086745365924
[batch_idx--100] train_loss: 0.001095867608005347, acc: 0.8828125, lr: 0.021751521533424346
[batch_idx--150] train_loss: 0.0010867017530990356, acc: 0.8836661837748344, lr: 0.021693973835426473
[batch_idx--200] train_loss: 0.0010906740599103382, acc: 0.8826181592039801, lr: 0.021636443961636685
[batch_idx--250] train_loss: 0.001090012893333022, acc: 0.8828280627490039, lr: 0.021578932222223245
[batch_idx--300] train_loss: 0.0010978950642395852, acc: 0.8820338455149501, lr: 0.021521438927256664
[batch_idx--350] train_loss: 0.0010975625878730604, acc: 0.8820000890313391, lr: 0.021463964386708015
[batch_idx--400] train_loss: 0.001100758457134833, acc: 0.8813902743142145, lr: 0.021406508910447243
[batch_idx--450] train_loss: 0.0011067779437103212, acc: 0.8811833929253307, lr: 0.021349072808241526
total time of one epoch: 206.04651308059692 s
train_loss:  0.0011067779437103212  acc:  0.8811833929253307
->>lr:0.021349
test_loss:  0.001066679874799553  test_acc:  0.8880754436034247
best acc:  89.15498200769326

------Epoch: 82------
[batch_idx--0] train_loss: 0.0011008101282641292, acc: 0.875, lr: 0.021347924285939714
[batch_idx--50] train_loss: 0.0011187281263261742, acc: 0.8776807598039216, lr: 0.02129050826428394
[batch_idx--100] train_loss: 0.0011013307969436272, acc: 0.8809947400990099, lr: 0.021233112242092567
[batch_idx--150] train_loss: 0.0010992381509720341, acc: 0.8811827400662252, lr: 0.02117573652881221
[batch_idx--200] train_loss: 0.0010978932007660728, acc: 0.8813355099502488, lr: 0.02111838143378
[batch_idx--250] train_loss: 0.0010982547625546823, acc: 0.8814429780876494, lr: 0.021061047266221912
[batch_idx--300] train_loss: 0.0010991378757326037, acc: 0.8813719892026578, lr: 0.021003734335251087
[batch_idx--350] train_loss: 0.0010978441948782218, acc: 0.8819221866096866, lr: 0.020946442949866164
[batch_idx--400] train_loss: 0.001096635166801828, acc: 0.8819065617206983, lr: 0.020889173418949643
[batch_idx--450] train_loss: 0.0011007989593400849, acc: 0.881721456590412, lr: 0.020831926051266162
total time of one epoch: 211.32732224464417 s
train_loss:  0.0011007989593400849  acc:  0.881721456590412
->>lr:0.020832
test_loss:  0.0010683852654560164  test_acc:  0.8875791041072093
best acc:  89.15498200769326

------Epoch: 83------
[batch_idx--0] train_loss: 0.0010284202871844172, acc: 0.87109375, lr: 0.020830781332097453
[batch_idx--50] train_loss: 0.0010760205446322467, acc: 0.8830422794117647, lr: 0.020773556888877096
[batch_idx--100] train_loss: 0.0010976115994312163, acc: 0.8807626856435643, lr: 0.020716355232228204
[batch_idx--150] train_loss: 0.0010822953186799705, acc: 0.8833816225165563, lr: 0.020659176670549492
[batch_idx--200] train_loss: 0.0010878600397921023, acc: 0.8834732587064676, lr: 0.020602021512115154
[batch_idx--250] train_loss: 0.001091114552626646, acc: 0.8827658117529881, lr: 0.02054489006507322
[batch_idx--300] train_loss: 0.0010916832685578875, acc: 0.8827995224252492, lr: 0.02048778263744388
[batch_idx--350] train_loss: 0.0010963864840084203, acc: 0.88240073005698, lr: 0.02043069953711782
[batch_idx--400] train_loss: 0.0010920094714866966, acc: 0.8825494856608479, lr: 0.020373641071854572
[batch_idx--450] train_loss: 0.0010973856792712065, acc: 0.8822595202554935, lr: 0.020316607549280843
total time of one epoch: 207.550395488739 s
train_loss:  0.0010973856792712065  acc:  0.8822595202554935
->>lr:0.020317
test_loss:  0.0010499222848237575  test_acc:  0.8905571410845018
best acc:  89.15498200769326

------Epoch: 84------
[batch_idx--0] train_loss: 0.0012022849405184388, acc: 0.86328125, lr: 0.020315467135356893
[batch_idx--50] train_loss: 0.0010952481328893233, acc: 0.8800551470588235, lr: 0.02025845937110404
[batch_idx--100] train_loss: 0.0010990033953192431, acc: 0.8804146039603961, lr: 0.020201477170534773
[batch_idx--150] train_loss: 0.0010912612409004017, acc: 0.8818812086092715, lr: 0.020144520840864624
[batch_idx--200] train_loss: 0.0010960289871954911, acc: 0.880966262437811, lr: 0.02008759068916964
[batch_idx--250] train_loss: 0.0010948179547574772, acc: 0.8813340388446215, lr: 0.020030687022384752
[batch_idx--300] train_loss: 0.001098515307863376, acc: 0.8807101328903655, lr: 0.019973810147302068
[batch_idx--350] train_loss: 0.0010970264099116444, acc: 0.8810318732193733, lr: 0.01991696037056928
[batch_idx--400] train_loss: 0.0010967061744870483, acc: 0.8811467425187033, lr: 0.01986013799868798
[batch_idx--450] train_loss: 0.0011005939894891247, acc: 0.8811313222480647, lr: 0.01980334333801198
total time of one epoch: 208.74831342697144 s
train_loss:  0.0011005939894891247  acc:  0.8811313222480647
->>lr:0.019803
test_loss:  0.001056339698521815  test_acc:  0.8922943293212557
best acc:  89.15498200769326
Saving..

------Epoch: 85------
[batch_idx--0] train_loss: 0.0010947230039164424, acc: 0.890625, lr: 0.019802207729556022
[batch_idx--50] train_loss: 0.0011402445413884433, acc: 0.8774509803921569, lr: 0.0197454416497602
[batch_idx--100] train_loss: 0.00111374566170138, acc: 0.8792543316831684, lr: 0.019688703899547008
[batch_idx--150] train_loss: 0.0010968849748305186, acc: 0.8810016556291391, lr: 0.01963199478481404
[batch_idx--200] train_loss: 0.0010944089524457185, acc: 0.8811217350746269, lr: 0.019575314611304503
[batch_idx--250] train_loss: 0.0010964272490914064, acc: 0.8811161603585658, lr: 0.019518663684605593
[batch_idx--300] train_loss: 0.0010993667213753658, acc: 0.8805024916943521, lr: 0.01946204231014678
[batch_idx--350] train_loss: 0.0011002842004893831, acc: 0.8804642984330484, lr: 0.019405450793198248
[batch_idx--400] train_loss: 0.0010943147125932623, acc: 0.8814779457605985, lr: 0.01934888943886919
[batch_idx--450] train_loss: 0.001093123411272137, acc: 0.8823549831638143, lr: 0.019292358552106172
total time of one epoch: 212.84141373634338 s
train_loss:  0.001093123411272137  acc:  0.8823549831638143
->>lr:0.019292
test_loss:  0.0010851068145540368  test_acc:  0.8841047276337014
best acc:  89.22943293212558

------Epoch: 86------
[batch_idx--0] train_loss: 0.0009110467508435249, acc: 0.890625, lr: 0.019291228247233613
[batch_idx--50] train_loss: 0.0010925563755353877, acc: 0.8825827205882353, lr: 0.019234728751373553
[batch_idx--100] train_loss: 0.0010890220678042583, acc: 0.8821550123762376, lr: 0.01917826033856888
[batch_idx--150] train_loss: 0.00109838103892479, acc: 0.8806136175496688, lr: 0.019121823313265066
[batch_idx--200] train_loss: 0.0010990539119134087, acc: 0.8801305970149254, lr: 0.01906541797973838
[batch_idx--250] train_loss: 0.001093844001680479, acc: 0.8809760956175299, lr: 0.01900904464209422
[batch_idx--300] train_loss: 0.0010892427265350134, acc: 0.8818651370431894, lr: 0.018952703604265476
[batch_idx--350] train_loss: 0.0010870252437411975, acc: 0.8822894408831908, lr: 0.018896395170010898
[batch_idx--400] train_loss: 0.0010860303643001638, acc: 0.882510520573566, lr: 0.01884011964291346
[batch_idx--450] train_loss: 0.0010880046465687632, acc: 0.8829971881834277, lr: 0.018783877326378724
total time of one epoch: 210.31850624084473 s
train_loss:  0.0010880046465687632  acc:  0.8829971881834277
->>lr:0.018784
test_loss:  0.0010903039601618636  test_acc:  0.8858419158704554
best acc:  89.22943293212558

------Epoch: 87------
[batch_idx--0] train_loss: 0.0011811759322881699, acc: 0.86328125, lr: 0.018782752820878636
[batch_idx--50] train_loss: 0.0010840331898162177, acc: 0.8858762254901961, lr: 0.018726544691500546
[batch_idx--100] train_loss: 0.0010714557743400778, acc: 0.8859839108910891, lr: 0.01867037038501655
[batch_idx--150] train_loss: 0.0010774896228809329, acc: 0.8839766142384106, lr: 0.018614230204286455
[batch_idx--200] train_loss: 0.0010777441761572267, acc: 0.8843866604477612, lr: 0.018558124451986114
[batch_idx--250] train_loss: 0.001083693002115015, acc: 0.883777390438247, lr: 0.018502053430605753
[batch_idx--300] train_loss: 0.0010858072374832887, acc: 0.8833835132890365, lr: 0.01844601744244835
[batch_idx--350] train_loss: 0.0010877530212564516, acc: 0.8828681445868946, lr: 0.018390016789628004
[batch_idx--400] train_loss: 0.0010890568144377925, acc: 0.8826079332917706, lr: 0.018334051774068303
[batch_idx--450] train_loss: 0.0010872472896326227, acc: 0.8830752941993265, lr: 0.0182781226975007
total time of one epoch: 208.02002882957458 s
train_loss:  0.0010872472896326227  acc:  0.8830752941993265
->>lr:0.018278
test_loss:  0.0010823100076773162  test_acc:  0.8858419158704554
best acc:  89.22943293212558

------Epoch: 88------
[batch_idx--0] train_loss: 0.0011191860539838672, acc: 0.88671875, lr: 0.01827700448461836
[batch_idx--50] train_loss: 0.0010938095316911738, acc: 0.8836550245098039, lr: 0.018221112376465492
[batch_idx--100] train_loss: 0.0010827281558425119, acc: 0.8851717202970297, lr: 0.018165256816209563
[batch_idx--150] train_loss: 0.00108646436915147, acc: 0.8840024834437086, lr: 0.018109438104991903
[batch_idx--200] train_loss: 0.0010761770000449608, acc: 0.884755907960199, lr: 0.01805365654375518
[batch_idx--250] train_loss: 0.0010744274941280455, acc: 0.8852402888446215, lr: 0.017997912433241763
[batch_idx--300] train_loss: 0.001073307729406635, acc: 0.8851744186046512, lr: 0.017942206073992117
[batch_idx--350] train_loss: 0.001072670750656932, acc: 0.8856392450142451, lr: 0.017886537766343167
[batch_idx--400] train_loss: 0.001079186958700948, acc: 0.884721789276808, lr: 0.017830907810426684
[batch_idx--450] train_loss: 0.001085112778857295, acc: 0.8843597042385531, lr: 0.017775316506167683
total time of one epoch: 212.49510407447815 s
train_loss:  0.001085112778857295  acc:  0.8843597042385531
->>lr:0.017775
test_loss:  0.0010721759625885855  test_acc:  0.886214170492617
best acc:  89.22943293212558

------Epoch: 89------
[batch_idx--0] train_loss: 0.0011779150227084756, acc: 0.875, lr: 0.017774205076388213
[batch_idx--50] train_loss: 0.0010809018025539961, acc: 0.8825827205882353, lr: 0.017718653505586445
[batch_idx--100] train_loss: 0.0010756797221775102, acc: 0.884166150990099, lr: 0.01766314119165336
[batch_idx--150] train_loss: 0.0010859342850898916, acc: 0.8822433774834437, lr: 0.017607668433879703
[batch_idx--200] train_loss: 0.0010828014303332389, acc: 0.882773631840796, lr: 0.017552235531342955
[batch_idx--250] train_loss: 0.0010794324543423565, acc: 0.8832326942231076, lr: 0.017496842782905715
[batch_idx--300] train_loss: 0.0010799937777103627, acc: 0.8833575581395349, lr: 0.017441490487214106
[batch_idx--350] train_loss: 0.0010849193834362716, acc: 0.8830128205128205, lr: 0.017386178942696135
[batch_idx--400] train_loss: 0.0010849471564550984, acc: 0.8829781016209476, lr: 0.01733090844756013
[batch_idx--450] train_loss: 0.0010870053367672764, acc: 0.8829798312910057, lr: 0.017275679299793074
total time of one epoch: 208.84256982803345 s
train_loss:  0.0010870053367672764  acc:  0.8829798312910057
->>lr:0.017276
test_loss:  0.0010983958990139883  test_acc:  0.8847251520039707
best acc:  89.22943293212558

------Epoch: 90------
[batch_idx--0] train_loss: 0.0009373066714033484, acc: 0.90234375, lr: 0.017274575140626316
[batch_idx--50] train_loss: 0.001075992471419786, acc: 0.8874080882352942, lr: 0.017219388473930602
[batch_idx--100] train_loss: 0.0010647535984551922, acc: 0.8876469678217822, lr: 0.017164243755855953
[batch_idx--150] train_loss: 0.0010672677909671668, acc: 0.8872878725165563, lr: 0.017109141283711254
[batch_idx--200] train_loss: 0.0010676937889011198, acc: 0.8872240360696517, lr: 0.0170540813545776
[batch_idx--250] train_loss: 0.001070802727996175, acc: 0.8860962400398407, lr: 0.016999064265306747
[batch_idx--300] train_loss: 0.001068829356319893, acc: 0.8856675664451827, lr: 0.016944090312519478
[batch_idx--350] train_loss: 0.0010669240777770805, acc: 0.8856503739316239, lr: 0.01688915979260398
[batch_idx--400] train_loss: 0.0010698829458775626, acc: 0.8853549719451371, lr: 0.016834273001714316
[batch_idx--450] train_loss: 0.0010729735837379333, acc: 0.8854705453535598, lr: 0.016779430235768767
total time of one epoch: 207.92496633529663 s
train_loss:  0.0010729735837379333  acc:  0.8854705453535598
->>lr:0.016779
test_loss:  0.0010812525632940876  test_acc:  0.8852214915001861
best acc:  89.22943293212558

------Epoch: 91------
[batch_idx--0] train_loss: 0.0008788520353846252, acc: 0.9140625, lr: 0.01677833383153542
[batch_idx--50] train_loss: 0.0010937469584556918, acc: 0.8827359068627451, lr: 0.016723536275641708
[batch_idx--100] train_loss: 0.001081428191472435, acc: 0.8840501237623762, lr: 0.01666878334172139
[batch_idx--150] train_loss: 0.00107521590520782, acc: 0.8844163907284768, lr: 0.01661407532497108
[batch_idx--200] train_loss: 0.0010722368024289608, acc: 0.8849696828358209, lr: 0.016559412520345193
[batch_idx--250] train_loss: 0.0010735435892300926, acc: 0.8850535358565738, lr: 0.016504795222554415
[batch_idx--300] train_loss: 0.0010675345400527763, acc: 0.8862904900332226, lr: 0.01645022372606408
[batch_idx--350] train_loss: 0.0010683470076623975, acc: 0.886039886039886, lr: 0.01639569832509256
[batch_idx--400] train_loss: 0.0010713610715091116, acc: 0.8856666926433915, lr: 0.016341219313609757
[batch_idx--450] train_loss: 0.0010755223954959576, acc: 0.8852622626444961, lr: 0.01628678698533542
total time of one epoch: 207.071209192276 s
train_loss:  0.0010755223954959576  acc:  0.8852622626444961
->>lr:0.016287
test_loss:  0.0011214654481740843  test_acc:  0.8790172477974935
best acc:  89.22943293212558

------Epoch: 92------
[batch_idx--0] train_loss: 0.0012937616556882858, acc: 0.875, lr: 0.016285698816954627
[batch_idx--50] train_loss: 0.001107558881973519, acc: 0.8814338235294118, lr: 0.016231314407882003
[batch_idx--100] train_loss: 0.0010897083828078195, acc: 0.8830058787128713, lr: 0.016176977274562434
[batch_idx--150] train_loss: 0.001076332277260622, acc: 0.8848302980132451, lr: 0.016122687709950775
[batch_idx--200] train_loss: 0.0010784646491543274, acc: 0.8843283582089553, lr: 0.01606844600674539
[batch_idx--250] train_loss: 0.0010735255965695853, acc: 0.8851002241035857, lr: 0.016014252457386614
[batch_idx--300] train_loss: 0.0010674196336823718, acc: 0.885797342192691, lr: 0.015960107354055172
[batch_idx--350] train_loss: 0.001070325262512895, acc: 0.8853721509971509, lr: 0.01590601098867059
[batch_idx--400] train_loss: 0.0010708399187248582, acc: 0.8852478179551122, lr: 0.015851963652889624
[batch_idx--450] train_loss: 0.001070130947741556, acc: 0.8850713368278543, lr: 0.015797965638104688
total time of one epoch: 210.83015847206116 s
train_loss:  0.001070130947741556  acc:  0.8850713368278543
->>lr:0.015798
test_loss:  0.0010540543459443658  test_acc:  0.8900608015882864
best acc:  89.22943293212558

------Epoch: 93------
[batch_idx--0] train_loss: 0.0010513452580198646, acc: 0.89453125, lr: 0.01579688618288306
[batch_idx--50] train_loss: 0.00104085169960836, acc: 0.8894761029411765, lr: 0.01574293877543077
[batch_idx--100] train_loss: 0.0010547372034179175, acc: 0.8866413985148515, lr: 0.015689041276774486
[batch_idx--150] train_loss: 0.001053297261951109, acc: 0.8864083195364238, lr: 0.015635193977498796
[batch_idx--200] train_loss: 0.001057647102899312, acc: 0.8863689365671642, lr: 0.015581397167917649
[batch_idx--250] train_loss: 0.0010594682729955153, acc: 0.8860962400398407, lr: 0.01552765113807274
[batch_idx--300] train_loss: 0.0010538070058091187, acc: 0.8865630191029901, lr: 0.015473956177732033
[batch_idx--350] train_loss: 0.0010567391443827808, acc: 0.8860621438746439, lr: 0.01542031257638813
[batch_idx--400] train_loss: 0.0010598031462848354, acc: 0.885374454488778, lr: 0.015366720623256752
[batch_idx--450] train_loss: 0.0010647522491521024, acc: 0.8851667997361752, lr: 0.015313180607275165
total time of one epoch: 207.88735461235046 s
train_loss:  0.0010647522491521024  acc:  0.8851667997361752
->>lr:0.015313
test_loss:  0.0010598816799457767  test_acc:  0.8885717830996401
best acc:  89.22943293212558

------Epoch: 94------
[batch_idx--0] train_loss: 0.0011082524433732033, acc: 0.8828125, lr: 0.015312110338697428
[batch_idx--50] train_loss: 0.0010712376154283537, acc: 0.8862591911764706, lr: 0.015258623595981367
[batch_idx--100] train_loss: 0.0010710116395136655, acc: 0.885055693069307, lr: 0.015205189373212608
[batch_idx--150] train_loss: 0.0010610254533860266, acc: 0.8873913493377483, lr: 0.015151807958478031
[batch_idx--200] train_loss: 0.0010654097593815728, acc: 0.8874766791044776, lr: 0.015098479639579785
[batch_idx--250] train_loss: 0.0010626229552173638, acc: 0.8878081424302788, lr: 0.015045204704033754
[batch_idx--300] train_loss: 0.0010640885991483704, acc: 0.887250830564784, lr: 0.01499198343906803
[batch_idx--350] train_loss: 0.001066938088079145, acc: 0.8867743945868946, lr: 0.014938816131621303
[batch_idx--400] train_loss: 0.0010625588772365559, acc: 0.8873324501246883, lr: 0.014885703068341395
[batch_idx--450] train_loss: 0.0010640212199974487, acc: 0.887214913041969, lr: 0.014832644535583656
total time of one epoch: 210.5883846282959 s
train_loss:  0.0010640212199974487  acc:  0.887214913041969
->>lr:0.014833
test_loss:  0.0010471722356792952  test_acc:  0.8905571410845018
best acc:  89.22943293212558

------Epoch: 95------
[batch_idx--0] train_loss: 0.001174683915451169, acc: 0.87890625, lr: 0.014831583923105
[batch_idx--50] train_loss: 0.0010708315930256218, acc: 0.8874080882352942, lr: 0.014778581306178257
[batch_idx--100] train_loss: 0.0010702259294541165, acc: 0.887028155940594, lr: 0.014725633797313148
[batch_idx--150] train_loss: 0.0010683389904057694, acc: 0.886796357615894, lr: 0.014672741681972468
[batch_idx--200] train_loss: 0.001066665035679436, acc: 0.8867964863184079, lr: 0.01461990524532032
[batch_idx--250] train_loss: 0.0010686413351579966, acc: 0.8860962400398407, lr: 0.014567124772220653
[batch_idx--300] train_loss: 0.0010658319350301082, acc: 0.8864202657807309, lr: 0.014514400547235684
[batch_idx--350] train_loss: 0.0010694687002991191, acc: 0.885917467948718, lr: 0.014461732854624376
[batch_idx--400] train_loss: 0.0010659193483348519, acc: 0.8861732387780549, lr: 0.014409121978340905
[batch_idx--450] train_loss: 0.0010670321778957369, acc: 0.8863817822057138, lr: 0.014356568202033099
total time of one epoch: 207.83588981628418 s
train_loss:  0.0010670321778957369  acc:  0.8863817822057138
->>lr:0.014357
test_loss:  0.001017208936744299  test_acc:  0.8941556024320635
best acc:  89.22943293212558
Saving..

------Epoch: 96------
[batch_idx--0] train_loss: 0.0010942686349153519, acc: 0.890625, lr: 0.014355517710873192
[batch_idx--50] train_loss: 0.0010859100627438987, acc: 0.8842677696078431, lr: 0.014303022468435317
[batch_idx--100] train_loss: 0.001076974783272547, acc: 0.8848623143564357, lr: 0.014250584898001182
[batch_idx--150] train_loss: 0.0010733368709399704, acc: 0.8847009519867549, lr: 0.014198205282284266
[batch_idx--200] train_loss: 0.0010654524354430945, acc: 0.8853583644278606, lr: 0.014145883903685591
[batch_idx--250] train_loss: 0.0010639943546092367, acc: 0.8862518675298805, lr: 0.014093621044292189
[batch_idx--300] train_loss: 0.001063862817626496, acc: 0.8860828488372093, lr: 0.014041416985875627
[batch_idx--350] train_loss: 0.0010657310256989212, acc: 0.8857505341880342, lr: 0.013989272009890398
[batch_idx--400] train_loss: 0.0010663393611713148, acc: 0.8853160068578554, lr: 0.013937186397472484
[batch_idx--450] train_loss: 0.001065105331977785, acc: 0.8856527927239907, lr: 0.01388516042943782
total time of one epoch: 211.53454852104187 s
train_loss:  0.001065105331977785  acc:  0.8856527927239907
->>lr:0.013885
test_loss:  0.0010243416524048788  test_acc:  0.8905571410845018
best acc:  89.41556024320636

------Epoch: 97------
[batch_idx--0] train_loss: 0.0012307341676205397, acc: 0.8671875, lr: 0.01388412052037681
[batch_idx--50] train_loss: 0.0010382847725778964, acc: 0.8881740196078431, lr: 0.01383215567857612
[batch_idx--100] train_loss: 0.0010577690808360677, acc: 0.8857905321782178, lr: 0.013780251047424422
[batch_idx--150] train_loss: 0.001055798366116915, acc: 0.8856581125827815, lr: 0.013728406906761904
[batch_idx--200] train_loss: 0.001049934101606075, acc: 0.886738184079602, lr: 0.013676623536102595
[batch_idx--250] train_loss: 0.0010460464493000502, acc: 0.8874657619521913, lr: 0.013624901214632912
[batch_idx--300] train_loss: 0.0010475106643701585, acc: 0.8871210548172758, lr: 0.01357324022121012
[batch_idx--350] train_loss: 0.0010477288555157532, acc: 0.8876424501424501, lr: 0.013521640834360844
[batch_idx--400] train_loss: 0.0010472511024356, acc: 0.8878292549875312, lr: 0.013470103332279566
[batch_idx--450] train_loss: 0.0010507245469087944, acc: 0.8878657965077933, lr: 0.013418627992827087
total time of one epoch: 207.0944881439209 s
train_loss:  0.0010507245469087944  acc:  0.8878657965077933
->>lr:0.013419
test_loss:  0.0010274166907162446  test_acc:  0.8947760268023328
best acc:  89.41556024320636
Saving..

------Epoch: 98------
[batch_idx--0] train_loss: 0.0010035078739747405, acc: 0.91015625, lr: 0.013417599122003463
[batch_idx--50] train_loss: 0.00107730410573091, acc: 0.8823529411764706, lr: 0.013366187474337023
[batch_idx--100] train_loss: 0.0010503924781419705, acc: 0.8854811262376238, lr: 0.013314838549554453
[batch_idx--150] train_loss: 0.001046673107170654, acc: 0.8856063741721855, lr: 0.013263552624499875
[batch_idx--200] train_loss: 0.0010499967298637242, acc: 0.8857081778606966, lr: 0.01321232997567776
[batch_idx--250] train_loss: 0.0010487004296865269, acc: 0.8861740537848606, lr: 0.01316117087925142
[batch_idx--300] train_loss: 0.0010486425326416188, acc: 0.8864462209302325, lr: 0.013110075611041534
[batch_idx--350] train_loss: 0.0010484213379617685, acc: 0.8864961716524217, lr: 0.01305904444652466
[batch_idx--400] train_loss: 0.0010481512569125622, acc: 0.8868843516209476, lr: 0.013008077660831736
[batch_idx--450] train_loss: 0.001048802979401441, acc: 0.887197556149547, lr: 0.01295717552874661
total time of one epoch: 207.81470441818237 s
train_loss:  0.001048802979401441  acc:  0.887197556149547
->>lr:0.012957
test_loss:  0.0010368802427195307  test_acc:  0.8914257352028788
best acc:  89.47760268023328

------Epoch: 99------
[batch_idx--0] train_loss: 0.001099989633075893, acc: 0.8828125, lr: 0.012956158147457115
[batch_idx--50] train_loss: 0.0010356158212137718, acc: 0.890625, lr: 0.012905322244772761
[batch_idx--100] train_loss: 0.0010474512058466967, acc: 0.8895420792079208, lr: 0.012854551549694835
[batch_idx--150] train_loss: 0.0010624463197355782, acc: 0.8870291804635762, lr: 0.012803846335949954
[batch_idx--200] train_loss: 0.001055195264168436, acc: 0.8882346082089553, lr: 0.012753206876911727
[batch_idx--250] train_loss: 0.0010528494791773358, acc: 0.8882750249003984, lr: 0.012702633445599246
[batch_idx--300] train_loss: 0.0010460390706633238, acc: 0.8887302740863787, lr: 0.012652126314675622
[batch_idx--350] train_loss: 0.001048983209547547, acc: 0.8882211538461539, lr: 0.012601685756446507
[batch_idx--400] train_loss: 0.0010496068532762125, acc: 0.8883942487531172, lr: 0.012551312042858621
[batch_idx--450] train_loss: 0.0010508335340545282, acc: 0.8887336411288923, lr: 0.012501005445498313
total time of one epoch: 212.9045283794403 s
train_loss:  0.0010508335340545282  acc:  0.8887336411288923
->>lr:0.012501
test_loss:  0.0010156258968431846  test_acc:  0.8949001116763866
best acc:  89.47760268023328
Saving..

------Epoch: 100------
[batch_idx--0] train_loss: 0.001162084168754518, acc: 0.8671875, lr: 0.012500000000000006
[batch_idx--50] train_loss: 0.001023699389085831, acc: 0.8871017156862745, lr: 0.012449762140604802
[batch_idx--100] train_loss: 0.001057320419067314, acc: 0.8835860148514851, lr: 0.012399591944936346
[batch_idx--150] train_loss: 0.001053618254457656, acc: 0.8844681291390728, lr: 0.012349489683483728
[batch_idx--200] train_loss: 0.0010471010374470582, acc: 0.8851445895522388, lr: 0.012299455626369788
[batch_idx--250] train_loss: 0.0010443033997908206, acc: 0.8858005478087649, lr: 0.012249490043349598
[batch_idx--300] train_loss: 0.0010393562261015177, acc: 0.8869653239202658, lr: 0.01219959320380913
[batch_idx--350] train_loss: 0.0010400966895701752, acc: 0.8873197115384616, lr: 0.012149765376763677
[batch_idx--400] train_loss: 0.0010386068741744501, acc: 0.887761066084788, lr: 0.012100006830856476
[batch_idx--450] train_loss: 0.0010418828430543501, acc: 0.8877790120456833, lr: 0.01205031783435723
total time of one epoch: 207.453143119812 s
train_loss:  0.0010418828430543501  acc:  0.8877790120456833
->>lr:0.012050
test_loss:  0.0009800015471090762  test_acc:  0.899615336890433
best acc:  89.49001116763867
Saving..

------Epoch: 101------
[batch_idx--0] train_loss: 0.0009910863591358066, acc: 0.90625, lr: 0.012049324765671741
[batch_idx--50] train_loss: 0.001014843143696221, acc: 0.8900122549019608, lr: 0.01199970698555119
[batch_idx--100] train_loss: 0.0010268742928631826, acc: 0.8876082920792079, lr: 0.011950159295598187
[batch_idx--150] train_loss: 0.0010269748190393216, acc: 0.8883226407284768, lr: 0.011900681962945607
[batch_idx--200] train_loss: 0.0010333379646021855, acc: 0.8879625310945274, lr: 0.011851275254347019
[batch_idx--250] train_loss: 0.0010359193427039244, acc: 0.8880882719123506, lr: 0.011801939436175232
[batch_idx--300] train_loss: 0.0010351756202022968, acc: 0.888172238372093, lr: 0.01175267477442085
[batch_idx--350] train_loss: 0.0010373429964068333, acc: 0.8878872863247863, lr: 0.011703481534690844
[batch_idx--400] train_loss: 0.0010355623001163069, acc: 0.8881604582294265, lr: 0.011654359982207095
[batch_idx--450] train_loss: 0.0010345611665282142, acc: 0.8884819661887735, lr: 0.011605310381805019
total time of one epoch: 210.7013988494873 s
train_loss:  0.0010345611665282142  acc:  0.8884819661887735
->>lr:0.011605
test_loss:  0.0010359995210417773  test_acc:  0.8899367167142326
best acc:  89.9615336890433

------Epoch: 102------
[batch_idx--0] train_loss: 0.0008730326080694795, acc: 0.8984375, lr: 0.01160433012552509
[batch_idx--50] train_loss: 0.0010086434822547815, acc: 0.8922334558823529, lr: 0.011555354188677439
[batch_idx--100] train_loss: 0.001024941219902127, acc: 0.8893487004950495, lr: 0.011506450737694249
[batch_idx--150] train_loss: 0.0010326010200491064, acc: 0.8889693708609272, lr: 0.011457620036235043
[batch_idx--200] train_loss: 0.0010264776930889459, acc: 0.8897504664179104, lr: 0.011408862347567132
[batch_idx--250] train_loss: 0.0010281807995323404, acc: 0.8895822958167331, lr: 0.011360177934564142
[batch_idx--300] train_loss: 0.0010291597839952307, acc: 0.889625726744186, lr: 0.011311567059704701
[batch_idx--350] train_loss: 0.0010281441201909613, acc: 0.8900462962962963, lr: 0.01126302998507092
[batch_idx--400] train_loss: 0.0010299895737062388, acc: 0.8902450903990025, lr: 0.011214566972347026
[batch_idx--450] train_loss: 0.0010364096321158578, acc: 0.8900527649529628, lr: 0.01116617828281797
total time of one epoch: 212.5724594593048 s
train_loss:  0.0010364096321158578  acc:  0.8900527649529628
->>lr:0.011166
test_loss:  0.0009994072115499693  test_acc:  0.8962650452909791
best acc:  89.9615336890433

------Epoch: 103------
[batch_idx--0] train_loss: 0.0009693429456092417, acc: 0.89453125, lr: 0.011165211268916392
[batch_idx--50] train_loss: 0.0010296843076289138, acc: 0.8911611519607843, lr: 0.011116898657806221
[batch_idx--100] train_loss: 0.0010350854395390812, acc: 0.8893873762376238, lr: 0.01106866089646273
[batch_idx--150] train_loss: 0.001025773353553963, acc: 0.8908319536423841, lr: 0.011020498244956429
[batch_idx--200] train_loss: 0.001026716304245632, acc: 0.890644434079602, lr: 0.010972410962952879
[batch_idx--250] train_loss: 0.001029823336006324, acc: 0.8899402390438247, lr: 0.010924399309711284
[batch_idx--300] train_loss: 0.0010264578346546702, acc: 0.8907937084717608, lr: 0.010876463544083113
[batch_idx--350] train_loss: 0.001028476024916836, acc: 0.8902243589743589, lr: 0.010828603924510663
[batch_idx--400] train_loss: 0.001024992612075581, acc: 0.890537328553616, lr: 0.010780820709025727
[batch_idx--450] train_loss: 0.0010280150805188138, acc: 0.890747040649842, lr: 0.010733114155248157
total time of one epoch: 210.49360704421997 s
train_loss:  0.0010280150805188138  acc:  0.890747040649842
->>lr:0.010733
test_loss:  0.0010210037072430564  test_acc:  0.893783347809902
best acc:  89.9615336890433

------Epoch: 104------
[batch_idx--0] train_loss: 0.0010283656883984804, acc: 0.890625, lr: 0.010732160807889211
[batch_idx--50] train_loss: 0.0010222223411569848, acc: 0.8910079656862745, lr: 0.010684532714024482
[batch_idx--100] train_loss: 0.0010166270128165436, acc: 0.8917079207920792, lr: 0.010636981800997085
[batch_idx--150] train_loss: 0.0010140677135351379, acc: 0.8916856374172185, lr: 0.01058950832517444
[batch_idx--200] train_loss: 0.001025216056518164, acc: 0.8908193407960199, lr: 0.010542112542506449
[batch_idx--250] train_loss: 0.0010262185304640863, acc: 0.890593874501992, lr: 0.01049479470852415
[batch_idx--300] train_loss: 0.0010244768022782359, acc: 0.8907417981727574, lr: 0.010447555078338317
[batch_idx--350] train_loss: 0.0010243191657736473, acc: 0.8911925747863247, lr: 0.010400393906638123
[batch_idx--400] train_loss: 0.0010225502457678727, acc: 0.8911412874064838, lr: 0.010353311447689712
[batch_idx--450] train_loss: 0.0010253738980624827, acc: 0.8912243551914465, lr: 0.01030630795533484
total time of one epoch: 213.20896553993225 s
train_loss:  0.0010253738980624827  acc:  0.8912243551914465
->>lr:0.010306
test_loss:  0.0010202006975523752  test_acc:  0.8921702444472018
best acc:  89.9615336890433

------Epoch: 105------
[batch_idx--0] train_loss: 0.0011892191832885146, acc: 0.8828125, lr: 0.010305368692688175
[batch_idx--50] train_loss: 0.0010169158705656289, acc: 0.8916973039215687, lr: 0.010258446007324987
[batch_idx--100] train_loss: 0.0010103083810409402, acc: 0.892868193069307, lr: 0.010211602800015714
[batch_idx--150] train_loss: 0.0010108718558350294, acc: 0.8928238824503312, lr: 0.010164839323312217
[batch_idx--200] train_loss: 0.0010184468646459652, acc: 0.8917716106965174, lr: 0.010118155829336504
[batch_idx--250] train_loss: 0.0010272680934373868, acc: 0.8901114292828686, lr: 0.010071552569779364
[batch_idx--300] train_loss: 0.0010215024250339827, acc: 0.8905730897009967, lr: 0.010025029795898983
[batch_idx--350] train_loss: 0.0010265030833810271, acc: 0.8899906517094017, lr: 0.00997858775851964
[batch_idx--400] train_loss: 0.0010252829668393121, acc: 0.8901281951371571, lr: 0.00993222670803032
[batch_idx--450] train_loss: 0.0010239331256483787, acc: 0.8905300794945673, lr: 0.009885946894383374
total time of one epoch: 211.4116530418396 s
train_loss:  0.0010239331256483787  acc:  0.8905300794945673
->>lr:0.009886
test_loss:  0.0010041471139448927  test_acc:  0.8955205360466559
best acc:  89.9615336890433

------Epoch: 106------
[batch_idx--0] train_loss: 0.0011067080777138472, acc: 0.90625, lr: 0.00988502212844063
[batch_idx--50] train_loss: 0.0010146117294389829, acc: 0.8920802696078431, lr: 0.009838825433419594
[batch_idx--100] train_loss: 0.0010142445346423526, acc: 0.8917079207920792, lr: 0.009792710478807351
[batch_idx--150] train_loss: 0.0010035255463602675, acc: 0.8927462748344371, lr: 0.009746677513229449
[batch_idx--200] train_loss: 0.001008963435355444, acc: 0.892587842039801, lr: 0.00970072678486938
[batch_idx--250] train_loss: 0.0010130238701659903, acc: 0.8921657121513944, lr: 0.009654858541467274
[batch_idx--300] train_loss: 0.0010111580364579379, acc: 0.8925456810631229, lr: 0.009609073030318542
[batch_idx--350] train_loss: 0.0010112330794766907, acc: 0.8928173967236467, lr: 0.009563370498272567
[batch_idx--400] train_loss: 0.001009573907407925, acc: 0.8930895417705735, lr: 0.009517751191731351
[batch_idx--450] train_loss: 0.0010136165572900329, acc: 0.892673655708682, lr: 0.00947221535664816
total time of one epoch: 212.8285689353943 s
train_loss:  0.0010136165572900329  acc:  0.892673655708682
->>lr:0.009472
test_loss:  0.0009991705606231945  test_acc:  0.8956446209207097
best acc:  89.9615336890433

------Epoch: 107------
[batch_idx--0] train_loss: 0.0011761982459574938, acc: 0.875, lr: 0.009471305493042243
[batch_idx--50] train_loss: 0.0010190954199060798, acc: 0.8916973039215687, lr: 0.00942585505176061
[batch_idx--100] train_loss: 0.0010269963468360428, acc: 0.890625, lr: 0.009380488577388602
[batch_idx--150] train_loss: 0.0010147504327319167, acc: 0.8921512831125827, lr: 0.009335206314516387
[batch_idx--200] train_loss: 0.001009853571521313, acc: 0.8924906716417911, lr: 0.0092900085072801
[batch_idx--250] train_loss: 0.0010084961972336667, acc: 0.8930061005976095, lr: 0.009244895399360565
[batch_idx--300] train_loss: 0.0010092818948666123, acc: 0.892999896179402, lr: 0.009199867233981912
[batch_idx--350] train_loss: 0.0010104265421870405, acc: 0.8929286858974359, lr: 0.009154924253910346
[batch_idx--400] train_loss: 0.0010140023317345955, acc: 0.8922907574812967, lr: 0.009110066701452797
[batch_idx--450] train_loss: 0.001020576364286747, acc: 0.8920140937966466, lr: 0.0090652948184556
total time of one epoch: 213.24620819091797 s
train_loss:  0.001020576364286747  acc:  0.8920140937966466
->>lr:0.009065
test_loss:  0.0009854486509593638  test_acc:  0.8957687057947636
best acc:  89.9615336890433

------Epoch: 108------
[batch_idx--0] train_loss: 0.0010639281244948506, acc: 0.8828125, lr: 0.009064400256282757
[batch_idx--50] train_loss: 0.0009912634028724449, acc: 0.8931525735294118, lr: 0.009019716004806225
[batch_idx--100] train_loss: 0.0009958261086854456, acc: 0.8934483292079208, lr: 0.0089751179099095
[batch_idx--150] train_loss: 0.001005665124286065, acc: 0.8922288907284768, lr: 0.008930606212040063
[batch_idx--200] train_loss: 0.0010114119162861796, acc: 0.8913246268656716, lr: 0.00888618115117962
[batch_idx--250] train_loss: 0.0010093457120715593, acc: 0.8920100846613546, lr: 0.00884184296684277
[batch_idx--300] train_loss: 0.00100793858233567, acc: 0.8920395556478405, lr: 0.00879759189807571
[batch_idx--350] train_loss: 0.0010075034247644967, acc: 0.8919270833333334, lr: 0.008753428183455004
[batch_idx--400] train_loss: 0.0010066370176676279, acc: 0.8921933447630923, lr: 0.008709352061086187
[batch_idx--450] train_loss: 0.0010137180855787585, acc: 0.8920488075814906, lr: 0.008665363768602597
total time of one epoch: 209.7609405517578 s
train_loss:  0.0010137180855787585  acc:  0.8920488075814906
->>lr:0.008665
test_loss:  0.0009850065159966298  test_acc:  0.8976299789055714
best acc:  89.9615336890433

------Epoch: 109------
[batch_idx--0] train_loss: 0.0010482324287295341, acc: 0.88671875, lr: 0.008664484900247363
[batch_idx--50] train_loss: 0.0010119092150810448, acc: 0.8916973039215687, lr: 0.00862058643856546
[batch_idx--100] train_loss: 0.0010086934169809712, acc: 0.8930615717821783, lr: 0.0085767762853424
[batch_idx--150] train_loss: 0.0010112954268157975, acc: 0.8914010761589404, lr: 0.008533054676777554
[batch_idx--200] train_loss: 0.0010143263637324544, acc: 0.8913246268656716, lr: 0.008489421848592919
[batch_idx--250] train_loss: 0.0010093227360468075, acc: 0.8928037848605578, lr: 0.008445878036031801
[batch_idx--300] train_loss: 0.0010065518354802111, acc: 0.8929090531561462, lr: 0.008402423473857626
[batch_idx--350] train_loss: 0.0010062727844674256, acc: 0.8925948183760684, lr: 0.008359058396352615
[batch_idx--400] train_loss: 0.0010089992162042258, acc: 0.8923004987531172, lr: 0.008315783037316537
[batch_idx--450] train_loss: 0.0010138260117920244, acc: 0.8924480161071962, lr: 0.008272597630065468
total time of one epoch: 212.3024079799652 s
train_loss:  0.0010138260117920244  acc:  0.8924480161071962
->>lr:0.008273
test_loss:  0.0009806296091426439  test_acc:  0.8977540637796253
best acc:  89.9615336890433

------Epoch: 110------
[batch_idx--0] train_loss: 0.0010415153810754418, acc: 0.8984375, lr: 0.008271734841028545
[batch_idx--50] train_loss: 0.0010100146869708802, acc: 0.8943014705882353, lr: 0.008228641424457422
[batch_idx--100] train_loss: 0.001003509956771637, acc: 0.8947633044554455, lr: 0.00818563842948918
[batch_idx--150] train_loss: 0.0010015239695469473, acc: 0.894453642384106, lr: 0.008142726087971458
[batch_idx--200] train_loss: 0.0009997228443719892, acc: 0.8942203047263682, lr: 0.00809990463126313
[batch_idx--250] train_loss: 0.0010088179770678994, acc: 0.8933173555776892, lr: 0.008057174290233077
[batch_idx--300] train_loss: 0.0010086577633191581, acc: 0.8934930440199336, lr: 0.008014535295258926
[batch_idx--350] train_loss: 0.0010103939880187123, acc: 0.8930177172364673, lr: 0.00797198787622585
[batch_idx--400] train_loss: 0.0010120774344355332, acc: 0.892339463840399, lr: 0.007929532262525246
[batch_idx--450] train_loss: 0.0010127646603306038, acc: 0.8922831256291873, lr: 0.007887168683053591
total time of one epoch: 208.71120166778564 s
train_loss:  0.0010127646603306038  acc:  0.8922831256291873
->>lr:0.007887
test_loss:  0.000983686270156441  test_acc:  0.8976299789055714
best acc:  89.9615336890433

------Epoch: 111------
[batch_idx--0] train_loss: 0.0011083452263846993, acc: 0.875, lr: 0.00788632235178279
[batch_idx--50] train_loss: 0.0009846692475691146, acc: 0.8929227941176471, lr: 0.00784405288251919
[batch_idx--100] train_loss: 0.000999759640636863, acc: 0.891823948019802, lr: 0.007801875908340622
[batch_idx--150] train_loss: 0.0010035131296253954, acc: 0.8917891142384106, lr: 0.007759791656641275
[batch_idx--200] train_loss: 0.0009941994858354293, acc: 0.8929570895522388, lr: 0.007717800354315446
[batch_idx--250] train_loss: 0.000991261879815182, acc: 0.8937842380478087, lr: 0.007675902227756282
[batch_idx--300] train_loss: 0.0009940087020186789, acc: 0.8940640573089701, lr: 0.007634097502854598
[batch_idx--350] train_loss: 0.0009973398658534528, acc: 0.8934183582621082, lr: 0.007592386404997634
[batch_idx--400] train_loss: 0.0009993106735570639, acc: 0.8934986751870324, lr: 0.007550769159067847
[batch_idx--450] train_loss: 0.0010023286337437747, acc: 0.8933158607282952, lr: 0.00750924598944171
total time of one epoch: 211.96114706993103 s
train_loss:  0.0010023286337437747  acc:  0.8933158607282952
->>lr:0.007509
test_loss:  0.0009841659843721968  test_acc:  0.8978781486536791
best acc:  89.9615336890433

------Epoch: 112------
[batch_idx--0] train_loss: 0.0010894283186644316, acc: 0.87109375, lr: 0.007508416487165862
[batch_idx--50] train_loss: 0.0009910067116531234, acc: 0.895297181372549, lr: 0.007466989505996053
[batch_idx--100] train_loss: 0.0009899891625933055, acc: 0.8945699257425742, lr: 0.007425657052821996
[batch_idx--150] train_loss: 0.0009874902821349486, acc: 0.8957471026490066, lr: 0.007384419350484717
[batch_idx--200] train_loss: 0.0009903381468579914, acc: 0.8953474813432836, lr: 0.0073432766213143985
[batch_idx--250] train_loss: 0.000990342012786518, acc: 0.8951693227091634, lr: 0.007302229087129178
[batch_idx--300] train_loss: 0.000997369019067119, acc: 0.8942976536544851, lr: 0.007261276969233954
[batch_idx--350] train_loss: 0.0009983702528919291, acc: 0.8938857727920227, lr: 0.007220420488419194
[batch_idx--400] train_loss: 0.0010001094421915283, acc: 0.8936740180798005, lr: 0.007179659864959754
[batch_idx--450] train_loss: 0.0010002236287625374, acc: 0.8942791682577151, lr: 0.007138995318613667
total time of one epoch: 209.58802270889282 s
train_loss:  0.0010002236287625374  acc:  0.8942791682577151
->>lr:0.007139
test_loss:  0.0009874578004647225  test_acc:  0.8993671671423253
best acc:  89.9615336890433

------Epoch: 113------
[batch_idx--0] train_loss: 0.0009557916782796383, acc: 0.9140625, lr: 0.007138183009179922
[batch_idx--50] train_loss: 0.0010208059090883563, acc: 0.8924632352941176, lr: 0.007097616687346986
[batch_idx--100] train_loss: 0.0010214087946368105, acc: 0.8926748143564357, lr: 0.00705714688495745
[batch_idx--150] train_loss: 0.0010096336204546276, acc: 0.8928497516556292, lr: 0.007016773820201414
[batch_idx--200] train_loss: 0.0010005091253288128, acc: 0.894414645522388, lr: 0.00697649771074741
[batch_idx--250] train_loss: 0.0009946771788381158, acc: 0.8950759462151394, lr: 0.006936318773741257
[batch_idx--300] train_loss: 0.0009921710196405995, acc: 0.8955824335548173, lr: 0.00689623722580488
[batch_idx--350] train_loss: 0.000994825481299173, acc: 0.8954104344729344, lr: 0.006856253283035133
[batch_idx--400] train_loss: 0.0009920470082105841, acc: 0.89518391521197, lr: 0.00681636716100264
[batch_idx--450] train_loss: 0.0009918946844068525, acc: 0.895381330926511, lr: 0.006776579074750619
total time of one epoch: 212.46312856674194 s
train_loss:  0.0009918946844068525  acc:  0.895381330926511
->>lr:0.006777
test_loss:  0.0009801498228155482  test_acc:  0.8984985730239484
best acc:  89.9615336890433

------Epoch: 114------
[batch_idx--0] train_loss: 0.0012757729273289442, acc: 0.84765625, lr: 0.006775784314464717
[batch_idx--50] train_loss: 0.001031896877833003, acc: 0.8902420343137255, lr: 0.006736096445698165
[batch_idx--100] train_loss: 0.0010275889947632382, acc: 0.890315594059406, lr: 0.0066965070454860194
[batch_idx--150] train_loss: 0.0010168687047264137, acc: 0.8915304221854304, lr: 0.006657016327271753
[batch_idx--200] train_loss: 0.0010046661858660036, acc: 0.8931514303482587, lr: 0.006617624503966805
[batch_idx--250] train_loss: 0.0010033592767735194, acc: 0.893566359561753, lr: 0.006578331787949427
[batch_idx--300] train_loss: 0.001005425353254504, acc: 0.8930128737541528, lr: 0.006539138391063526
[batch_idx--350] train_loss: 0.0010044144367350749, acc: 0.8933404558404558, lr: 0.006500044524617568
[batch_idx--400] train_loss: 0.0010027516178352446, acc: 0.8938298784289277, lr: 0.0064610503993833834
[batch_idx--450] train_loss: 0.001001122931324505, acc: 0.8942531329190821, lr: 0.006422156225595066
total time of one epoch: 212.16209769248962 s
train_loss:  0.001001122931324505  acc:  0.8942531329190821
->>lr:0.006422
test_loss:  0.0010123274797895643  test_acc:  0.8932870083136866
best acc:  89.9615336890433

------Epoch: 115------
[batch_idx--0] train_loss: 0.0009038621792569757, acc: 0.9296875, lr: 0.00642137936306515
[batch_idx--50] train_loss: 0.0009824719026629977, acc: 0.8975949754901961, lr: 0.006382587355775901
[batch_idx--100] train_loss: 0.0009747787907784159, acc: 0.898128094059406, lr: 0.006343895722960522
[batch_idx--150] train_loss: 0.000983607015473805, acc: 0.8963162251655629, lr: 0.006305304673222229
[batch_idx--200] train_loss: 0.0009798754614184781, acc: 0.8962608830845771, lr: 0.0062668144146219495
[batch_idx--250] train_loss: 0.000983732196862301, acc: 0.8956517679282868, lr: 0.006228425154677217
[batch_idx--300] train_loss: 0.0009882763187490724, acc: 0.8953877699335548, lr: 0.0061901371003610295
[batch_idx--350] train_loss: 0.000989422048879867, acc: 0.8951655982905983, lr: 0.00615195045810075
[batch_idx--400] train_loss: 0.0009920623525338447, acc: 0.8945507325436409, lr: 0.006113865433776986
[batch_idx--450] train_loss: 0.000994321697005197, acc: 0.8945655569826778, lr: 0.006075882232722457
total time of one epoch: 212.69061970710754 s
train_loss:  0.000994321697005197  acc:  0.8945655569826778
->>lr:0.006076
test_loss:  0.000983274566179056  test_acc:  0.8998635066385408
best acc:  89.9615336890433
Saving..

------Epoch: 116------
[batch_idx--0] train_loss: 0.0009592657443135977, acc: 0.90625, lr: 0.006075123608706093
[batch_idx--50] train_loss: 0.0009615909223736939, acc: 0.8972120098039216, lr: 0.006037244478350651
[batch_idx--100] train_loss: 0.0009715766565284074, acc: 0.8953047648514851, lr: 0.00599946758436096
[batch_idx--150] train_loss: 0.0009791193956305698, acc: 0.8950486341059603, lr: 0.005961793130408489
[batch_idx--200] train_loss: 0.0009880975402534861, acc: 0.8937733208955224, lr: 0.005924221319612417
[batch_idx--250] train_loss: 0.000989177465796901, acc: 0.8939398655378487, lr: 0.005886752354538527
[batch_idx--300] train_loss: 0.0009929774206462764, acc: 0.8933502906976745, lr: 0.0058493864371981065
[batch_idx--350] train_loss: 0.0009886600757734133, acc: 0.8937967414529915, lr: 0.005812123769046874
[batch_idx--400] train_loss: 0.0009909974742957166, acc: 0.8941221165835411, lr: 0.005774964550983902
[batch_idx--450] train_loss: 0.0009950991043235226, acc: 0.894435380289513, lr: 0.005737908983350504
total time of one epoch: 209.03096771240234 s
train_loss:  0.0009950991043235226  acc:  0.894435380289513
->>lr:0.005738
test_loss:  0.0009897347899757761  test_acc:  0.9002357612607024
best acc:  89.98635066385408
Saving..

------Epoch: 117------
[batch_idx--0] train_loss: 0.0009968857048079371, acc: 0.90625, lr: 0.005737168930605272
[batch_idx--50] train_loss: 0.0009889343100618205, acc: 0.8955269607843137, lr: 0.005700219292222111
[batch_idx--100] train_loss: 0.000981814606059896, acc: 0.8969291460396039, lr: 0.005663373707252357
[batch_idx--150] train_loss: 0.0009748440741604527, acc: 0.8978942466887417, lr: 0.005626632374346372
[batch_idx--200] train_loss: 0.0009762640337028833, acc: 0.8978350435323383, lr: 0.005589995491592479
[batch_idx--250] train_loss: 0.0009824218178832108, acc: 0.8967722858565738, lr: 0.005553463256515865
[batch_idx--300] train_loss: 0.000980674038545238, acc: 0.8975031146179402, lr: 0.005517035866077508
[batch_idx--350] train_loss: 0.0009863405820762373, acc: 0.8970129985754985, lr: 0.0054807135166731365
[batch_idx--400] train_loss: 0.0009868628119857068, acc: 0.8967327774314214, lr: 0.005444496404132135
[batch_idx--450] train_loss: 0.0009876756146190672, acc: 0.8965529211649946, lr: 0.005408384723716528
total time of one epoch: 209.3413600921631 s
train_loss:  0.0009876756146190672  acc:  0.8965529211649946
->>lr:0.005408
test_loss:  0.0009839338783088313  test_acc:  0.8994912520163793
best acc:  90.02357612607024

------Epoch: 118------
[batch_idx--0] train_loss: 0.0010095200268551707, acc: 0.8984375, lr: 0.005407663566854007
[batch_idx--50] train_loss: 0.0009561005874774328, acc: 0.9005821078431373, lr: 0.005371659627775735
[batch_idx--100] train_loss: 0.0009633235934208894, acc: 0.8987082301980198, lr: 0.005335761513517229
[batch_idx--150] train_loss: 0.0009602652585121575, acc: 0.8982305463576159, lr: 0.0052999694176206515
[batch_idx--200] train_loss: 0.0009699455284008487, acc: 0.896494092039801, lr: 0.005264283533056586
[batch_idx--250] train_loss: 0.00096924537727869, acc: 0.8965855328685259, lr: 0.0052287040522229575
[batch_idx--300] train_loss: 0.0009732156399439439, acc: 0.8959587832225914, lr: 0.005193231166944048
[batch_idx--350] train_loss: 0.000972666298576559, acc: 0.8961226851851852, lr: 0.005157865068469426
[batch_idx--400] train_loss: 0.0009760286046733192, acc: 0.8958268391521197, lr: 0.005122605947472936
[batch_idx--450] train_loss: 0.0009770047236544962, acc: 0.8958499670219044, lr: 0.0050874539940516635
total time of one epoch: 215.0940215587616 s
train_loss:  0.0009770047236544962  acc:  0.8958499670219044
->>lr:0.005087
test_loss:  0.0009803587571017602  test_acc:  0.9004839310088101
best acc:  90.02357612607024
Saving..

------Epoch: 119------
[batch_idx--0] train_loss: 0.0007803594344295561, acc: 0.92578125, lr: 0.005086752049395094
[batch_idx--50] train_loss: 0.0009656811553035296, acc: 0.8962928921568627, lr: 0.005051709602139323
[batch_idx--100] train_loss: 0.0009687828559354685, acc: 0.896194306930693, lr: 0.005016774704691432
[batch_idx--150] train_loss: 0.0009593126670124367, acc: 0.8973768625827815, lr: 0.004981947545400465
[batch_idx--200] train_loss: 0.0009710670623173057, acc: 0.896358053482587, lr: 0.004947228312034608
[batch_idx--250] train_loss: 0.0009745394106512793, acc: 0.8964299053784861, lr: 0.004912617191780173
[batch_idx--300] train_loss: 0.0009757732362192484, acc: 0.8962442898671097, lr: 0.004878114371240583
[batch_idx--350] train_loss: 0.0009770510204805012, acc: 0.8958778490028491, lr: 0.004843720036435387
[batch_idx--400] train_loss: 0.0009830402804914852, acc: 0.8953884819201995, lr: 0.004809434372799207
[batch_idx--450] train_loss: 0.0009832939097291374, acc: 0.8953726524803, lr: 0.004775257565180805
total time of one epoch: 211.07259678840637 s
train_loss:  0.0009832939097291374  acc:  0.8953726524803
->>lr:0.004775
test_loss:  0.0009698210623175856  test_acc:  0.9002357612607024
best acc:  90.048393100881

------Epoch: 120------
[batch_idx--0] train_loss: 0.0008882925030775368, acc: 0.88671875, lr: 0.004774575140626317
[batch_idx--50] train_loss: 0.0009533335893031429, acc: 0.9008118872549019, lr: 0.004740509555968578
[batch_idx--100] train_loss: 0.0009833569845903924, acc: 0.8962716584158416, lr: 0.004706553198931926
[batch_idx--150] train_loss: 0.000979052069026434, acc: 0.8956953642384106, lr: 0.004672706252589681
[batch_idx--200] train_loss: 0.0009790807507760748, acc: 0.8963969216417911, lr: 0.004638968899425284
[batch_idx--250] train_loss: 0.0009794995447053052, acc: 0.8962742778884463, lr: 0.004605341321331294
[batch_idx--300] train_loss: 0.0009812017629291256, acc: 0.8958809177740864, lr: 0.004571823699608443
[batch_idx--350] train_loss: 0.000978438140382656, acc: 0.8961338141025641, lr: 0.0045384162149646355
[batch_idx--400] train_loss: 0.0009769929568294873, acc: 0.8964210567331671, lr: 0.004505119047513989
[batch_idx--450] train_loss: 0.0009785077792962879, acc: 0.8965008504877287, lr: 0.0044719323767758445
total time of one epoch: 213.7843234539032 s
train_loss:  0.0009785077792962879  acc:  0.8965008504877287
->>lr:0.004472
test_loss:  0.0009769471474329315  test_acc:  0.9003598461347562
best acc:  90.048393100881

------Epoch: 121------
[batch_idx--0] train_loss: 0.0008775954484008253, acc: 0.90625, lr: 0.004471269771657399
[batch_idx--50] train_loss: 0.0009616050748245828, acc: 0.8972120098039216, lr: 0.004438195991889007
[batch_idx--100] train_loss: 0.0009598460804560397, acc: 0.8990563118811881, lr: 0.004405233069644058
[batch_idx--150] train_loss: 0.000963784523373038, acc: 0.8989031456953642, lr: 0.004372381182639854
[batch_idx--200] train_loss: 0.0009724164215977586, acc: 0.8979905161691543, lr: 0.004339640507995033
[batch_idx--250] train_loss: 0.000972637389294907, acc: 0.8981884960159362, lr: 0.00430701122222864
[batch_idx--300] train_loss: 0.0009732837289837855, acc: 0.8980222176079734, lr: 0.004274493501259191
[batch_idx--350] train_loss: 0.0009756806695255374, acc: 0.8979366987179487, lr: 0.004242087520403681
[batch_idx--400] train_loss: 0.0009742911014952081, acc: 0.8978627649625935, lr: 0.004209793454376692
[batch_idx--450] train_loss: 0.0009764188255094524, acc: 0.8975943347103135, lr: 0.0041776114772894115
total time of one epoch: 210.49643898010254 s
train_loss:  0.0009764188255094524  acc:  0.8975943347103135
->>lr:0.004178
test_loss:  0.0009763368247889278  test_acc:  0.899739421764487
best acc:  90.048393100881

------Epoch: 122------
[batch_idx--0] train_loss: 0.0011355882743373513, acc: 0.88671875, lr: 0.004176968982247515
[batch_idx--50] train_loss: 0.0009730365880600669, acc: 0.8972120098039216, lr: 0.004144901514621361
[batch_idx--100] train_loss: 0.0009546516478144665, acc: 0.899636448019802, lr: 0.0041129464857952575
[batch_idx--150] train_loss: 0.0009673768245855606, acc: 0.8977907698675497, lr: 0.004081104068052505
[batch_idx--200] train_loss: 0.0009654540845438542, acc: 0.8985929726368159, lr: 0.00404937443306925
[batch_idx--250] train_loss: 0.0009642878532932841, acc: 0.8981573705179283, lr: 0.004017757751913604
[batch_idx--300] train_loss: 0.0009654409677931959, acc: 0.8980481727574751, lr: 0.003986254195044678
[batch_idx--350] train_loss: 0.0009661856871244213, acc: 0.897758636039886, lr: 0.003954863932311695
[batch_idx--400] train_loss: 0.0009677958565281049, acc: 0.8980575903990025, lr: 0.003923587132953052
[batch_idx--450] train_loss: 0.0009746704769530961, acc: 0.8976984760648453, lr: 0.003892423965595415
total time of one epoch: 215.43410325050354 s
train_loss:  0.0009746704769530961  acc:  0.8976984760648453
->>lr:0.003892
test_loss:  0.0009762591590270731  test_acc:  0.8986226578980022
best acc:  90.048393100881

------Epoch: 123------
[batch_idx--0] train_loss: 0.0010505650425329804, acc: 0.87109375, lr: 0.003891801862449629
[batch_idx--50] train_loss: 0.000961583171624179, acc: 0.8974417892156863, lr: 0.003860754772816863
[batch_idx--100] train_loss: 0.0009619019808026381, acc: 0.8974706064356436, lr: 0.0038298216539413596
[batch_idx--150] train_loss: 0.0009855066930307755, acc: 0.8948158112582781, lr: 0.0037990026725968685
[batch_idx--200] train_loss: 0.0009778609125184552, acc: 0.8962414490049752, lr: 0.003768297994941761
[batch_idx--250] train_loss: 0.000978654747006977, acc: 0.8959318974103586, lr: 0.0037377077865181603
[batch_idx--300] train_loss: 0.0009822718017081732, acc: 0.8955824335548173, lr: 0.003707232212251013
[batch_idx--350] train_loss: 0.0009780573019190053, acc: 0.8963563924501424, lr: 0.003676871436447249
[batch_idx--400] train_loss: 0.0009729818596581272, acc: 0.89691786159601, lr: 0.0036466256227948553
[batch_idx--450] train_loss: 0.0009763623629266197, acc: 0.8968132745513243, lr: 0.003616494934362016
total time of one epoch: 210.18121576309204 s
train_loss:  0.0009763623629266197  acc:  0.8968132745513243
->>lr:0.003616
test_loss:  0.0009660953781802685  test_acc:  0.9016006948752947
best acc:  90.048393100881
Saving..

------Epoch: 124------
[batch_idx--0] train_loss: 0.0007825797656551003, acc: 0.9375, lr: 0.003615893495987335
[batch_idx--50] train_loss: 0.0009778777032396664, acc: 0.8975183823529411, lr: 0.003585880402627581
[batch_idx--100] train_loss: 0.0009775694769733393, acc: 0.896194306930693, lr: 0.0035559827619909834
[batch_idx--150] train_loss: 0.0009745177007218613, acc: 0.8967818708609272, lr: 0.0035262007352685563
[batch_idx--200] train_loss: 0.0009736808541633967, acc: 0.8966301305970149, lr: 0.003496534483028016
[batch_idx--250] train_loss: 0.0009699136040088131, acc: 0.8971146663346613, lr: 0.0034669841652128805
[batch_idx--300] train_loss: 0.0009747259974389946, acc: 0.8962442898671097, lr: 0.00343754994114161
[batch_idx--350] train_loss: 0.0009735800789210128, acc: 0.8961783297720798, lr: 0.0034082319695067616
[batch_idx--400] train_loss: 0.0009702380518417369, acc: 0.8965087281795511, lr: 0.003379030408374123
[batch_idx--450] train_loss: 0.0009682803711645945, acc: 0.897082306383865, lr: 0.00334994541518186
total time of one epoch: 210.66127395629883 s
train_loss:  0.0009682803711645945  acc:  0.897082306383865
->>lr:0.003350
test_loss:  0.0009645907380974667  test_acc:  0.9014766100012408
best acc:  90.16006948752947

------Epoch: 125------
[batch_idx--0] train_loss: 0.0009339904063381255, acc: 0.90625, lr: 0.003349364905389038
[batch_idx--50] train_loss: 0.0009863079381723177, acc: 0.8933057598039216, lr: 0.003320398973036992
[batch_idx--100] train_loss: 0.0009738969228156648, acc: 0.8979347153465347, lr: 0.0032915499247325843
[batch_idx--150] train_loss: 0.0009723408799155905, acc: 0.8975320778145696, lr: 0.003262817916013447
[batch_idx--200] train_loss: 0.0009640011054913129, acc: 0.8986512748756219, lr: 0.0032342031017861847
[batch_idx--250] train_loss: 0.000963988247795023, acc: 0.8987020667330677, lr: 0.003205705636325565
[batch_idx--300] train_loss: 0.0009642923210184415, acc: 0.8983207018272426, lr: 0.0031773256732736594
[batch_idx--350] train_loss: 0.000959850041603038, acc: 0.8987602386039886, lr: 0.0031490633656390573
[batch_idx--400] train_loss: 0.0009600051742295579, acc: 0.8986128428927681, lr: 0.0031209188657960046
[batch_idx--450] train_loss: 0.0009608443460593755, acc: 0.898991564550283, lr: 0.0030928923254835983
total time of one epoch: 215.16778588294983 s
train_loss:  0.0009608443460593755  acc:  0.898991564550283
->>lr:0.003093
test_loss:  0.0009776959164531048  test_acc:  0.9003598461347562
best acc:  90.16006948752947

------Epoch: 126------
[batch_idx--0] train_loss: 0.0010407621739432216, acc: 0.88671875, lr: 0.0030923329989034107
[batch_idx--50] train_loss: 0.0009641461074352264, acc: 0.9003523284313726, lr: 0.003064426932974329
[batch_idx--100] train_loss: 0.0009594578007789384, acc: 0.8993270420792079, lr: 0.003036639131148192
[batch_idx--150] train_loss: 0.0009574078953214335, acc: 0.8995498758278145, lr: 0.003008969743240972
[batch_idx--200] train_loss: 0.0009588684454625148, acc: 0.8986318407960199, lr: 0.002981418918430234
[batch_idx--250] train_loss: 0.0009589644885933643, acc: 0.8983441235059761, lr: 0.002953986805254319
[batch_idx--300] train_loss: 0.000957851722624549, acc: 0.8985283430232558, lr: 0.002926673551611542
[batch_idx--350] train_loss: 0.0009598135498771577, acc: 0.8985710470085471, lr: 0.002899479304759398
[batch_idx--400] train_loss: 0.0009607743807752476, acc: 0.8982037094763092, lr: 0.0028724042113137424
[batch_idx--450] train_loss: 0.00096673602786933, acc: 0.8982365397299268, lr: 0.002845448417248059
total time of one epoch: 212.95414185523987 s
train_loss:  0.00096673602786933  acc:  0.8982365397299268
->>lr:0.002845
test_loss:  0.0009757106136130789  test_acc:  0.8988708276461099
best acc:  90.16006948752947

------Epoch: 127------
[batch_idx--0] train_loss: 0.0009663071832619607, acc: 0.8828125, lr: 0.0028449105192196373
[batch_idx--50] train_loss: 0.0009408925475059625, acc: 0.8998927696078431, lr: 0.0028180765602363435
[batch_idx--100] train_loss: 0.0009447941095522134, acc: 0.9002165841584159, lr: 0.0027913621935367313
[batch_idx--150] train_loss: 0.0009392425367787529, acc: 0.9016711506622517, lr: 0.002764767563149445
[batch_idx--200] train_loss: 0.0009440864478029422, acc: 0.9011971393034826, lr: 0.002738292812457563
[batch_idx--250] train_loss: 0.0009489520840194684, acc: 0.9010987300796812, lr: 0.00271193808419784
[batch_idx--300] train_loss: 0.0009521794266785275, acc: 0.9005268895348837, lr: 0.002685703520459948
[batch_idx--350] train_loss: 0.0009491113681171058, acc: 0.9008190883190883, lr: 0.0026595892626856965
[batch_idx--400] train_loss: 0.0009510360069995621, acc: 0.9001129987531172, lr: 0.0026335954516682747
[batch_idx--450] train_loss: 0.000955276291715394, acc: 0.899789981601694, lr: 0.0026077222275514957
total time of one epoch: 213.5309727191925 s
train_loss:  0.000955276291715394  acc:  0.899789981601694
->>lr:0.002608
test_loss:  0.0009642286578158407  test_acc:  0.9020970343715101
best acc:  90.16006948752947
Saving..

------Epoch: 128------
[batch_idx--0] train_loss: 0.0009645808022469282, acc: 0.90625, lr: 0.0026072059940146775
[batch_idx--50] train_loss: 0.000977105297851285, acc: 0.8962162990196079, lr: 0.002581455912238459
[batch_idx--100] train_loss: 0.0009761346270108946, acc: 0.8966584158415841, lr: 0.0025558266984695406
[batch_idx--150] train_loss: 0.0009794228622344453, acc: 0.8968853476821192, lr: 0.002530318490886033
[batch_idx--200] train_loss: 0.0009744416807073896, acc: 0.8975629664179104, lr: 0.0025049314270136516
[batch_idx--250] train_loss: 0.0009652273567111428, acc: 0.8984841882470119, lr: 0.0024796656437249655
[batch_idx--300] train_loss: 0.000963206815632351, acc: 0.899047446013289, lr: 0.0024545212772386807
[batch_idx--350] train_loss: 0.0009613588601257917, acc: 0.899116363960114, lr: 0.0024294984631188735
[batch_idx--400] train_loss: 0.0009603849401699839, acc: 0.8993336970074813, lr: 0.0024045973362742893
[batch_idx--450] train_loss: 0.0009623883597206978, acc: 0.8991911688131357, lr: 0.0023798180309576172
total time of one epoch: 211.1212499141693 s
train_loss:  0.0009623883597206978  acc:  0.8991911688131357
->>lr:0.002380
test_loss:  0.0009609603906982456  test_acc:  0.902965628489887
best acc:  90.209703437151
Saving..

------Epoch: 129------
[batch_idx--0] train_loss: 0.0010053716832771897, acc: 0.8828125, lr: 0.0023793236883495163
[batch_idx--50] train_loss: 0.0009611156191585548, acc: 0.8963694852941176, lr: 0.002354668778617275
[batch_idx--100] train_loss: 0.0009526368207528745, acc: 0.8986308787128713, lr: 0.0023301359595992556
[batch_idx--150] train_loss: 0.0009481184637877128, acc: 0.8991618377483444, lr: 0.0023057253635624278
[batch_idx--200] train_loss: 0.0009494703546842903, acc: 0.8990010883084577, lr: 0.0022814371221148186
[batch_idx--250] train_loss: 0.0009513054487380789, acc: 0.8992000747011952, lr: 0.0022572713662047635
[batch_idx--300] train_loss: 0.0009467359162337979, acc: 0.8999299210963455, lr: 0.0022332282261202457
[batch_idx--350] train_loss: 0.0009483936933622804, acc: 0.8998620014245015, lr: 0.0022093078314881667
[batch_idx--400] train_loss: 0.0009494194271161391, acc: 0.8998012780548629, lr: 0.002185510311273653
[batch_idx--450] train_loss: 0.0009547617058454444, acc: 0.8996250911236852, lr: 0.0021618357937793764
total time of one epoch: 210.42825770378113 s
train_loss:  0.0009547617058454444  acc:  0.8996250911236852
->>lr:0.002162
test_loss:  0.0009652073455220757  test_acc:  0.9027174587417793
best acc:  90.29656284898871

------Epoch: 130------
[batch_idx--0] train_loss: 0.0008928360184654593, acc: 0.8984375, lr: 0.0021613635589349755
[batch_idx--50] train_loss: 0.0009411007608743567, acc: 0.8995863970588235, lr: 0.0021378146357049848
[batch_idx--100] train_loss: 0.0009425390779160628, acc: 0.8993657178217822, lr: 0.0021143889723431067
[batch_idx--150] train_loss: 0.0009436622741539648, acc: 0.9002742135761589, lr: 0.0020910866951471623
[batch_idx--200] train_loss: 0.000948116613612209, acc: 0.8999727922885572, lr: 0.0020679079297497515
[batch_idx--250] train_loss: 0.00095226865496479, acc: 0.8995891434262948, lr: 0.0020448528011175527
[batch_idx--300] train_loss: 0.0009513115866165423, acc: 0.8994108181063123, lr: 0.0020219214335506857
[batch_idx--350] train_loss: 0.0009496020781011599, acc: 0.8996839387464387, lr: 0.0019991139506819965
[batch_idx--400] train_loss: 0.0009562479957132287, acc: 0.8987589619700748, lr: 0.001976430475476429
[batch_idx--450] train_loss: 0.0009572628960383242, acc: 0.8991564550282918, lr: 0.0019538711302303584
total time of one epoch: 214.6788182258606 s
train_loss:  0.0009572628960383242  acc:  0.8991564550282918
->>lr:0.001954
test_loss:  0.0009637272158987336  test_acc:  0.9018488646234024
best acc:  90.29656284898871

------Epoch: 131------
[batch_idx--0] train_loss: 0.0009195146267302334, acc: 0.9375, lr: 0.00195342121028749
[batch_idx--50] train_loss: 0.0009577519890359219, acc: 0.9002757352941176, lr: 0.001930988602895767
[batch_idx--100] train_loss: 0.0009490807983323489, acc: 0.9000618811881188, lr: 0.001908680370460203
[batch_idx--150] train_loss: 0.0009485333633689297, acc: 0.9006105132450332, lr: 0.0018864966332540673
[batch_idx--200] train_loss: 0.0009525457193810882, acc: 0.9001865671641791, lr: 0.0018644375108794243
[batch_idx--250] train_loss: 0.0009509325737089096, acc: 0.9002583416334662, lr: 0.0018425031222664813
[batch_idx--300] train_loss: 0.000952595509542307, acc: 0.899968853820598, lr: 0.0018206935856729584
[batch_idx--350] train_loss: 0.000954445585823403, acc: 0.8994947471509972, lr: 0.0017990090186834396
[batch_idx--400] train_loss: 0.0009537499654629359, acc: 0.8999181733167082, lr: 0.0017774495382087503
[batch_idx--450] train_loss: 0.0009530428553240431, acc: 0.9002759745895095, lr: 0.001756015260485311
total time of one epoch: 214.33530950546265 s
train_loss:  0.0009530428553240431  acc:  0.9002759745895095
->>lr:0.001756
test_loss:  0.0009605601302357669  test_acc:  0.9024692889936716
best acc:  90.29656284898871

------Epoch: 132------
[batch_idx--0] train_loss: 0.0008876811480149627, acc: 0.9296875, lr: 0.0017555878527937164
[batch_idx--50] train_loss: 0.0009673381059923593, acc: 0.8978247549019608, lr: 0.0017342814009232738
[batch_idx--100] train_loss: 0.0009585238479096258, acc: 0.8978186881188119, lr: 0.0017131003845420657
[batch_idx--150] train_loss: 0.0009587629839303034, acc: 0.8977907698675497, lr: 0.0016920449178460556
[batch_idx--200] train_loss: 0.0009638237664406535, acc: 0.8973686256218906, lr: 0.0016711151143543159
[batch_idx--250] train_loss: 0.0009672717862406308, acc: 0.8966789093625498, lr: 0.0016503110869084154
[batch_idx--300] train_loss: 0.0009631331386570618, acc: 0.8975290697674418, lr: 0.0016296329476718054
[batch_idx--350] train_loss: 0.0009580117489802956, acc: 0.8981370192307693, lr: 0.0016090808081292208
[batch_idx--400] train_loss: 0.0009541469887409945, acc: 0.8989830112219451, lr: 0.0015886547790860768
[batch_idx--450] train_loss: 0.0009535570437969335, acc: 0.8992345610441906, lr: 0.0015683549706678873
total time of one epoch: 211.82657027244568 s
train_loss:  0.0009535570437969335  acc:  0.8992345610441906
->>lr:0.001568
test_loss:  0.0009718207892745581  test_acc:  0.9014766100012408
best acc:  90.29656284898871

------Epoch: 133------
[batch_idx--0] train_loss: 0.0009619413176551461, acc: 0.90234375, lr: 0.0015679502627027138
[batch_idx--50] train_loss: 0.0009459999147985203, acc: 0.8997395833333334, lr: 0.0015477793120675237
[batch_idx--100] train_loss: 0.0009493687199336468, acc: 0.8993270420792079, lr: 0.0015277348024344995
[batch_idx--150] train_loss: 0.0009455046657355663, acc: 0.8999637831125827, lr: 0.001507816841872195
[batch_idx--200] train_loss: 0.0009450379270244742, acc: 0.900322605721393, lr: 0.0014880255377669072
[batch_idx--250] train_loss: 0.0009464673014762125, acc: 0.90042953187251, lr: 0.0014683609968220602
[batch_idx--300] train_loss: 0.0009474636810101519, acc: 0.9002673380398671, lr: 0.0014488233250576467
[batch_idx--350] train_loss: 0.0009435602053177365, acc: 0.9003516737891738, lr: 0.0014294126278096538
[batch_idx--400] train_loss: 0.0009413925342103861, acc: 0.9008435941396509, lr: 0.0014101290097294967
[batch_idx--450] train_loss: 0.0009442417724840088, acc: 0.9006491477765821, lr: 0.0013909725747834447
total time of one epoch: 212.9870240688324 s
train_loss:  0.0009442417724840088  acc:  0.9006491477765821
->>lr:0.001391
test_loss:  0.0009718896500569358  test_acc:  0.8999875915125947
best acc:  90.29656284898871

------Epoch: 134------
[batch_idx--0] train_loss: 0.000896961020771414, acc: 0.91015625, lr: 0.001390590744062975
[batch_idx--50] train_loss: 0.0009462179002059879, acc: 0.9008884803921569, lr: 0.0013715641423086456
[batch_idx--100] train_loss: 0.000948306788588957, acc: 0.9003326113861386, lr: 0.0013526649316081968
[batch_idx--150] train_loss: 0.0009548561192666557, acc: 0.8991877069536424, lr: 0.0013338932138554
[batch_idx--200] train_loss: 0.0009502506445958951, acc: 0.8999533582089553, lr: 0.0013152490902566538
[batch_idx--250] train_loss: 0.0009448892131737207, acc: 0.9004917828685259, lr: 0.0012967326613304436
[batch_idx--300] train_loss: 0.0009462399627901985, acc: 0.900500934385382, lr: 0.0012783440269067943
[batch_idx--350] train_loss: 0.0009497150492209655, acc: 0.8996394230769231, lr: 0.0012600832861267342
[batch_idx--400] train_loss: 0.0009463213581854287, acc: 0.9002104114713217, lr: 0.0012419505374417718
[batch_idx--450] train_loss: 0.0009521348149408904, acc: 0.9000676918804458, lr: 0.0012239458786133446
total time of one epoch: 210.99604296684265 s
train_loss:  0.0009521348149408904  acc:  0.9000676918804458
->>lr:0.001224
test_loss:  0.0009661868560371867  test_acc:  0.8999875915125947
best acc:  90.29656284898871

------Epoch: 135------
[batch_idx--0] train_loss: 0.0009011321817524731, acc: 0.90234375, lr: 0.0012235870926211618
[batch_idx--50] train_loss: 0.0009305936218166322, acc: 0.9013480392156863, lr: 0.0012057131854440546
[batch_idx--100] train_loss: 0.000943169704324907, acc: 0.9014928836633663, lr: 0.0011879675634946297
[batch_idx--150] train_loss: 0.0009419390078270129, acc: 0.9011796357615894, lr: 0.0011703503224471529
[batch_idx--200] train_loss: 0.0009512863326377574, acc: 0.8994092039800995, lr: 0.001152861557283752
[batch_idx--250] train_loss: 0.0009449024453287967, acc: 0.9003361553784861, lr: 0.0011355013622938726
[batch_idx--300] train_loss: 0.0009479903684854755, acc: 0.899579526578073, lr: 0.0011182698310737928
[batch_idx--350] train_loss: 0.0009459534729963588, acc: 0.8995837784900285, lr: 0.0011011670565261005
[batch_idx--400] train_loss: 0.0009453995297012613, acc: 0.8996843827930174, lr: 0.0010841931308592041
[batch_idx--450] train_loss: 0.0009466751859812287, acc: 0.899850730725171, lr: 0.00106734814558683
total time of one epoch: 213.9249348640442 s
train_loss:  0.0009466751859812287  acc:  0.899850730725171
->>lr:0.001067
test_loss:  0.000968130650480682  test_acc:  0.899739421764487
best acc:  90.29656284898871

------Epoch: 136------
[batch_idx--0] train_loss: 0.0008744533406570554, acc: 0.90234375, lr: 0.001067012561698319
[batch_idx--50] train_loss: 0.0009275516734787208, acc: 0.9034160539215687, lr: 0.0010502991891848613
[batch_idx--100] train_loss: 0.0009324323630310816, acc: 0.9022663985148515, lr: 0.0010337149398027378
[batch_idx--150] train_loss: 0.0009353768503731301, acc: 0.902292011589404, lr: 0.001017259902964765
[batch_idx--200] train_loss: 0.0009391973723555493, acc: 0.9013137437810945, lr: 0.0010009341673871241
[batch_idx--250] train_loss: 0.0009419872463528675, acc: 0.900367280876494, lr: 0.000984737821088863
[batch_idx--300] train_loss: 0.0009401311569590357, acc: 0.9009421719269103, lr: 0.000968670951391451
[batch_idx--350] train_loss: 0.0009366950654342473, acc: 0.9009637642450142, lr: 0.0009527336449182884
[batch_idx--400] train_loss: 0.0009367288893873703, acc: 0.9012916926433915, lr: 0.0009369259875942449
[batch_idx--450] train_loss: 0.000940668354849402, acc: 0.9010917485333426, lr: 0.0009212480646451971
total time of one epoch: 211.38760352134705 s
train_loss:  0.000940668354849402  acc:  0.9010917485333426
->>lr:0.000921
test_loss:  0.0009602630684964192  test_acc:  0.903089713363941
best acc:  90.29656284898871
Saving..

------Epoch: 137------
[batch_idx--0] train_loss: 0.0009985397337004542, acc: 0.90625, lr: 0.0009209358300585474
[batch_idx--50] train_loss: 0.0009341057465302155, acc: 0.9011182598039216, lr: 0.0009053903232463079
[batch_idx--100] train_loss: 0.0009322828148712985, acc: 0.9017249381188119, lr: 0.0008899747208313852
[batch_idx--150] train_loss: 0.0009288419433561036, acc: 0.9029128725165563, lr: 0.0008746891059259105
[batch_idx--200] train_loss: 0.0009215962036341355, acc: 0.9035875310945274, lr: 0.0008595335609412142
[batch_idx--250] train_loss: 0.0009292435161658076, acc: 0.9029506972111554, lr: 0.0008445081675873518
[batch_idx--300] train_loss: 0.0009306105920438503, acc: 0.902421615448505, lr: 0.0008296130068726787
[batch_idx--350] train_loss: 0.0009317864540186936, acc: 0.9020877849002849, lr: 0.0008148481591034013
[batch_idx--400] train_loss: 0.0009356135273981663, acc: 0.9017397911471322, lr: 0.0008002137038831625
[batch_idx--450] train_loss: 0.0009397865972447495, acc: 0.9015343492901031, lr: 0.000785709720112604
total time of one epoch: 212.85376024246216 s
train_loss:  0.0009397865972447495  acc:  0.9015343492901031
->>lr:0.000786
test_loss:  0.0009637658361436593  test_acc:  0.9023452041196178
best acc:  90.3089713363941

------Epoch: 138------
[batch_idx--0] train_loss: 0.0008357411716133356, acc: 0.93359375, lr: 0.0007854209717842232
[batch_idx--50] train_loss: 0.0009363250414311301, acc: 0.9008884803921569, lr: 0.0007710501494462701
[batch_idx--100] train_loss: 0.000935694023547233, acc: 0.9018022896039604, lr: 0.0007568099557912517
[batch_idx--150] train_loss: 0.0009355602700368113, acc: 0.9024989652317881, lr: 0.000742700467594179
[batch_idx--200] train_loss: 0.0009349097468223034, acc: 0.9021882773631841, lr: 0.0007287217609253605
[batch_idx--250] train_loss: 0.0009324647042347467, acc: 0.9020791832669323, lr: 0.0007148739111500131
[batch_idx--300] train_loss: 0.0009297257951813505, acc: 0.9019544227574751, lr: 0.0007011569929278511
[batch_idx--350] train_loss: 0.000932920260316403, acc: 0.9017539173789174, lr: 0.0006875710802126706
[batch_idx--400] train_loss: 0.0009324043798155878, acc: 0.90169108478803, lr: 0.0006741162462519713
[batch_idx--450] train_loss: 0.0009336872485083161, acc: 0.9018120595688548, lr: 0.0006607925635865458
total time of one epoch: 211.5550298690796 s
train_loss:  0.0009336872485083161  acc:  0.9018120595688548
->>lr:0.000661
test_loss:  0.0009594089300168894  test_acc:  0.9023452041196178
best acc:  90.3089713363941

------Epoch: 139------
[batch_idx--0] train_loss: 0.0008662653272040188, acc: 0.91015625, lr: 0.0006605274281709927
[batch_idx--50] train_loss: 0.0009579768851764646, acc: 0.8992800245098039, lr: 0.0006473375938249676
[batch_idx--100] train_loss: 0.000940764687107046, acc: 0.9009514232673267, lr: 0.0006342790551494393
[batch_idx--150] train_loss: 0.0009485894073238781, acc: 0.898385761589404, lr: 0.0006213518825486042
[batch_idx--200] train_loss: 0.000943460893256599, acc: 0.8997590174129353, lr: 0.0006085561457184031
[batch_idx--250] train_loss: 0.0009379711178821545, acc: 0.9007252241035857, lr: 0.0005958919136461599
[batch_idx--300] train_loss: 0.0009409433561052348, acc: 0.9004879568106312, lr: 0.000583359254610194
[batch_idx--350] train_loss: 0.0009403295169565879, acc: 0.9005853810541311, lr: 0.0005709582361794502
[batch_idx--400] train_loss: 0.0009409472056864261, acc: 0.9003078241895262, lr: 0.0005586889252131494
[batch_idx--450] train_loss: 0.0009445703814443266, acc: 0.9005710417606831, lr: 0.0005465513878604278
total time of one epoch: 215.48378157615662 s
train_loss:  0.0009445703814443266  acc:  0.9005710417606831
->>lr:0.000547
test_loss:  0.0009649464836752522  test_acc:  0.9003598461347562
best acc:  90.3089713363941

------Epoch: 140------
[batch_idx--0] train_loss: 0.0008934439974837005, acc: 0.8984375, lr: 0.0005463099816548578
[batch_idx--50] train_loss: 0.0009169993367429604, acc: 0.9046415441176471, lr: 0.0005343069207980278
[batch_idx--100] train_loss: 0.0009211209380196979, acc: 0.904006806930693, lr: 0.0005224357650086414
[batch_idx--150] train_loss: 0.0009201306091091096, acc: 0.9040769867549668, lr: 0.0005106965782891965
[batch_idx--200] train_loss: 0.0009241698524655209, acc: 0.9033348880597015, lr: 0.0004990894239306987
[batch_idx--250] train_loss: 0.0009298720248637209, acc: 0.9025305029880478, lr: 0.0004876143645123038
[batch_idx--300] train_loss: 0.0009331881587681332, acc: 0.9022399294019934, lr: 0.00047627146190098725
[batch_idx--350] train_loss: 0.0009373920306993219, acc: 0.901809561965812, lr: 0.00046506077725121944
[batch_idx--400] train_loss: 0.0009376320539697298, acc: 0.901759273690773, lr: 0.00045398237100461594
[batch_idx--450] train_loss: 0.0009401185616432377, acc: 0.901664525983268, lr: 0.0004430363028896239
total time of one epoch: 212.53045105934143 s
train_loss:  0.0009401185616432377  acc:  0.901664525983268
->>lr:0.000443
test_loss:  0.0009591575147555652  test_acc:  0.9025933738677255
best acc:  90.3089713363941

------Epoch: 141------
[batch_idx--0] train_loss: 0.0008000897942110896, acc: 0.9140625, lr: 0.00044281873178278475
[batch_idx--50] train_loss: 0.000926475000668171, acc: 0.9029564950980392, lr: 0.0004320077093543484
[batch_idx--100] train_loss: 0.0009495059689875729, acc: 0.8999458539603961, lr: 0.0004213291435323757
[batch_idx--150] train_loss: 0.000943378674094596, acc: 0.9008433360927153, lr: 0.0004107830918895994
[batch_idx--200] train_loss: 0.0009425489801857898, acc: 0.900400342039801, lr: 0.00040036961128431806
[batch_idx--250] train_loss: 0.0009422081847771616, acc: 0.8999782121513944, lr: 0.00039008875786008537
[batch_idx--300] train_loss: 0.0009396770633323941, acc: 0.9004620016611296, lr: 0.00037994058704539927
[batch_idx--350] train_loss: 0.0009417888859984733, acc: 0.9003628027065527, lr: 0.0003699251535534104
[batch_idx--400] train_loss: 0.0009417366577565503, acc: 0.900434460723192, lr: 0.0003600425113816253
[batch_idx--450] train_loss: 0.0009421064790705414, acc: 0.9006665046690041, lr: 0.0003502927138116147
total time of one epoch: 215.08222699165344 s
train_loss:  0.0009421064790705414  acc:  0.9006665046690041
->>lr:0.000350
test_loss:  0.0009575847941720615  test_acc:  0.902965628489887
best acc:  90.3089713363941

------Epoch: 142------
[batch_idx--0] train_loss: 0.001026239013299346, acc: 0.8828125, lr: 0.00035009907323737546
[batch_idx--50] train_loss: 0.0009222673606036194, acc: 0.9052542892156863, lr: 0.00034048483130907914
[batch_idx--100] train_loss: 0.0009318385134902921, acc: 0.9030399133663366, lr: 0.00033100353942642217
[batch_idx--150] train_loss: 0.0009334967533336175, acc: 0.9020333195364238, lr: 0.0003216552487071145
[batch_idx--200] train_loss: 0.0009382015693033883, acc: 0.9017607276119403, lr: 0.00031244000955181765
[batch_idx--250] train_loss: 0.0009400547302116554, acc: 0.9015344870517928, lr: 0.00030335787164384453
[batch_idx--300] train_loss: 0.0009395994574366836, acc: 0.9015131852159468, lr: 0.00029440888394890454
[batch_idx--350] train_loss: 0.0009371737151557946, acc: 0.9016092414529915, lr: 0.00028559309471483943
[batch_idx--400] train_loss: 0.0009373574292094463, acc: 0.9016423784289277, lr: 0.00027691055147135437
[batch_idx--450] train_loss: 0.0009370330325036037, acc: 0.9020029853854966, lr: 0.0002683613010297709
total time of one epoch: 211.98155665397644 s
train_loss:  0.0009370330325036037  acc:  0.9020029853854966
->>lr:0.000268
test_loss:  0.000962286007908737  test_acc:  0.9024692889936716
best acc:  90.3089713363941

------Epoch: 143------
[batch_idx--0] train_loss: 0.0009691390441730618, acc: 0.88671875, lr: 0.0002681916759252945
[batch_idx--50] train_loss: 0.0009164873718320593, acc: 0.9042585784313726, lr: 0.00025977843162139916
[batch_idx--100] train_loss: 0.0009327607741118363, acc: 0.9012221534653465, lr: 0.0002514985724860308
[batch_idx--150] train_loss: 0.0009282594870479888, acc: 0.902317880794702, lr: 0.00024335214315946986
[batch_idx--200] train_loss: 0.0009388066897752569, acc: 0.9014497823383084, lr: 0.00023533918756261376
[batch_idx--250] train_loss: 0.0009374838789453753, acc: 0.901409985059761, lr: 0.00022745974889675503
[batch_idx--300] train_loss: 0.000936625824128881, acc: 0.9015131852159468, lr: 0.0002197138696433315
[batch_idx--350] train_loss: 0.0009368990423248025, acc: 0.9013421474358975, lr: 0.0002121015915637098
[batch_idx--400] train_loss: 0.0009376278586634562, acc: 0.9010481608478803, lr: 0.0002046229556989493
[batch_idx--450] train_loss: 0.0009394958253210047, acc: 0.9012653174575624, lr: 0.00019727800236959416
total time of one epoch: 217.40745401382446 s
train_loss:  0.0009394958253210047  acc:  0.9012653174575624
->>lr:0.000197
test_loss:  0.0009612188728708593  test_acc:  0.9027174587417793
best acc:  90.3089713363941

------Epoch: 144------
[batch_idx--0] train_loss: 0.000932350754737854, acc: 0.890625, lr: 0.0001971324671380531
[batch_idx--50] train_loss: 0.0009293236333749019, acc: 0.9028033088235294, lr: 0.00018992391078557493
[batch_idx--100] train_loss: 0.0009436628759359148, acc: 0.9003712871287128, lr: 0.00018284911621737067
[batch_idx--150] train_loss: 0.0009347029714166674, acc: 0.9012055049668874, lr: 0.00017590812157669555
[batch_idx--200] train_loss: 0.0009365297097536685, acc: 0.9009250621890548, lr: 0.00016910096428543743
[batch_idx--250] train_loss: 0.0009333624303214757, acc: 0.9015344870517928, lr: 0.00016242768104390848
[batch_idx--300] train_loss: 0.000933779192395335, acc: 0.9018635797342193, lr: 0.00015588830783064834
[batch_idx--350] train_loss: 0.00092738421658383, acc: 0.90234375, lr: 0.0001494828799022241
[batch_idx--400] train_loss: 0.0009276666679939817, acc: 0.9023827150872819, lr: 0.00014321143179305552
[batch_idx--450] train_loss: 0.0009350389201824736, acc: 0.9019769500468636, lr: 0.00013707399731520964
total time of one epoch: 213.49591732025146 s
train_loss:  0.0009350389201824736  acc:  0.9019769500468636
->>lr:0.000137
test_loss:  0.0009593517364794718  test_acc:  0.902965628489887
best acc:  90.3089713363941

------Epoch: 145------
[batch_idx--0] train_loss: 0.0010050178971141577, acc: 0.89453125, lr: 0.00013695261579316776
[batch_idx--50] train_loss: 0.0009371520204962615, acc: 0.9010416666666666, lr: 0.0001309519093031647
[batch_idx--100] train_loss: 0.0009454882001771711, acc: 0.9003326113861386, lr: 0.0001250852825408405
[batch_idx--150] train_loss: 0.0009494797505487669, acc: 0.8995498758278145, lr: 0.0001193527671357053
[batch_idx--200] train_loss: 0.0009435892408593229, acc: 0.9003031716417911, lr: 0.00011375439399421428
[batch_idx--250] train_loss: 0.0009361475541913118, acc: 0.9015500498007968, lr: 0.00010829019329959833
[batch_idx--300] train_loss: 0.0009377225852521922, acc: 0.9016818936877077, lr: 0.00010296019451171701
[batch_idx--350] train_loss: 0.0009386687920272265, acc: 0.9015535968660968, lr: 9.776442636688366e-05
[batch_idx--400] train_loss: 0.0009364064513157561, acc: 0.902148924563591, lr: 9.270291687771548e-05
[batch_idx--450] train_loss: 0.0009389956052318956, acc: 0.9020897698476065, lr: 8.77756933329893e-05
total time of one epoch: 211.42046666145325 s
train_loss:  0.0009389956052318956  acc:  0.9020897698476065
->>lr:0.000088
test_loss:  0.0009607627335161559  test_acc:  0.9019729494974562
best acc:  90.3089713363941

------Epoch: 146------
[batch_idx--0] train_loss: 0.0007842491613700986, acc: 0.90625, lr: 8.767851876239075e-05
[batch_idx--50] train_loss: 0.0009483204442350304, acc: 0.9017310049019608, lr: 8.288829424305533e-05
[batch_idx--100] train_loss: 0.0009470224290588262, acc: 0.9008353960396039, lr: 7.82324085830094e-05
[batch_idx--150] train_loss: 0.0009402274304464312, acc: 0.9007915976821192, lr: 7.371088688413186e-05
[batch_idx--200] train_loss: 0.0009365596617942685, acc: 0.9011194029850746, lr: 6.93237535238922e-05
[batch_idx--250] train_loss: 0.0009365578799367515, acc: 0.9015189243027888, lr: 6.507103215520893e-05
[batch_idx--300] train_loss: 0.0009338974289787914, acc: 0.9017727367109635, lr: 6.09527457063358e-05
[batch_idx--350] train_loss: 0.0009349982217392032, acc: 0.9017205306267806, lr: 5.6968916380720215e-05
[batch_idx--400] train_loss: 0.0009357157317768234, acc: 0.9017203086034913, lr: 5.311956565690057e-05
[batch_idx--450] train_loss: 0.000939615751037405, acc: 0.9015517061825251, lr: 4.9404714288381335e-05
total time of one epoch: 215.21617937088013 s
train_loss:  0.000939615751037405  acc:  0.9015517061825251
->>lr:0.000049
test_loss:  0.0009600472928779802  test_acc:  0.9022211192455639
best acc:  90.3089713363941

------Epoch: 147------
[batch_idx--0] train_loss: 0.000719528878107667, acc: 0.92578125, lr: 4.933178929321103e-05
[batch_idx--50] train_loss: 0.0009246536772515552, acc: 0.8998927696078431, lr: 4.57541478953355e-05
[batch_idx--100] train_loss: 0.0009433989566381984, acc: 0.8982054455445545, lr: 4.231104556289278e-05
[batch_idx--150] train_loss: 0.0009383535585427866, acc: 0.8996274834437086, lr: 3.9002500859128264e-05
[batch_idx--200] train_loss: 0.0009363043059442026, acc: 0.8998950559701493, lr: 3.582853162182598e-05
[batch_idx--250] train_loss: 0.0009372977104383072, acc: 0.9002116533864541, lr: 3.2789154963222546e-05
[batch_idx--300] train_loss: 0.0009373069473579402, acc: 0.9001505398671097, lr: 2.9884387269901725e-05
[batch_idx--350] train_loss: 0.000936508197450156, acc: 0.9002626424501424, lr: 2.7114244202716688e-05
[batch_idx--400] train_loss: 0.0009363400186655899, acc: 0.9006585099750624, lr: 2.4478740696695647e-05
[batch_idx--450] train_loss: 0.0009384108846649912, acc: 0.9006491477765821, lr: 2.1977890960975244e-05
total time of one epoch: 205.55140018463135 s
train_loss:  0.0009384108846649912  acc:  0.9006491477765821
->>lr:0.000022
test_loss:  0.0009591526389195969  test_acc:  0.9028415436158332
best acc:  90.3089713363941

------Epoch: 148------
[batch_idx--0] train_loss: 0.0008870278252288699, acc: 0.90234375, lr: 2.192924752854042e-05
[batch_idx--50] train_loss: 0.000937734263739092, acc: 0.8994332107843137, lr: 1.9565758523884538e-05
[batch_idx--100] train_loss: 0.0009345769758871065, acc: 0.9008740717821783, lr: 1.7336949777524425e-05
[batch_idx--150] train_loss: 0.00094019686448579, acc: 0.9002224751655629, lr: 1.524283330592846e-05
[batch_idx--200] train_loss: 0.0009391897176137537, acc: 0.9010416666666666, lr: 1.3283420399376467e-05
[batch_idx--250] train_loss: 0.0009343882223064325, acc: 0.9016745517928287, lr: 1.14587216219042e-05
[batch_idx--300] train_loss: 0.000931220838646915, acc: 0.9022788621262459, lr: 9.768746811253394e-06
[batch_idx--350] train_loss: 0.0009291705796813481, acc: 0.9022881054131054, lr: 8.213505078799587e-06
[batch_idx--400] train_loss: 0.0009329898712257773, acc: 0.901583930798005, lr: 6.793004809518832e-06
[batch_idx--450] train_loss: 0.0009338666544646851, acc: 0.9017339535529558, lr: 5.507253661940492e-06
total time of one epoch: 209.844708442688 s
train_loss:  0.0009338666544646851  acc:  0.9017339535529558
->>lr:0.000006
test_loss:  0.0009596688229831488  test_acc:  0.9027174587417793
best acc:  90.3089713363941

------Epoch: 149------
[batch_idx--0] train_loss: 0.0008939490071497858, acc: 0.90625, lr: 5.482913128862511e-06
[batch_idx--50] train_loss: 0.0009522079980895654, acc: 0.8998927696078431, lr: 4.334613221818051e-06
[batch_idx--100] train_loss: 0.00093196947784578, acc: 0.9026144801980198, lr: 3.321075690718156e-06
[batch_idx--150] train_loss: 0.0009269066677669323, acc: 0.9034819950331126, lr: 2.4423059999861833e-06
[batch_idx--200] train_loss: 0.0009380456017311755, acc: 0.9016635572139303, lr: 1.6983088874406029e-06
[batch_idx--250] train_loss: 0.0009351813292828393, acc: 0.9019079930278885, lr: 1.089088364294999e-06
[batch_idx--300] train_loss: 0.0009341868287667112, acc: 0.9017857142857143, lr: 6.146477151164343e-07
[batch_idx--350] train_loss: 0.0009299779113148607, acc: 0.9021323005698005, lr: 2.749894978198997e-07
[batch_idx--400] train_loss: 0.0009335232669246056, acc: 0.901671602244389, lr: 7.011554364610984e-08
[batch_idx--450] train_loss: 0.000939758199584535, acc: 0.901664525983268, lr: 2.6957161503027296e-11
total time of one epoch: 212.59060716629028 s
train_loss:  0.000939758199584535  acc:  0.901664525983268
->>lr:0.000000
test_loss:  0.0009590815574777586  test_acc:  0.9035860528601564
best acc:  90.3089713363941
Saving..