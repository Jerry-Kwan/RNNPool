Model: mobilenet_fg_fl
Batch size: 256
Number of dataloader workers: 32

loading annotations into memory...
Done (t=2.03s)
creating index...
index created!
Len of trainloader: 451

loading annotations into memory...
Done (t=0.13s)
creating index...
index created!
Len of testloader: 32

use 4 GPUs!
DataParallel device_ids: [0, 1, 2, 3]

------Epoch: 0------
[batch_idx--0] train_loss: 0.0027454181108623743, acc: 0.4609375, lr: 0.05
[batch_idx--50] train_loss: 0.002817368627909352, acc: 0.5389859068627451, lr: 0.04999993260712715
[batch_idx--100] train_loss: 0.002704340879261346, acc: 0.5713180693069307, lr: 0.04999973042887193
[batch_idx--150] train_loss: 0.0026457039762707735, acc: 0.5911889486754967, lr: 0.049999393466324364
[batch_idx--200] train_loss: 0.002615533505024305, acc: 0.6003575870646766, lr: 0.04999892172130118
[batch_idx--250] train_loss: 0.0025850696502201466, acc: 0.6102776394422311, lr: 0.04999831519634575
[batch_idx--300] train_loss: 0.0025675363198194986, acc: 0.6166164867109635, lr: 0.0499975738947281
[batch_idx--350] train_loss: 0.0025539275642187252, acc: 0.6213942307692307, lr: 0.04999669782044491
[batch_idx--400] train_loss: 0.002546133762666784, acc: 0.6244057824189526, lr: 0.049995686978219496
[batch_idx--450] train_loss: 0.002541142952774467, acc: 0.6273909119311278, lr: 0.04999454137350172
total time of one epoch: 320.41686487197876 s
train_loss:  0.002541142952774467  acc:  0.6273909119311278
->>lr:0.049995
test_loss:  0.0037561932395862164  test_acc:  0.5284774785953592
best acc:  0
Saving..
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(

------Epoch: 1------
[batch_idx--0] train_loss: 0.0025944651570171118, acc: 0.61328125, lr: 0.04999451708687114
[batch_idx--50] train_loss: 0.0024026933573551624, acc: 0.6674325980392157, lr: 0.04999323403077913
[batch_idx--100] train_loss: 0.0023990308077507976, acc: 0.6695931311881188, lr: 0.04999181622541965
[batch_idx--150] train_loss: 0.0023751072570163483, acc: 0.6765573261589404, lr: 0.0499902636784367
[batch_idx--200] train_loss: 0.002370815673166543, acc: 0.6770638992537313, lr: 0.04998857639820074
[batch_idx--250] train_loss: 0.0023551473080503393, acc: 0.6809325199203188, lr: 0.04998675439380862
[batch_idx--300] train_loss: 0.0023410394254057016, acc: 0.6839441445182725, lr: 0.04998479767508354
[batch_idx--350] train_loss: 0.0023345206884078235, acc: 0.6853855056980057, lr: 0.04998270625257502
[batch_idx--400] train_loss: 0.002323010545618776, acc: 0.6877630143391521, lr: 0.04998048013755882
[batch_idx--450] train_loss: 0.002317004502192049, acc: 0.6895372652480299, lr: 0.049978119342036866
total time of one epoch: 315.9665732383728 s
train_loss:  0.002317004502192049  acc:  0.6895372652480299
->>lr:0.049978
test_loss:  0.002715301315458141  test_acc:  0.5835711626752699
best acc:  52.84774785953592
Saving..

------Epoch: 2------
[batch_idx--0] train_loss: 0.0021869163028895855, acc: 0.71875, lr: 0.04997807075247146
[batch_idx--50] train_loss: 0.002174962389593323, acc: 0.71484375, lr: 0.04997557259595109
[batch_idx--100] train_loss: 0.002170856715880777, acc: 0.7163521039603961, lr: 0.04997293978538365
[batch_idx--150] train_loss: 0.0021773245885647486, acc: 0.7159561258278145, lr: 0.04997017233496374
[batch_idx--200] train_loss: 0.0021542144090224485, acc: 0.7193913246268657, lr: 0.04996727025961189
[batch_idx--250] train_loss: 0.0021430682233234207, acc: 0.7213489790836654, lr: 0.04996423357497442
[batch_idx--300] train_loss: 0.002133657466589266, acc: 0.7228509136212624, lr: 0.04996106229742341
[batch_idx--350] train_loss: 0.002123808368849449, acc: 0.7241920405982906, lr: 0.04995775644405658
[batch_idx--400] train_loss: 0.0021120654677442667, acc: 0.7261046602244389, lr: 0.049954316032697205
[batch_idx--450] train_loss: 0.0021074123787409014, acc: 0.7275315027597459, lr: 0.049950741081894026
total time of one epoch: 315.60300946235657 s
train_loss:  0.0021074123787409014  acc:  0.7275315027597459
->>lr:0.049951
test_loss:  0.002380675070781923  test_acc:  0.6892914753691525
best acc:  58.35711626752699
Saving..

------Epoch: 3------
[batch_idx--0] train_loss: 0.0018961239838972688, acc: 0.75390625, lr: 0.04995066821070679
[batch_idx--50] train_loss: 0.0020328236346626107, acc: 0.7413449754901961, lr: 0.04994695604953209
[batch_idx--100] train_loss: 0.002032042453342145, acc: 0.7421101485148515, lr: 0.0499431093885944
[batch_idx--150] train_loss: 0.002016040003112215, acc: 0.7462748344370861, lr: 0.04993912824863275
[batch_idx--200] train_loss: 0.002017463429423225, acc: 0.7454912935323383, lr: 0.049935012651111166
[batch_idx--250] train_loss: 0.002013815799728036, acc: 0.7462026892430279, lr: 0.0499307626182186
[batch_idx--300] train_loss: 0.0020046819413724382, acc: 0.7477808347176079, lr: 0.0499263781728688
[batch_idx--350] train_loss: 0.00199814731728795, acc: 0.7484975961538461, lr: 0.04992185933870021
[batch_idx--400] train_loss: 0.001991041838725625, acc: 0.7497272443890274, lr: 0.049917206140075804
[batch_idx--450] train_loss: 0.001994879603164531, acc: 0.750069427569688, lr: 0.04991241860208297
total time of one epoch: 314.03811955451965 s
train_loss:  0.001994879603164531  acc:  0.750069427569688
->>lr:0.049912
test_loss:  0.0020554450926820343  test_acc:  0.74364065020474
best acc:  68.92914753691525
Saving..

------Epoch: 4------
[batch_idx--0] train_loss: 0.0019024155335500836, acc: 0.765625, lr: 0.049912321481237615
[batch_idx--50] train_loss: 0.001959664674074042, acc: 0.7542892156862745, lr: 0.04990739694368515
[batch_idx--100] train_loss: 0.0019616843685323353, acc: 0.7547957920792079, lr: 0.04990233811964985
[batch_idx--150] train_loss: 0.0019521517494064293, acc: 0.7556136175496688, lr: 0.049897145036406014
[batch_idx--200] train_loss: 0.001954104915835816, acc: 0.7549168221393034, lr: 0.04989181772195179
[batch_idx--250] train_loss: 0.0019405812073306022, acc: 0.7572522410358565, lr: 0.04988635620500901
[batch_idx--300] train_loss: 0.0019346706432281093, acc: 0.7593957641196013, lr: 0.049880760515023076
[batch_idx--350] train_loss: 0.0019308322645256832, acc: 0.7601940883190883, lr: 0.04987503068216274
[batch_idx--400] train_loss: 0.0019225803627156445, acc: 0.761416770573566, lr: 0.04986916673732
[batch_idx--450] train_loss: 0.0019243352210074358, acc: 0.7622192522650745, lr: 0.049863168712109905
total time of one epoch: 318.9564542770386 s
train_loss:  0.0019243352210074358  acc:  0.7622192522650745
->>lr:0.049863
test_loss:  0.0025012026591667218  test_acc:  0.68470033502916
best acc:  74.364065020474

------Epoch: 5------
[batch_idx--0] train_loss: 0.001915807486511767, acc: 0.75390625, lr: 0.049863047384206834
[batch_idx--50] train_loss: 0.0018878971801742034, acc: 0.7644761029411765, lr: 0.04985691263034154
[batch_idx--100] train_loss: 0.001893352282620819, acc: 0.7641939975247525, lr: 0.049850643862176046
[batch_idx--150] train_loss: 0.001889723454083976, acc: 0.7663752069536424, lr: 0.04984424111350797
[batch_idx--200] train_loss: 0.0018832744939011796, acc: 0.7663051927860697, lr: 0.0498377044188573
[batch_idx--250] train_loss: 0.0018838038130021427, acc: 0.7664498256972112, lr: 0.04983103381346615
[batch_idx--300] train_loss: 0.001881357285880988, acc: 0.7672471968438538, lr: 0.049824229333298636
[batch_idx--350] train_loss: 0.0018751317760548913, acc: 0.7683404558404558, lr: 0.049817291015040614
[batch_idx--400] train_loss: 0.0018768586851819011, acc: 0.768186954488778, lr: 0.04981021889609956
[batch_idx--450] train_loss: 0.00187801640023873, acc: 0.7693963272815635, lr: 0.0498030130146043
total time of one epoch: 315.95945954322815 s
train_loss:  0.00187801640023873  acc:  0.7693963272815635
->>lr:0.049803
test_loss:  0.0022946338689657105  test_acc:  0.7087728005956074
best acc:  74.364065020474

------Epoch: 6------
[batch_idx--0] train_loss: 0.0016523731173947453, acc: 0.81640625, lr: 0.04980286753286195
[batch_idx--50] train_loss: 0.0018447755068978842, acc: 0.7767310049019608, lr: 0.04979552525358963
[batch_idx--100] train_loss: 0.0018489681631511095, acc: 0.7738629331683168, lr: 0.04978804929098283
[batch_idx--150] train_loss: 0.0018389614133953753, acc: 0.7753776903973509, lr: 0.049780439685347705
[batch_idx--200] train_loss: 0.0018329537857036612, acc: 0.7762943097014925, lr: 0.0497726964777109
[batch_idx--250] train_loss: 0.0018387277169056623, acc: 0.7756629731075697, lr: 0.049764819709819365
[batch_idx--300] train_loss: 0.0018383723341757771, acc: 0.7751764950166113, lr: 0.04975680942414015
[batch_idx--350] train_loss: 0.0018383177143901034, acc: 0.7758079594017094, lr: 0.04974866566386016
[batch_idx--400] train_loss: 0.00183628611104038, acc: 0.7760481608478803, lr: 0.049740388472885894
[batch_idx--450] train_loss: 0.0018392786294140148, acc: 0.7760006248481272, lr: 0.04973197789584324
total time of one epoch: 313.46787095069885 s
train_loss:  0.0018392786294140148  acc:  0.7760006248481272
->>lr:0.049732
test_loss:  0.00203820485411366  test_acc:  0.7561732224841792
best acc:  74.364065020474
Saving..

------Epoch: 7------
[batch_idx--0] train_loss: 0.0020808398257941008, acc: 0.7265625, lr: 0.049731808324074714
[batch_idx--50] train_loss: 0.0018291055206574645, acc: 0.7774969362745098, lr: 0.04972326173996171
[batch_idx--100] train_loss: 0.0018090793510235036, acc: 0.779586943069307, lr: 0.049714581862117906
[batch_idx--150] train_loss: 0.0018112782160720684, acc: 0.7784819950331126, lr: 0.049705768737340256
[batch_idx--200] train_loss: 0.0018187851826915174, acc: 0.7770133706467661, lr: 0.04969682241314409
[batch_idx--250] train_loss: 0.0018137684467608532, acc: 0.7779973854581673, lr: 0.0496877429377629
[batch_idx--300] train_loss: 0.0018123373875790507, acc: 0.7783300456810631, lr: 0.04967853036014805
[batch_idx--350] train_loss: 0.0018160957116713254, acc: 0.7780337428774928, lr: 0.04966918472996849
[batch_idx--400] train_loss: 0.0018135441671545964, acc: 0.7786783042394015, lr: 0.04965970609761053
[batch_idx--450] train_loss: 0.0018150012090672356, acc: 0.7789686534522859, lr: 0.04965009451417756
total time of one epoch: 322.5670289993286 s
train_loss:  0.0018150012090672356  acc:  0.7789686534522859
->>lr:0.049650
test_loss:  0.0019473081702170707  test_acc:  0.7646109939198412
best acc:  75.61732224841792
Saving..

------Epoch: 8------
[batch_idx--0] train_loss: 0.0019378839060664177, acc: 0.765625, lr: 0.04964990092676263
[batch_idx--50] train_loss: 0.001817114066843893, acc: 0.7783394607843137, lr: 0.0496401537866232
[batch_idx--100] train_loss: 0.0017977878658820203, acc: 0.7800123762376238, lr: 0.04963027380082368
[batch_idx--150] train_loss: 0.0017946476397406779, acc: 0.7818967301324503, lr: 0.04962026102263131
[batch_idx--200] train_loss: 0.0017924246335383597, acc: 0.7826881218905473, lr: 0.04961011550602926
[batch_idx--250] train_loss: 0.0017890007827853955, acc: 0.7840201693227091, lr: 0.04959983730571641
[batch_idx--300] train_loss: 0.0017874260097308907, acc: 0.7841699543189369, lr: 0.04958942647710693
[batch_idx--350] train_loss: 0.0017895034462627438, acc: 0.7837985220797721, lr: 0.04957888307633007
[batch_idx--400] train_loss: 0.0017835313461237864, acc: 0.7852049563591023, lr: 0.04956820716022985
[batch_idx--450] train_loss: 0.0017821112654183232, acc: 0.7855035234491616, lr: 0.049557398786364705
total time of one epoch: 319.15251755714417 s
train_loss:  0.0017821112654183232  acc:  0.7855035234491616
->>lr:0.049557
test_loss:  0.0019239238864923768  test_acc:  0.7632460603052488
best acc:  76.46109939198412

------Epoch: 9------
[batch_idx--0] train_loss: 0.0017408685525879264, acc: 0.765625, lr: 0.049557181268217225
[batch_idx--50] train_loss: 0.00176001544676575, acc: 0.7850030637254902, lr: 0.04954623784746919
[batch_idx--100] train_loss: 0.0017487915188977772, acc: 0.7887144183168316, lr: 0.04953516208740226
[batch_idx--150] train_loss: 0.0017531851348189624, acc: 0.7880018625827815, lr: 0.049523954047730606
[batch_idx--200] train_loss: 0.0017550823531247936, acc: 0.7878770211442786, lr: 0.04951261378888158
[batch_idx--250] train_loss: 0.0017551363796455808, acc: 0.7877085408366534, lr: 0.049501141371995405
[batch_idx--300] train_loss: 0.0017548582812096688, acc: 0.7879594061461794, lr: 0.0494895368589248
[batch_idx--350] train_loss: 0.001755940414795339, acc: 0.7876602564102564, lr: 0.0494778003122347
[batch_idx--400] train_loss: 0.0017546264125508004, acc: 0.7881468204488778, lr: 0.049465931795201847
[batch_idx--450] train_loss: 0.0017569638920864046, acc: 0.7887752976707051, lr: 0.049453931371814544
total time of one epoch: 314.2423424720764 s
train_loss:  0.0017569638920864046  acc:  0.7887752976707051
->>lr:0.049454
test_loss:  0.0017849142800816413  test_acc:  0.7888075443603425
best acc:  76.46109939198412
Saving..

------Epoch: 10------
[batch_idx--0] train_loss: 0.0014448532601818442, acc: 0.8203125, lr: 0.049453690018345146
[batch_idx--50] train_loss: 0.0017517036507271376, acc: 0.7888327205882353, lr: 0.04944155511713453
[batch_idx--100] train_loss: 0.0017370338272764394, acc: 0.7906482054455446, lr: 0.04942928844099462
[batch_idx--150] train_loss: 0.001739963917647618, acc: 0.7902266142384106, lr: 0.0494168900560603
[batch_idx--200] train_loss: 0.0017304274146977942, acc: 0.7918610074626866, lr: 0.04940436002917662
[batch_idx--250] train_loss: 0.0017295144771993813, acc: 0.7923306772908366, lr: 0.04939169842789834
[batch_idx--300] train_loss: 0.0017285688236460981, acc: 0.7924626245847176, lr: 0.04937890532048959
[batch_idx--350] train_loss: 0.0017275771609059087, acc: 0.7922119836182336, lr: 0.04936598077592351
[batch_idx--400] train_loss: 0.001725172933465116, acc: 0.7922478958852868, lr: 0.049352924863881875
[batch_idx--450] train_loss: 0.0017303722322278895, acc: 0.7924896726490089, lr: 0.04933973765475472
total time of one epoch: 315.589168548584 s
train_loss:  0.0017303722322278895  acc:  0.7924896726490089
->>lr:0.049340
test_loss:  0.0019400790084131688  test_acc:  0.7678372006452413
best acc:  78.88075443603425

------Epoch: 11------
[batch_idx--0] train_loss: 0.001706258743070066, acc: 0.78125, lr: 0.04933947257182901
[batch_idx--50] train_loss: 0.001713948344866581, acc: 0.7964920343137255, lr: 0.04932615151292455
[batch_idx--100] train_loss: 0.001710537723081168, acc: 0.7970297029702971, lr: 0.04931269930128121
[batch_idx--150] train_loss: 0.0017132686400193942, acc: 0.7954521937086093, lr: 0.04929911600942565
[batch_idx--200] train_loss: 0.0017147436315212306, acc: 0.7952231032338308, lr: 0.04928540171059123
[batch_idx--250] train_loss: 0.001718405993150703, acc: 0.7938091384462151, lr: 0.04927155647871764
[batch_idx--300] train_loss: 0.0017160946484717024, acc: 0.7940718438538206, lr: 0.04925758038845046
[batch_idx--350] train_loss: 0.001711839586138152, acc: 0.7944934116809117, lr: 0.04924347351514081
[batch_idx--400] train_loss: 0.0017064816853788651, acc: 0.7958813902743143, lr: 0.049229235934844906
[batch_idx--450] train_loss: 0.0017062665476733462, acc: 0.7962995105356337, lr: 0.04921486772432365
total time of one epoch: 315.6813898086548 s
train_loss:  0.0017062665476733462  acc:  0.7962995105356337
->>lr:0.049215
test_loss:  0.0017211275104258104  test_acc:  0.7982379947884353
best acc:  78.88075443603425
Saving..

------Epoch: 12------
[batch_idx--0] train_loss: 0.0018820962868630886, acc: 0.76171875, lr: 0.04921457902821578
[batch_idx--50] train_loss: 0.001692048399526553, acc: 0.7963388480392157, lr: 0.04920007765467417
[batch_idx--100] train_loss: 0.001691747989302667, acc: 0.7948251856435643, lr: 0.049185445808112044
[batch_idx--150] train_loss: 0.001688475890967082, acc: 0.7976252069536424, lr: 0.049170683567415975
[batch_idx--200] train_loss: 0.0016847430822203187, acc: 0.7974580223880597, lr: 0.04915579101217554
[batch_idx--250] train_loss: 0.0016823010171292372, acc: 0.7984935258964143, lr: 0.04914076822268292
[batch_idx--300] train_loss: 0.001683712562939084, acc: 0.798717815614618, lr: 0.04912561527993242
[batch_idx--350] train_loss: 0.001684611969019825, acc: 0.7985665954415955, lr: 0.049110332265620074
[batch_idx--400] train_loss: 0.0016843371204753172, acc: 0.7987258416458853, lr: 0.049094919262143176
[batch_idx--450] train_loss: 0.0016907605147909654, acc: 0.7988770090602978, lr: 0.049079376352599846
total time of one epoch: 313.9540159702301 s
train_loss:  0.0016907605147909654  acc:  0.7988770090602978
->>lr:0.049079
test_loss:  0.001704199865269948  test_acc:  0.8030773048765355
best acc:  79.82379947884353
Saving..

------Epoch: 13------
[batch_idx--0] train_loss: 0.0016096014296635985, acc: 0.80859375, lr: 0.049079064169941455
[batch_idx--50] train_loss: 0.001704858700452628, acc: 0.7954963235294118, lr: 0.04906338884254441
[batch_idx--100] train_loss: 0.0016871284034176922, acc: 0.7983833539603961, lr: 0.04904758377907498
[batch_idx--150] train_loss: 0.001676426774094387, acc: 0.8005484271523179, lr: 0.04903164906474507
[batch_idx--200] train_loss: 0.0016708393240653311, acc: 0.8013837064676617, lr: 0.04901558478546556
[batch_idx--250] train_loss: 0.0016641795655630855, acc: 0.8030845368525896, lr: 0.04899939102784589
[batch_idx--300] train_loss: 0.0016686249805917574, acc: 0.8020660299003323, lr: 0.04898306787919357
[batch_idx--350] train_loss: 0.0016691947005625465, acc: 0.8020388176638177, lr: 0.04896661542751371
[batch_idx--400] train_loss: 0.0016673191632271891, acc: 0.8019404613466334, lr: 0.04895003376150854
[batch_idx--450] train_loss: 0.0016712256226734273, acc: 0.8025653486999688, lr: 0.04893332297057697
total time of one epoch: 312.5634024143219 s
train_loss:  0.0016712256226734273  acc:  0.8025653486999688
->>lr:0.048933
test_loss:  0.002277153850947824  test_acc:  0.7283782106961162
best acc:  80.30773048765356

------Epoch: 14------
[batch_idx--0] train_loss: 0.0016487673856317997, acc: 0.79296875, lr: 0.048932987438301684
[batch_idx--50] train_loss: 0.0016576460284162679, acc: 0.8026194852941176, lr: 0.04891614503276587
[batch_idx--100] train_loss: 0.0016479322175025055, acc: 0.8042233910891089, lr: 0.04889917368501234
[batch_idx--150] train_loss: 0.001650987469763896, acc: 0.8043253311258278, lr: 0.04888207348654094
[batch_idx--200] train_loss: 0.0016545036336203193, acc: 0.8028801305970149, lr: 0.048864844529546175
[batch_idx--250] train_loss: 0.001648306837806337, acc: 0.8040183017928287, lr: 0.04884748690691675
[batch_idx--300] train_loss: 0.0016506672071051657, acc: 0.803545473421927, lr: 0.048830000712235096
[batch_idx--350] train_loss: 0.0016504553145996993, acc: 0.8032629985754985, lr: 0.048812386039776785
[batch_idx--400] train_loss: 0.0016511244632006435, acc: 0.8033139806733167, lr: 0.0487946429845101
[batch_idx--450] train_loss: 0.001654910771293576, acc: 0.8033116950741139, lr: 0.048776771642095464
total time of one epoch: 311.2435472011566 s
train_loss:  0.001654910771293576  acc:  0.8033116950741139
->>lr:0.048777
test_loss:  0.001716140896647721  test_acc:  0.7973694006700583
best acc:  80.30773048765356

------Epoch: 15------
[batch_idx--0] train_loss: 0.0017054816707968712, acc: 0.80078125, lr: 0.048776412907378844
[batch_idx--50] train_loss: 0.0016704989693072788, acc: 0.7974111519607843, lr: 0.04875841081133997
[batch_idx--100] train_loss: 0.001646453776341485, acc: 0.8022896039603961, lr: 0.04874028062349638
[batch_idx--150] train_loss: 0.0016459908393452202, acc: 0.8024110099337748, lr: 0.0487220224415957
[batch_idx--200] train_loss: 0.0016339501685726998, acc: 0.8047652363184079, lr: 0.04870363636407563
[batch_idx--250] train_loss: 0.0016366438972633852, acc: 0.8055590139442231, lr: 0.04868512249006343
[batch_idx--300] train_loss: 0.0016410771863337025, acc: 0.8048562084717608, lr: 0.048666480919375345
[batch_idx--350] train_loss: 0.0016387686543989173, acc: 0.8050547542735043, lr: 0.0486477117525161
[batch_idx--400] train_loss: 0.0016368461178820069, acc: 0.8057590399002493, lr: 0.04862881509067834
[batch_idx--450] train_loss: 0.001637777736398278, acc: 0.8062797236782726, lr: 0.04860979103574209
total time of one epoch: 313.87686944007874 s
train_loss:  0.001637777736398278  acc:  0.8062797236782726
->>lr:0.048610
test_loss:  0.001641202633427337  test_acc:  0.808661124208959
best acc:  80.30773048765356
Saving..

------Epoch: 16------
[batch_idx--0] train_loss: 0.0016587622230872512, acc: 0.8203125, lr: 0.04860940925593703
[batch_idx--50] train_loss: 0.0016276961393362167, acc: 0.8112745098039216, lr: 0.048590255365709406
[batch_idx--100] train_loss: 0.0016241660606724643, acc: 0.8087871287128713, lr: 0.04857097429027534
[batch_idx--150] train_loss: 0.001617471449268328, acc: 0.8091887417218543, lr: 0.0485515661335874
[batch_idx--200] train_loss: 0.0016207133526380975, acc: 0.8078746890547264, lr: 0.048532031000283304
[batch_idx--250] train_loss: 0.0016189289782047864, acc: 0.8089672559760956, lr: 0.048512368995685354
[batch_idx--300] train_loss: 0.001618839787594677, acc: 0.8086586378737541, lr: 0.04849258022579986
[batch_idx--350] train_loss: 0.001615126622559508, acc: 0.8088942307692307, lr: 0.04847266479731658
[batch_idx--400] train_loss: 0.00161531438442537, acc: 0.8089444357855362, lr: 0.048452622817608176
[batch_idx--450] train_loss: 0.0016169007954864967, acc: 0.8094994272225501, lr: 0.04843245439472954
total time of one epoch: 318.9395709037781 s
train_loss:  0.0016169007954864967  acc:  0.8094994272225501
->>lr:0.048432
test_loss:  0.0018115169668570393  test_acc:  0.7819828762873806
best acc:  80.86611242089589

------Epoch: 17------
[batch_idx--0] train_loss: 0.0016000780742615461, acc: 0.8125, lr: 0.04843204973729729
[batch_idx--50] train_loss: 0.0016480762347140733, acc: 0.8061427696078431, lr: 0.048411752454410206
[batch_idx--100] train_loss: 0.0016300555440772436, acc: 0.8081683168316832, lr: 0.0483913289487026
[batch_idx--150] train_loss: 0.0016256236765743387, acc: 0.8083091887417219, lr: 0.04837077933028638
[batch_idx--200] train_loss: 0.0016272011767859704, acc: 0.808710354477612, lr: 0.04835010370995336
[batch_idx--250] train_loss: 0.0016163919103402361, acc: 0.8092318227091634, lr: 0.0483293021991747
[batch_idx--300] train_loss: 0.001614528303993773, acc: 0.8098395971760798, lr: 0.04830837491010029
[batch_idx--350] train_loss: 0.0016087129429524017, acc: 0.8108529202279202, lr: 0.04828732195555814
[batch_idx--400] train_loss: 0.0016068082745245046, acc: 0.8113407886533666, lr: 0.04826614344905377
[batch_idx--450] train_loss: 0.0016122588644497148, acc: 0.8112351164647481, lr: 0.04824483950476961
total time of one epoch: 319.9419860839844 s
train_loss:  0.0016122588644497148  acc:  0.8112351164647481
->>lr:0.048245
test_loss:  0.0016924530537670726  test_acc:  0.7950117880630351
best acc:  80.86611242089589

------Epoch: 18------
[batch_idx--0] train_loss: 0.0017261684406548738, acc: 0.8046875, lr: 0.04824441214720629
[batch_idx--50] train_loss: 0.0016130638153602679, acc: 0.8108149509803921, lr: 0.04822298037471885
[batch_idx--100] train_loss: 0.0015983502207655865, acc: 0.8120358910891089, lr: 0.04820142339716232
[batch_idx--150] train_loss: 0.0016000197301402886, acc: 0.812396523178808, lr: 0.04817974133075961
[batch_idx--200] train_loss: 0.001596628037276701, acc: 0.8131218905472637, lr: 0.04815793429240808
[batch_idx--250] train_loss: 0.0015939624198115026, acc: 0.8133248256972112, lr: 0.04813600239967885
[batch_idx--300] train_loss: 0.0015930050003196909, acc: 0.8135901162790697, lr: 0.04811394577081616
[batch_idx--350] train_loss: 0.0015958600393642388, acc: 0.8129006410256411, lr: 0.04809176452473679
[batch_idx--400] train_loss: 0.0015896634057052713, acc: 0.8138735193266833, lr: 0.048069458781029376
[batch_idx--450] train_loss: 0.0015936128586426196, acc: 0.8140469330371091, lr: 0.048047028659953764
total time of one epoch: 311.5132176876068 s
train_loss:  0.0015936128586426196  acc:  0.8140469330371091
->>lr:0.048047
test_loss:  0.001723208432902265  test_acc:  0.8048144931132895
best acc:  80.86611242089589

------Epoch: 19------
[batch_idx--0] train_loss: 0.0014161866856738925, acc: 0.87890625, lr: 0.04804657878971252
[batch_idx--50] train_loss: 0.0016283363482787036, acc: 0.8064491421568627, lr: 0.04802402192830846
[batch_idx--100] train_loss: 0.0016104221565298514, acc: 0.8099087252475248, lr: 0.04800134093450581
[batch_idx--150] train_loss: 0.0015980678322163738, acc: 0.8114134933774835, lr: 0.04797853593058756
[batch_idx--200] train_loss: 0.0015881833966719496, acc: 0.8130441542288557, lr: 0.04795560703950527
[batch_idx--250] train_loss: 0.0015897630288106096, acc: 0.8129046314741036, lr: 0.047932554384878465
[batch_idx--300] train_loss: 0.0015907751433427548, acc: 0.8129412375415282, lr: 0.0479093780909939
[batch_idx--350] train_loss: 0.00158807031937644, acc: 0.8132122507122507, lr: 0.047886078282804945
[batch_idx--400] train_loss: 0.001585964841868013, acc: 0.8133864557356608, lr: 0.047862655085930884
[batch_idx--450] train_loss: 0.0015879350395582028, acc: 0.8134915124796056, lr: 0.04783910862665624
total time of one epoch: 311.22902631759644 s
train_loss:  0.0015879350395582028  acc:  0.8134915124796056
->>lr:0.047839
test_loss:  0.0015576901396209303  test_acc:  0.8270256855689292
best acc:  80.86611242089589
Saving..

------Epoch: 20------
[batch_idx--0] train_loss: 0.0017152151558548212, acc: 0.796875, lr: 0.04783863644106502
[batch_idx--50] train_loss: 0.0015544031550377316, acc: 0.8177849264705882, lr: 0.047814964384929284
[batch_idx--100] train_loss: 0.0015584092407422785, acc: 0.8170637376237624, lr: 0.047791169323514016
[batch_idx--150] train_loss: 0.001556174999984931, acc: 0.8172599337748344, lr: 0.047767251385108636
[batch_idx--200] train_loss: 0.0015588625935392816, acc: 0.8177472014925373, lr: 0.04774321069866503
[batch_idx--250] train_loss: 0.0015646794182897742, acc: 0.8162661852589641, lr: 0.04771904739379687
[batch_idx--300] train_loss: 0.0015654217427058077, acc: 0.8159909676079734, lr: 0.0476947616007789
[batch_idx--350] train_loss: 0.0015589140678631231, acc: 0.8168291488603988, lr: 0.0476703534505463
[batch_idx--400] train_loss: 0.0015606254814169427, acc: 0.8163478023690773, lr: 0.047645823074693894
[batch_idx--450] train_loss: 0.0015650856206056811, acc: 0.8164161488527094, lr: 0.047621170605475466
total time of one epoch: 312.5634515285492 s
train_loss:  0.0015650856206056811  acc:  0.8164161488527094
->>lr:0.047621
test_loss:  0.0015850566371023573  test_acc:  0.8147412830375977
best acc:  82.70256855689291

------Epoch: 21------
[batch_idx--0] train_loss: 0.0015209900448098779, acc: 0.82421875, lr: 0.04762067631165049
[batch_idx--50] train_loss: 0.0016024573386518978, acc: 0.8113511029411765, lr: 0.047595899444129244
[batch_idx--100] train_loss: 0.0015713251022953945, acc: 0.8156327351485149, lr: 0.04757100075240174
[batch_idx--150] train_loss: 0.0015576303665162316, acc: 0.8175962334437086, lr: 0.04754598037070751
[batch_idx--200] train_loss: 0.0015524941165259672, acc: 0.8183885261194029, lr: 0.047520838433942204
[batch_idx--250] train_loss: 0.0015562839543565633, acc: 0.8180247758964143, lr: 0.04749557507765681
[batch_idx--300] train_loss: 0.0015516890618219922, acc: 0.8191315406976745, lr: 0.047470190438056926
[batch_idx--350] train_loss: 0.001552170468228962, acc: 0.8188212250712251, lr: 0.047444684652002064
[batch_idx--400] train_loss: 0.001547699865880434, acc: 0.8197767300498753, lr: 0.04741905785700488
[batch_idx--450] train_loss: 0.0015530010729487083, acc: 0.8190891102856944, lr: 0.04739331019123044
total time of one epoch: 312.5357069969177 s
train_loss:  0.0015530010729487083  acc:  0.8190891102856944
->>lr:0.047393
test_loss:  0.001582215287605813  test_acc:  0.8198287628738057
best acc:  82.70256855689291

------Epoch: 22------
[batch_idx--0] train_loss: 0.0015302870888262987, acc: 0.828125, lr: 0.047392794005985325
[batch_idx--50] train_loss: 0.0015362746735085168, acc: 0.8204656862745098, lr: 0.04736692319503155
[batch_idx--100] train_loss: 0.0015285435353986697, acc: 0.8217821782178217, lr: 0.047340931794380904
[batch_idx--150] train_loss: 0.001515744486823678, acc: 0.8251759105960265, lr: 0.04731481994416418
[batch_idx--200] train_loss: 0.0015234069108722075, acc: 0.824160447761194, lr: 0.04728858778516159
[batch_idx--250] train_loss: 0.0015284608686862299, acc: 0.823269422310757, lr: 0.04726223545880198
[batch_idx--300] train_loss: 0.001534400489243162, acc: 0.8219995847176079, lr: 0.04723576310716207
[batch_idx--350] train_loss: 0.0015381998783826531, acc: 0.8211471688034188, lr: 0.047209170872965694
[batch_idx--400] train_loss: 0.001543332659755543, acc: 0.8199131078553616, lr: 0.047182458899583
[batch_idx--450] train_loss: 0.00155007579608069, acc: 0.8192366438712813, lr: 0.04715562733102973
total time of one epoch: 312.3084125518799 s
train_loss:  0.00155007579608069  acc:  0.8192366438712813
->>lr:0.047156
test_loss:  0.0015854709444840058  test_acc:  0.8199528477478595
best acc:  82.70256855689291

------Epoch: 23------
[batch_idx--0] train_loss: 0.0015835505910217762, acc: 0.81640625, lr: 0.04715508948078037
[batch_idx--50] train_loss: 0.0015261384211115393, acc: 0.8214613970588235, lr: 0.047128136074186804
[batch_idx--100] train_loss: 0.0015257589880948758, acc: 0.8210860148514851, lr: 0.04710106336530035
[batch_idx--150] train_loss: 0.0015287376571730372, acc: 0.8199503311258278, lr: 0.04707387150008163
[batch_idx--200] train_loss: 0.0015196111470238485, acc: 0.8228000621890548, lr: 0.04704656062513368
[batch_idx--250] train_loss: 0.0015240637061419893, acc: 0.8220866533864541, lr: 0.04701913088770116
[batch_idx--300] train_loss: 0.0015284052138770637, acc: 0.8217400332225914, lr: 0.04699158243566958
[batch_idx--350] train_loss: 0.0015317001827777578, acc: 0.8213029736467237, lr: 0.04696391541756448
[batch_idx--400] train_loss: 0.0015300837469675074, acc: 0.8217249844139651, lr: 0.046936129982550645
[batch_idx--450] train_loss: 0.001531273786128695, acc: 0.8220831742284861, lr: 0.0469082262804313
total time of one epoch: 287.2948124408722 s
train_loss:  0.001531273786128695  acc:  0.8220831742284861
->>lr:0.046908
test_loss:  0.001552778314547143  test_acc:  0.8185879141332671
best acc:  82.70256855689291

------Epoch: 24------
[batch_idx--0] train_loss: 0.001611324492841959, acc: 0.82421875, lr: 0.04690766700109659
[batch_idx--50] train_loss: 0.0015218997871795413, acc: 0.8246783088235294, lr: 0.04687964282151817
[batch_idx--100] train_loss: 0.001520424129183192, acc: 0.824528155940594, lr: 0.046851500679380806
[batch_idx--150] train_loss: 0.0015313040499038847, acc: 0.8226148592715232, lr: 0.046823240726410885
[batch_idx--200] train_loss: 0.0015363572559212867, acc: 0.8219449626865671, lr: 0.046794863114969956
[batch_idx--250] train_loss: 0.0015300124980123393, acc: 0.8223200946215139, lr: 0.04676636799805392
[batch_idx--300] train_loss: 0.0015290326143358138, acc: 0.8224797549833887, lr: 0.046737755529292206
[batch_idx--350] train_loss: 0.0015328407454758119, acc: 0.8220486111111112, lr: 0.046709025862946923
[batch_idx--400] train_loss: 0.0015336856797007737, acc: 0.8218613622194514, lr: 0.046680179153912066
[batch_idx--450] train_loss: 0.0015327178613481665, acc: 0.8225084180928247, lr: 0.04665121555771262
total time of one epoch: 290.7123646736145 s
train_loss:  0.0015327178613481665  acc:  0.8225084180928247
->>lr:0.046651
test_loss:  0.0016103595706010991  test_acc:  0.8148653679116515
best acc:  82.70256855689291

------Epoch: 25------
[batch_idx--0] train_loss: 0.001522942679002881, acc: 0.8125, lr: 0.046650635094610975
[batch_idx--50] train_loss: 0.0015276918192302772, acc: 0.8229166666666666, lr: 0.04662155243437907
[batch_idx--100] train_loss: 0.001517483155418298, acc: 0.8241413985148515, lr: 0.04659235320306443
[batch_idx--150] train_loss: 0.0015156491326525905, acc: 0.8238565811258278, lr: 0.046563037558092685
[batch_idx--200] train_loss: 0.0015091405491071258, acc: 0.8251904539800995, lr: 0.04653360565751704
[batch_idx--250] train_loss: 0.0015125901403974192, acc: 0.8249968874501992, lr: 0.04650405766001754
[batch_idx--300] train_loss: 0.0015116775167821302, acc: 0.8252829111295681, lr: 0.04647439372490014
[batch_idx--350] train_loss: 0.001514673919915792, acc: 0.8250422898860399, lr: 0.046444614012095875
[batch_idx--400] train_loss: 0.0015140313976223666, acc: 0.8250272755610972, lr: 0.046414718682159954
[batch_idx--450] train_loss: 0.0015177505747320237, acc: 0.8248082063387371, lr: 0.04638470789627097
total time of one epoch: 289.44707798957825 s
train_loss:  0.0015177505747320237  acc:  0.8248082063387371
->>lr:0.046385
test_loss:  0.0015117949699257958  test_acc:  0.8317409107829755
best acc:  82.70256855689291
Saving..

------Epoch: 26------
[batch_idx--0] train_loss: 0.0014206644846126437, acc: 0.8515625, lr: 0.04638410650401267
[batch_idx--50] train_loss: 0.0015109489105787932, acc: 0.823452818627451, lr: 0.04635397811974326
[batch_idx--100] train_loss: 0.0015149077303744484, acc: 0.8240640470297029, lr: 0.04632373460699926
[batch_idx--150] train_loss: 0.001498632850002078, acc: 0.8261848096026491, lr: 0.04629337612883644
[batch_idx--200] train_loss: 0.0014919749535249537, acc: 0.8276197139303483, lr: 0.046262902848930414
[batch_idx--250] train_loss: 0.0014949700270085577, acc: 0.8274869272908366, lr: 0.04623231493157573
[batch_idx--300] train_loss: 0.0014981279483040257, acc: 0.8267234219269103, lr: 0.046201612541685
[batch_idx--350] train_loss: 0.0014991272012689855, acc: 0.8268117877492878, lr: 0.046170795844788
[batch_idx--400] train_loss: 0.0015030299099115772, acc: 0.8256701995012469, lr: 0.04613986500703078
[batch_idx--450] train_loss: 0.0015065028529482175, acc: 0.8254330544659284, lr: 0.0461088201951748
total time of one epoch: 286.96165561676025 s
train_loss:  0.0015065028529482175  acc:  0.8254330544659284
->>lr:0.046109
test_loss:  0.0014682764864423492  test_acc:  0.8358357116267527
best acc:  83.17409107829755
Saving..

------Epoch: 27------
[batch_idx--0] train_loss: 0.001634614309296012, acc: 0.8125, lr: 0.04610819813755038
[batch_idx--50] train_loss: 0.0015304064031179045, acc: 0.8212316176470589, lr: 0.04607703724454855
[batch_idx--100] train_loss: 0.0015165873279905703, acc: 0.8238706683168316, lr: 0.046045762716179425
[batch_idx--150] train_loss: 0.0014994885157238668, acc: 0.8257191639072847, lr: 0.04601437472105743
[batch_idx--200] train_loss: 0.001495792219457008, acc: 0.8265702736318408, lr: 0.04598287342840873
[batch_idx--250] train_loss: 0.0014955053728378093, acc: 0.8266309760956175, lr: 0.04595125900807036
[batch_idx--300] train_loss: 0.0014996716703916358, acc: 0.8259317898671097, lr: 0.045919531630489216
[batch_idx--350] train_loss: 0.0014982112508235325, acc: 0.8260995370370371, lr: 0.045887691466721246
[batch_idx--400] train_loss: 0.0015012673770038044, acc: 0.8254169264339152, lr: 0.04585573868843045
[batch_idx--450] train_loss: 0.0015007999118519793, acc: 0.8259364043461659, lr: 0.04582367346788801
total time of one epoch: 290.76690006256104 s
train_loss:  0.0015007999118519793  acc:  0.8259364043461659
->>lr:0.045824
test_loss:  0.001469683792857648  test_acc:  0.8363320511229682
best acc:  83.58357116267527
Saving..

------Epoch: 28------
[batch_idx--0] train_loss: 0.0015959723386913538, acc: 0.81640625, lr: 0.04582303101775249
[batch_idx--50] train_loss: 0.0015309890618036483, acc: 0.8257506127450981, lr: 0.04579085128421578
[batch_idx--100] train_loss: 0.0015188442637664404, acc: 0.8255337252475248, lr: 0.04575855945826332
[batch_idx--150] train_loss: 0.0015025226975982355, acc: 0.8262882864238411, lr: 0.04572615571399419
[batch_idx--200] train_loss: 0.001499885201468063, acc: 0.8269589552238806, lr: 0.045693640226110915
[batch_idx--250] train_loss: 0.0014929739193456522, acc: 0.8284051294820717, lr: 0.045661013169918455
[batch_idx--300] train_loss: 0.0014932368757463125, acc: 0.8284753945182725, lr: 0.04562827472132332
[batch_idx--350] train_loss: 0.0014899287192400364, acc: 0.8287927350427351, lr: 0.045595425056832534
[batch_idx--400] train_loss: 0.0014911478500293006, acc: 0.8288166302992519, lr: 0.04556246435355277
[batch_idx--450] train_loss: 0.0014936043753339089, acc: 0.8286961502412608, lr: 0.04552939278918935
total time of one epoch: 289.7853307723999 s
train_loss:  0.0014936043753339089  acc:  0.8286961502412608
->>lr:0.045529
test_loss:  0.0014653431931386915  test_acc:  0.8363320511229682
best acc:  83.6332051122968

------Epoch: 29------
[batch_idx--0] train_loss: 0.0015621160855516791, acc: 0.83203125, lr: 0.045528730228342605
[batch_idx--50] train_loss: 0.0014762401001016591, acc: 0.8302696078431373, lr: 0.04549554576936571
[batch_idx--100] train_loss: 0.001488474749794027, acc: 0.8275835396039604, lr: 0.04546225081009201
[batch_idx--150] train_loss: 0.0014804693645125392, acc: 0.8287458609271523, lr: 0.04542884553002893
[batch_idx--200] train_loss: 0.0014803889143832065, acc: 0.8285719838308457, lr: 0.04539533010927871
[batch_idx--250] train_loss: 0.0014770357063470549, acc: 0.8292922061752988, lr: 0.04536170472853737
[batch_idx--300] train_loss: 0.001475798847939683, acc: 0.8294227574750831, lr: 0.045327969569093796
[batch_idx--350] train_loss: 0.0014774413106756078, acc: 0.8295940170940171, lr: 0.04529412481282874
[batch_idx--400] train_loss: 0.0014765438141226953, acc: 0.829751792394015, lr: 0.04526017064221382
[batch_idx--450] train_loss: 0.0014785689001413271, acc: 0.8300586662963862, lr: 0.04522610724031057
total time of one epoch: 285.84437465667725 s
train_loss:  0.0014785689001413271  acc:  0.8300586662963862
->>lr:0.045226
test_loss:  0.0014496016094119248  test_acc:  0.838937833478099
best acc:  83.6332051122968
Saving..

------Epoch: 30------
[batch_idx--0] train_loss: 0.0014611856313422322, acc: 0.83984375, lr: 0.04522542485937369
[batch_idx--50] train_loss: 0.001458089851189916, acc: 0.8337162990196079, lr: 0.04519125023075707
[batch_idx--100] train_loss: 0.0014586180257196032, acc: 0.8335782797029703, lr: 0.045156966742431685
[batch_idx--150] train_loss: 0.001458129355227513, acc: 0.8334540562913907, lr: 0.04512257457923455
[batch_idx--200] train_loss: 0.0014625060139223933, acc: 0.8323227611940298, lr: 0.04508807392658861
[batch_idx--250] train_loss: 0.0014648364130518884, acc: 0.8312375498007968, lr: 0.0450534649705017
[batch_idx--300] train_loss: 0.0014631252316603333, acc: 0.8313045058139535, lr: 0.04501874789756559
[batch_idx--350] train_loss: 0.0014654354015206043, acc: 0.8310964209401709, lr: 0.04498392289495493
[batch_idx--400] train_loss: 0.0014679507965551797, acc: 0.8305700592269327, lr: 0.04494899015042629
[batch_idx--450] train_loss: 0.0014689158997801544, acc: 0.8307702988856875, lr: 0.04491394985231711
total time of one epoch: 286.4359631538391 s
train_loss:  0.0014689158997801544  acc:  0.8307702988856875
->>lr:0.044914
test_loss:  0.0016941774355919963  test_acc:  0.8050626628613972
best acc:  83.8937833478099

------Epoch: 31------
[batch_idx--0] train_loss: 0.0014567238977178931, acc: 0.85546875, lr: 0.04491324795060491
[batch_idx--50] train_loss: 0.0014535134849960312, acc: 0.8358609068627451, lr: 0.04487809814247016
[batch_idx--100] train_loss: 0.001470221832422263, acc: 0.8315284653465347, lr: 0.044842841162964144
[batch_idx--150] train_loss: 0.0014715200276206562, acc: 0.8313586506622517, lr: 0.04480747720217241
[batch_idx--200] train_loss: 0.001474372813227906, acc: 0.8304570895522388, lr: 0.04477200645075726
[batch_idx--250] train_loss: 0.0014681370119078167, acc: 0.8306306025896414, lr: 0.04473642909995676
[batch_idx--300] train_loss: 0.0014608078899227108, acc: 0.8316938330564784, lr: 0.044700745341583706
[batch_idx--350] train_loss: 0.0014581015529880497, acc: 0.8319978632478633, lr: 0.044664955368024575
[batch_idx--400] train_loss: 0.0014620224786736536, acc: 0.8313493609725686, lr: 0.044629059372238496
[batch_idx--450] train_loss: 0.0014701656608988411, acc: 0.8308917971326414, lr: 0.044593057547756214
total time of one epoch: 290.86083722114563 s
train_loss:  0.0014701656608988411  acc:  0.8308917971326414
->>lr:0.044593
test_loss:  0.0015074337315716183  test_acc:  0.8322372502791909
best acc:  83.8937833478099

------Epoch: 32------
[batch_idx--0] train_loss: 0.0017810644349083304, acc: 0.76953125, lr: 0.044592336433146
[batch_idx--50] train_loss: 0.0014576094850496041, acc: 0.8296568627450981, lr: 0.04455622686336067
[batch_idx--100] train_loss: 0.0014610174331021043, acc: 0.8307936262376238, lr: 0.0445200118575505
[batch_idx--150] train_loss: 0.001451746345534674, acc: 0.8316949503311258, lr: 0.04448369161096615
[batch_idx--200] train_loss: 0.0014567507960282229, acc: 0.8307291666666666, lr: 0.044447266319425686
[batch_idx--250] train_loss: 0.0014531641170768387, acc: 0.8316421812749004, lr: 0.044410736179313494
[batch_idx--300] train_loss: 0.0014502920745639903, acc: 0.8328228820598007, lr: 0.04437410138757928
[batch_idx--350] train_loss: 0.0014528697990066773, acc: 0.8326655982905983, lr: 0.04433736214173695
[batch_idx--400] train_loss: 0.0014557537374242286, acc: 0.8322747817955112, lr: 0.04430051863986356
[batch_idx--450] train_loss: 0.0014576614756550564, acc: 0.8325493803589405, lr: 0.04426357108059828
total time of one epoch: 291.1387882232666 s
train_loss:  0.0014576614756550564  acc:  0.8325493803589405
->>lr:0.044264
test_loss:  0.0015268614546864216  test_acc:  0.8266534309467676
best acc:  83.8937833478099

------Epoch: 33------
[batch_idx--0] train_loss: 0.001418428961187601, acc: 0.8359375, lr: 0.044262831069394735
[batch_idx--50] train_loss: 0.0014619782393542574, acc: 0.8319546568627451, lr: 0.04422577757680957
[batch_idx--100] train_loss: 0.0014479130605641421, acc: 0.8341197400990099, lr: 0.04418862042979371
[batch_idx--150] train_loss: 0.001436881185971842, acc: 0.8348768625827815, lr: 0.044151359828677295
[batch_idx--200] train_loss: 0.0014324398330222833, acc: 0.8355488184079602, lr: 0.04411399597434825
[batch_idx--250] train_loss: 0.0014336401257159343, acc: 0.834972609561753, lr: 0.04407652906825116
[batch_idx--300] train_loss: 0.001435485142097496, acc: 0.8350031146179402, lr: 0.04403895931238623
[batch_idx--350] train_loss: 0.001438336590493358, acc: 0.8348579950142451, lr: 0.044001286909308164
[batch_idx--400] train_loss: 0.0014382810956052971, acc: 0.8349633728179551, lr: 0.04396351206212508
[batch_idx--450] train_loss: 0.0014437298590548398, acc: 0.8347276703578991, lr: 0.043925634974497405
total time of one epoch: 287.7044687271118 s
train_loss:  0.0014437298590548398  acc:  0.8347276703578991
->>lr:0.043926
test_loss:  0.0014823550421512073  test_acc:  0.833105844397568
best acc:  83.8937833478099

------Epoch: 34------
[batch_idx--0] train_loss: 0.0014643874019384384, acc: 0.83203125, lr: 0.043924876391293916
[batch_idx--50] train_loss: 0.0014338154852499858, acc: 0.8371629901960784, lr: 0.0438868952287954
[batch_idx--100] train_loss: 0.0014383568218678678, acc: 0.8353960396039604, lr: 0.04384881223892658
[batch_idx--150] train_loss: 0.0014401154780748072, acc: 0.8342560016556292, lr: 0.04381062762700922
[batch_idx--200] train_loss: 0.0014438890146591993, acc: 0.8342078669154229, lr: 0.043772341598912995
[batch_idx--250] train_loss: 0.0014384627426636824, acc: 0.835003735059761, lr: 0.04373395436105431
[batch_idx--300] train_loss: 0.0014383271518333559, acc: 0.8355222176079734, lr: 0.04369546612039528
[batch_idx--350] train_loss: 0.001440881726270982, acc: 0.8354700854700855, lr: 0.04365687708444255
[batch_idx--400] train_loss: 0.0014442848660019309, acc: 0.8344860504987531, lr: 0.04361818746124621
[batch_idx--450] train_loss: 0.0014441640931274558, acc: 0.8347710625889541, lr: 0.04357939745939863
total time of one epoch: 288.35526037216187 s
train_loss:  0.0014441640931274558  acc:  0.8347710625889541
->>lr:0.043579
test_loss:  0.0014584530618738367  test_acc:  0.8314927410348678
best acc:  83.8937833478099

------Epoch: 35------
[batch_idx--0] train_loss: 0.0014055416686460376, acc: 0.8515625, lr: 0.04357862063693486
[batch_idx--50] train_loss: 0.0014493331911188422, acc: 0.8310355392156863, lr: 0.04353972846431615
[batch_idx--100] train_loss: 0.0014451163968458624, acc: 0.8316058168316832, lr: 0.043500736336052385
[batch_idx--150] train_loss: 0.0014365061574819072, acc: 0.8330401490066225, lr: 0.04346164446236689
[batch_idx--200] train_loss: 0.001436893527039248, acc: 0.8335665422885572, lr: 0.04342245305402075
[batch_idx--250] train_loss: 0.0014384923705949904, acc: 0.8340388446215139, lr: 0.04338316232231171
[batch_idx--300] train_loss: 0.0014399313913237464, acc: 0.8342114825581395, lr: 0.043343772479072985
[batch_idx--350] train_loss: 0.001437889934421923, acc: 0.8344462250712251, lr: 0.043304283736672146
[batch_idx--400] train_loss: 0.0014347027022823542, acc: 0.8353237998753117, lr: 0.04326469630800999
[batch_idx--450] train_loss: 0.0014379190874413408, acc: 0.8358298330266949, lr: 0.04322501040651934
total time of one epoch: 286.4644296169281 s
train_loss:  0.0014379190874413408  acc:  0.8358298330266949
->>lr:0.043225
test_loss:  0.0017055523744631174  test_acc:  0.7981139099143815
best acc:  83.8937833478099

------Epoch: 36------
[batch_idx--0] train_loss: 0.0015231596771627665, acc: 0.8203125, lr: 0.04322421568553529
[batch_idx--50] train_loss: 0.001488424714325982, acc: 0.8277420343137255, lr: 0.04318442956218869
[batch_idx--100] train_loss: 0.001442942529741564, acc: 0.8341584158415841, lr: 0.04314454539876614
[batch_idx--150] train_loss: 0.0014506708129019236, acc: 0.8332988410596026, lr: 0.043104563410300306
[batch_idx--200] train_loss: 0.001452041374037589, acc: 0.8335471082089553, lr: 0.043064483812351256
[batch_idx--250] train_loss: 0.0014465663570955218, acc: 0.8344123505976095, lr: 0.04302430682100536
[batch_idx--300] train_loss: 0.0014378972540290847, acc: 0.8352886212624585, lr: 0.042984032652874024
[batch_idx--350] train_loss: 0.001436031516707712, acc: 0.8352697649572649, lr: 0.04294366152509261
[batch_idx--400] train_loss: 0.0014340686582799936, acc: 0.8357718983790524, lr: 0.04290319365531922
[batch_idx--450] train_loss: 0.0014369326351740617, acc: 0.8359773666122817, lr: 0.04286262926173353
total time of one epoch: 288.76271891593933 s
train_loss:  0.0014369326351740617  acc:  0.8359773666122817
->>lr:0.042863
test_loss:  0.0013986865585739906  test_acc:  0.8445216528105224
best acc:  83.8937833478099
Saving..

------Epoch: 37------
[batch_idx--0] train_loss: 0.001365793403238058, acc: 0.8515625, lr: 0.04286181699082009
[batch_idx--50] train_loss: 0.0014307081503063149, acc: 0.8334099264705882, lr: 0.04282115436825425
[batch_idx--100] train_loss: 0.0014283957148874455, acc: 0.8348159034653465, lr: 0.04278039566418517
[batch_idx--150] train_loss: 0.0014250467088850623, acc: 0.8363772764900662, lr: 0.04273954109836054
[batch_idx--200] train_loss: 0.0014210087316694545, acc: 0.8372590174129353, lr: 0.0426985908910449
[batch_idx--250] train_loss: 0.0014256121125999853, acc: 0.8372447709163346, lr: 0.042657545263018404
[batch_idx--300] train_loss: 0.0014312578762797918, acc: 0.8363917151162791, lr: 0.042616404435575676
[batch_idx--350] train_loss: 0.0014329488495990973, acc: 0.83634926994302, lr: 0.04257516863052461
[batch_idx--400] train_loss: 0.0014290386837607532, acc: 0.8366583541147132, lr: 0.04253383807018514
[batch_idx--450] train_loss: 0.0014321835186628217, acc: 0.8371836706356094, lr: 0.042492412977388094
total time of one epoch: 289.5991590023041 s
train_loss:  0.0014321835186628217  acc:  0.8371836706356094
->>lr:0.042492
test_loss:  0.0014325399518027792  test_acc:  0.8400545973445837
best acc:  84.45216528105225

------Epoch: 38------
[batch_idx--0] train_loss: 0.0012328678276389837, acc: 0.87109375, lr: 0.042491583512834136
[batch_idx--50] train_loss: 0.0014591767617008265, acc: 0.8310355392156863, lr: 0.04245006222701923
[batch_idx--100] train_loss: 0.0014393844798502357, acc: 0.8360535272277227, lr: 0.04240844686041831
[batch_idx--150] train_loss: 0.0014536743690660655, acc: 0.8329625413907285, lr: 0.042366737637397726
[batch_idx--200] train_loss: 0.0014440788973159903, acc: 0.8341495646766169, lr: 0.04232493478282982
[batch_idx--250] train_loss: 0.0014411171956685376, acc: 0.8343345368525896, lr: 0.042283038522091754
[batch_idx--300] train_loss: 0.0014347939533908601, acc: 0.8350290697674418, lr: 0.04224104908106427
[batch_idx--350] train_loss: 0.0014311708430321808, acc: 0.8357260505698005, lr: 0.0421989666861305
[batch_idx--400] train_loss: 0.0014287702384476835, acc: 0.8358790523690773, lr: 0.04215679156417471
[batch_idx--450] train_loss: 0.0014292224610584713, acc: 0.8361856493213455, lr: 0.04211452394258114
total time of one epoch: 290.0331041812897 s
train_loss:  0.0014292224610584713  acc:  0.8361856493213455
->>lr:0.042115
test_loss:  0.0013941939666410551  test_acc:  0.8419158704553915
best acc:  84.45216528105225

------Epoch: 39------
[batch_idx--0] train_loss: 0.001529290690086782, acc: 0.8125, lr: 0.04211367764821722
[batch_idx--50] train_loss: 0.0014201847895724223, acc: 0.8377757352941176, lr: 0.04207131591176148
[batch_idx--100] train_loss: 0.0014017478811858904, acc: 0.8402691831683168, lr: 0.042028862136503926
[batch_idx--150] train_loss: 0.0014057860483063867, acc: 0.8392487582781457, lr: 0.0419863165513311
[batch_idx--200] train_loss: 0.0014079252735188055, acc: 0.8391829912935324, lr: 0.041943679385624544
[batch_idx--250] train_loss: 0.0014067300622243864, acc: 0.8390033615537849, lr: 0.04190095086925955
[batch_idx--300] train_loss: 0.0014085866057583164, acc: 0.8390521179401993, lr: 0.041858131232603915
[batch_idx--350] train_loss: 0.001406529414509967, acc: 0.8392873041310541, lr: 0.04181522070651669
[batch_idx--400] train_loss: 0.0014120101481049027, acc: 0.8380708385286783, lr: 0.04177221952234698
[batch_idx--450] train_loss: 0.0014130341016928018, acc: 0.8383205470892492, lr: 0.041729127911932645
total time of one epoch: 293.8889582157135 s
train_loss:  0.0014130341016928018  acc:  0.8383205470892492
->>lr:0.041729
test_loss:  0.0013940438973961346  test_acc:  0.8439012284402532
best acc:  84.45216528105225

------Epoch: 40------
[batch_idx--0] train_loss: 0.0012149204267188907, acc: 0.8515625, lr: 0.04172826515897146
[batch_idx--50] train_loss: 0.001420936410260551, acc: 0.8345588235294118, lr: 0.04168508155313258
[batch_idx--100] train_loss: 0.0013908349971130196, acc: 0.8403465346534653, lr: 0.04164180799084732
[batch_idx--150] train_loss: 0.0013925044015605027, acc: 0.8406198261589404, lr: 0.04159844470542206
[batch_idx--200] train_loss: 0.0013970705768584612, acc: 0.8407377176616916, lr: 0.041554991930646906
[batch_idx--250] train_loss: 0.0014058985405108072, acc: 0.8397348107569721, lr: 0.041511449900794445
[batch_idx--300] train_loss: 0.0014033718518077388, acc: 0.8409598214285714, lr: 0.04146781885061848
[batch_idx--350] train_loss: 0.0014019351415442266, acc: 0.8411235754985755, lr: 0.04142409901535277
[batch_idx--400] train_loss: 0.001401264818229636, acc: 0.8407302057356608, lr: 0.04138029063070971
[batch_idx--450] train_loss: 0.00140495020001956, acc: 0.8405248724268407, lr: 0.041336393932879134
total time of one epoch: 293.3002841472626 s
train_loss:  0.00140495020001956  acc:  0.8405248724268407
->>lr:0.041336
test_loss:  0.0013271960457466809  test_acc:  0.8489887082764611
best acc:  84.45216528105225
Saving..

------Epoch: 41------
[batch_idx--0] train_loss: 0.001387351076118648, acc: 0.83984375, lr: 0.04133551509975264
[batch_idx--50] train_loss: 0.0013652130568801773, acc: 0.8454350490196079, lr: 0.041291528566287365
[batch_idx--100] train_loss: 0.0013911854925261129, acc: 0.8424737004950495, lr: 0.041247454198189024
[batch_idx--150] train_loss: 0.0013924216071378118, acc: 0.8428445778145696, lr: 0.04120329223308148
[batch_idx--200] train_loss: 0.0013949373199497882, acc: 0.841923196517413, lr: 0.041159042909060875
[batch_idx--250] train_loss: 0.001393363955319373, acc: 0.8413533366533864, lr: 0.04111470646469433
[batch_idx--300] train_loss: 0.0013949181548044383, acc: 0.8416606104651163, lr: 0.04107028313901867
[batch_idx--350] train_loss: 0.0013969345270334996, acc: 0.8409677706552706, lr: 0.04102577317153916
[batch_idx--400] train_loss: 0.0013980628836068542, acc: 0.8406133104738155, lr: 0.04098117680222813
[batch_idx--450] train_loss: 0.0014017410851792848, acc: 0.8408546533828584, lr: 0.04093649427152381
total time of one epoch: 290.60142993927 s
train_loss:  0.0014017410851792848  acc:  0.8408546533828584
->>lr:0.040936
test_loss:  0.001403290919385428  test_acc:  0.8412954460851222
best acc:  84.8988708276461

------Epoch: 42------
[batch_idx--0] train_loss: 0.0013923118822276592, acc: 0.83984375, lr: 0.040935599743717244
[batch_idx--50] train_loss: 0.001403018256978077, acc: 0.8407628676470589, lr: 0.04089082957657292
[batch_idx--100] train_loss: 0.0014003356492220617, acc: 0.8405785891089109, lr: 0.04084597373513602
[batch_idx--150] train_loss: 0.001395360686945797, acc: 0.8414217715231788, lr: 0.04080103246124366
[batch_idx--200] train_loss: 0.0013969334859438055, acc: 0.8408737562189055, lr: 0.04075600599719357
[batch_idx--250] train_loss: 0.0013965899477234162, acc: 0.8411198954183267, lr: 0.04071089458574278
[batch_idx--300] train_loss: 0.0013938434329193296, acc: 0.8418422965116279, lr: 0.04066569847010627
[batch_idx--350] train_loss: 0.0013908376364021474, acc: 0.84200275997151, lr: 0.040620417893955756
[batch_idx--400] train_loss: 0.0013919005093822009, acc: 0.8415484725685786, lr: 0.04057505310141827
[batch_idx--450] train_loss: 0.0013945453378713653, acc: 0.8415489290797376, lr: 0.04052960433707492
total time of one epoch: 285.5209963321686 s
train_loss:  0.0013945453378713653  acc:  0.8415489290797376
->>lr:0.040530
test_loss:  0.0013341369027164856  test_acc:  0.8544484427348307
best acc:  84.8988708276461
Saving..

------Epoch: 43------
[batch_idx--0] train_loss: 0.0016148732975125313, acc: 0.7890625, lr: 0.040528694506957764
[batch_idx--50] train_loss: 0.0013765345131247944, acc: 0.8439031862745098, lr: 0.04048316034380937
[batch_idx--100] train_loss: 0.0013731820220680962, acc: 0.8441754331683168, lr: 0.040437542704288454
[batch_idx--150] train_loss: 0.0013827605840645188, acc: 0.8432326158940397, lr: 0.04039184183433934
[batch_idx--200] train_loss: 0.0013837908233622488, acc: 0.8428365982587065, lr: 0.04034605798035504
[batch_idx--250] train_loss: 0.001387339652575315, acc: 0.8426450448207171, lr: 0.04030019138917598
[batch_idx--300] train_loss: 0.0013856507963083214, acc: 0.8428805024916943, lr: 0.040254242308088696
[batch_idx--350] train_loss: 0.0013846417479721187, acc: 0.8428708155270656, lr: 0.040208210984824425
[batch_idx--400] train_loss: 0.0013857366809821188, acc: 0.8425615648379052, lr: 0.04016209766755781
[batch_idx--450] train_loss: 0.001390145043385837, acc: 0.8426858055333774, lr: 0.040115902604905565
total time of one epoch: 288.60779190063477 s
train_loss:  0.001390145043385837  acc:  0.8426858055333774
->>lr:0.040116
test_loss:  0.001353532878351738  test_acc:  0.846631095669438
best acc:  85.44484427348306

------Epoch: 44------
[batch_idx--0] train_loss: 0.001513098948635161, acc: 0.81640625, lr: 0.040114977871559376
[batch_idx--50] train_loss: 0.0014084911056082038, acc: 0.8399969362745098, lr: 0.04006869968519579
[batch_idx--100] train_loss: 0.0013925859965107376, acc: 0.8430538366336634, lr: 0.04002234025699524
[batch_idx--150] train_loss: 0.0013836075355983433, acc: 0.8441639072847682, lr: 0.039975899836901335
[batch_idx--200] train_loss: 0.0013807182604521143, acc: 0.8442358519900498, lr: 0.03992937867529435
[batch_idx--250] train_loss: 0.0013796265507896109, acc: 0.8435632470119522, lr: 0.03988277702298985
[batch_idx--300] train_loss: 0.0013813829796691967, acc: 0.8432308970099668, lr: 0.03983609513123738
[batch_idx--350] train_loss: 0.0013808031577054421, acc: 0.8430822649572649, lr: 0.03978933325171908
[batch_idx--400] train_loss: 0.001376456157199834, acc: 0.8435649158354115, lr: 0.03974249163654834
[batch_idx--450] train_loss: 0.0013827702341098914, acc: 0.8433540458916235, lr: 0.03969557053826845
total time of one epoch: 289.01968264579773 s
train_loss:  0.0013827702341098914  acc:  0.8433540458916235
->>lr:0.039696
test_loss:  0.0014967933927669257  test_acc:  0.8321131654051371
best acc:  85.44484427348306

------Epoch: 45------
[batch_idx--0] train_loss: 0.001385507988743484, acc: 0.859375, lr: 0.03969463130731183
[batch_idx--50] train_loss: 0.0013943212631834195, acc: 0.8408394607843137, lr: 0.0396476293968751
[batch_idx--100] train_loss: 0.0013956399530744052, acc: 0.8416615099009901, lr: 0.03960054851477232
[batch_idx--150] train_loss: 0.0013861580226039946, acc: 0.8432326158940397, lr: 0.039553388914836764
[batch_idx--200] train_loss: 0.0013722324157736047, acc: 0.8446828358208955, lr: 0.039506150851326104
[batch_idx--250] train_loss: 0.001374970994930551, acc: 0.8441857569721115, lr: 0.039458834578921055
[batch_idx--300] train_loss: 0.0013758858829810967, acc: 0.8437629775747508, lr: 0.03941144035272397
[batch_idx--350] train_loss: 0.0013783283447422235, acc: 0.8435830662393162, lr: 0.03936396842825749
[batch_idx--400] train_loss: 0.0013777212613724414, acc: 0.843662328553616, lr: 0.03931641906146319
[batch_idx--450] train_loss: 0.0013793959298600475, acc: 0.8437358975249072, lr: 0.03926879250870011
total time of one epoch: 287.0235970020294 s
train_loss:  0.0013793959298600475  acc:  0.8437358975249072
->>lr:0.039269
test_loss:  0.0012970322569482511  test_acc:  0.8585432435786078
best acc:  85.44484427348306
Saving..

------Epoch: 46------
[batch_idx--0] train_loss: 0.0014453220646828413, acc: 0.8515625, lr: 0.0392678391921108
[batch_idx--50] train_loss: 0.001417483388008002, acc: 0.8362438725490197, lr: 0.03922013417419226
[batch_idx--100] train_loss: 0.0013978342251335777, acc: 0.8400371287128713, lr: 0.03917235248941817
[batch_idx--150] train_loss: 0.001381524251804792, acc: 0.8432843543046358, lr: 0.03912449439540013
[batch_idx--200] train_loss: 0.001377292196335855, acc: 0.8443330223880597, lr: 0.0390765601501617
[batch_idx--250] train_loss: 0.0013758589358688648, acc: 0.8442946962151394, lr: 0.03902855001213699
[batch_idx--300] train_loss: 0.0013775399126471377, acc: 0.84375, lr: 0.0389804642401693
[batch_idx--350] train_loss: 0.001374951036092414, acc: 0.8439837072649573, lr: 0.03893230309350968
[batch_idx--400] train_loss: 0.0013740366403747377, acc: 0.8441591334164589, lr: 0.03888406683181559
[batch_idx--450] train_loss: 0.0013807331294532071, acc: 0.843831360433228, lr: 0.03883575571514944
total time of one epoch: 290.65722250938416 s
train_loss:  0.0013807331294532071  acc:  0.843831360433228
->>lr:0.038836
test_loss:  0.0013732054065217273  test_acc:  0.8494850477726765
best acc:  85.85432435786078

------Epoch: 47------
[batch_idx--0] train_loss: 0.00142805150244385, acc: 0.8359375, lr: 0.038834788731083605
[batch_idx--50] train_loss: 0.0013663069089399832, acc: 0.8454350490196079, lr: 0.038786401530680796
[batch_idx--100] train_loss: 0.0013818690544086518, acc: 0.8436339727722773, lr: 0.03873794000186154
[batch_idx--150] train_loss: 0.0013808480676707644, acc: 0.8441639072847682, lr: 0.03868940440590278
[batch_idx--200] train_loss: 0.0013795663777562738, acc: 0.8441969838308457, lr: 0.03864079500448077
[batch_idx--250] train_loss: 0.0013723054472208616, acc: 0.8453218376494024, lr: 0.03859211205966969
[batch_idx--300] train_loss: 0.0013774362461567173, acc: 0.8441003945182725, lr: 0.038543355833940224
[batch_idx--350] train_loss: 0.001369970770051273, acc: 0.8453414351851852, lr: 0.03849452659015813
[batch_idx--400] train_loss: 0.0013674042272402388, acc: 0.8458054083541147, lr: 0.03844562459158286
[batch_idx--450] train_loss: 0.0013693443773629313, acc: 0.8458187246155449, lr: 0.0383966501018661
total time of one epoch: 293.450345993042 s
train_loss:  0.0013693443773629313  acc:  0.8458187246155449
->>lr:0.038397
test_loss:  0.0013154901860887144  test_acc:  0.8560615460975307
best acc:  85.85432435786078

------Epoch: 48------
[batch_idx--0] train_loss: 0.00125261174980551, acc: 0.87890625, lr: 0.03839566987447492
[batch_idx--50] train_loss: 0.00133703996692145, acc: 0.8478860294117647, lr: 0.038346621715813135
[batch_idx--100] train_loss: 0.0013448477418410896, acc: 0.8475788985148515, lr: 0.038297501599776934
[batch_idx--150] train_loss: 0.0013450373701183805, acc: 0.8483288493377483, lr: 0.03824830979119395
[batch_idx--200] train_loss: 0.0013452023105575374, acc: 0.8482004042288557, lr: 0.038199046555278386
[batch_idx--250] train_loss: 0.0013469098747125362, acc: 0.8482943227091634, lr: 0.038149712157629516
[batch_idx--300] train_loss: 0.0013504143436114456, acc: 0.8474096760797342, lr: 0.038100306864230285
[batch_idx--350] train_loss: 0.0013530152071097553, acc: 0.8471443198005698, lr: 0.038050830941445866
[batch_idx--400] train_loss: 0.0013555429464768144, acc: 0.8470425498753117, lr: 0.03800128465602222
[batch_idx--450] train_loss: 0.001360673449495655, acc: 0.846504321866213, lr: 0.03795166827508467
total time of one epoch: 290.7081196308136 s
train_loss:  0.001360673449495655  acc:  0.846504321866213
->>lr:0.037952
test_loss:  0.0012970593227377481  test_acc:  0.857550564586177
best acc:  85.85432435786078

------Epoch: 49------
[batch_idx--0] train_loss: 0.0015450502978637815, acc: 0.8359375, lr: 0.03795067523432826
[batch_idx--50] train_loss: 0.0013519362706289279, acc: 0.8475030637254902, lr: 0.037900987631550954
[batch_idx--100] train_loss: 0.001361188857982138, acc: 0.8457611386138614, lr: 0.03785123047400412
[batch_idx--150] train_loss: 0.001360473080402524, acc: 0.8463369205298014, lr: 0.03780140402994997
[batch_idx--200] train_loss: 0.0013572330272696282, acc: 0.8469760572139303, lr: 0.03775150856802428
[batch_idx--250] train_loss: 0.001352473888898721, acc: 0.84765625, lr: 0.03770154435723495
[batch_idx--300] train_loss: 0.001352961669812146, acc: 0.8472928779069767, lr: 0.037651511666960506
[batch_idx--350] train_loss: 0.001351086836722162, acc: 0.8475449608262108, lr: 0.03760141076694869
[batch_idx--400] train_loss: 0.0013519674208609764, acc: 0.8471399625935162, lr: 0.037551241927314974
[batch_idx--450] train_loss: 0.0013569233685004599, acc: 0.8470770993161384, lr: 0.03750100541854115
total time of one epoch: 289.8786389827728 s
train_loss:  0.0013569233685004599  acc:  0.8470770993161384
->>lr:0.037501
test_loss:  0.0014345821301507246  test_acc:  0.8410472763370145
best acc:  85.85432435786078

------Epoch: 50------
[batch_idx--0] train_loss: 0.001195393386296928, acc: 0.86328125, lr: 0.037500000000000006
[batch_idx--50] train_loss: 0.0013358149992521195, acc: 0.8463541666666666, lr: 0.037449694747731944
[batch_idx--100] train_loss: 0.0013407447794913361, acc: 0.84765625, lr: 0.03739932237380827
[batch_idx--150] train_loss: 0.0013383117262335705, acc: 0.8481736341059603, lr: 0.03734888314980809
[batch_idx--200] train_loss: 0.0013451167545628858, acc: 0.8481615360696517, lr: 0.037298377347670955
[batch_idx--250] train_loss: 0.0013460983365469897, acc: 0.8478430029880478, lr: 0.03724780523969534
[batch_idx--300] train_loss: 0.001345654837384919, acc: 0.8475654069767442, lr: 0.03719716709853723
[batch_idx--350] train_loss: 0.001348808634312468, acc: 0.8468660968660968, lr: 0.037146463197208594
[batch_idx--400] train_loss: 0.001351197842134632, acc: 0.8466723815461347, lr: 0.03709569380907597
[batch_idx--450] train_loss: 0.0013551146821903371, acc: 0.8466344985593779, lr: 0.03704485920785895
total time of one epoch: 291.3122582435608 s
train_loss:  0.0013551146821903371  acc:  0.8466344985593779
->>lr:0.037045
test_loss:  0.0012771381324804042  test_acc:  0.8599081771932001
best acc:  85.85432435786078
Saving..

------Epoch: 51------
[batch_idx--0] train_loss: 0.0013205769937485456, acc: 0.8515625, lr: 0.037043841852542884
[batch_idx--50] train_loss: 0.0013377819137246, acc: 0.8493412990196079, lr: 0.03699294101633032
[batch_idx--100] train_loss: 0.0013418142749503771, acc: 0.8485457920792079, lr: 0.036941975521017835
[batch_idx--150] train_loss: 0.0013497214119061087, acc: 0.8478114652317881, lr: 0.0368909456413823
[batch_idx--200] train_loss: 0.0013484961259994303, acc: 0.8468983208955224, lr: 0.03683985165254776
[batch_idx--250] train_loss: 0.0013449185328888317, acc: 0.8474539342629482, lr: 0.03678869382998386
[batch_idx--300] train_loss: 0.001346332231649442, acc: 0.8474356312292359, lr: 0.03673747244950439
[batch_idx--350] train_loss: 0.0013446826336870868, acc: 0.8477341524216524, lr: 0.03668618778726586
[batch_idx--400] train_loss: 0.0013475661327716363, acc: 0.8474322007481296, lr: 0.0366348401197659
[batch_idx--450] train_loss: 0.0013523987660680893, acc: 0.8472419897941472, lr: 0.036583429723841876
total time of one epoch: 289.121609210968 s
train_loss:  0.0013523987660680893  acc:  0.8472419897941472
->>lr:0.036583
test_loss:  0.0013150884260801719  test_acc:  0.8560615460975307
best acc:  85.99081771932002

------Epoch: 52------
[batch_idx--0] train_loss: 0.001357459113933146, acc: 0.8359375, lr: 0.036582400877996545
[batch_idx--50] train_loss: 0.001339403960360762, acc: 0.8521752450980392, lr: 0.03653092678462853
[batch_idx--100] train_loss: 0.001343716046597698, acc: 0.8491646039603961, lr: 0.036479390523077894
[batch_idx--150] train_loss: 0.0013448561268815439, acc: 0.8495447019867549, lr: 0.036427792371198774
[batch_idx--200] train_loss: 0.0013510303488418237, acc: 0.8483364427860697, lr: 0.036376132607179
[batch_idx--250] train_loss: 0.0013498999544816366, acc: 0.8483721364541833, lr: 0.03632441150953856
[batch_idx--300] train_loss: 0.0013480633095005819, acc: 0.8479547342192691, lr: 0.036272629357128106
[batch_idx--350] train_loss: 0.0013440631245769709, acc: 0.8481681801994302, lr: 0.0362207864291275
[batch_idx--400] train_loss: 0.0013419197418812912, acc: 0.848328397755611, lr: 0.03616888300504424
[batch_idx--450] train_loss: 0.0013442671771356886, acc: 0.8485784705106397, lr: 0.03611691936471199
total time of one epoch: 286.804306268692 s
train_loss:  0.0013442671771356886  acc:  0.8485784705106397
->>lr:0.036117
test_loss:  0.0013197367711108026  test_acc:  0.8570542250899615
best acc:  85.99081771932002

------Epoch: 53------
[batch_idx--0] train_loss: 0.0015635817544534802, acc: 0.83984375, lr: 0.036115879479623185
[batch_idx--50] train_loss: 0.0013606439814811537, acc: 0.8459712009803921, lr: 0.0360638547073383
[batch_idx--100] train_loss: 0.0013431418262938462, acc: 0.8486618193069307, lr: 0.036011770285057136
[batch_idx--150] train_loss: 0.0013380700044660822, acc: 0.8481736341059603, lr: 0.03595962649358918
[batch_idx--200] train_loss: 0.0013367670367527475, acc: 0.8486862562189055, lr: 0.03590742361406404
[batch_idx--250] train_loss: 0.0013430972685165466, acc: 0.8476406872509961, lr: 0.03585516192792988
[batch_idx--300] train_loss: 0.0013453960641089246, acc: 0.8473058554817275, lr: 0.03580284171695191
[batch_idx--350] train_loss: 0.0013448892874667086, acc: 0.8474893162393162, lr: 0.03575046326321087
[batch_idx--400] train_loss: 0.0013418395730940872, acc: 0.8480946072319202, lr: 0.035698026849101526
[batch_idx--450] train_loss: 0.0013420828068018845, acc: 0.8488475023431805, lr: 0.03564553275733112
total time of one epoch: 290.9932351112366 s
train_loss:  0.0013420828068018845  acc:  0.8488475023431805
->>lr:0.035646
test_loss:  0.0012735672307112092  test_acc:  0.8553170368532076
best acc:  85.99081771932002

------Epoch: 54------
[batch_idx--0] train_loss: 0.001255446346476674, acc: 0.875, lr: 0.03564448228912682
[batch_idx--50] train_loss: 0.00134024708235052, acc: 0.8530177696078431, lr: 0.035591929657709624
[batch_idx--100] train_loss: 0.001323837079776285, acc: 0.8545405321782178, lr: 0.03553931992064693
[batch_idx--150] train_loss: 0.001318760715434266, acc: 0.8542011589403974, lr: 0.035486653361580446
[batch_idx--200] train_loss: 0.0013184035778976977, acc: 0.8536030783582089, lr: 0.03543393026445823
[batch_idx--250] train_loss: 0.0013212215141912708, acc: 0.8530720866533864, lr: 0.03538115091353316
[batch_idx--300] train_loss: 0.0013285684896295774, acc: 0.85125103820598, lr: 0.035328315593361394
[batch_idx--350] train_loss: 0.0013316823791465762, acc: 0.8505386396011396, lr: 0.03527542458880086
[batch_idx--400] train_loss: 0.001335187371387065, acc: 0.8498967425187033, lr: 0.035222478185009704
[batch_idx--450] train_loss: 0.0013410416127987198, acc: 0.8495504564862707, lr: 0.035169476667444736
total time of one epoch: 291.481068611145 s
train_loss:  0.0013410416127987198  acc:  0.8495504564862707
->>lr:0.035169
test_loss:  0.0012918269239298565  test_acc:  0.8579228192083385
best acc:  85.99081771932002

------Epoch: 55------
[batch_idx--0] train_loss: 0.0014645596966147423, acc: 0.80859375, lr: 0.035168416076895005
[batch_idx--50] train_loss: 0.0013481771696687622, acc: 0.8452052696078431, lr: 0.03511535863766653
[batch_idx--100] train_loss: 0.0013327233684664167, acc: 0.8481203589108911, lr: 0.03506224666219176
[batch_idx--150] train_loss: 0.0013294559664444516, acc: 0.8492342715231788, lr: 0.03500908043682018
[batch_idx--200] train_loss: 0.0013334990602996738, acc: 0.8492109763681592, lr: 0.034955860248193804
[batch_idx--250] train_loss: 0.0013287716472810838, acc: 0.8500529133466136, lr: 0.034902586383245504
[batch_idx--300] train_loss: 0.0013320704847048239, acc: 0.8493822674418605, lr: 0.03484925912919761
[batch_idx--350] train_loss: 0.0013305340791412992, acc: 0.8494368767806267, lr: 0.03479587877356025
[batch_idx--400] train_loss: 0.0013273344694536894, acc: 0.8499844139650873, lr: 0.034742445604129875
[batch_idx--450] train_loss: 0.0013325680360872032, acc: 0.8494549935779498, lr: 0.034688959908987675
total time of one epoch: 289.7594299316406 s
train_loss:  0.0013325680360872032  acc:  0.8494549935779498
->>lr:0.034689
test_loss:  0.001296901236191061  test_acc:  0.859163667948877
best acc:  85.99081771932002

------Epoch: 56------
[batch_idx--0] train_loss: 0.001324026845395565, acc: 0.84375, lr: 0.034687889661302575
[batch_idx--50] train_loss: 0.0013313348468977446, acc: 0.8465839460784313, lr: 0.034634350687009215
[batch_idx--100] train_loss: 0.0013530108280074182, acc: 0.8453743811881188, lr: 0.034580759769790186
[batch_idx--150] train_loss: 0.0013291464527970217, acc: 0.8500362168874173, lr: 0.034527117198577144
[batch_idx--200] train_loss: 0.0013365719295964015, acc: 0.8482198383084577, lr: 0.034473423262580266
[batch_idx--250] train_loss: 0.0013285949631441994, acc: 0.849586030876494, lr: 0.03441967825128663
[batch_idx--300] train_loss: 0.0013270198641750232, acc: 0.8498494601328903, lr: 0.0343658824544587
[batch_idx--350] train_loss: 0.0013238673147803804, acc: 0.8503160612535613, lr: 0.034312036162132735
[batch_idx--400] train_loss: 0.0013307908976954545, acc: 0.8490687344139651, lr: 0.034258139664617236
[batch_idx--450] train_loss: 0.001329639420333837, acc: 0.8498542021036554, lr: 0.0342041932524914
total time of one epoch: 292.9921898841858 s
train_loss:  0.001329639420333837  acc:  0.8498542021036554
->>lr:0.034204
test_loss:  0.0014157956062763734  test_acc:  0.8393100881002605
best acc:  85.99081771932002

------Epoch: 57------
[batch_idx--0] train_loss: 0.0014050394529476762, acc: 0.84765625, lr: 0.03420311381711696
[batch_idx--50] train_loss: 0.0013421096989665838, acc: 0.8498774509803921, lr: 0.03414911679172232
[batch_idx--100] train_loss: 0.001312399210435993, acc: 0.851871905940594, lr: 0.034095070439506506
[batch_idx--150] train_loss: 0.0013162153179368731, acc: 0.8525455298013245, lr: 0.03404097505185664
[batch_idx--200] train_loss: 0.0013236274736567368, acc: 0.8510183457711443, lr: 0.0339868309204242
[batch_idx--250] train_loss: 0.0013258727304489013, acc: 0.8504731075697212, lr: 0.03393263833712346
[batch_idx--300] train_loss: 0.0013222090085423814, acc: 0.8513678363787376, lr: 0.03387839759412996
[batch_idx--350] train_loss: 0.0013251324284402522, acc: 0.8507946047008547, lr: 0.03382410898387883
[batch_idx--400] train_loss: 0.0013232500611123933, acc: 0.8509000935162094, lr: 0.033769772799063326
[batch_idx--450] train_loss: 0.0013250537747129594, acc: 0.8508088311868643, lr: 0.03371538933263315
total time of one epoch: 287.08176469802856 s
train_loss:  0.0013250537747129594  acc:  0.8508088311868643
->>lr:0.033715
test_loss:  0.0013318763971180815  test_acc:  0.8489887082764611
best acc:  85.99081771932002

------Epoch: 58------
[batch_idx--0] train_loss: 0.0013037380995228887, acc: 0.83984375, lr: 0.03371430118304538
[batch_idx--50] train_loss: 0.0013256268324695673, acc: 0.8530177696078431, lr: 0.03365986979142943
[batch_idx--100] train_loss: 0.001323950286761, acc: 0.8516398514851485, lr: 0.03360539171073317
[batch_idx--150] train_loss: 0.0013140640568469239, acc: 0.8527266142384106, lr: 0.03355086723467137
[batch_idx--200] train_loss: 0.00131515875361415, acc: 0.8524370335820896, lr: 0.03349629665720888
[batch_idx--250] train_loss: 0.0013125834135947177, acc: 0.852511827689243, lr: 0.03344168027255918
[batch_idx--300] train_loss: 0.0013076551459680166, acc: 0.8533663828903655, lr: 0.033387018375182646
[batch_idx--350] train_loss: 0.001308398543156556, acc: 0.85330974002849, lr: 0.03333231125978507
[batch_idx--400] train_loss: 0.0013086721254628793, acc: 0.8534036003740648, lr: 0.03327755922131603
[batch_idx--450] train_loss: 0.0013111530897773102, acc: 0.852822230707814, lr: 0.033222762554967304
total time of one epoch: 289.25632524490356 s
train_loss:  0.0013111530897773102  acc:  0.852822230707814
->>lr:0.033223
test_loss:  0.0012816692355667515  test_acc:  0.8581709889564462
best acc:  85.99081771932002

------Epoch: 59------
[batch_idx--0] train_loss: 0.001355247339233756, acc: 0.8359375, lr: 0.03322166616846458
[batch_idx--50] train_loss: 0.0013034082652416592, acc: 0.8517156862745098, lr: 0.033166824286034645
[batch_idx--100] train_loss: 0.0013068241233208982, acc: 0.8520266089108911, lr: 0.03311193837274467
[batch_idx--150] train_loss: 0.0012998086699463477, acc: 0.8542270281456954, lr: 0.03305700872450816
[batch_idx--200] train_loss: 0.001294490711564263, acc: 0.8550412002487562, lr: 0.03300203563747449
[batch_idx--250] train_loss: 0.0012963061092005842, acc: 0.8540214143426295, lr: 0.0329470194080272
[batch_idx--300] train_loss: 0.0013032835704023854, acc: 0.8529640780730897, lr: 0.032891960332782424
[batch_idx--350] train_loss: 0.0013039257849017398, acc: 0.8529090990028491, lr: 0.03283685870858731
[batch_idx--400] train_loss: 0.001305135430308277, acc: 0.8530139495012469, lr: 0.03278171483251839
[batch_idx--450] train_loss: 0.0013115882462818248, acc: 0.852891658277502, lr: 0.03272652900188
total time of one epoch: 291.3582293987274 s
train_loss:  0.0013115882462818248  acc:  0.852891658277502
->>lr:0.032727
test_loss:  0.0012794842157489328  test_acc:  0.8568060553418538
best acc:  85.99081771932002

------Epoch: 60------
[batch_idx--0] train_loss: 0.0014733881689608097, acc: 0.828125, lr: 0.032725424859373686
[batch_idx--50] train_loss: 0.0013396455381321265, acc: 0.8477328431372549, lr: 0.032670196541591943
[batch_idx--100] train_loss: 0.001311512551003016, acc: 0.8526454207920792, lr: 0.03261492687048379
[batch_idx--150] train_loss: 0.0013045700936152643, acc: 0.8530887831125827, lr: 0.03255961614403176
[batch_idx--200] train_loss: 0.0012999421914585343, acc: 0.8533115671641791, lr: 0.03250426466043975
[batch_idx--250] train_loss: 0.0013037291916636416, acc: 0.8531187749003984, lr: 0.03244887271813142
[batch_idx--300] train_loss: 0.00130389945309275, acc: 0.8536648671096345, lr: 0.032393440615748524
[batch_idx--350] train_loss: 0.0013040341420279566, acc: 0.8535879629629629, lr: 0.03233796865214936
[batch_idx--400] train_loss: 0.001306632249163199, acc: 0.8532574812967582, lr: 0.03228245712640712
[batch_idx--450] train_loss: 0.0013090675814346176, acc: 0.852882979831291, lr: 0.0322269063378083
total time of one epoch: 287.36790561676025 s
train_loss:  0.0013090675814346176  acc:  0.852882979831291
->>lr:0.032227
test_loss:  0.001252106999564014  test_acc:  0.8607767713115771
best acc:  85.99081771932002
Saving..

------Epoch: 61------
[batch_idx--0] train_loss: 0.0011939172400161624, acc: 0.859375, lr: 0.03222579492361179
[batch_idx--50] train_loss: 0.0012929065258004795, acc: 0.8558517156862745, lr: 0.032170204395443734
[batch_idx--100] train_loss: 0.0012839405652190937, acc: 0.857131806930693, lr: 0.03211457520962184
[batch_idx--150] train_loss: 0.0012825449287971569, acc: 0.8568656870860927, lr: 0.032058907666066935
[batch_idx--200] train_loss: 0.0012774036010490982, acc: 0.8576259328358209, lr: 0.03200320206490668
[batch_idx--250] train_loss: 0.0012767889030904794, acc: 0.857491907370518, lr: 0.03194745870647391
[batch_idx--300] train_loss: 0.001283794575165091, acc: 0.8567535299003323, lr: 0.03189167789130505
[batch_idx--350] train_loss: 0.0012854114140017738, acc: 0.8564592236467237, lr: 0.031835859920138446
[batch_idx--400] train_loss: 0.0012920512528939085, acc: 0.8556830579800498, lr: 0.03178000509391275
[batch_idx--450] train_loss: 0.0013008776448374013, acc: 0.8552521956468914, lr: 0.03172411371376536
total time of one epoch: 290.0273497104645 s
train_loss:  0.0013008776448374013  acc:  0.8552521956468914
->>lr:0.031724
test_loss:  0.001246184713418319  test_acc:  0.8689663729991314
best acc:  86.07767713115771
Saving..

------Epoch: 62------
[batch_idx--0] train_loss: 0.001155939418822527, acc: 0.87890625, lr: 0.031722995515381644
[batch_idx--50] train_loss: 0.0012937186527814642, acc: 0.85546875, lr: 0.03166706716067022
[batch_idx--100] train_loss: 0.0013131779321183515, acc: 0.8524133663366337, lr: 0.03161110286093404
[batch_idx--150] train_loss: 0.0013130403776030173, acc: 0.8524679221854304, lr: 0.031555102917900694
[batch_idx--200] train_loss: 0.001309215578259854, acc: 0.8529617537313433, lr: 0.03149906763348994
[batch_idx--250] train_loss: 0.0013089663654276397, acc: 0.853507843625498, lr: 0.0314429973098121
[batch_idx--300] train_loss: 0.001304680460281175, acc: 0.8536389119601329, lr: 0.031386892249166375
[batch_idx--350] train_loss: 0.0013000875181767909, acc: 0.8540553774928775, lr: 0.03133075275403927
[batch_idx--400] train_loss: 0.0013022970428813406, acc: 0.8542705735660848, lr: 0.03127457912710293
[batch_idx--450] train_loss: 0.0013053814560194598, acc: 0.8540285347311417, lr: 0.031218371671213524
total time of one epoch: 293.2250828742981 s
train_loss:  0.0013053814560194598  acc:  0.8540285347311417
->>lr:0.031218
test_loss:  0.0012738920608633638  test_acc:  0.8606526864375232
best acc:  86.89663729991314

------Epoch: 63------
[batch_idx--0] train_loss: 0.0012240295764058828, acc: 0.859375, lr: 0.031217247179121367
[batch_idx--50] train_loss: 0.0013094447375110844, acc: 0.8540134803921569, lr: 0.0311610055298914
[batch_idx--100] train_loss: 0.0012924533330438898, acc: 0.8534962871287128, lr: 0.031104730664032437
[batch_idx--150] train_loss: 0.001289629408648694, acc: 0.8540976821192053, lr: 0.031048422884946483
[batch_idx--200] train_loss: 0.0012868952451491572, acc: 0.8549634639303483, lr: 0.030992082496212964
[batch_idx--250] train_loss: 0.0012856959154276526, acc: 0.8549240537848606, lr: 0.030935709801587143
[batch_idx--300] train_loss: 0.0012836725916326715, acc: 0.85546875, lr: 0.03087930510499845
[batch_idx--350] train_loss: 0.001287173453427883, acc: 0.8549123041310541, lr: 0.030822868710548842
[batch_idx--400] train_loss: 0.0012915800579595949, acc: 0.8548258260598504, lr: 0.030766400922511174
[batch_idx--450] train_loss: 0.001292741253905325, acc: 0.8553823723400562, lr: 0.030709902045327583
total time of one epoch: 290.8233642578125 s
train_loss:  0.001292741253905325  acc:  0.8553823723400562
->>lr:0.030710
test_loss:  0.0012938078852974314  test_acc:  0.8571783099640153
best acc:  86.89663729991314

------Epoch: 64------
[batch_idx--0] train_loss: 0.0013094916939735413, acc: 0.859375, lr: 0.030708771752766397
[batch_idx--50] train_loss: 0.0013158972324876516, acc: 0.8491115196078431, lr: 0.030652241478464032
[batch_idx--100] train_loss: 0.0013034663596513249, acc: 0.8519492574257426, lr: 0.03059568073049836
[batch_idx--150] train_loss: 0.0013067851664917852, acc: 0.8517953228476821, lr: 0.030539089813812693
[batch_idx--200] train_loss: 0.0012977802975390532, acc: 0.853389303482587, lr: 0.03048246903351297
[batch_idx--250] train_loss: 0.0012910460776823806, acc: 0.8546594870517928, lr: 0.030425818694866172
[batch_idx--300] train_loss: 0.0012959749109121008, acc: 0.8544954318936877, lr: 0.030369139103298623
[batch_idx--350] train_loss: 0.0013016139371373671, acc: 0.8538995726495726, lr: 0.030312430564394355
[batch_idx--400] train_loss: 0.0012976947937862126, acc: 0.8544653990024937, lr: 0.03025569338389348
[batch_idx--450] train_loss: 0.0012983948234927135, acc: 0.8543322803485264, lr: 0.03019892786769053
total time of one epoch: 288.19125747680664 s
train_loss:  0.0012983948234927135  acc:  0.8543322803485264
->>lr:0.030199
test_loss:  0.0012693649423907865  test_acc:  0.8620176200521157
best acc:  86.89663729991314

------Epoch: 65------
[batch_idx--0] train_loss: 0.0013117884518578649, acc: 0.8671875, lr: 0.03019779227044398
[batch_idx--50] train_loss: 0.0012488439599252945, acc: 0.8585324754901961, lr: 0.03014099816711588
[batch_idx--100] train_loss: 0.0012689666565516872, acc: 0.8575185643564357, lr: 0.030084176346456905
[batch_idx--150] train_loss: 0.0012721840252896265, acc: 0.8572795943708609, lr: 0.030027327114817932
[batch_idx--200] train_loss: 0.001272685611238286, acc: 0.8572761194029851, lr: 0.029970450778697578
[batch_idx--250] train_loss: 0.0012775315043694559, acc: 0.8562780129482072, lr: 0.02991354764474065
[batch_idx--300] train_loss: 0.001273967054373959, acc: 0.856922238372093, lr: 0.02985661801973638
[batch_idx--350] train_loss: 0.0012773679381308074, acc: 0.8564814814814815, lr: 0.02979966221061685
[batch_idx--400] train_loss: 0.0012804131513343023, acc: 0.8562772755610972, lr: 0.029742680524455323
[batch_idx--450] train_loss: 0.001286277792344062, acc: 0.8559030791127157, lr: 0.02968567326846454
total time of one epoch: 291.6235053539276 s
train_loss:  0.001286277792344062  acc:  0.8559030791127157
->>lr:0.029686
test_loss:  0.0012668806383251507  test_acc:  0.8636307234148157
best acc:  86.89663729991314

------Epoch: 66------
[batch_idx--0] train_loss: 0.001168790040537715, acc: 0.875, lr: 0.02968453286464312
[batch_idx--50] train_loss: 0.001275036520525521, acc: 0.8549325980392157, lr: 0.029627499844060053
[batch_idx--100] train_loss: 0.0012864532447097324, acc: 0.8538830445544554, lr: 0.029570441874636297
[batch_idx--150] train_loss: 0.0012876690008418498, acc: 0.8541235513245033, lr: 0.029513359263995894
[batch_idx--200] train_loss: 0.001293603525165728, acc: 0.853564210199005, lr: 0.029456252319895716
[batch_idx--250] train_loss: 0.0012895662977130142, acc: 0.8547217380478087, lr: 0.029399121350223874
[batch_idx--300] train_loss: 0.0012864263637758716, acc: 0.8553519518272426, lr: 0.029341966662997956
[batch_idx--350] train_loss: 0.0012849372081283447, acc: 0.8555577813390314, lr: 0.02928478856636346
[batch_idx--400] train_loss: 0.0012817484236083126, acc: 0.855858400872818, lr: 0.02922758736859208
[batch_idx--450] train_loss: 0.0012833710607152507, acc: 0.8559204360051377, lr: 0.02917036337808005
total time of one epoch: 288.09293842315674 s
train_loss:  0.0012833710607152507  acc:  0.8559204360051377
->>lr:0.029170
test_loss:  0.0012566426660038576  test_acc:  0.8610249410596849
best acc:  86.89663729991314

------Epoch: 67------
[batch_idx--0] train_loss: 0.0012675250181928277, acc: 0.8359375, lr: 0.02916921866790256
[batch_idx--50] train_loss: 0.0012861922515702306, acc: 0.8552389705882353, lr: 0.029111971746632322
[batch_idx--100] train_loss: 0.0012815289561277127, acc: 0.8553913985148515, lr: 0.02905470265595496
[batch_idx--150] train_loss: 0.0012921802730404383, acc: 0.8537613824503312, lr: 0.028997411704632756
[batch_idx--200] train_loss: 0.0012845833303953582, acc: 0.8550023320895522, lr: 0.02894009920154584
[batch_idx--250] train_loss: 0.0012858133522823335, acc: 0.8551574950199203, lr: 0.02888276545569057
[batch_idx--300] train_loss: 0.0012818105575671897, acc: 0.8558321220930233, lr: 0.0288254107761778
[batch_idx--350] train_loss: 0.0012833002108637445, acc: 0.8557692307692307, lr: 0.028768035472231265
[batch_idx--400] train_loss: 0.0012826724426456243, acc: 0.8554979738154613, lr: 0.0287106398531859
[batch_idx--450] train_loss: 0.0012873181583181442, acc: 0.8559725066824035, lr: 0.02865322422848614
total time of one epoch: 289.7393147945404 s
train_loss:  0.0012873181583181442  acc:  0.8559725066824035
->>lr:0.028653
test_loss:  0.001262642817604348  test_acc:  0.8604045166894155
best acc:  86.89663729991314

------Epoch: 68------
[batch_idx--0] train_loss: 0.0012606069212779403, acc: 0.86328125, lr: 0.028652075714060296
[batch_idx--50] train_loss: 0.001247260361161156, acc: 0.8599877450980392, lr: 0.028594640002494582
[batch_idx--100] train_loss: 0.0012570773389669928, acc: 0.8586788366336634, lr: 0.028537184910679542
[batch_idx--150] train_loss: 0.0012693778243199583, acc: 0.8580039321192053, lr: 0.028479710748380266
[batch_idx--200] train_loss: 0.001268659137416427, acc: 0.8581895211442786, lr: 0.028422217825464665
[batch_idx--250] train_loss: 0.0012720455805143988, acc: 0.8579121015936255, lr: 0.028364706451901797
[batch_idx--300] train_loss: 0.0012701216186288484, acc: 0.8578825789036545, lr: 0.028307176937760206
[batch_idx--350] train_loss: 0.0012704346486847539, acc: 0.8581174323361823, lr: 0.028249629593206222
[batch_idx--400] train_loss: 0.0012705755022881632, acc: 0.8578845854114713, lr: 0.02819206472850232
[batch_idx--450] train_loss: 0.0012764778077037522, acc: 0.8572135244905752, lr: 0.02813448265400542
total time of one epoch: 290.8517653942108 s
train_loss:  0.0012764778077037522  acc:  0.8572135244905752
->>lr:0.028134
test_loss:  0.001254342480678537  test_acc:  0.8625139595483311
best acc:  86.89663729991314

------Epoch: 69------
[batch_idx--0] train_loss: 0.0012726557906717062, acc: 0.85546875, lr: 0.028133330839107608
[batch_idx--50] train_loss: 0.0012659481349949014, acc: 0.8592984068627451, lr: 0.028075731530447786
[batch_idx--100] train_loss: 0.0012628177548574266, acc: 0.8609607054455446, lr: 0.028018115639197247
[batch_idx--150] train_loss: 0.0012628639988841747, acc: 0.8597630380794702, lr: 0.027960483475988025
[batch_idx--200] train_loss: 0.0012595103129823299, acc: 0.8595693407960199, lr: 0.02790283535153988
[batch_idx--250] train_loss: 0.0012574385992154865, acc: 0.8594995019920318, lr: 0.027845171576658636
[batch_idx--300] train_loss: 0.0012568953453618848, acc: 0.8595437084717608, lr: 0.027787492462234484
[batch_idx--350] train_loss: 0.0012606854447391829, acc: 0.8587295227920227, lr: 0.02772979831924033
[batch_idx--400] train_loss: 0.0012656989586632467, acc: 0.8583619077306733, lr: 0.02767208945873009
[batch_idx--450] train_loss: 0.0012706819510885721, acc: 0.8581941889124172, lr: 0.027614366191837037
total time of one epoch: 295.16112184524536 s
train_loss:  0.0012706819510885721  acc:  0.8581941889124172
->>lr:0.027614
test_loss:  0.0012814977917811432  test_acc:  0.8576746494602308
best acc:  86.89663729991314

------Epoch: 70------
[batch_idx--0] train_loss: 0.0012952393153682351, acc: 0.8515625, lr: 0.02761321158169134
[batch_idx--50] train_loss: 0.001245871080113027, acc: 0.8621323529411765, lr: 0.027555473940897853
[batch_idx--100] train_loss: 0.0012456559798551153, acc: 0.8611927599009901, lr: 0.027497722522445946
[batch_idx--150] train_loss: 0.0012540776465266993, acc: 0.8600475993377483, lr: 0.027439957637698322
[batch_idx--200] train_loss: 0.0012579805177719847, acc: 0.8598608519900498, lr: 0.027382179598090313
[batch_idx--250] train_loss: 0.0012574599229311385, acc: 0.8597951942231076, lr: 0.027324388715128153
[batch_idx--300] train_loss: 0.0012589913311002905, acc: 0.8594139327242525, lr: 0.027266585300387343
[batch_idx--350] train_loss: 0.0012545172069380935, acc: 0.8597978988603988, lr: 0.027208769665510946
[batch_idx--400] train_loss: 0.0012556769449073367, acc: 0.859745168329177, lr: 0.027150942122207884
[batch_idx--450] train_loss: 0.001259547788650444, acc: 0.8596348109834415, lr: 0.027093102982251305
total time of one epoch: 295.32088828086853 s
train_loss:  0.001259547788650444  acc:  0.8596348109834415
->>lr:0.027093
test_loss:  0.001275538303580203  test_acc:  0.8605286015634694
best acc:  86.89663729991314

------Epoch: 71------
[batch_idx--0] train_loss: 0.0015474370447918773, acc: 0.828125, lr: 0.02709194608330789
[batch_idx--50] train_loss: 0.0012638378459229774, acc: 0.8583792892156863, lr: 0.027034095436018247
[batch_idx--100] train_loss: 0.0012498661186453877, acc: 0.859684405940594, lr: 0.026976233822045795
[batch_idx--150] train_loss: 0.0012455862023195389, acc: 0.8614962748344371, lr: 0.026918361553347366
[batch_idx--200] train_loss: 0.0012465596346147544, acc: 0.8616487873134329, lr: 0.026860478941937244
[batch_idx--250] train_loss: 0.001253595380427917, acc: 0.860433266932271, lr: 0.026802586299885446
[batch_idx--300] train_loss: 0.001256627861821894, acc: 0.8600498338870431, lr: 0.026744683939316106
[batch_idx--350] train_loss: 0.0012572371182655465, acc: 0.8598869301994302, lr: 0.026686772172405743
[batch_idx--400] train_loss: 0.001259983704771447, acc: 0.8596672381546134, lr: 0.02662885131138157
[batch_idx--450] train_loss: 0.0012636488434089592, acc: 0.8594352067205887, lr: 0.026570921668519862
total time of one epoch: 291.63629722595215 s
train_loss:  0.0012636488434089592  acc:  0.8594352067205887
->>lr:0.026571
test_loss:  0.0012225483376951131  test_acc:  0.866732845266162
best acc:  86.89663729991314

------Epoch: 72------
[batch_idx--0] train_loss: 0.0013424033531919122, acc: 0.84375, lr: 0.026569762988232833
[batch_idx--50] train_loss: 0.0012602320593763509, acc: 0.8594515931372549, lr: 0.026511824709652916
[batch_idx--100] train_loss: 0.0012569921742433148, acc: 0.8606126237623762, lr: 0.02645387828017616
[batch_idx--150] train_loss: 0.001244146324808259, acc: 0.8620653973509934, lr: 0.026395924012216673
[batch_idx--200] train_loss: 0.0012460418024670278, acc: 0.8615516169154229, lr: 0.02633796221823084
[batch_idx--250] train_loss: 0.0012421223128110585, acc: 0.8620829183266933, lr: 0.026279993210715575
[batch_idx--300] train_loss: 0.0012436633903697208, acc: 0.861749896179402, lr: 0.026222017302206753
[batch_idx--350] train_loss: 0.0012499413171456729, acc: 0.8608885327635327, lr: 0.02616403480527739
[batch_idx--400] train_loss: 0.0012535840925235683, acc: 0.8604465399002493, lr: 0.02610604603253605
[batch_idx--450] train_loss: 0.0012573624270870729, acc: 0.8605894400666505, lr: 0.026048051296625147
total time of one epoch: 290.5733938217163 s
train_loss:  0.0012573624270870729  acc:  0.8605894400666505
->>lr:0.026048
test_loss:  0.001233188018252705  test_acc:  0.8666087603921082
best acc:  86.89663729991314

------Epoch: 73------
[batch_idx--0] train_loss: 0.0011469940654933453, acc: 0.875, lr: 0.02604689134322999
[batch_idx--50] train_loss: 0.0012229693615261245, acc: 0.8615196078431373, lr: 0.025988890847003655
[batch_idx--100] train_loss: 0.001230969036108639, acc: 0.8624690594059405, lr: 0.025930885019241706
[batch_idx--150] train_loss: 0.0012482567574668502, acc: 0.8599182533112583, lr: 0.025872874172678507
[batch_idx--200] train_loss: 0.0012480914873645563, acc: 0.8600163246268657, lr: 0.02581485862007545
[batch_idx--250] train_loss: 0.0012537636267729994, acc: 0.8591104332669323, lr: 0.02575683867421932
[batch_idx--300] train_loss: 0.001251359883443672, acc: 0.8594788205980066, lr: 0.02569881464792059
[batch_idx--350] train_loss: 0.0012517912730248247, acc: 0.8595308048433048, lr: 0.02564078685401172
[batch_idx--400] train_loss: 0.0012541167659248385, acc: 0.8591119856608479, lr: 0.025582755605345495
[batch_idx--450] train_loss: 0.0012570268822354833, acc: 0.8589405352865623, lr: 0.02552472121479332
total time of one epoch: 288.7523009777069 s
train_loss:  0.0012570268822354833  acc:  0.8589405352865623
->>lr:0.025525
test_loss:  0.0013287400382818574  test_acc:  0.8532075939942921
best acc:  86.89663729991314

------Epoch: 74------
[batch_idx--0] train_loss: 0.0012207370018586516, acc: 0.86328125, lr: 0.025523560497083927
[batch_idx--50] train_loss: 0.0012710310139821149, acc: 0.8581495098039216, lr: 0.025465523224145754
[batch_idx--100] train_loss: 0.0012622902430317337, acc: 0.8601485148514851, lr: 0.02540748344137178
[batch_idx--150] train_loss: 0.0012754045568702632, acc: 0.8575641556291391, lr: 0.02534944146167944
[batch_idx--200] train_loss: 0.0012575010861738108, acc: 0.8600940609452736, lr: 0.025291397597997967
[batch_idx--250] train_loss: 0.0012531531631456785, acc: 0.8604955179282868, lr: 0.025233352163266793
[batch_idx--300] train_loss: 0.00125633815861929, acc: 0.8597383720930233, lr: 0.025175305470433812
[batch_idx--350] train_loss: 0.0012582169521992703, acc: 0.8594974180911681, lr: 0.025117257832453683
[batch_idx--400] train_loss: 0.0012550878679923286, acc: 0.8598620635910225, lr: 0.025059209562286185
[batch_idx--450] train_loss: 0.0012561850743506963, acc: 0.8602770160030548, lr: 0.02500116097289448
total time of one epoch: 290.7487106323242 s
train_loss:  0.0012561850743506963  acc:  0.8602770160030548
->>lr:0.025001
test_loss:  0.001239023077412506  test_acc:  0.864251147785085
best acc:  86.89663729991314

------Epoch: 75------
[batch_idx--0] train_loss: 0.0010378224542364478, acc: 0.91015625, lr: 0.025
[batch_idx--50] train_loss: 0.0012570386158996354, acc: 0.8603707107843137, lr: 0.024941951407416053
[batch_idx--100] train_loss: 0.001245262845889619, acc: 0.8627011138613861, lr: 0.024883903127797022
[batch_idx--150] train_loss: 0.0012473716818425335, acc: 0.8625310430463576, lr: 0.02482585547410613
[batch_idx--200] train_loss: 0.0012429991907287222, acc: 0.8633784203980099, lr: 0.024767808759303227
[batch_idx--250] train_loss: 0.0012422566783551379, acc: 0.8631878735059761, lr: 0.024709763296343102
[batch_idx--300] train_loss: 0.0012452639527216654, acc: 0.8626453488372093, lr: 0.024651719398173802
[batch_idx--350] train_loss: 0.0012423559516519733, acc: 0.8628027065527065, lr: 0.024593677377734924
[batch_idx--400] train_loss: 0.0012500189140815278, acc: 0.8612940305486284, lr: 0.02453563754795596
[batch_idx--450] train_loss: 0.0012535297319892546, acc: 0.8612837157635297, lr: 0.024477600221754565
total time of one epoch: 291.9980685710907 s
train_loss:  0.0012535297319892546  acc:  0.8612837157635297
->>lr:0.024478
test_loss:  0.001259876341866506  test_acc:  0.8672291847623774
best acc:  86.89663729991314

------Epoch: 76------
[batch_idx--0] train_loss: 0.0013623188715428114, acc: 0.83984375, lr: 0.02447643950291608
[batch_idx--50] train_loss: 0.0012432929794943216, acc: 0.8625919117647058, lr: 0.024418405052717584
[batch_idx--100] train_loss: 0.001241436182051012, acc: 0.8623143564356436, lr: 0.024360373738147447
[batch_idx--150] train_loss: 0.0012384326982046692, acc: 0.8624016970198676, lr: 0.024302345872077406
[batch_idx--200] train_loss: 0.0012419663499392086, acc: 0.8622512437810945, lr: 0.024244321767360646
[batch_idx--250] train_loss: 0.0012397294097850878, acc: 0.8626898655378487, lr: 0.024186301736830045
[batch_idx--300] train_loss: 0.0012380175522228461, acc: 0.8627751245847176, lr: 0.024128286093296536
[batch_idx--350] train_loss: 0.0012394297220266592, acc: 0.8627693198005698, lr: 0.02407027514954738
[batch_idx--400] train_loss: 0.0012399049888323166, acc: 0.8626578086034913, lr: 0.024012269218344526
[batch_idx--450] train_loss: 0.0012388981735989382, acc: 0.8629499774360399, lr: 0.023954268612422863
total time of one epoch: 289.04348945617676 s
train_loss:  0.0012388981735989382  acc:  0.8629499774360399
->>lr:0.023954
test_loss:  0.001247557206697626  test_acc:  0.8592877528229309
best acc:  86.89663729991314

------Epoch: 77------
[batch_idx--0] train_loss: 0.0012538859155029058, acc: 0.86328125, lr: 0.02395310865677001
[batch_idx--50] train_loss: 0.0012495804409149523, acc: 0.8602175245098039, lr: 0.023895113804784887
[batch_idx--100] train_loss: 0.0012515752431060565, acc: 0.8603805693069307, lr: 0.02383712490971616
[batch_idx--150] train_loss: 0.0012531163863257954, acc: 0.8606943294701986, lr: 0.023779142284206876
[batch_idx--200] train_loss: 0.0012448187876928282, acc: 0.8617653917910447, lr: 0.023721166240866298
[batch_idx--250] train_loss: 0.001246872782406668, acc: 0.861398157370518, lr: 0.0236631970922682
[batch_idx--300] train_loss: 0.00124619791707321, acc: 0.8615941652823921, lr: 0.023605235150949158
[batch_idx--350] train_loss: 0.0012385650090820175, acc: 0.8628360933048433, lr: 0.02354728072940694
[batch_idx--400] train_loss: 0.0012398557066847745, acc: 0.86262858478803, lr: 0.02348933414009873
[batch_idx--450] train_loss: 0.0012453731040677827, acc: 0.8622817370777935, lr: 0.02343139569543949
total time of one epoch: 295.85629892349243 s
train_loss:  0.0012453731040677827  acc:  0.8622817370777935
->>lr:0.023431
test_loss:  0.0012199245629024825  test_acc:  0.8682218637548083
best acc:  86.89663729991314

------Epoch: 78------
[batch_idx--0] train_loss: 0.0012720999075099826, acc: 0.8359375, lr: 0.023430237011767167
[batch_idx--50] train_loss: 0.001249964279350916, acc: 0.8599877450980392, lr: 0.02337230719645424
[batch_idx--100] train_loss: 0.0012437007683882544, acc: 0.8628944925742574, lr: 0.023314386156732855
[batch_idx--150] train_loss: 0.0012342319719721594, acc: 0.8640831953642384, lr: 0.023256474204880216
[batch_idx--200] train_loss: 0.0012440949939631519, acc: 0.8630480410447762, lr: 0.023198571653124563
[batch_idx--250] train_loss: 0.001244411536629694, acc: 0.8628143675298805, lr: 0.02314067881364343
[batch_idx--300] train_loss: 0.0012407028358011967, acc: 0.8631904069767442, lr: 0.02308279599856199
[batch_idx--350] train_loss: 0.0012379941317263428, acc: 0.8634593126780626, lr: 0.023024923519951404
[batch_idx--400] train_loss: 0.0012349228501236276, acc: 0.86414822319202, lr: 0.02296706168982706
[batch_idx--450] train_loss: 0.0012370549384445716, acc: 0.8641649599055785, lr: 0.022909210820146964
total time of one epoch: 292.59652853012085 s
train_loss:  0.0012370549384445716  acc:  0.8641649599055785
->>lr:0.022909
test_loss:  0.0012012743793833802  test_acc:  0.8700831368656161
best acc:  86.89663729991314
Saving..

------Epoch: 79------
[batch_idx--0] train_loss: 0.0011170045472681522, acc: 0.890625, lr: 0.022908053916692112
[batch_idx--50] train_loss: 0.001190127808299354, acc: 0.8669577205882353, lr: 0.022850214547982983
[batch_idx--100] train_loss: 0.0012261649129202239, acc: 0.8627397896039604, lr: 0.022792386769691267
[batch_idx--150] train_loss: 0.0012307660557816904, acc: 0.8628414735099338, lr: 0.022734570893591363
[batch_idx--200] train_loss: 0.0012278052177789867, acc: 0.8627176616915423, lr: 0.022676767231393526
[batch_idx--250] train_loss: 0.0012270006936959982, acc: 0.8625809262948207, lr: 0.02261897609474213
[batch_idx--300] train_loss: 0.0012283614408101057, acc: 0.8630865863787376, lr: 0.022561197795214035
[batch_idx--350] train_loss: 0.0012295915368092684, acc: 0.8629807692307693, lr: 0.022503432644316902
[batch_idx--400] train_loss: 0.0012278504496349713, acc: 0.8631740960099751, lr: 0.022445680953487472
[batch_idx--450] train_loss: 0.0012354658594653132, acc: 0.8626462318186552, lr: 0.022387943034089947
total time of one epoch: 290.723393201828 s
train_loss:  0.0012354658594653132  acc:  0.8626462318186552
->>lr:0.022388
test_loss:  0.00121276937623905  test_acc:  0.8656160813996774
best acc:  87.0083136865616

------Epoch: 80------
[batch_idx--0] train_loss: 0.0010404433123767376, acc: 0.87890625, lr: 0.022386788418308663
[batch_idx--50] train_loss: 0.0012461802073042182, acc: 0.8608302696078431, lr: 0.022329064866462054
[batch_idx--100] train_loss: 0.0012326251777663533, acc: 0.8637066831683168, lr: 0.022271355714774788
[batch_idx--150] train_loss: 0.0012321197728484574, acc: 0.8644971026490066, lr: 0.022213661274381714
[batch_idx--200] train_loss: 0.001231422402261205, acc: 0.8639808768656716, lr: 0.022155981856338363
[batch_idx--250] train_loss: 0.0012271228400374432, acc: 0.864308391434263, lr: 0.022098317771619257
[batch_idx--300] train_loss: 0.0012260151367968696, acc: 0.8640209717607974, lr: 0.022040669331116272
[batch_idx--350] train_loss: 0.0012289021994011141, acc: 0.8635817307692307, lr: 0.021983036845636923
[batch_idx--400] train_loss: 0.0012312741869447423, acc: 0.8631156483790524, lr: 0.02192542062590272
[batch_idx--450] train_loss: 0.0012367608145742674, acc: 0.8628892283125629, lr: 0.02186782098254747
total time of one epoch: 287.7635962963104 s
train_loss:  0.0012367608145742674  acc:  0.8628892283125629
->>lr:0.021868
test_loss:  0.0011998642846629466  test_acc:  0.8685941183769699
best acc:  87.0083136865616

------Epoch: 81------
[batch_idx--0] train_loss: 0.001141272601671517, acc: 0.875, lr: 0.02186666916089239
[batch_idx--50] train_loss: 0.0012431134990252117, acc: 0.8628216911764706, lr: 0.021809086745365924
[batch_idx--100] train_loss: 0.0012411497807646595, acc: 0.8632425742574258, lr: 0.021751521533424346
[batch_idx--150] train_loss: 0.001231271502197973, acc: 0.8636175496688742, lr: 0.021693973835426473
[batch_idx--200] train_loss: 0.0012270188204068413, acc: 0.8638059701492538, lr: 0.021636443961636685
[batch_idx--250] train_loss: 0.0012265209709683737, acc: 0.8640126992031872, lr: 0.021578932222223245
[batch_idx--300] train_loss: 0.0012280671206377199, acc: 0.8638003529900332, lr: 0.021521438927256664
[batch_idx--350] train_loss: 0.0012317321883803737, acc: 0.8631031873219374, lr: 0.021463964386708015
[batch_idx--400] train_loss: 0.0012262738256092808, acc: 0.8639046913965087, lr: 0.021406508910447243
[batch_idx--450] train_loss: 0.001225833495559698, acc: 0.8641042107821015, lr: 0.021349072808241526
total time of one epoch: 291.4532296657562 s
train_loss:  0.001225833495559698  acc:  0.8641042107821015
->>lr:0.021349
test_loss:  0.0012591855633065044  test_acc:  0.8625139595483311
best acc:  87.0083136865616

------Epoch: 82------
[batch_idx--0] train_loss: 0.001201291219331324, acc: 0.8515625, lr: 0.021347924285939714
[batch_idx--50] train_loss: 0.001216567195632367, acc: 0.8671109068627451, lr: 0.02129050826428394
[batch_idx--100] train_loss: 0.0012231831465349856, acc: 0.8653697400990099, lr: 0.021233112242092567
[batch_idx--150] train_loss: 0.001230394526690072, acc: 0.8643677566225165, lr: 0.02117573652881221
[batch_idx--200] train_loss: 0.0012265841102468507, acc: 0.8650303171641791, lr: 0.02111838143378
[batch_idx--250] train_loss: 0.0012255049516090685, acc: 0.865242156374502, lr: 0.021061047266221912
[batch_idx--300] train_loss: 0.0012204634612410692, acc: 0.8658248546511628, lr: 0.021003734335251087
[batch_idx--350] train_loss: 0.0012204680269109112, acc: 0.8657184829059829, lr: 0.020946442949866164
[batch_idx--400] train_loss: 0.0012204641488756975, acc: 0.8655509663341646, lr: 0.020889173418949643
[batch_idx--450] train_loss: 0.001226392312381874, acc: 0.8651629812198424, lr: 0.020831926051266162
total time of one epoch: 289.7850229740143 s
train_loss:  0.001226392312381874  acc:  0.8651629812198424
->>lr:0.020832
test_loss:  0.001208154372533478  test_acc:  0.8710758158580469
best acc:  87.0083136865616
Saving..

------Epoch: 83------
[batch_idx--0] train_loss: 0.001166846021078527, acc: 0.87109375, lr: 0.020830781332097453
[batch_idx--50] train_loss: 0.0012599843709419172, acc: 0.8587622549019608, lr: 0.020773556888877096
[batch_idx--100] train_loss: 0.0012503129292952616, acc: 0.8606899752475248, lr: 0.020716355232228204
[batch_idx--150] train_loss: 0.001247133131043381, acc: 0.8611082367549668, lr: 0.020659176670549492
[batch_idx--200] train_loss: 0.0012389631062718247, acc: 0.8621346393034826, lr: 0.020602021512115154
[batch_idx--250] train_loss: 0.0012343895194432382, acc: 0.8625498007968128, lr: 0.02054489006507322
[batch_idx--300] train_loss: 0.0012225097964248587, acc: 0.8640339493355482, lr: 0.02048778263744388
[batch_idx--350] train_loss: 0.00121901715884086, acc: 0.8648059116809117, lr: 0.02043069953711782
[batch_idx--400] train_loss: 0.001223488658128952, acc: 0.8641579644638404, lr: 0.020373641071854572
[batch_idx--450] train_loss: 0.00122326829573147, acc: 0.8648852709410907, lr: 0.020316607549280843
total time of one epoch: 290.14269828796387 s
train_loss:  0.00122326829573147  acc:  0.8648852709410907
->>lr:0.020317
test_loss:  0.0011871556206781407  test_acc:  0.8724407494726393
best acc:  87.1075815858047
Saving..

------Epoch: 84------
[batch_idx--0] train_loss: 0.001276342198252678, acc: 0.859375, lr: 0.020315467135356893
[batch_idx--50] train_loss: 0.0011751123672059062, acc: 0.8710171568627451, lr: 0.02025845937110404
[batch_idx--100] train_loss: 0.0011971850976311039, acc: 0.868850556930693, lr: 0.020201477170534773
[batch_idx--150] train_loss: 0.001196814305842885, acc: 0.8689983443708609, lr: 0.020144520840864624
[batch_idx--200] train_loss: 0.0012021979834856604, acc: 0.8674595771144279, lr: 0.02008759068916964
[batch_idx--250] train_loss: 0.0012055834550299196, acc: 0.8670007470119522, lr: 0.020030687022384752
[batch_idx--300] train_loss: 0.0012089555775220708, acc: 0.8658248546511628, lr: 0.019973810147302068
[batch_idx--350] train_loss: 0.0012126568999364334, acc: 0.8650062321937322, lr: 0.01991696037056928
[batch_idx--400] train_loss: 0.001210240484331444, acc: 0.8653853647132169, lr: 0.01986013799868798
[batch_idx--450] train_loss: 0.0012178480549888972, acc: 0.8651716596660534, lr: 0.01980334333801198
total time of one epoch: 288.6169602870941 s
train_loss:  0.0012178480549888972  acc:  0.8651716596660534
->>lr:0.019803
test_loss:  0.0012377987784832874  test_acc:  0.865119741903462
best acc:  87.24407494726393

------Epoch: 85------
[batch_idx--0] train_loss: 0.0012330996105447412, acc: 0.87109375, lr: 0.019802207729556022
[batch_idx--50] train_loss: 0.001205747591002899, acc: 0.8678768382352942, lr: 0.0197454416497602
[batch_idx--100] train_loss: 0.0012162077836554018, acc: 0.8653310643564357, lr: 0.019688703899547008
[batch_idx--150] train_loss: 0.001216772051346149, acc: 0.8653507864238411, lr: 0.01963199478481404
[batch_idx--200] train_loss: 0.0012091888923925435, acc: 0.8662935323383084, lr: 0.019575314611304503
[batch_idx--250] train_loss: 0.0012044798776663216, acc: 0.8663782370517928, lr: 0.019518663684605593
[batch_idx--300] train_loss: 0.001207814398925578, acc: 0.866188226744186, lr: 0.01946204231014678
[batch_idx--350] train_loss: 0.0012058913032789622, acc: 0.8661858974358975, lr: 0.019405450793198248
[batch_idx--400] train_loss: 0.0012068146844963518, acc: 0.8657847568578554, lr: 0.01934888943886919
[batch_idx--450] train_loss: 0.0012113140009416819, acc: 0.86549276217586, lr: 0.019292358552106172
total time of one epoch: 295.03273725509644 s
train_loss:  0.0012113140009416819  acc:  0.86549276217586
->>lr:0.019292
test_loss:  0.0011946152336826128  test_acc:  0.8694627124953468
best acc:  87.24407494726393

------Epoch: 86------
[batch_idx--0] train_loss: 0.0012037173146381974, acc: 0.87890625, lr: 0.019291228247233613
[batch_idx--50] train_loss: 0.0011847124254677956, acc: 0.8684895833333334, lr: 0.019234728751373553
[batch_idx--100] train_loss: 0.0012072905717131746, acc: 0.8657178217821783, lr: 0.01917826033856888
[batch_idx--150] train_loss: 0.0012085947492591642, acc: 0.8650662251655629, lr: 0.019121823313265066
[batch_idx--200] train_loss: 0.0012076734139500602, acc: 0.8645833333333334, lr: 0.01906541797973838
[batch_idx--250] train_loss: 0.0012056619293924673, acc: 0.8647597111553785, lr: 0.01900904464209422
[batch_idx--300] train_loss: 0.0012053257924585024, acc: 0.8649683347176079, lr: 0.018952703604265476
[batch_idx--350] train_loss: 0.001206525998452726, acc: 0.8652733262108262, lr: 0.018896395170010898
[batch_idx--400] train_loss: 0.0012051456201730988, acc: 0.8658529457605985, lr: 0.01884011964291346
[batch_idx--450] train_loss: 0.001205014485905791, acc: 0.8667511368764537, lr: 0.018783877326378724
total time of one epoch: 293.8723056316376 s
train_loss:  0.001205014485905791  acc:  0.8667511368764537
->>lr:0.018784
test_loss:  0.0012028836012478279  test_acc:  0.8699590519915622
best acc:  87.24407494726393

------Epoch: 87------
[batch_idx--0] train_loss: 0.0011941040866076946, acc: 0.8671875, lr: 0.018782752820878636
[batch_idx--50] train_loss: 0.0011857289537860482, acc: 0.8713235294117647, lr: 0.018726544691500546
[batch_idx--100] train_loss: 0.0011859979736388172, acc: 0.8702815594059405, lr: 0.01867037038501655
[batch_idx--150] train_loss: 0.001192779038934074, acc: 0.8696450745033113, lr: 0.018614230204286455
[batch_idx--200] train_loss: 0.0011970209307037294, acc: 0.869130907960199, lr: 0.018558124451986114
[batch_idx--250] train_loss: 0.0012037783267024712, acc: 0.8676232569721115, lr: 0.018502053430605753
[batch_idx--300] train_loss: 0.0011984995932571986, acc: 0.867719580564784, lr: 0.01844601744244835
[batch_idx--350] train_loss: 0.00120193057675631, acc: 0.8673655626780626, lr: 0.018390016789628004
[batch_idx--400] train_loss: 0.0012038270976252742, acc: 0.8670316396508728, lr: 0.018334051774068303
[batch_idx--450] train_loss: 0.0012109027080465207, acc: 0.8670462040476273, lr: 0.0182781226975007
total time of one epoch: 289.62088894844055 s
train_loss:  0.0012109027080465207  acc:  0.8670462040476273
->>lr:0.018278
test_loss:  0.0012195820284919298  test_acc:  0.8671050998883236
best acc:  87.24407494726393

------Epoch: 88------
[batch_idx--0] train_loss: 0.0013212962076067924, acc: 0.84765625, lr: 0.01827700448461836
[batch_idx--50] train_loss: 0.0011899719338900612, acc: 0.8686427696078431, lr: 0.018221112376465492
[batch_idx--100] train_loss: 0.0012082448079352183, acc: 0.8657951732673267, lr: 0.018165256816209563
[batch_idx--150] train_loss: 0.0011991363196843458, acc: 0.8674720612582781, lr: 0.018109438104991903
[batch_idx--200] train_loss: 0.001197683645194554, acc: 0.8675373134328358, lr: 0.01805365654375518
[batch_idx--250] train_loss: 0.0011966737326739201, acc: 0.8680901394422311, lr: 0.017997912433241763
[batch_idx--300] train_loss: 0.0011948738073113304, acc: 0.868108907807309, lr: 0.017942206073992117
[batch_idx--350] train_loss: 0.0011998269364683547, acc: 0.8674212072649573, lr: 0.017886537766343167
[batch_idx--400] train_loss: 0.0012016393819956244, acc: 0.8670608634663342, lr: 0.017830907810426684
[batch_idx--450] train_loss: 0.001207456935821596, acc: 0.8667424584302427, lr: 0.017775316506167683
total time of one epoch: 290.8908305168152 s
train_loss:  0.001207456935821596  acc:  0.8667424584302427
->>lr:0.017775
test_loss:  0.0012173860921266876  test_acc:  0.8707035612358853
best acc:  87.24407494726393

------Epoch: 89------
[batch_idx--0] train_loss: 0.001164559624157846, acc: 0.86328125, lr: 0.017774205076388213
[batch_idx--50] train_loss: 0.0012005500623262395, acc: 0.8671109068627451, lr: 0.017718653505586445
[batch_idx--100] train_loss: 0.0011901651159860194, acc: 0.8686958539603961, lr: 0.01766314119165336
[batch_idx--150] train_loss: 0.0011849050997565223, acc: 0.8701365894039735, lr: 0.017607668433879703
[batch_idx--200] train_loss: 0.0011847685351828808, acc: 0.8695195895522388, lr: 0.017552235531342955
[batch_idx--250] train_loss: 0.0011864826338276622, acc: 0.869210657370518, lr: 0.017496842782905715
[batch_idx--300] train_loss: 0.001191162305846934, acc: 0.8691211586378738, lr: 0.017441490487214106
[batch_idx--350] train_loss: 0.001194056200607815, acc: 0.8684673254985755, lr: 0.017386178942696135
[batch_idx--400] train_loss: 0.0011913990694797248, acc: 0.8687850685785536, lr: 0.01733090844756013
[batch_idx--450] train_loss: 0.0011947126402485212, acc: 0.8684868261186517, lr: 0.017275679299793074
total time of one epoch: 290.73868703842163 s
train_loss:  0.0011947126402485212  acc:  0.8684868261186517
->>lr:0.017276
test_loss:  0.0012066050474571818  test_acc:  0.8719444099764239
best acc:  87.24407494726393

------Epoch: 90------
[batch_idx--0] train_loss: 0.0012641906505450606, acc: 0.85546875, lr: 0.017274575140626316
[batch_idx--50] train_loss: 0.0011681171166071412, acc: 0.8709405637254902, lr: 0.017219388473930602
[batch_idx--100] train_loss: 0.0011788571200398083, acc: 0.8691599628712872, lr: 0.017164243755855953
[batch_idx--150] train_loss: 0.0011845739012497742, acc: 0.8687913907284768, lr: 0.017109141283711254
[batch_idx--200] train_loss: 0.0011923130910347832, acc: 0.8669931592039801, lr: 0.0170540813545776
[batch_idx--250] train_loss: 0.0011918856356519301, acc: 0.8673431274900398, lr: 0.016999064265306747
[batch_idx--300] train_loss: 0.001189327433873958, acc: 0.8679661544850499, lr: 0.016944090312519478
[batch_idx--350] train_loss: 0.001186390342708263, acc: 0.8683115206552706, lr: 0.01688915979260398
[batch_idx--400] train_loss: 0.0011898783371467932, acc: 0.8676940461346634, lr: 0.016834273001714316
[batch_idx--450] train_loss: 0.0011912748867022348, acc: 0.8677144444058735, lr: 0.016779430235768767
total time of one epoch: 289.6106994152069 s
train_loss:  0.0011912748867022348  acc:  0.8677144444058735
->>lr:0.016779
test_loss:  0.0011817304257320579  test_acc:  0.8711999007321007
best acc:  87.24407494726393

------Epoch: 91------
[batch_idx--0] train_loss: 0.0010343835456296802, acc: 0.90234375, lr: 0.01677833383153542
[batch_idx--50] train_loss: 0.0011889844192374572, acc: 0.8704810049019608, lr: 0.016723536275641708
[batch_idx--100] train_loss: 0.00119710809465885, acc: 0.8695467202970297, lr: 0.01666878334172139
[batch_idx--150] train_loss: 0.0011969232486116867, acc: 0.8690759519867549, lr: 0.01661407532497108
[batch_idx--200] train_loss: 0.001194285177590965, acc: 0.869014303482587, lr: 0.016559412520345193
[batch_idx--250] train_loss: 0.0011922470607008207, acc: 0.8684169571713147, lr: 0.016504795222554415
[batch_idx--300] train_loss: 0.0011889207777505326, acc: 0.8690043604651163, lr: 0.01645022372606408
[batch_idx--350] train_loss: 0.0011883262815842793, acc: 0.8690015135327636, lr: 0.01639569832509256
[batch_idx--400] train_loss: 0.0011885254442090276, acc: 0.8688824812967582, lr: 0.016341219313609757
[batch_idx--450] train_loss: 0.0011891723496433796, acc: 0.8688947130905683, lr: 0.01628678698533542
total time of one epoch: 288.98947381973267 s
train_loss:  0.0011891723496433796  acc:  0.8688947130905683
->>lr:0.016287
test_loss:  0.0011935850251976825  test_acc:  0.8721925797245316
best acc:  87.24407494726393

------Epoch: 92------
[batch_idx--0] train_loss: 0.0013394041452556849, acc: 0.83203125, lr: 0.016285698816954627
[batch_idx--50] train_loss: 0.001189298240705302, acc: 0.8691023284313726, lr: 0.016231314407882003
[batch_idx--100] train_loss: 0.0011847333142321816, acc: 0.869430693069307, lr: 0.016176977274562434
[batch_idx--150] train_loss: 0.0011911420745232347, acc: 0.8685844370860927, lr: 0.016122687709950775
[batch_idx--200] train_loss: 0.0011867578080577304, acc: 0.8680425995024875, lr: 0.01606844600674539
[batch_idx--250] train_loss: 0.001183530700020121, acc: 0.8684013944223108, lr: 0.016014252457386614
[batch_idx--300] train_loss: 0.0011840181114257274, acc: 0.8686799210963455, lr: 0.015960107354055172
[batch_idx--350] train_loss: 0.0011795124278186245, acc: 0.8692574786324786, lr: 0.01590601098867059
[batch_idx--400] train_loss: 0.0011797689745943539, acc: 0.8692721321695761, lr: 0.015851963652889624
[batch_idx--450] train_loss: 0.0011854658351597694, acc: 0.8687732148436144, lr: 0.015797965638104688
total time of one epoch: 295.7197103500366 s
train_loss:  0.0011854658351597694  acc:  0.8687732148436144
->>lr:0.015798
test_loss:  0.0012307354949487766  test_acc:  0.870951730983993
best acc:  87.24407494726393

------Epoch: 93------
[batch_idx--0] train_loss: 0.0014172721421346068, acc: 0.828125, lr: 0.01579688618288306
[batch_idx--50] train_loss: 0.0011734601450335308, acc: 0.870327818627451, lr: 0.01574293877543077
[batch_idx--100] train_loss: 0.0011821080034939886, acc: 0.8682704207920792, lr: 0.015689041276774486
[batch_idx--150] train_loss: 0.001183468488041953, acc: 0.8689724751655629, lr: 0.015635193977498796
[batch_idx--200] train_loss: 0.0011753936918494083, acc: 0.8702969527363185, lr: 0.015581397167917649
[batch_idx--250] train_loss: 0.0011793879944686425, acc: 0.8694907868525896, lr: 0.01552765113807274
[batch_idx--300] train_loss: 0.0011823818722254042, acc: 0.8693158222591362, lr: 0.015473956177732033
[batch_idx--350] train_loss: 0.001183926693510073, acc: 0.86934650997151, lr: 0.01542031257638813
[batch_idx--400] train_loss: 0.0011845550273703017, acc: 0.8689701527431422, lr: 0.015366720623256752
[batch_idx--450] train_loss: 0.001188069781783214, acc: 0.8689207484292012, lr: 0.015313180607275165
total time of one epoch: 295.01946806907654 s
train_loss:  0.001188069781783214  acc:  0.8689207484292012
->>lr:0.015313
test_loss:  0.0011494896288086129  test_acc:  0.8766596351904703
best acc:  87.24407494726393
Saving..

------Epoch: 94------
[batch_idx--0] train_loss: 0.0016278675757348537, acc: 0.80859375, lr: 0.015312110338697428
[batch_idx--50] train_loss: 0.0012137787507883475, acc: 0.8641237745098039, lr: 0.015258623595981367
[batch_idx--100] train_loss: 0.0011964512851762373, acc: 0.8681930693069307, lr: 0.015205189373212608
[batch_idx--150] train_loss: 0.0011897253894882387, acc: 0.8689207367549668, lr: 0.015151807958478031
[batch_idx--200] train_loss: 0.0011858295151773858, acc: 0.8697333644278606, lr: 0.015098479639579785
[batch_idx--250] train_loss: 0.001191257842142966, acc: 0.8679500747011952, lr: 0.015045204704033754
[batch_idx--300] train_loss: 0.0011811920956467151, acc: 0.8690692483388704, lr: 0.01499198343906803
[batch_idx--350] train_loss: 0.0011845646549461999, acc: 0.8688345797720798, lr: 0.014938816131621303
[batch_idx--400] train_loss: 0.0011824034903421441, acc: 0.8695935941396509, lr: 0.014885703068341395
[batch_idx--450] train_loss: 0.0011890908568651627, acc: 0.8694240983094387, lr: 0.014832644535583656
total time of one epoch: 291.75326442718506 s
train_loss:  0.0011890908568651627  acc:  0.8694240983094387
->>lr:0.014833
test_loss:  0.001169094120854109  test_acc:  0.8718203251023701
best acc:  87.66596351904703

------Epoch: 95------
[batch_idx--0] train_loss: 0.001160512794740498, acc: 0.87109375, lr: 0.014831583923105
[batch_idx--50] train_loss: 0.0012016859905355994, acc: 0.8666513480392157, lr: 0.014778581306178257
[batch_idx--100] train_loss: 0.0011946604463806616, acc: 0.8657564975247525, lr: 0.014725633797313148
[batch_idx--150] train_loss: 0.0011814647864562687, acc: 0.8680153145695364, lr: 0.014672741681972468
[batch_idx--200] train_loss: 0.0011735862353816628, acc: 0.8701026119402985, lr: 0.01461990524532032
[batch_idx--250] train_loss: 0.0011720760802894207, acc: 0.8704868027888446, lr: 0.014567124772220653
[batch_idx--300] train_loss: 0.0011725588256889254, acc: 0.8706135797342193, lr: 0.014514400547235684
[batch_idx--350] train_loss: 0.00117198403585076, acc: 0.8708711716524217, lr: 0.014461732854624376
[batch_idx--400] train_loss: 0.0011683022327595705, acc: 0.8713372817955112, lr: 0.014409121978340905
[batch_idx--450] train_loss: 0.001170390719448874, acc: 0.8714114624917555, lr: 0.014356568202033099
total time of one epoch: 293.44855761528015 s
train_loss:  0.001170390719448874  acc:  0.8714114624917555
->>lr:0.014357
test_loss:  0.0011592539498137102  test_acc:  0.8765355503164164
best acc:  87.66596351904703

------Epoch: 96------
[batch_idx--0] train_loss: 0.0010720877908170223, acc: 0.8828125, lr: 0.014355517710873192
[batch_idx--50] train_loss: 0.0011850054713660012, acc: 0.8694852941176471, lr: 0.014303022468435317
[batch_idx--100] train_loss: 0.0011653773219204775, acc: 0.8723313737623762, lr: 0.014250584898001182
[batch_idx--150] train_loss: 0.0011673031142752444, acc: 0.8718439569536424, lr: 0.014198205282284266
[batch_idx--200] train_loss: 0.0011679760837204644, acc: 0.8722209266169154, lr: 0.014145883903685591
[batch_idx--250] train_loss: 0.0011637577800028235, acc: 0.8728367778884463, lr: 0.014093621044292189
[batch_idx--300] train_loss: 0.0011667552001099798, acc: 0.8722876868770764, lr: 0.014041416985875627
[batch_idx--350] train_loss: 0.0011655639336667317, acc: 0.8723735754985755, lr: 0.013989272009890398
[batch_idx--400] train_loss: 0.00116678131128803, acc: 0.871658743765586, lr: 0.013937186397472484
[batch_idx--450] train_loss: 0.001170438272604307, acc: 0.8717152081091402, lr: 0.01388516042943782
total time of one epoch: 291.2590141296387 s
train_loss:  0.001170438272604307  acc:  0.8717152081091402
->>lr:0.013885
test_loss:  0.0011473883524442787  test_acc:  0.876907804938578
best acc:  87.66596351904703
Saving..

------Epoch: 97------
[batch_idx--0] train_loss: 0.0010513863526284695, acc: 0.875, lr: 0.01388412052037681
[batch_idx--50] train_loss: 0.0011897868049951892, acc: 0.867953431372549, lr: 0.01383215567857612
[batch_idx--100] train_loss: 0.0011870834589152053, acc: 0.8687732054455446, lr: 0.013780251047424422
[batch_idx--150] train_loss: 0.0011800681414323186, acc: 0.8702400662251656, lr: 0.013728406906761904
[batch_idx--200] train_loss: 0.0011834565582523001, acc: 0.8700248756218906, lr: 0.013676623536102595
[batch_idx--250] train_loss: 0.0011797888785140566, acc: 0.8706735557768924, lr: 0.013624901214632912
[batch_idx--300] train_loss: 0.0011826865469798619, acc: 0.8702891403654485, lr: 0.01357324022121012
[batch_idx--350] train_loss: 0.0011796079784302715, acc: 0.8706152065527065, lr: 0.013521640834360844
[batch_idx--400] train_loss: 0.0011820472760051674, acc: 0.8702560006234414, lr: 0.013470103332279566
[batch_idx--450] train_loss: 0.0011787635206371328, acc: 0.8712292151213247, lr: 0.013418627992827087
total time of one epoch: 289.8210611343384 s
train_loss:  0.0011787635206371328  acc:  0.8712292151213247
->>lr:0.013419
test_loss:  0.0011579071041342194  test_acc:  0.8750465318277701
best acc:  87.6907804938578

------Epoch: 98------
[batch_idx--0] train_loss: 0.001247028587386012, acc: 0.859375, lr: 0.013417599122003463
[batch_idx--50] train_loss: 0.0011562153162872966, acc: 0.8720128676470589, lr: 0.013366187474337023
[batch_idx--100] train_loss: 0.0011529833819523528, acc: 0.8726021039603961, lr: 0.013314838549554453
[batch_idx--150] train_loss: 0.0011675722730524888, acc: 0.8706281043046358, lr: 0.013263552624499875
[batch_idx--200] train_loss: 0.0011736339086143124, acc: 0.8699082711442786, lr: 0.01321232997567776
[batch_idx--250] train_loss: 0.0011701766022135952, acc: 0.8712649402390438, lr: 0.01316117087925142
[batch_idx--300] train_loss: 0.0011641191039389103, acc: 0.8716647632890365, lr: 0.013110075611041534
[batch_idx--350] train_loss: 0.001166989647735579, acc: 0.8718839031339032, lr: 0.01305904444652466
[batch_idx--400] train_loss: 0.0011662081452411717, acc: 0.8717951215710723, lr: 0.013008077660831736
[batch_idx--450] train_loss: 0.0011686806064900204, acc: 0.871862741694727, lr: 0.01295717552874661
total time of one epoch: 291.9116380214691 s
train_loss:  0.0011686806064900204  acc:  0.871862741694727
->>lr:0.012957
test_loss:  0.001162584510034745  test_acc:  0.8779004839310088
best acc:  87.6907804938578
Saving..

------Epoch: 99------
[batch_idx--0] train_loss: 0.0011705202050507069, acc: 0.87109375, lr: 0.012956158147457115
[batch_idx--50] train_loss: 0.0011736256305548344, acc: 0.8671875, lr: 0.012905322244772761
[batch_idx--100] train_loss: 0.0011680059844978376, acc: 0.8700881806930693, lr: 0.012854551549694835
[batch_idx--150] train_loss: 0.001161856653896586, acc: 0.8708350579470199, lr: 0.012803846335949954
[batch_idx--200] train_loss: 0.0011712751876613802, acc: 0.8704524253731343, lr: 0.012753206876911727
[batch_idx--250] train_loss: 0.00116507851948175, acc: 0.8712805029880478, lr: 0.012702633445599246
[batch_idx--300] train_loss: 0.0011609214949003881, acc: 0.8712754360465116, lr: 0.012652126314675622
[batch_idx--350] train_loss: 0.0011659109808419674, acc: 0.8712384259259259, lr: 0.012601685756446507
[batch_idx--400] train_loss: 0.0011656169892530284, acc: 0.8710840087281796, lr: 0.012551312042858621
[batch_idx--450] train_loss: 0.0011624999721442895, acc: 0.8719929183878918, lr: 0.012501005445498313
total time of one epoch: 296.80075216293335 s
train_loss:  0.0011624999721442895  acc:  0.8719929183878918
->>lr:0.012501
test_loss:  0.0011698688333154923  test_acc:  0.8741779377093932
best acc:  87.79004839310088

------Epoch: 100------
[batch_idx--0] train_loss: 0.0013381532626226544, acc: 0.83984375, lr: 0.012500000000000006
[batch_idx--50] train_loss: 0.001172222391081353, acc: 0.8706341911764706, lr: 0.012449762140604802
[batch_idx--100] train_loss: 0.001169470497314809, acc: 0.8716738861386139, lr: 0.012399591944936346
[batch_idx--150] train_loss: 0.0011559147750095323, acc: 0.8735771937086093, lr: 0.012349489683483728
[batch_idx--200] train_loss: 0.0011624405377739068, acc: 0.873056592039801, lr: 0.012299455626369788
[batch_idx--250] train_loss: 0.0011595862760371807, acc: 0.8734748505976095, lr: 0.012249490043349598
[batch_idx--300] train_loss: 0.0011595256707439218, acc: 0.8731312292358804, lr: 0.01219959320380913
[batch_idx--350] train_loss: 0.0011566138542403184, acc: 0.8734308226495726, lr: 0.012149765376763677
[batch_idx--400] train_loss: 0.001156754073358264, acc: 0.8736849283042394, lr: 0.012100006830856476
[batch_idx--450] train_loss: 0.0011597331385054326, acc: 0.8737199291838789, lr: 0.01205031783435723
total time of one epoch: 296.1897032260895 s
train_loss:  0.0011597331385054326  acc:  0.8737199291838789
->>lr:0.012050
test_loss:  0.0012137830767742176  test_acc:  0.8705794763618315
best acc:  87.79004839310088

------Epoch: 101------
[batch_idx--0] train_loss: 0.0008455422357656062, acc: 0.9140625, lr: 0.012049324765671741
[batch_idx--50] train_loss: 0.001161860797426426, acc: 0.8710171568627451, lr: 0.01199970698555119
[batch_idx--100] train_loss: 0.0011617426159976068, acc: 0.8715965346534653, lr: 0.011950159295598187
[batch_idx--150] train_loss: 0.0011503255705577352, acc: 0.8734478476821192, lr: 0.011900681962945607
[batch_idx--200] train_loss: 0.0011537737471968936, acc: 0.8735618781094527, lr: 0.011851275254347019
[batch_idx--250] train_loss: 0.0011552823111470566, acc: 0.8733036603585658, lr: 0.011801939436175232
[batch_idx--300] train_loss: 0.0011540968025233163, acc: 0.8731961171096345, lr: 0.01175267477442085
[batch_idx--350] train_loss: 0.0011519071330287178, acc: 0.8735087250712251, lr: 0.011703481534690844
[batch_idx--400] train_loss: 0.0011526644935348348, acc: 0.8735290679551122, lr: 0.011654359982207095
[batch_idx--450] train_loss: 0.0011538041982317798, acc: 0.8733727913354393, lr: 0.011605310381805019
total time of one epoch: 292.9025592803955 s
train_loss:  0.0011538041982317798  acc:  0.8733727913354393
->>lr:0.011605
test_loss:  0.001132630175093975  test_acc:  0.8771559746866857
best acc:  87.79004839310088

------Epoch: 102------
[batch_idx--0] train_loss: 0.0011870356975123286, acc: 0.8671875, lr: 0.01160433012552509
[batch_idx--50] train_loss: 0.0011316852189837863, acc: 0.8734681372549019, lr: 0.011555354188677439
[batch_idx--100] train_loss: 0.0011391708233144762, acc: 0.8731435643564357, lr: 0.011506450737694249
[batch_idx--150] train_loss: 0.0011435498711683892, acc: 0.8729563327814569, lr: 0.011457620036235043
[batch_idx--200] train_loss: 0.0011414606822075424, acc: 0.8728622512437811, lr: 0.011408862347567132
[batch_idx--250] train_loss: 0.0011479046714744452, acc: 0.8724632719123506, lr: 0.011360177934564142
[batch_idx--300] train_loss: 0.0011507320058055568, acc: 0.872326619601329, lr: 0.011311567059704701
[batch_idx--350] train_loss: 0.0011498315019023598, acc: 0.8726963141025641, lr: 0.01126302998507092
[batch_idx--400] train_loss: 0.0011476341358030637, acc: 0.8730225218204489, lr: 0.011214566972347026
[batch_idx--450] train_loss: 0.0011524867748646825, acc: 0.8729388690248898, lr: 0.01116617828281797
total time of one epoch: 292.45577025413513 s
train_loss:  0.0011524867748646825  acc:  0.8729388690248898
->>lr:0.011166
test_loss:  0.001150398100409086  test_acc:  0.8759151259461472
best acc:  87.79004839310088

------Epoch: 103------
[batch_idx--0] train_loss: 0.0009879576973617077, acc: 0.88671875, lr: 0.011165211268916392
[batch_idx--50] train_loss: 0.0011570196423003926, acc: 0.8745404411764706, lr: 0.011116898657806221
[batch_idx--100] train_loss: 0.0011488065073995085, acc: 0.8738397277227723, lr: 0.01106866089646273
[batch_idx--150] train_loss: 0.0011258139884074694, acc: 0.8769143211920529, lr: 0.011020498244956429
[batch_idx--200] train_loss: 0.001139463832201112, acc: 0.8745918843283582, lr: 0.010972410962952879
[batch_idx--250] train_loss: 0.0011378371950324284, acc: 0.8746109312749004, lr: 0.010924399309711284
[batch_idx--300] train_loss: 0.0011378213472392077, acc: 0.8748183139534884, lr: 0.010876463544083113
[batch_idx--350] train_loss: 0.0011389634727521606, acc: 0.8749220975783476, lr: 0.010828603924510663
[batch_idx--400] train_loss: 0.0011404347317142325, acc: 0.8745811253117207, lr: 0.010780820709025727
[batch_idx--450] train_loss: 0.0011421150620713155, acc: 0.8748568056375187, lr: 0.010733114155248157
total time of one epoch: 289.7708978652954 s
train_loss:  0.0011421150620713155  acc:  0.8748568056375187
->>lr:0.010733
test_loss:  0.0011452461741582706  test_acc:  0.8774041444347934
best acc:  87.79004839310088

------Epoch: 104------
[batch_idx--0] train_loss: 0.0011222637258470058, acc: 0.890625, lr: 0.010732160807889211
[batch_idx--50] train_loss: 0.001125372615277621, acc: 0.8793658088235294, lr: 0.010684532714024482
[batch_idx--100] train_loss: 0.0011201892820380554, acc: 0.8778233292079208, lr: 0.010636981800997085
[batch_idx--150] train_loss: 0.0011309264162216114, acc: 0.8758278145695364, lr: 0.01058950832517444
[batch_idx--200] train_loss: 0.0011300400579440876, acc: 0.8762437810945274, lr: 0.010542112542506449
[batch_idx--250] train_loss: 0.001131381811685415, acc: 0.8762450199203188, lr: 0.01049479470852415
[batch_idx--300] train_loss: 0.001136581975412849, acc: 0.8754023048172758, lr: 0.010447555078338317
[batch_idx--350] train_loss: 0.0011355245233502802, acc: 0.8752782229344729, lr: 0.010400393906638123
[batch_idx--400] train_loss: 0.0011372312029853853, acc: 0.8749902587281796, lr: 0.010353311447689712
[batch_idx--450] train_loss: 0.0011416514581188, acc: 0.8747786996216197, lr: 0.01030630795533484
total time of one epoch: 289.7595236301422 s
train_loss:  0.0011416514581188  acc:  0.8747786996216197
->>lr:0.010306
test_loss:  0.0011418719921237497  test_acc:  0.8759151259461472
best acc:  87.79004839310088

------Epoch: 105------
[batch_idx--0] train_loss: 0.0011506661539897323, acc: 0.8671875, lr: 0.010305368692688175
[batch_idx--50] train_loss: 0.0011269679856851843, acc: 0.8751531862745098, lr: 0.010258446007324987
[batch_idx--100] train_loss: 0.0011365185019163654, acc: 0.8757735148514851, lr: 0.010211602800015714
[batch_idx--150] train_loss: 0.0011367178017070011, acc: 0.8755949917218543, lr: 0.010164839323312217
[batch_idx--200] train_loss: 0.001133379809655694, acc: 0.8760105721393034, lr: 0.010118155829336504
[batch_idx--250] train_loss: 0.0011329131455539143, acc: 0.875949327689243, lr: 0.010071552569779364
[batch_idx--300] train_loss: 0.0011364453380534494, acc: 0.8754282599667774, lr: 0.010025029795898983
[batch_idx--350] train_loss: 0.0011345677885712467, acc: 0.8756899928774928, lr: 0.00997858775851964
[batch_idx--400] train_loss: 0.0011348377144198745, acc: 0.8756331826683291, lr: 0.00993222670803032
[batch_idx--450] train_loss: 0.0011424486291192525, acc: 0.875472975318499, lr: 0.009885946894383374
total time of one epoch: 288.5547065734863 s
train_loss:  0.0011424486291192525  acc:  0.875472975318499
->>lr:0.009886
test_loss:  0.0011383663696070614  test_acc:  0.8780245688050626
best acc:  87.79004839310088
Saving..

------Epoch: 106------
[batch_idx--0] train_loss: 0.0008582775481045246, acc: 0.91015625, lr: 0.00988502212844063
[batch_idx--50] train_loss: 0.0011422422990732478, acc: 0.8736979166666666, lr: 0.009838825433419594
[batch_idx--100] train_loss: 0.0011231060131766492, acc: 0.8770111386138614, lr: 0.009792710478807351
[batch_idx--150] train_loss: 0.0011337123320141918, acc: 0.8754397764900662, lr: 0.009746677513229449
[batch_idx--200] train_loss: 0.0011315671191319118, acc: 0.8764769900497512, lr: 0.00970072678486938
[batch_idx--250] train_loss: 0.0011328864579211431, acc: 0.8761516434262948, lr: 0.009654858541467274
[batch_idx--300] train_loss: 0.0011332556609206668, acc: 0.8761160714285714, lr: 0.009609073030318542
[batch_idx--350] train_loss: 0.0011346091292771985, acc: 0.8759682158119658, lr: 0.009563370498272567
[batch_idx--400] train_loss: 0.0011366693264667754, acc: 0.8755942175810474, lr: 0.009517751191731351
[batch_idx--450] train_loss: 0.0011401185027774695, acc: 0.8758461485055715, lr: 0.00947221535664816
total time of one epoch: 288.7708442211151 s
train_loss:  0.0011401185027774695  acc:  0.8758461485055715
->>lr:0.009472
test_loss:  0.0011507133878272881  test_acc:  0.8774041444347934
best acc:  87.80245688050627

------Epoch: 107------
[batch_idx--0] train_loss: 0.0008970230119302869, acc: 0.91796875, lr: 0.009471305493042243
[batch_idx--50] train_loss: 0.0011295004092686462, acc: 0.8770680147058824, lr: 0.00942585505176061
[batch_idx--100] train_loss: 0.0011216056640352132, acc: 0.8769337871287128, lr: 0.009380488577388602
[batch_idx--150] train_loss: 0.001133073638239567, acc: 0.8756984685430463, lr: 0.009335206314516387
[batch_idx--200] train_loss: 0.0011301721626920487, acc: 0.8759911380597015, lr: 0.0092900085072801
[batch_idx--250] train_loss: 0.001131397060701156, acc: 0.875996015936255, lr: 0.009244895399360565
[batch_idx--300] train_loss: 0.001133177424989876, acc: 0.8755191029900332, lr: 0.009199867233981912
[batch_idx--350] train_loss: 0.0011317200742813193, acc: 0.8756454772079773, lr: 0.009154924253910346
[batch_idx--400] train_loss: 0.001129801281172773, acc: 0.8756331826683291, lr: 0.009110066701452797
[batch_idx--450] train_loss: 0.0011324216410107492, acc: 0.8759936820911584, lr: 0.0090652948184556
total time of one epoch: 294.3295087814331 s
train_loss:  0.0011324216410107492  acc:  0.8759936820911584
->>lr:0.009065
test_loss:  0.0011277463033338652  test_acc:  0.8781486536791165
best acc:  87.80245688050627
Saving..

------Epoch: 108------
[batch_idx--0] train_loss: 0.0010538584319874644, acc: 0.8828125, lr: 0.009064400256282757
[batch_idx--50] train_loss: 0.0011276347030812473, acc: 0.87890625, lr: 0.009019716004806225
[batch_idx--100] train_loss: 0.0011257713702092372, acc: 0.8784421410891089, lr: 0.0089751179099095
[batch_idx--150] train_loss: 0.0011219573053007094, acc: 0.8780008278145696, lr: 0.008930606212040063
[batch_idx--200] train_loss: 0.001115983823807771, acc: 0.8786341728855721, lr: 0.00888618115117962
[batch_idx--250] train_loss: 0.0011162070948927407, acc: 0.8788128735059761, lr: 0.00884184296684277
[batch_idx--300] train_loss: 0.0011159720595854883, acc: 0.8788673172757475, lr: 0.00879759189807571
[batch_idx--350] train_loss: 0.0011161053380756467, acc: 0.8788839921652422, lr: 0.008753428183455004
[batch_idx--400] train_loss: 0.001116533421863688, acc: 0.8789841801745636, lr: 0.008709352061086187
[batch_idx--450] train_loss: 0.0011209641349616904, acc: 0.8783542194605478, lr: 0.008665363768602597
total time of one epoch: 293.1397705078125 s
train_loss:  0.0011209641349616904  acc:  0.8783542194605478
->>lr:0.008665
test_loss:  0.001128240236426601  test_acc:  0.8792654175456012
best acc:  87.81486536791165
Saving..

------Epoch: 109------
[batch_idx--0] train_loss: 0.0011248094961047173, acc: 0.8671875, lr: 0.008664484900247363
[batch_idx--50] train_loss: 0.0011492508929222822, acc: 0.8706341911764706, lr: 0.00862058643856546
[batch_idx--100] train_loss: 0.0011522603747988174, acc: 0.8702042079207921, lr: 0.0085767762853424
[batch_idx--150] train_loss: 0.0011411644591616825, acc: 0.8728269867549668, lr: 0.008533054676777554
[batch_idx--200] train_loss: 0.0011351073704618238, acc: 0.8737367848258707, lr: 0.008489421848592919
[batch_idx--250] train_loss: 0.0011257572763736742, acc: 0.8755135707171314, lr: 0.008445878036031801
[batch_idx--300] train_loss: 0.001128596383258329, acc: 0.8750648878737541, lr: 0.008402423473857626
[batch_idx--350] train_loss: 0.0011277729418179142, acc: 0.87541176994302, lr: 0.008359058396352615
[batch_idx--400] train_loss: 0.0011298242319744555, acc: 0.8751753428927681, lr: 0.008315783037316537
[batch_idx--450] train_loss: 0.0011307860828697377, acc: 0.875438261533655, lr: 0.008272597630065468
total time of one epoch: 290.2397029399872 s
train_loss:  0.0011307860828697377  acc:  0.875438261533655
->>lr:0.008273
test_loss:  0.0011518209218564703  test_acc:  0.8777763990569549
best acc:  87.92654175456012

------Epoch: 110------
[batch_idx--0] train_loss: 0.0007827853551134467, acc: 0.92578125, lr: 0.008271734841028545
[batch_idx--50] train_loss: 0.0010955800706356326, acc: 0.8805147058823529, lr: 0.008228641424457422
[batch_idx--100] train_loss: 0.0011076356548271925, acc: 0.8784421410891089, lr: 0.00818563842948918
[batch_idx--150] train_loss: 0.0011110854699794474, acc: 0.878983857615894, lr: 0.008142726087971458
[batch_idx--200] train_loss: 0.0011108474735291073, acc: 0.8791200248756219, lr: 0.00809990463126313
[batch_idx--250] train_loss: 0.001115911567177386, acc: 0.8778168575697212, lr: 0.008057174290233077
[batch_idx--300] train_loss: 0.0011150647253355018, acc: 0.8779588870431894, lr: 0.008014535295258926
[batch_idx--350] train_loss: 0.00111517789650926, acc: 0.8778935185185185, lr: 0.00797198787622585
[batch_idx--400] train_loss: 0.0011158594806467245, acc: 0.8776106608478803, lr: 0.007929532262525246
[batch_idx--450] train_loss: 0.0011221078690448571, acc: 0.8770958447599542, lr: 0.007887168683053591
total time of one epoch: 290.37792801856995 s
train_loss:  0.0011221078690448571  acc:  0.8770958447599542
->>lr:0.007887
test_loss:  0.0011367773278236745  test_acc:  0.8795135872937089
best acc:  87.92654175456012
Saving..

------Epoch: 111------
[batch_idx--0] train_loss: 0.0009970258688554168, acc: 0.8984375, lr: 0.00788632235178279
[batch_idx--50] train_loss: 0.0011106684082644242, acc: 0.8776041666666666, lr: 0.00784405288251919
[batch_idx--100] train_loss: 0.0011068790618533103, acc: 0.8779006806930693, lr: 0.007801875908340622
[batch_idx--150] train_loss: 0.0011131129168214535, acc: 0.8772764900662252, lr: 0.007759791656641275
[batch_idx--200] train_loss: 0.0011153376457948628, acc: 0.8776819029850746, lr: 0.007717800354315446
[batch_idx--250] train_loss: 0.001115218257119664, acc: 0.8778324203187251, lr: 0.007675902227756282
[batch_idx--300] train_loss: 0.0011143185286488742, acc: 0.8778420888704319, lr: 0.007634097502854598
[batch_idx--350] train_loss: 0.0011163998499348164, acc: 0.8774372329059829, lr: 0.007592386404997634
[batch_idx--400] train_loss: 0.0011199370106134072, acc: 0.8768605829177057, lr: 0.007550769159067847
[batch_idx--450] train_loss: 0.0011211246851841115, acc: 0.877269413684174, lr: 0.00750924598944171
total time of one epoch: 290.2018802165985 s
train_loss:  0.0011211246851841115  acc:  0.877269413684174
->>lr:0.007509
test_loss:  0.00114218303976498  test_acc:  0.8759151259461472
best acc:  87.9513587293709

------Epoch: 112------
[batch_idx--0] train_loss: 0.0011376012116670609, acc: 0.87109375, lr: 0.007508416487165862
[batch_idx--50] train_loss: 0.0011148217371573636, acc: 0.8755361519607843, lr: 0.007466989505996053
[batch_idx--100] train_loss: 0.0010982775446350254, acc: 0.8787515470297029, lr: 0.007425657052821996
[batch_idx--150] train_loss: 0.001102626938156981, acc: 0.8776903973509934, lr: 0.007384419350484717
[batch_idx--200] train_loss: 0.001106975591435695, acc: 0.8775069962686567, lr: 0.0073432766213143985
[batch_idx--250] train_loss: 0.0011070308705005217, acc: 0.8776456673306773, lr: 0.007302229087129178
[batch_idx--300] train_loss: 0.0011091019714210937, acc: 0.8782054609634552, lr: 0.007261276969233954
[batch_idx--350] train_loss: 0.0011138559220905317, acc: 0.8777265847578347, lr: 0.007220420488419194
[batch_idx--400] train_loss: 0.0011173603383294699, acc: 0.8770943734413965, lr: 0.007179659864959754
[batch_idx--450] train_loss: 0.0011196601096819113, acc: 0.87732148436144, lr: 0.007138995318613667
total time of one epoch: 290.5948073863983 s
train_loss:  0.0011196601096819113  acc:  0.87732148436144
->>lr:0.007139
test_loss:  0.0011471326345396863  test_acc:  0.878644993175332
best acc:  87.9513587293709

------Epoch: 113------
[batch_idx--0] train_loss: 0.0011751842685043812, acc: 0.86328125, lr: 0.007138183009179922
[batch_idx--50] train_loss: 0.0010853927301736, acc: 0.8821997549019608, lr: 0.007097616687346986
[batch_idx--100] train_loss: 0.0011079837245368722, acc: 0.8796797648514851, lr: 0.00705714688495745
[batch_idx--150] train_loss: 0.0011248071049648454, acc: 0.8780008278145696, lr: 0.007016773820201414
[batch_idx--200] train_loss: 0.0011177637466039526, acc: 0.878945118159204, lr: 0.00697649771074741
[batch_idx--250] train_loss: 0.001117632383447274, acc: 0.8787661852589641, lr: 0.006936318773741257
[batch_idx--300] train_loss: 0.0011154603363135427, acc: 0.8790360257475083, lr: 0.00689623722580488
[batch_idx--350] train_loss: 0.0011182291488935295, acc: 0.8788728632478633, lr: 0.006856253283035133
[batch_idx--400] train_loss: 0.001116745925259932, acc: 0.8790621103491272, lr: 0.00681636716100264
[batch_idx--450] train_loss: 0.0011195105677330576, acc: 0.8788402124483633, lr: 0.006776579074750619
total time of one epoch: 294.2509319782257 s
train_loss:  0.0011195105677330576  acc:  0.8788402124483633
->>lr:0.006777
test_loss:  0.0011206027913114277  test_acc:  0.8801340116639782
best acc:  87.9513587293709
Saving..

------Epoch: 114------
[batch_idx--0] train_loss: 0.0011462952243164182, acc: 0.87109375, lr: 0.006775784314464717
[batch_idx--50] train_loss: 0.001105572632285675, acc: 0.8779105392156863, lr: 0.006736096445698165
[batch_idx--100] train_loss: 0.0010879350702813135, acc: 0.8813428217821783, lr: 0.0066965070454860194
[batch_idx--150] train_loss: 0.0010948095590937019, acc: 0.8805360099337748, lr: 0.006657016327271753
[batch_idx--200] train_loss: 0.0011009052054104002, acc: 0.8795281405472637, lr: 0.006617624503966805
[batch_idx--250] train_loss: 0.0010969641006670417, acc: 0.879964516932271, lr: 0.006578331787949427
[batch_idx--300] train_loss: 0.001096732596916292, acc: 0.8799574335548173, lr: 0.006539138391063526
[batch_idx--350] train_loss: 0.0010991185061776866, acc: 0.8796407585470085, lr: 0.006500044524617568
[batch_idx--400] train_loss: 0.0011034864970619913, acc: 0.8791108167082294, lr: 0.0064610503993833834
[batch_idx--450] train_loss: 0.0011084758065459622, acc: 0.8788402124483633, lr: 0.006422156225595066
total time of one epoch: 291.579466342926 s
train_loss:  0.0011084758065459622  acc:  0.8788402124483633
->>lr:0.006422
test_loss:  0.001123795752002282  test_acc:  0.8822434545228937
best acc:  88.01340116639781
Saving..

------Epoch: 115------
[batch_idx--0] train_loss: 0.0010915385792031884, acc: 0.87109375, lr: 0.00642137936306515
[batch_idx--50] train_loss: 0.0010851947408096463, acc: 0.8817401960784313, lr: 0.006382587355775901
[batch_idx--100] train_loss: 0.0010873650772367965, acc: 0.8820389851485149, lr: 0.006343895722960522
[batch_idx--150] train_loss: 0.0011031152017488583, acc: 0.8795529801324503, lr: 0.006305304673222229
[batch_idx--200] train_loss: 0.0011075484790533448, acc: 0.8782843594527363, lr: 0.0062668144146219495
[batch_idx--250] train_loss: 0.001112805501570873, acc: 0.8777390438247012, lr: 0.006228425154677217
[batch_idx--300] train_loss: 0.0011115241594662104, acc: 0.8776474252491694, lr: 0.0061901371003610295
[batch_idx--350] train_loss: 0.0011086127736693264, acc: 0.8779825498575499, lr: 0.00615195045810075
[batch_idx--400] train_loss: 0.0011080773589387072, acc: 0.878146430798005, lr: 0.006113865433776986
[batch_idx--450] train_loss: 0.0011124065824192606, acc: 0.8779116187037873, lr: 0.006075882232722457
total time of one epoch: 293.274836063385 s
train_loss:  0.0011124065824192606  acc:  0.8779116187037873
->>lr:0.006076
test_loss:  0.0011246586104068882  test_acc:  0.8805062662861397
best acc:  88.22434545228937

------Epoch: 116------
[batch_idx--0] train_loss: 0.000911829702090472, acc: 0.89453125, lr: 0.006075123608706093
[batch_idx--50] train_loss: 0.0010927262163593196, acc: 0.8817401960784313, lr: 0.006037244478350651
[batch_idx--100] train_loss: 0.0010859202668485738, acc: 0.8820389851485149, lr: 0.00599946758436096
[batch_idx--150] train_loss: 0.0010763204321943669, acc: 0.8837437913907285, lr: 0.005961793130408489
[batch_idx--200] train_loss: 0.0010908195663206464, acc: 0.8819768345771144, lr: 0.005924221319612417
[batch_idx--250] train_loss: 0.001096875887768588, acc: 0.880867156374502, lr: 0.005886752354538527
[batch_idx--300] train_loss: 0.0010956960770477885, acc: 0.8808139534883721, lr: 0.0058493864371981065
[batch_idx--350] train_loss: 0.0010967047416082347, acc: 0.8805533297720798, lr: 0.005812123769046874
[batch_idx--400] train_loss: 0.0011010666013790522, acc: 0.8798706359102244, lr: 0.005774964550983902
[batch_idx--450] train_loss: 0.001108045841161771, acc: 0.8792307425278578, lr: 0.005737908983350504
total time of one epoch: 294.0468487739563 s
train_loss:  0.001108045841161771  acc:  0.8792307425278578
->>lr:0.005738
test_loss:  0.0011162378956180218  test_acc:  0.8826157091450553
best acc:  88.22434545228937
Saving..

------Epoch: 117------
[batch_idx--0] train_loss: 0.0010049460688605905, acc: 0.875, lr: 0.005737168930605272
[batch_idx--50] train_loss: 0.0011159645407186711, acc: 0.8808210784313726, lr: 0.005700219292222111
[batch_idx--100] train_loss: 0.001092401049030705, acc: 0.8818456064356436, lr: 0.005663373707252357
[batch_idx--150] train_loss: 0.0010901735517325878, acc: 0.8816225165562914, lr: 0.005626632374346372
[batch_idx--200] train_loss: 0.0010897727635114532, acc: 0.8816853233830846, lr: 0.005589995491592479
[batch_idx--250] train_loss: 0.0010886990462440952, acc: 0.8812095368525896, lr: 0.005553463256515865
[batch_idx--300] train_loss: 0.0010921825564689193, acc: 0.8804246262458472, lr: 0.005517035866077508
[batch_idx--350] train_loss: 0.001092001950823333, acc: 0.8809094551282052, lr: 0.0054807135166731365
[batch_idx--400] train_loss: 0.0010950688108397728, acc: 0.8803966645885287, lr: 0.005444496404132135
[batch_idx--450] train_loss: 0.0010994007544488631, acc: 0.879959732009581, lr: 0.005408384723716528
total time of one epoch: 287.75145745277405 s
train_loss:  0.0010994007544488631  acc:  0.879959732009581
->>lr:0.005408
test_loss:  0.0011320856660659948  test_acc:  0.8814989452785705
best acc:  88.26157091450553

------Epoch: 118------
[batch_idx--0] train_loss: 0.0010880634654313326, acc: 0.875, lr: 0.005407663566854007
[batch_idx--50] train_loss: 0.001105216088677373, acc: 0.8780637254901961, lr: 0.005371659627775735
[batch_idx--100] train_loss: 0.0010876509396700502, acc: 0.8816909034653465, lr: 0.005335761513517229
[batch_idx--150] train_loss: 0.0010944418246789977, acc: 0.8815707781456954, lr: 0.0052999694176206515
[batch_idx--200] train_loss: 0.0010946890225156734, acc: 0.8816853233830846, lr: 0.005264283533056586
[batch_idx--250] train_loss: 0.0010917336915144734, acc: 0.8816608565737052, lr: 0.0052287040522229575
[batch_idx--300] train_loss: 0.0010908679801512795, acc: 0.8818002491694352, lr: 0.005193231166944048
[batch_idx--350] train_loss: 0.0010922570713527734, acc: 0.8816773504273504, lr: 0.005157865068469426
[batch_idx--400] train_loss: 0.001093730031880794, acc: 0.8811175187032418, lr: 0.005122605947472936
[batch_idx--450] train_loss: 0.0010965559293417083, acc: 0.8812007498177526, lr: 0.0050874539940516635
total time of one epoch: 291.23367381095886 s
train_loss:  0.0010965559293417083  acc:  0.8812007498177526
->>lr:0.005087
test_loss:  0.0011045637982316757  test_acc:  0.884476982255863
best acc:  88.26157091450553
Saving..

------Epoch: 119------
[batch_idx--0] train_loss: 0.001043453230522573, acc: 0.875, lr: 0.005086752049395094
[batch_idx--50] train_loss: 0.0011166745280919998, acc: 0.8799019607843137, lr: 0.005051709602139323
[batch_idx--100] train_loss: 0.0011040702448364826, acc: 0.8806079826732673, lr: 0.005016774704691432
[batch_idx--150] train_loss: 0.0010907552736990204, acc: 0.8818553394039735, lr: 0.004981947545400465
[batch_idx--200] train_loss: 0.0010822709729149012, acc: 0.8825598569651741, lr: 0.004947228312034608
[batch_idx--250] train_loss: 0.0010827671874693013, acc: 0.8820343625498008, lr: 0.004912617191780173
[batch_idx--300] train_loss: 0.001092719721516588, acc: 0.8805284468438538, lr: 0.004878114371240583
[batch_idx--350] train_loss: 0.0010949647237488368, acc: 0.8798076923076923, lr: 0.004843720036435387
[batch_idx--400] train_loss: 0.0010933413092184003, acc: 0.8804551122194514, lr: 0.004809434372799207
[batch_idx--450] train_loss: 0.0010956098178547266, acc: 0.8804630818898185, lr: 0.004775257565180805
total time of one epoch: 289.1708207130432 s
train_loss:  0.0010956098178547266  acc:  0.8804630818898185
->>lr:0.004775
test_loss:  0.001109092190671254  test_acc:  0.8823675393969476
best acc:  88.44769822558631

------Epoch: 120------
[batch_idx--0] train_loss: 0.001213043462485075, acc: 0.859375, lr: 0.004774575140626317
[batch_idx--50] train_loss: 0.0010602866954571915, acc: 0.8848805147058824, lr: 0.004740509555968578
[batch_idx--100] train_loss: 0.0010741710470353097, acc: 0.8836246905940595, lr: 0.004706553198931926
[batch_idx--150] train_loss: 0.00107238330147445, acc: 0.8844939983443708, lr: 0.004672706252589681
[batch_idx--200] train_loss: 0.00107231343411771, acc: 0.8843672263681592, lr: 0.004638968899425284
[batch_idx--250] train_loss: 0.0010749479772920064, acc: 0.8835439492031872, lr: 0.004605341321331294
[batch_idx--300] train_loss: 0.0010867545294553735, acc: 0.8818262043189369, lr: 0.004571823699608443
[batch_idx--350] train_loss: 0.001089899645165734, acc: 0.8811542913105413, lr: 0.0045384162149646355
[batch_idx--400] train_loss: 0.001090654539103455, acc: 0.8810006234413965, lr: 0.004505119047513989
[batch_idx--450] train_loss: 0.001091424727131998, acc: 0.8809924671086888, lr: 0.0044719323767758445
total time of one epoch: 290.535701751709 s
train_loss:  0.001091424727131998  acc:  0.8809924671086888
->>lr:0.004472
test_loss:  0.0011136300149042623  test_acc:  0.8803821814120859
best acc:  88.44769822558631

------Epoch: 121------
[batch_idx--0] train_loss: 0.0011403693351894617, acc: 0.88671875, lr: 0.004471269771657399
[batch_idx--50] train_loss: 0.0010650808678702543, acc: 0.8839613970588235, lr: 0.004438195991889007
[batch_idx--100] train_loss: 0.0010595766327224007, acc: 0.8845142326732673, lr: 0.004405233069644058
[batch_idx--150] train_loss: 0.0010685294501125715, acc: 0.8836403145695364, lr: 0.004372381182639854
[batch_idx--200] train_loss: 0.0010730787012401728, acc: 0.8835121268656716, lr: 0.004339640507995033
[batch_idx--250] train_loss: 0.0010795745132695068, acc: 0.8830303784860558, lr: 0.00430701122222864
[batch_idx--300] train_loss: 0.001084558048673853, acc: 0.8822674418604651, lr: 0.004274493501259191
[batch_idx--350] train_loss: 0.0010847888485279115, acc: 0.8823116987179487, lr: 0.004242087520403681
[batch_idx--400] train_loss: 0.0010841857109792493, acc: 0.8820624220698254, lr: 0.004209793454376692
[batch_idx--450] train_loss: 0.0010902930729883376, acc: 0.8816520290207241, lr: 0.0041776114772894115
total time of one epoch: 290.28319811820984 s
train_loss:  0.0010902930729883376  acc:  0.8816520290207241
->>lr:0.004178
test_loss:  0.0011145560687285585  test_acc:  0.8833602183893783
best acc:  88.44769822558631

------Epoch: 122------
[batch_idx--0] train_loss: 0.0013094890164211392, acc: 0.8671875, lr: 0.004176968982247515
[batch_idx--50] train_loss: 0.0010585631175404962, acc: 0.8877144607843137, lr: 0.004144901514621361
[batch_idx--100] train_loss: 0.001067508481175519, acc: 0.884475556930693, lr: 0.0041129464857952575
[batch_idx--150] train_loss: 0.0010684701299529201, acc: 0.8853218129139073, lr: 0.004081104068052505
[batch_idx--200] train_loss: 0.0010757859505536914, acc: 0.8840757151741293, lr: 0.00404937443306925
[batch_idx--250] train_loss: 0.0010788675051635183, acc: 0.8837151394422311, lr: 0.004017757751913604
[batch_idx--300] train_loss: 0.0010816643522755301, acc: 0.8827605897009967, lr: 0.003986254195044678
[batch_idx--350] train_loss: 0.0010836411392226009, acc: 0.8825899216524217, lr: 0.003954863932311695
[batch_idx--400] train_loss: 0.0010873922495231814, acc: 0.8818188902743143, lr: 0.003923587132953052
[batch_idx--450] train_loss: 0.001089723084045515, acc: 0.8816259936820912, lr: 0.003892423965595415
total time of one epoch: 295.34637331962585 s
train_loss:  0.001089723084045515  acc:  0.8816259936820912
->>lr:0.003892
test_loss:  0.0011255873693309273  test_acc:  0.8801340116639782
best acc:  88.44769822558631

------Epoch: 123------
[batch_idx--0] train_loss: 0.0009017007541842759, acc: 0.90625, lr: 0.003891801862449629
[batch_idx--50] train_loss: 0.001073078284332273, acc: 0.883578431372549, lr: 0.003860754772816863
[batch_idx--100] train_loss: 0.0010755247549421275, acc: 0.8831992574257426, lr: 0.0038298216539413596
[batch_idx--150] train_loss: 0.0010753561764190727, acc: 0.8833040149006622, lr: 0.0037990026725968685
[batch_idx--200] train_loss: 0.001077288353412565, acc: 0.8825792910447762, lr: 0.003768297994941761
[batch_idx--250] train_loss: 0.001076619538981319, acc: 0.8829992529880478, lr: 0.0037377077865181603
[batch_idx--300] train_loss: 0.0010768018882997036, acc: 0.8833056478405316, lr: 0.003707232212251013
[batch_idx--350] train_loss: 0.0010796338175503043, acc: 0.8830573361823362, lr: 0.003676871436447249
[batch_idx--400] train_loss: 0.0010786728385924142, acc: 0.8828125, lr: 0.0036466256227948553
[batch_idx--450] train_loss: 0.0010819694850225635, acc: 0.8828756899364738, lr: 0.003616494934362016
total time of one epoch: 292.6013696193695 s
train_loss:  0.0010819694850225635  acc:  0.8828756899364738
->>lr:0.003616
test_loss:  0.0011231746219023684  test_acc:  0.8826157091450553
best acc:  88.44769822558631

------Epoch: 124------
[batch_idx--0] train_loss: 0.0010543079115450382, acc: 0.88671875, lr: 0.003615893495987335
[batch_idx--50] train_loss: 0.0010651059645027214, acc: 0.8861060049019608, lr: 0.003585880402627581
[batch_idx--100] train_loss: 0.0010826495870265482, acc: 0.8834313118811881, lr: 0.0035559827619909834
[batch_idx--150] train_loss: 0.001079057698717822, acc: 0.8840024834437086, lr: 0.0035262007352685563
[batch_idx--200] train_loss: 0.0010847004839399858, acc: 0.882929104477612, lr: 0.003496534483028016
[batch_idx--250] train_loss: 0.0010828890142483688, acc: 0.8828903137450199, lr: 0.0034669841652128805
[batch_idx--300] train_loss: 0.0010881367438485183, acc: 0.8820338455149501, lr: 0.00343754994114161
[batch_idx--350] train_loss: 0.001088633893874933, acc: 0.8816328347578347, lr: 0.0034082319695067616
[batch_idx--400] train_loss: 0.0010868445389493, acc: 0.8817312188279302, lr: 0.003379030408374123
[batch_idx--450] train_loss: 0.001090879863563289, acc: 0.8816433505745132, lr: 0.00334994541518186
total time of one epoch: 293.3735749721527 s
train_loss:  0.001090879863563289  acc:  0.8816433505745132
->>lr:0.003350
test_loss:  0.0011083880973995317  test_acc:  0.881995284774786
best acc:  88.44769822558631

------Epoch: 125------
[batch_idx--0] train_loss: 0.0009640417993068695, acc: 0.8984375, lr: 0.003349364905389038
[batch_idx--50] train_loss: 0.0010870048232997458, acc: 0.8812806372549019, lr: 0.003320398973036992
[batch_idx--100] train_loss: 0.001080599174336853, acc: 0.8828125, lr: 0.0032915499247325843
[batch_idx--150] train_loss: 0.001072819193590753, acc: 0.8843387831125827, lr: 0.003262817916013447
[batch_idx--200] train_loss: 0.0010730254814834959, acc: 0.8843477922885572, lr: 0.0032342031017861847
[batch_idx--250] train_loss: 0.0010726330416885564, acc: 0.883808515936255, lr: 0.003205705636325565
[batch_idx--300] train_loss: 0.0010683731896496467, acc: 0.8843957641196013, lr: 0.0031773256732736594
[batch_idx--350] train_loss: 0.0010730414394291908, acc: 0.8839031339031339, lr: 0.0031490633656390573
[batch_idx--400] train_loss: 0.0010712948702380266, acc: 0.8843418796758105, lr: 0.0031209188657960046
[batch_idx--450] train_loss: 0.0010778458632062459, acc: 0.8838910681431597, lr: 0.0030928923254835983
total time of one epoch: 288.0896396636963 s
train_loss:  0.0010778458632062459  acc:  0.8838910681431597
->>lr:0.003093
test_loss:  0.001118697783523642  test_acc:  0.8813748604045167
best acc:  88.44769822558631

------Epoch: 126------
[batch_idx--0] train_loss: 0.0012055870611220598, acc: 0.88671875, lr: 0.0030923329989034107
[batch_idx--50] train_loss: 0.0010625070654878429, acc: 0.8874080882352942, lr: 0.003064426932974329
[batch_idx--100] train_loss: 0.0010666108925338133, acc: 0.8854037747524752, lr: 0.003036639131148192
[batch_idx--150] train_loss: 0.0010764667859134442, acc: 0.8842870447019867, lr: 0.003008969743240972
[batch_idx--200] train_loss: 0.0010727656277160701, acc: 0.8838813743781094, lr: 0.002981418918430234
[batch_idx--250] train_loss: 0.0010810055446707127, acc: 0.8825946215139442, lr: 0.002953986805254319
[batch_idx--300] train_loss: 0.0010806191128607456, acc: 0.88250103820598, lr: 0.002926673551611542
[batch_idx--350] train_loss: 0.0010745162056411412, acc: 0.8830573361823362, lr: 0.002899479304759398
[batch_idx--400] train_loss: 0.0010721902985722663, acc: 0.8834262001246883, lr: 0.0028724042113137424
[batch_idx--450] train_loss: 0.001073253873974777, acc: 0.8837869267886278, lr: 0.002845448417248059
total time of one epoch: 288.72303652763367 s
train_loss:  0.001073253873974777  acc:  0.8837869267886278
->>lr:0.002845
test_loss:  0.0011048651441242043  test_acc:  0.8857178309964016
best acc:  88.44769822558631
Saving..

------Epoch: 127------
[batch_idx--0] train_loss: 0.001256964635103941, acc: 0.8359375, lr: 0.0028449105192196373
[batch_idx--50] train_loss: 0.00105860520053801, acc: 0.8809742647058824, lr: 0.0028180765602363435
[batch_idx--100] train_loss: 0.0010497952496752807, acc: 0.8837407178217822, lr: 0.0027913621935367313
[batch_idx--150] train_loss: 0.0010511529988868299, acc: 0.8837179221854304, lr: 0.002764767563149445
[batch_idx--200] train_loss: 0.0010517601150236283, acc: 0.8843672263681592, lr: 0.002738292812457563
[batch_idx--250] train_loss: 0.0010620152799920939, acc: 0.8835595119521913, lr: 0.00271193808419784
[batch_idx--300] train_loss: 0.0010641667815126429, acc: 0.8833705357142857, lr: 0.002685703520459948
[batch_idx--350] train_loss: 0.0010614024620818935, acc: 0.8837250712250713, lr: 0.0026595892626856965
[batch_idx--400] train_loss: 0.0010650099077763645, acc: 0.8835625779301746, lr: 0.0026335954516682747
[batch_idx--450] train_loss: 0.0010684371037501755, acc: 0.8834484673863991, lr: 0.0026077222275514957
total time of one epoch: 287.98948550224304 s
train_loss:  0.0010684371037501755  acc:  0.8834484673863991
->>lr:0.002608
test_loss:  0.001113639962571122  test_acc:  0.8855937461223476
best acc:  88.57178309964016

------Epoch: 128------
[batch_idx--0] train_loss: 0.0012049399083480239, acc: 0.8515625, lr: 0.0026072059940146775
[batch_idx--50] train_loss: 0.0010990359964232672, acc: 0.8782935049019608, lr: 0.002581455912238459
[batch_idx--100] train_loss: 0.0010818445076474386, acc: 0.8813041460396039, lr: 0.0025558266984695406
[batch_idx--150] train_loss: 0.0010786621607007422, acc: 0.8817001241721855, lr: 0.002530318490886033
[batch_idx--200] train_loss: 0.0010775705105601926, acc: 0.8817824937810945, lr: 0.0025049314270136516
[batch_idx--250] train_loss: 0.0010735703322876883, acc: 0.8825790587649402, lr: 0.0024796656437249655
[batch_idx--300] train_loss: 0.001075803487294004, acc: 0.882202553986711, lr: 0.0024545212772386807
[batch_idx--350] train_loss: 0.0010736580048236687, acc: 0.8827791132478633, lr: 0.0024294984631188735
[batch_idx--400] train_loss: 0.0010753714267868187, acc: 0.8825202618453866, lr: 0.0024045973362742893
[batch_idx--450] train_loss: 0.0010741062186363276, acc: 0.8832141493387023, lr: 0.0023798180309576172
total time of one epoch: 287.69971084594727 s
train_loss:  0.0010741062186363276  acc:  0.8832141493387023
->>lr:0.002380
test_loss:  0.001107732914106206  test_acc:  0.8868345948628862
best acc:  88.57178309964016
Saving..

------Epoch: 129------
[batch_idx--0] train_loss: 0.000932189344894141, acc: 0.89453125, lr: 0.0023793236883495163
[batch_idx--50] train_loss: 0.0010674615189725277, acc: 0.8819699754901961, lr: 0.002354668778617275
[batch_idx--100] train_loss: 0.001071878979766354, acc: 0.884011448019802, lr: 0.0023301359595992556
[batch_idx--150] train_loss: 0.0010685604647733271, acc: 0.8849855132450332, lr: 0.0023057253635624278
[batch_idx--200] train_loss: 0.0010775773527114583, acc: 0.8839785447761194, lr: 0.0022814371221148186
[batch_idx--250] train_loss: 0.001083079515399775, acc: 0.8831704432270916, lr: 0.0022572713662047635
[batch_idx--300] train_loss: 0.001078520217126056, acc: 0.883422446013289, lr: 0.0022332282261202457
[batch_idx--350] train_loss: 0.0010761757352405316, acc: 0.8833689458689459, lr: 0.0022093078314881667
[batch_idx--400] train_loss: 0.0010756820479774862, acc: 0.8835333541147132, lr: 0.002185510311273653
[batch_idx--450] train_loss: 0.0010815203938865073, acc: 0.8834484673863991, lr: 0.0021618357937793764
total time of one epoch: 290.4616234302521 s
train_loss:  0.0010815203938865073  acc:  0.8834484673863991
->>lr:0.002162
test_loss:  0.0011161995212912545  test_acc:  0.8858419158704554
best acc:  88.68345948628863

------Epoch: 130------
[batch_idx--0] train_loss: 0.0010888194665312767, acc: 0.88671875, lr: 0.0021613635589349755
[batch_idx--50] train_loss: 0.0010512222241445938, acc: 0.8843443627450981, lr: 0.0021378146357049848
[batch_idx--100] train_loss: 0.0010534104381660276, acc: 0.8852490717821783, lr: 0.0021143889723431067
[batch_idx--150] train_loss: 0.0010575722453542151, acc: 0.8853735513245033, lr: 0.0020910866951471623
[batch_idx--200] train_loss: 0.0010588017865130446, acc: 0.8849696828358209, lr: 0.0020679079297497515
[batch_idx--250] train_loss: 0.0010635705692118472, acc: 0.8843376494023905, lr: 0.0020448528011175527
[batch_idx--300] train_loss: 0.0010687047265627828, acc: 0.8835522217607974, lr: 0.0020219214335506857
[batch_idx--350] train_loss: 0.0010662474686099466, acc: 0.884025551994302, lr: 0.0019991139506819965
[batch_idx--400] train_loss: 0.0010628262971657935, acc: 0.8846925654613467, lr: 0.001976430475476429
[batch_idx--450] train_loss: 0.0010621615903069319, acc: 0.8847762696566807, lr: 0.0019538711302303584
total time of one epoch: 294.1642904281616 s
train_loss:  0.0010621615903069319  acc:  0.8847762696566807
->>lr:0.001954
test_loss:  0.0011088296221893913  test_acc:  0.8853455763742399
best acc:  88.68345948628863

------Epoch: 131------
[batch_idx--0] train_loss: 0.0013058047043159604, acc: 0.8671875, lr: 0.00195342121028749
[batch_idx--50] train_loss: 0.0010501765908545577, acc: 0.8845741421568627, lr: 0.001930988602895767
[batch_idx--100] train_loss: 0.0010624085282123104, acc: 0.8832766089108911, lr: 0.001908680370460203
[batch_idx--150] train_loss: 0.0010604875043515635, acc: 0.8835109685430463, lr: 0.0018864966332540673
[batch_idx--200] train_loss: 0.0010615785186878631, acc: 0.8833760883084577, lr: 0.0018644375108794243
[batch_idx--250] train_loss: 0.001059872052350278, acc: 0.8841042081673307, lr: 0.0018425031222664813
[batch_idx--300] train_loss: 0.0010639550999747558, acc: 0.883811773255814, lr: 0.0018206935856729584
[batch_idx--350] train_loss: 0.0010637001043578287, acc: 0.8836694266381766, lr: 0.0017990090186834396
[batch_idx--400] train_loss: 0.0010692671246471306, acc: 0.8829196539900249, lr: 0.0017774495382087503
[batch_idx--450] train_loss: 0.0010704961388275898, acc: 0.8831186864303815, lr: 0.001756015260485311
total time of one epoch: 294.1294445991516 s
train_loss:  0.0010704961388275898  acc:  0.8831186864303815
->>lr:0.001756
test_loss:  0.0011109634041268472  test_acc:  0.8827397940191091
best acc:  88.68345948628863

------Epoch: 132------
[batch_idx--0] train_loss: 0.0008491341723129153, acc: 0.91796875, lr: 0.0017555878527937164
[batch_idx--50] train_loss: 0.001064546013652694, acc: 0.8831188725490197, lr: 0.0017342814009232738
[batch_idx--100] train_loss: 0.0010652003128607157, acc: 0.8834313118811881, lr: 0.0017131003845420657
[batch_idx--150] train_loss: 0.001059483733284133, acc: 0.8843646523178808, lr: 0.0016920449178460556
[batch_idx--200] train_loss: 0.001052979212219535, acc: 0.8850668532338308, lr: 0.0016711151143543159
[batch_idx--250] train_loss: 0.0010579816769322463, acc: 0.8848200946215139, lr: 0.0016503110869084154
[batch_idx--300] train_loss: 0.0010609170870601735, acc: 0.8844995847176079, lr: 0.0016296329476718054
[batch_idx--350] train_loss: 0.0010605410392796806, acc: 0.8844484508547008, lr: 0.0016090808081292208
[batch_idx--400] train_loss: 0.0010602924610752882, acc: 0.8846438591022444, lr: 0.0015886547790860768
[batch_idx--450] train_loss: 0.0010653652994867854, acc: 0.884498559377929, lr: 0.0015683549706678873
total time of one epoch: 289.35504269599915 s
train_loss:  0.0010653652994867854  acc:  0.884498559377929
->>lr:0.001568
test_loss:  0.001109881811689866  test_acc:  0.8870827646109939
best acc:  88.68345948628863
Saving..

------Epoch: 133------
[batch_idx--0] train_loss: 0.0008399372454732656, acc: 0.921875, lr: 0.0015679502627027138
[batch_idx--50] train_loss: 0.0010398084163099673, acc: 0.8890931372549019, lr: 0.0015477793120675237
[batch_idx--100] train_loss: 0.0010633312614109036, acc: 0.884166150990099, lr: 0.0015277348024344995
[batch_idx--150] train_loss: 0.0010634542154518284, acc: 0.8840024834437086, lr: 0.001507816841872195
[batch_idx--200] train_loss: 0.001067890191684704, acc: 0.8836287313432836, lr: 0.0014880255377669072
[batch_idx--250] train_loss: 0.0010671332419156078, acc: 0.8836840139442231, lr: 0.0014683609968220602
[batch_idx--300] train_loss: 0.0010648713185315785, acc: 0.8836300872093024, lr: 0.0014488233250576467
[batch_idx--350] train_loss: 0.0010601507451390567, acc: 0.8844595797720798, lr: 0.0014294126278096538
[batch_idx--400] train_loss: 0.0010575471285375257, acc: 0.8849166147132169, lr: 0.0014101290097294967
[batch_idx--450] train_loss: 0.0010601549248683455, acc: 0.8850973721664873, lr: 0.0013909725747834447
total time of one epoch: 291.2796206474304 s
train_loss:  0.0010601549248683455  acc:  0.8850973721664873
->>lr:0.001391
test_loss:  0.0011181591654374117  test_acc:  0.8829879637672168
best acc:  88.70827646109939

------Epoch: 134------
[batch_idx--0] train_loss: 0.0008429537992924452, acc: 0.921875, lr: 0.001390590744062975
[batch_idx--50] train_loss: 0.0010564458115921154, acc: 0.8875612745098039, lr: 0.0013715641423086456
[batch_idx--100] train_loss: 0.001061599275171019, acc: 0.8848236386138614, lr: 0.0013526649316081968
[batch_idx--150] train_loss: 0.001066527256529334, acc: 0.8847268211920529, lr: 0.0013338932138554
[batch_idx--200] train_loss: 0.0010580539750282777, acc: 0.8858053482587065, lr: 0.0013152490902566538
[batch_idx--250] train_loss: 0.0010596735062508053, acc: 0.8856293575697212, lr: 0.0012967326613304436
[batch_idx--300] train_loss: 0.001058860557607106, acc: 0.8856545888704319, lr: 0.0012783440269067943
[batch_idx--350] train_loss: 0.0010560128895534028, acc: 0.8860287571225072, lr: 0.0012600832861267342
[batch_idx--400] train_loss: 0.001056083646850275, acc: 0.886134273690773, lr: 0.0012419505374417718
[batch_idx--450] train_loss: 0.0010571455890173449, acc: 0.8860172874648523, lr: 0.0012239458786133446
total time of one epoch: 290.15469908714294 s
train_loss:  0.0010571455890173449  acc:  0.8860172874648523
->>lr:0.001224
test_loss:  0.0011202025419430012  test_acc:  0.883608388137486
best acc:  88.70827646109939

------Epoch: 135------
[batch_idx--0] train_loss: 0.0012366216396912932, acc: 0.85546875, lr: 0.0012235870926211618
[batch_idx--50] train_loss: 0.0011003436440802819, acc: 0.8774509803921569, lr: 0.0012057131854440546
[batch_idx--100] train_loss: 0.001072684211292221, acc: 0.883121905940594, lr: 0.0011879675634946297
[batch_idx--150] train_loss: 0.001066639114306956, acc: 0.8840024834437086, lr: 0.0011703503224471529
[batch_idx--200] train_loss: 0.0010647981196516818, acc: 0.8838619402985075, lr: 0.001152861557283752
[batch_idx--250] train_loss: 0.001063007642923153, acc: 0.8835283864541833, lr: 0.0011355013622938726
[batch_idx--300] train_loss: 0.0010665139133896543, acc: 0.88312396179402, lr: 0.0011182698310737928
[batch_idx--350] train_loss: 0.0010650740986811978, acc: 0.8832576566951567, lr: 0.0011011670565261005
[batch_idx--400] train_loss: 0.0010676128482631875, acc: 0.8829975841645885, lr: 0.0010841931308592041
[batch_idx--450] train_loss: 0.0010692246988134838, acc: 0.8833009338008123, lr: 0.00106734814558683
total time of one epoch: 291.3876242637634 s
train_loss:  0.0010692246988134838  acc:  0.8833009338008123
->>lr:0.001067
test_loss:  0.00111124295760272  test_acc:  0.8852214915001861
best acc:  88.70827646109939

------Epoch: 136------
[batch_idx--0] train_loss: 0.0012213395675644279, acc: 0.85546875, lr: 0.001067012561698319
[batch_idx--50] train_loss: 0.0010684758171384387, acc: 0.8845741421568627, lr: 0.0010502991891848613
[batch_idx--100] train_loss: 0.0010596803092111898, acc: 0.8874149133663366, lr: 0.0010337149398027378
[batch_idx--150] train_loss: 0.0010648413633755007, acc: 0.886770488410596, lr: 0.001017259902964765
[batch_idx--200] train_loss: 0.0010629202290183277, acc: 0.8863106343283582, lr: 0.0010009341673871241
[batch_idx--250] train_loss: 0.0010625588444647827, acc: 0.8864074950199203, lr: 0.000984737821088863
[batch_idx--300] train_loss: 0.0010595448240498545, acc: 0.8858232973421927, lr: 0.000968670951391451
[batch_idx--350] train_loss: 0.0010599519809020785, acc: 0.8856503739316239, lr: 0.0009527336449182884
[batch_idx--400] train_loss: 0.001059482631243375, acc: 0.8854426433915212, lr: 0.0009369259875942449
[batch_idx--450] train_loss: 0.0010601641101330146, acc: 0.8855920436005138, lr: 0.0009212480646451971
total time of one epoch: 290.4690315723419 s
train_loss:  0.0010601641101330146  acc:  0.8855920436005138
->>lr:0.000921
test_loss:  0.0011103867500824437  test_acc:  0.8853455763742399
best acc:  88.70827646109939

------Epoch: 137------
[batch_idx--0] train_loss: 0.0009169640834443271, acc: 0.89453125, lr: 0.0009209358300585474
[batch_idx--50] train_loss: 0.0010636234336404823, acc: 0.8864889705882353, lr: 0.0009053903232463079
[batch_idx--100] train_loss: 0.001053231487645408, acc: 0.8876856435643564, lr: 0.0008899747208313852
[batch_idx--150] train_loss: 0.001057643093714577, acc: 0.886615273178808, lr: 0.0008746891059259105
[batch_idx--200] train_loss: 0.0010592835220920654, acc: 0.8857081778606966, lr: 0.0008595335609412142
[batch_idx--250] train_loss: 0.001054992186196846, acc: 0.8864853087649402, lr: 0.0008445081675873518
[batch_idx--300] train_loss: 0.0010488000698387623, acc: 0.8872897632890365, lr: 0.0008296130068726787
[batch_idx--350] train_loss: 0.0010557856531468806, acc: 0.8868411680911681, lr: 0.0008148481591034013
[batch_idx--400] train_loss: 0.0010511701969555265, acc: 0.8873519326683291, lr: 0.0008002137038831625
[batch_idx--450] train_loss: 0.0010545670476141693, acc: 0.887240948380602, lr: 0.000785709720112604
total time of one epoch: 292.7734384536743 s
train_loss:  0.0010545670476141693  acc:  0.887240948380602
->>lr:0.000786
test_loss:  0.0011056103870847678  test_acc:  0.8857178309964016
best acc:  88.70827646109939

------Epoch: 138------
[batch_idx--0] train_loss: 0.0009225081885233521, acc: 0.91015625, lr: 0.0007854209717842232
[batch_idx--50] train_loss: 0.0010599966695093934, acc: 0.8843443627450981, lr: 0.0007710501494462701
[batch_idx--100] train_loss: 0.0010659012391397932, acc: 0.8840887995049505, lr: 0.0007568099557912517
[batch_idx--150] train_loss: 0.001057260493602949, acc: 0.8854511589403974, lr: 0.000742700467594179
[batch_idx--200] train_loss: 0.0010595394142634649, acc: 0.8852417599502488, lr: 0.0007287217609253605
[batch_idx--250] train_loss: 0.001059914425208393, acc: 0.8849757221115537, lr: 0.0007148739111500131
[batch_idx--300] train_loss: 0.0010620374901628624, acc: 0.8837858181063123, lr: 0.0007011569929278511
[batch_idx--350] train_loss: 0.0010619725028060887, acc: 0.8835024928774928, lr: 0.0006875710802126706
[batch_idx--400] train_loss: 0.0010587894745308097, acc: 0.8838158509975063, lr: 0.0006741162462519713
[batch_idx--450] train_loss: 0.0010566101719375353, acc: 0.8846981636407818, lr: 0.0006607925635865458
total time of one epoch: 293.2856168746948 s
train_loss:  0.0010566101719375353  acc:  0.8846981636407818
->>lr:0.000661
test_loss:  0.0011066533056555707  test_acc:  0.8849733217520784
best acc:  88.70827646109939

------Epoch: 139------
[batch_idx--0] train_loss: 0.0011702252086251974, acc: 0.87890625, lr: 0.0006605274281709927
[batch_idx--50] train_loss: 0.001037465403879098, acc: 0.8877910539215687, lr: 0.0006473375938249676
[batch_idx--100] train_loss: 0.0010321514541513776, acc: 0.8881110767326733, lr: 0.0006342790551494393
[batch_idx--150] train_loss: 0.0010290969878632501, acc: 0.8882709023178808, lr: 0.0006213518825486042
[batch_idx--200] train_loss: 0.0010359090192831905, acc: 0.8881763059701493, lr: 0.0006085561457184031
[batch_idx--250] train_loss: 0.0010376472540470619, acc: 0.8878703934262948, lr: 0.0005958919136461599
[batch_idx--300] train_loss: 0.0010401150395403743, acc: 0.8879775747508306, lr: 0.000583359254610194
[batch_idx--350] train_loss: 0.0010373605985029937, acc: 0.8884771189458689, lr: 0.0005709582361794502
[batch_idx--400] train_loss: 0.0010357414477648785, acc: 0.888628039276808, lr: 0.0005586889252131494
[batch_idx--450] train_loss: 0.0010414596926482354, acc: 0.8884819661887735, lr: 0.0005465513878604278
total time of one epoch: 292.86570978164673 s
train_loss:  0.0010414596926482354  acc:  0.8884819661887735
->>lr:0.000547
test_loss:  0.0011095142380033627  test_acc:  0.8854696612482938
best acc:  88.70827646109939

------Epoch: 140------
[batch_idx--0] train_loss: 0.0013110830914229155, acc: 0.85546875, lr: 0.0005463099816548578
[batch_idx--50] train_loss: 0.0010619532949218125, acc: 0.8828125, lr: 0.0005343069207980278
[batch_idx--100] train_loss: 0.0010614993038015569, acc: 0.8835860148514851, lr: 0.0005224357650086414
[batch_idx--150] train_loss: 0.0010564589648606219, acc: 0.8849855132450332, lr: 0.0005106965782891965
[batch_idx--200] train_loss: 0.0010475577700846082, acc: 0.8861940298507462, lr: 0.0004990894239306987
[batch_idx--250] train_loss: 0.0010491319376867694, acc: 0.8864541832669323, lr: 0.0004876143645123038
[batch_idx--300] train_loss: 0.0010504636235157665, acc: 0.8861217815614618, lr: 0.00047627146190098725
[batch_idx--350] train_loss: 0.0010463060264573817, acc: 0.8865740740740741, lr: 0.00046506077725121944
[batch_idx--400] train_loss: 0.001044149657605713, acc: 0.8869720230673317, lr: 0.00045398237100461594
[batch_idx--450] train_loss: 0.0010506874450503152, acc: 0.8865987433609887, lr: 0.0004430363028896239
total time of one epoch: 288.65746116638184 s
train_loss:  0.0010506874450503152  acc:  0.8865987433609887
->>lr:0.000443
test_loss:  0.001107738817991017  test_acc:  0.886214170492617
best acc:  88.70827646109939

------Epoch: 141------
[batch_idx--0] train_loss: 0.0012365214060992002, acc: 0.8515625, lr: 0.00044281873178278475
[batch_idx--50] train_loss: 0.001027189844570981, acc: 0.8899356617647058, lr: 0.0004320077093543484
[batch_idx--100] train_loss: 0.0010305814448476648, acc: 0.8903929455445545, lr: 0.0004213291435323757
[batch_idx--150] train_loss: 0.0010298288038728253, acc: 0.8891504552980133, lr: 0.0004107830918895994
[batch_idx--200] train_loss: 0.0010340189777282229, acc: 0.8887010261194029, lr: 0.00040036961128431806
[batch_idx--250] train_loss: 0.0010379643603395004, acc: 0.8882594621513944, lr: 0.00039008875786008537
[batch_idx--300] train_loss: 0.0010403007796062063, acc: 0.8879126868770764, lr: 0.00037994058704539927
[batch_idx--350] train_loss: 0.0010470930270338563, acc: 0.8874755163817664, lr: 0.0003699251535534104
[batch_idx--400] train_loss: 0.001048915212285331, acc: 0.8869817643391521, lr: 0.0003600425113816253
[batch_idx--450] train_loss: 0.0010500734660764254, acc: 0.8867462769465755, lr: 0.0003502927138116147
total time of one epoch: 287.1909091472626 s
train_loss:  0.0010500734660764254  acc:  0.8867462769465755
->>lr:0.000350
test_loss:  0.0011079855423172438  test_acc:  0.8847251520039707
best acc:  88.70827646109939

------Epoch: 142------
[batch_idx--0] train_loss: 0.001147818984463811, acc: 0.8828125, lr: 0.00035009907323737546
[batch_idx--50] train_loss: 0.0010540674579804581, acc: 0.8834252450980392, lr: 0.00034048483130907914
[batch_idx--100] train_loss: 0.0010546663122500597, acc: 0.8837793935643564, lr: 0.00033100353942642217
[batch_idx--150] train_loss: 0.0010388046233230177, acc: 0.8859426738410596, lr: 0.0003216552487071145
[batch_idx--200] train_loss: 0.0010361699717564147, acc: 0.8869519589552238, lr: 0.00031244000955181765
[batch_idx--250] train_loss: 0.001038263168323236, acc: 0.8870611304780877, lr: 0.00030335787164384453
[batch_idx--300] train_loss: 0.001038923307493688, acc: 0.8868615033222591, lr: 0.00029440888394890454
[batch_idx--350] train_loss: 0.0010381015979464663, acc: 0.8874532585470085, lr: 0.00028559309471483943
[batch_idx--400] train_loss: 0.0010416151312971837, acc: 0.8871863310473815, lr: 0.00027691055147135437
[batch_idx--450] train_loss: 0.001045618697415869, acc: 0.8869198458707953, lr: 0.0002683613010297709
total time of one epoch: 288.0425009727478 s
train_loss:  0.001045618697415869  acc:  0.8869198458707953
->>lr:0.000268
test_loss:  0.001111485982062518  test_acc:  0.8847251520039707
best acc:  88.70827646109939

------Epoch: 143------
[batch_idx--0] train_loss: 0.000985568156465888, acc: 0.90625, lr: 0.0002681916759252945
[batch_idx--50] train_loss: 0.001033261365841563, acc: 0.8894761029411765, lr: 0.00025977843162139916
[batch_idx--100] train_loss: 0.0010183034090113154, acc: 0.8905476485148515, lr: 0.0002514985724860308
[batch_idx--150] train_loss: 0.0010442445709968344, acc: 0.8869257036423841, lr: 0.00024335214315946986
[batch_idx--200] train_loss: 0.001039237936261337, acc: 0.8868742226368159, lr: 0.00023533918756261376
[batch_idx--250] train_loss: 0.0010391710510670366, acc: 0.8872945717131474, lr: 0.00022745974889675503
[batch_idx--300] train_loss: 0.0010394693612959546, acc: 0.8877439784053156, lr: 0.0002197138696433315
[batch_idx--350] train_loss: 0.001043638357749352, acc: 0.8871082621082621, lr: 0.0002121015915637098
[batch_idx--400] train_loss: 0.0010454206861859824, acc: 0.887001246882793, lr: 0.0002046229556989493
[batch_idx--450] train_loss: 0.00104726700575638, acc: 0.8870587010101711, lr: 0.00019727800236959416
total time of one epoch: 286.2675859928131 s
train_loss:  0.00104726700575638  acc:  0.8870587010101711
->>lr:0.000197
test_loss:  0.0011078767521917738  test_acc:  0.8858419158704554
best acc:  88.70827646109939

------Epoch: 144------
[batch_idx--0] train_loss: 0.0008692102856002748, acc: 0.91015625, lr: 0.0001971324671380531
[batch_idx--50] train_loss: 0.0010625096562994168, acc: 0.8840379901960784, lr: 0.00018992391078557493
[batch_idx--100] train_loss: 0.001046583170559958, acc: 0.8869121287128713, lr: 0.00018284911621737067
[batch_idx--150] train_loss: 0.0010480258146621632, acc: 0.8865117963576159, lr: 0.00017590812157669555
[batch_idx--200] train_loss: 0.001042520093664397, acc: 0.8876321517412935, lr: 0.00016910096428543743
[batch_idx--250] train_loss: 0.0010424093120690598, acc: 0.8875902639442231, lr: 0.00016242768104390848
[batch_idx--300] train_loss: 0.0010433942986500645, acc: 0.8878737541528239, lr: 0.00015588830783064834
[batch_idx--350] train_loss: 0.0010491188940926432, acc: 0.8872418091168092, lr: 0.0001494828799022241
[batch_idx--400] train_loss: 0.0010456093171834389, acc: 0.8876246882793017, lr: 0.00014321143179305552
[batch_idx--450] train_loss: 0.001048786327779266, acc: 0.8873624466275558, lr: 0.00013707399731520964
total time of one epoch: 292.2551591396332 s
train_loss:  0.001048786327779266  acc:  0.8873624466275558
->>lr:0.000137
test_loss:  0.0011082177999993236  test_acc:  0.8858419158704554
best acc:  88.70827646109939

------Epoch: 145------
[batch_idx--0] train_loss: 0.001044983509927988, acc: 0.87890625, lr: 0.00013695261579316776
[batch_idx--50] train_loss: 0.0010472951701148321, acc: 0.8887867647058824, lr: 0.0001309519093031647
[batch_idx--100] train_loss: 0.0010462321720252016, acc: 0.8879563737623762, lr: 0.0001250852825408405
[batch_idx--150] train_loss: 0.0010542520769063802, acc: 0.8861754966887417, lr: 0.0001193527671357053
[batch_idx--200] train_loss: 0.0010552217095594538, acc: 0.8856110074626866, lr: 0.00011375439399421428
[batch_idx--250] train_loss: 0.0010519472741154562, acc: 0.8858939243027888, lr: 0.00010829019329959833
[batch_idx--300] train_loss: 0.001052209843674124, acc: 0.8862645348837209, lr: 0.00010296019451171701
[batch_idx--350] train_loss: 0.0010459078392916043, acc: 0.887252938034188, lr: 9.776442636688366e-05
[batch_idx--400] train_loss: 0.0010487253117512103, acc: 0.8867479738154613, lr: 9.270291687771548e-05
[batch_idx--450] train_loss: 0.001050268790545978, acc: 0.8869458812094283, lr: 8.77756933329893e-05
total time of one epoch: 295.3214657306671 s
train_loss:  0.001050268790545978  acc:  0.8869458812094283
->>lr:0.000088
test_loss:  0.001108144865850758  test_acc:  0.8850974066261322
best acc:  88.70827646109939

------Epoch: 146------
[batch_idx--0] train_loss: 0.0010384232737123966, acc: 0.8671875, lr: 8.767851876239075e-05
[batch_idx--50] train_loss: 0.0010334429634716728, acc: 0.8871017156862745, lr: 8.288829424305533e-05
[batch_idx--100] train_loss: 0.0010394316015645197, acc: 0.887762995049505, lr: 7.82324085830094e-05
[batch_idx--150] train_loss: 0.001048446734688732, acc: 0.886796357615894, lr: 7.371088688413186e-05
[batch_idx--200] train_loss: 0.0010441200366354923, acc: 0.8878264925373134, lr: 6.93237535238922e-05
[batch_idx--250] train_loss: 0.0010472212004868603, acc: 0.8869521912350598, lr: 6.507103215520893e-05
[batch_idx--300] train_loss: 0.0010479562341520236, acc: 0.8871340323920266, lr: 6.09527457063358e-05
[batch_idx--350] train_loss: 0.0010544212120107543, acc: 0.8860510149572649, lr: 5.6968916380720215e-05
[batch_idx--400] train_loss: 0.0010489063037552422, acc: 0.8866700436408977, lr: 5.311956565690057e-05
[batch_idx--450] train_loss: 0.0010481397383225127, acc: 0.8871194501336481, lr: 4.9404714288381335e-05
total time of one epoch: 295.35845732688904 s
train_loss:  0.0010481397383225127  acc:  0.8871194501336481
->>lr:0.000049
test_loss:  0.0011067792804679913  test_acc:  0.8850974066261322
best acc:  88.70827646109939

------Epoch: 147------
[batch_idx--0] train_loss: 0.001086477655917406, acc: 0.88671875, lr: 4.933178929321103e-05
[batch_idx--50] train_loss: 0.001053536398674124, acc: 0.8842677696078431, lr: 4.57541478953355e-05
[batch_idx--100] train_loss: 0.0010495568028568189, acc: 0.8859065594059405, lr: 4.231104556289278e-05
[batch_idx--150] train_loss: 0.001055242538849965, acc: 0.8847785596026491, lr: 3.9002500859128264e-05
[batch_idx--200] train_loss: 0.0010499525644390181, acc: 0.8853389303482587, lr: 3.582853162182598e-05
[batch_idx--250] train_loss: 0.0010500405073273497, acc: 0.8853647908366534, lr: 3.2789154963222546e-05
[batch_idx--300] train_loss: 0.0010489703460048847, acc: 0.8855637458471761, lr: 2.9884387269901725e-05
[batch_idx--350] train_loss: 0.0010451645234817284, acc: 0.8859842414529915, lr: 2.7114244202716688e-05
[batch_idx--400] train_loss: 0.001048796801210063, acc: 0.8858225529925187, lr: 2.4478740696695647e-05
[batch_idx--450] train_loss: 0.0010513108601675901, acc: 0.8859565383413753, lr: 2.1977890960975244e-05
total time of one epoch: 290.37054800987244 s
train_loss:  0.0010513108601675901  acc:  0.8859565383413753
->>lr:0.000022
test_loss:  0.0011082490371524703  test_acc:  0.8850974066261322
best acc:  88.70827646109939

------Epoch: 148------
[batch_idx--0] train_loss: 0.0011177072301506996, acc: 0.875, lr: 2.192924752854042e-05
[batch_idx--50] train_loss: 0.0010257954743471654, acc: 0.8899356617647058, lr: 1.9565758523884538e-05
[batch_idx--100] train_loss: 0.0010353698911569496, acc: 0.888381806930693, lr: 1.7336949777524425e-05
[batch_idx--150] train_loss: 0.0010378733570286572, acc: 0.8872878725165563, lr: 1.524283330592846e-05
[batch_idx--200] train_loss: 0.001038988468072734, acc: 0.8881374378109452, lr: 1.3283420399376467e-05
[batch_idx--250] train_loss: 0.001041712929759976, acc: 0.8870611304780877, lr: 1.14587216219042e-05
[batch_idx--300] train_loss: 0.0010405173061099956, acc: 0.8870691445182725, lr: 9.768746811253394e-06
[batch_idx--350] train_loss: 0.0010374506303318842, acc: 0.8870748753561254, lr: 8.213505078799587e-06
[batch_idx--400] train_loss: 0.0010354373089625428, acc: 0.88758572319202, lr: 6.793004809518832e-06
[batch_idx--450] train_loss: 0.0010434685177128844, acc: 0.8868417398548963, lr: 5.507253661940492e-06
total time of one epoch: 289.8978726863861 s
train_loss:  0.0010434685177128844  acc:  0.8868417398548963
->>lr:0.000006
test_loss:  0.001108218545149834  test_acc:  0.886214170492617
best acc:  88.70827646109939

------Epoch: 149------
[batch_idx--0] train_loss: 0.001153944176621735, acc: 0.86328125, lr: 5.482913128862511e-06
[batch_idx--50] train_loss: 0.001056949051060513, acc: 0.8821997549019608, lr: 4.334613221818051e-06
[batch_idx--100] train_loss: 0.0010590916568653124, acc: 0.8839727722772277, lr: 3.321075690718156e-06
[batch_idx--150] train_loss: 0.0010545644222986915, acc: 0.8852183360927153, lr: 2.4423059999861833e-06
[batch_idx--200] train_loss: 0.0010538126497798186, acc: 0.8855721393034826, lr: 1.6983088874406029e-06
[batch_idx--250] train_loss: 0.0010512185172155588, acc: 0.8864230577689243, lr: 1.089088364294999e-06
[batch_idx--300] train_loss: 0.001051060050923959, acc: 0.8866149294019934, lr: 6.146477151164343e-07
[batch_idx--350] train_loss: 0.001051483367386664, acc: 0.8865184294871795, lr: 2.749894978198997e-07
[batch_idx--400] train_loss: 0.0010472303575736253, acc: 0.8871376246882793, lr: 7.011554364610984e-08
[batch_idx--450] train_loss: 0.0010473081692636838, acc: 0.8872756621654458, lr: 2.6957161503027296e-11
total time of one epoch: 290.3792254924774 s
train_loss:  0.0010473081692636838  acc:  0.8872756621654458
->>lr:0.000000
test_loss:  0.0011076442781756748  test_acc:  0.8850974066261322
best acc:  88.70827646109939