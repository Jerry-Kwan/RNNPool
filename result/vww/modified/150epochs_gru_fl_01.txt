Model: mobilenet_gru_fl
Batch size: 256
Number of dataloader workers: 32

loading annotations into memory...
Done (t=2.33s)
creating index...
index created!
Len of trainloader: 451

loading annotations into memory...
Done (t=0.15s)
creating index...
index created!
Len of testloader: 32

use 4 GPUs!
DataParallel device_ids: [0, 1, 2, 3]

------Epoch: 0------
[batch_idx--0] train_loss: 0.002707683714106679, acc: 0.51953125, lr: 0.05
[batch_idx--50] train_loss: 0.0028352677438627273, acc: 0.5259650735294118, lr: 0.04999993260712715
[batch_idx--100] train_loss: 0.0026940558391558653, acc: 0.5782410272277227, lr: 0.04999973042887193
[batch_idx--150] train_loss: 0.0026099827242336724, acc: 0.6051065811258278, lr: 0.049999393466324364
[batch_idx--200] train_loss: 0.002555107792830141, acc: 0.6222014925373134, lr: 0.04999892172130118
[batch_idx--250] train_loss: 0.002521245208832313, acc: 0.6324078685258964, lr: 0.04999831519634575
[batch_idx--300] train_loss: 0.0024910608261662763, acc: 0.6409624169435216, lr: 0.0499975738947281
[batch_idx--350] train_loss: 0.002465781725231993, acc: 0.6476473468660968, lr: 0.04999669782044491
[batch_idx--400] train_loss: 0.0024420380989493722, acc: 0.65321072319202, lr: 0.049995686978219496
[batch_idx--450] train_loss: 0.002425780142425816, acc: 0.6585031415975284, lr: 0.04999454137350172
total time of one epoch: 424.4286139011383 s
train_loss:  0.002425780142425816  acc:  0.6585031415975284
->>lr:0.049995
test_loss:  0.003276136343348099  test_acc:  0.5284774785953592
best acc:  0
Saving..
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(

------Epoch: 1------
[batch_idx--0] train_loss: 0.0021194254513829947, acc: 0.7109375, lr: 0.04999451708687114
[batch_idx--50] train_loss: 0.002243564240451829, acc: 0.7060355392156863, lr: 0.04999323403077913
[batch_idx--100] train_loss: 0.002230715788070961, acc: 0.7066831683168316, lr: 0.04999181622541965
[batch_idx--150] train_loss: 0.002218697011156242, acc: 0.7091525248344371, lr: 0.0499902636784367
[batch_idx--200] train_loss: 0.002206320347917725, acc: 0.7115982587064676, lr: 0.04998857639820074
[batch_idx--250] train_loss: 0.002193906769783522, acc: 0.7131474103585658, lr: 0.04998675439380862
[batch_idx--300] train_loss: 0.00218516874453517, acc: 0.7151292566445183, lr: 0.04998479767508354
[batch_idx--350] train_loss: 0.0021831437960622615, acc: 0.7155337428774928, lr: 0.04998270625257502
[batch_idx--400] train_loss: 0.002177744118805668, acc: 0.7164608011221946, lr: 0.04998048013755882
[batch_idx--450] train_loss: 0.002173865062234452, acc: 0.7181587808518762, lr: 0.049978119342036866
total time of one epoch: 422.861447095871 s
train_loss:  0.002173865062234452  acc:  0.7181587808518762
->>lr:0.049978
test_loss:  0.003125000597599615  test_acc:  0.5979650080655168
best acc:  52.84774785953592
Saving..

------Epoch: 2------
[batch_idx--0] train_loss: 0.002017263788729906, acc: 0.72265625, lr: 0.04997807075247146
[batch_idx--50] train_loss: 0.0020863605028602714, acc: 0.7376685049019608, lr: 0.04997557259595109
[batch_idx--100] train_loss: 0.002095378921505543, acc: 0.7342976485148515, lr: 0.04997293978538365
[batch_idx--150] train_loss: 0.002082796048817058, acc: 0.7358236754966887, lr: 0.04997017233496374
[batch_idx--200] train_loss: 0.002077973611069037, acc: 0.736396144278607, lr: 0.04996727025961189
[batch_idx--250] train_loss: 0.0020683470114405116, acc: 0.7371762948207171, lr: 0.04996423357497442
[batch_idx--300] train_loss: 0.002067465096111858, acc: 0.7374506852159468, lr: 0.04996106229742341
[batch_idx--350] train_loss: 0.0020652257026759564, acc: 0.7374465811965812, lr: 0.04995775644405658
[batch_idx--400] train_loss: 0.0020605759295121654, acc: 0.7383202150872819, lr: 0.049954316032697205
[batch_idx--450] train_loss: 0.0020576533590050206, acc: 0.7395771861006005, lr: 0.049950741081894026
total time of one epoch: 435.0980923175812 s
train_loss:  0.0020576533590050206  acc:  0.7395771861006005
->>lr:0.049951
test_loss:  0.0022976274806315055  test_acc:  0.7061670182404765
best acc:  59.796500806551684
Saving..

------Epoch: 3------
[batch_idx--0] train_loss: 0.0021467877086251974, acc: 0.7109375, lr: 0.04995066821070679
[batch_idx--50] train_loss: 0.0020631786376493527, acc: 0.7338388480392157, lr: 0.04994695604953209
[batch_idx--100] train_loss: 0.002043544689405451, acc: 0.7382038985148515, lr: 0.0499431093885944
[batch_idx--150] train_loss: 0.0020360441173778365, acc: 0.7401438327814569, lr: 0.04993912824863275
[batch_idx--200] train_loss: 0.002027111145348024, acc: 0.7417016480099502, lr: 0.049935012651111166
[batch_idx--250] train_loss: 0.002021426881804498, acc: 0.7429500747011952, lr: 0.0499307626182186
[batch_idx--300] train_loss: 0.0020188973424492087, acc: 0.7434593023255814, lr: 0.0499263781728688
[batch_idx--350] train_loss: 0.0020078785576196946, acc: 0.7448027955840456, lr: 0.04992185933870021
[batch_idx--400] train_loss: 0.002002255735335932, acc: 0.7461132325436409, lr: 0.049917206140075804
[batch_idx--450] train_loss: 0.002001534179217714, acc: 0.7464678723921269, lr: 0.04991241860208297
total time of one epoch: 415.4292702674866 s
train_loss:  0.002001534179217714  acc:  0.7464678723921269
->>lr:0.049912
test_loss:  0.002407939229329269  test_acc:  0.7075319518550689
best acc:  70.61670182404765
Saving..

------Epoch: 4------
[batch_idx--0] train_loss: 0.001845296355895698, acc: 0.77734375, lr: 0.049912321481237615
[batch_idx--50] train_loss: 0.0019450514969945537, acc: 0.7536764705882353, lr: 0.04990739694368515
[batch_idx--100] train_loss: 0.001951998778581988, acc: 0.7532874381188119, lr: 0.04990233811964985
[batch_idx--150] train_loss: 0.0019454612305683904, acc: 0.7548634105960265, lr: 0.049897145036406014
[batch_idx--200] train_loss: 0.0019417178581946006, acc: 0.755907960199005, lr: 0.04989181772195179
[batch_idx--250] train_loss: 0.00194412518470767, acc: 0.7557737798804781, lr: 0.04988635620500901
[batch_idx--300] train_loss: 0.0019396366048728014, acc: 0.7569819352159468, lr: 0.049880760515023076
[batch_idx--350] train_loss: 0.0019376737117353412, acc: 0.7566550925925926, lr: 0.04987503068216274
[batch_idx--400] train_loss: 0.0019336334726380699, acc: 0.7575007793017456, lr: 0.04986916673732
[batch_idx--450] train_loss: 0.0019341964165628996, acc: 0.7583573437011838, lr: 0.049863168712109905
total time of one epoch: 416.9483268260956 s
train_loss:  0.0019341964165628996  acc:  0.7583573437011838
->>lr:0.049863
test_loss:  0.0019961665316867035  test_acc:  0.7553046283658023
best acc:  70.75319518550688
Saving..

------Epoch: 5------
[batch_idx--0] train_loss: 0.001988703152164817, acc: 0.73828125, lr: 0.049863047384206834
[batch_idx--50] train_loss: 0.0019313005808119972, acc: 0.7587316176470589, lr: 0.04985691263034154
[batch_idx--100] train_loss: 0.001909137844098824, acc: 0.762917698019802, lr: 0.049850643862176046
[batch_idx--150] train_loss: 0.0018992336530127372, acc: 0.7639435016556292, lr: 0.04984424111350797
[batch_idx--200] train_loss: 0.0018940950999851917, acc: 0.7645366915422885, lr: 0.0498377044188573
[batch_idx--250] train_loss: 0.001893456836984274, acc: 0.7644422310756972, lr: 0.04983103381346615
[batch_idx--300] train_loss: 0.0018906387805233268, acc: 0.7641974667774086, lr: 0.049824229333298636
[batch_idx--350] train_loss: 0.00188927390072707, acc: 0.7644787215099715, lr: 0.049817291015040614
[batch_idx--400] train_loss: 0.0018856426424572147, acc: 0.7650112998753117, lr: 0.04981021889609956
[batch_idx--450] train_loss: 0.0018879756873031448, acc: 0.7647446801124727, lr: 0.0498030130146043
total time of one epoch: 403.4625201225281 s
train_loss:  0.0018879756873031448  acc:  0.7647446801124727
->>lr:0.049803
test_loss:  0.001980797120131102  test_acc:  0.7580344955949869
best acc:  75.53046283658023
Saving..

------Epoch: 6------
[batch_idx--0] train_loss: 0.0018571170512586832, acc: 0.77734375, lr: 0.04980286753286195
[batch_idx--50] train_loss: 0.001873730414766161, acc: 0.7663143382352942, lr: 0.04979552525358963
[batch_idx--100] train_loss: 0.0018662694717139596, acc: 0.7667079207920792, lr: 0.04978804929098283
[batch_idx--150] train_loss: 0.0018668233012990249, acc: 0.7675393211920529, lr: 0.049780439685347705
[batch_idx--200] train_loss: 0.0018671129428230189, acc: 0.7666744402985075, lr: 0.0497726964777109
[batch_idx--250] train_loss: 0.0018669043132382263, acc: 0.7670723356573705, lr: 0.049764819709819365
[batch_idx--300] train_loss: 0.0018611454325217593, acc: 0.7686747300664452, lr: 0.04975680942414015
[batch_idx--350] train_loss: 0.0018554583004147791, acc: 0.7693643162393162, lr: 0.04974866566386016
[batch_idx--400] train_loss: 0.0018531178830289037, acc: 0.7698234881546134, lr: 0.049740388472885894
[batch_idx--450] train_loss: 0.0018539702595490668, acc: 0.7706026313048912, lr: 0.04973197789584324
total time of one epoch: 403.10543727874756 s
train_loss:  0.0018539702595490668  acc:  0.7706026313048912
->>lr:0.049732
test_loss:  0.0018674299991786117  test_acc:  0.7752822930884725
best acc:  75.8034495594987
Saving..

------Epoch: 7------
[batch_idx--0] train_loss: 0.001584986923262477, acc: 0.82421875, lr: 0.049731808324074714
[batch_idx--50] train_loss: 0.0018483039662789773, acc: 0.7718290441176471, lr: 0.04972326173996171
[batch_idx--100] train_loss: 0.001830748134836702, acc: 0.7750232054455446, lr: 0.049714581862117906
[batch_idx--150] train_loss: 0.0018298235083529294, acc: 0.7750155215231788, lr: 0.049705768737340256
[batch_idx--200] train_loss: 0.0018301480438152504, acc: 0.775439210199005, lr: 0.04969682241314409
[batch_idx--250] train_loss: 0.0018201004825087182, acc: 0.7770947460159362, lr: 0.0496877429377629
[batch_idx--300] train_loss: 0.0018239398947158872, acc: 0.7764482973421927, lr: 0.04967853036014805
[batch_idx--350] train_loss: 0.0018181571189016953, acc: 0.7772435897435898, lr: 0.04966918472996849
[batch_idx--400] train_loss: 0.0018143471530139297, acc: 0.7784737375311721, lr: 0.04965970609761053
[batch_idx--450] train_loss: 0.0018168821867260404, acc: 0.7792203283924046, lr: 0.04965009451417756
total time of one epoch: 405.2463102340698 s
train_loss:  0.0018168821867260404  acc:  0.7792203283924046
->>lr:0.049650
test_loss:  0.0021723872645792648  test_acc:  0.7275096165777392
best acc:  77.52822930884726

------Epoch: 8------
[batch_idx--0] train_loss: 0.0019454233115538955, acc: 0.76953125, lr: 0.04964990092676263
[batch_idx--50] train_loss: 0.0018401160292948286, acc: 0.7748161764705882, lr: 0.0496401537866232
[batch_idx--100] train_loss: 0.0018079490988690517, acc: 0.7805925123762376, lr: 0.04963027380082368
[batch_idx--150] train_loss: 0.0017959007705000557, acc: 0.7821036837748344, lr: 0.04962026102263131
[batch_idx--200] train_loss: 0.00179350045011541, acc: 0.7825132151741293, lr: 0.04961011550602926
[batch_idx--250] train_loss: 0.0017894897827937962, acc: 0.7830708416334662, lr: 0.04959983730571641
[batch_idx--300] train_loss: 0.0017955575348728916, acc: 0.7821454526578073, lr: 0.04958942647710693
[batch_idx--350] train_loss: 0.0017986834759656817, acc: 0.7813612891737892, lr: 0.04957888307633007
[batch_idx--400] train_loss: 0.0017945107407612434, acc: 0.7821949033665836, lr: 0.04956820716022985
[batch_idx--450] train_loss: 0.0017971361530118033, acc: 0.7825875655222689, lr: 0.049557398786364705
total time of one epoch: 408.0795044898987 s
train_loss:  0.0017971361530118033  acc:  0.7825875655222689
->>lr:0.049557
test_loss:  0.0018443895719056982  test_acc:  0.7788807544360342
best acc:  77.52822930884726
Saving..

------Epoch: 9------
[batch_idx--0] train_loss: 0.0016826906939968467, acc: 0.8125, lr: 0.049557181268217225
[batch_idx--50] train_loss: 0.001814144757101495, acc: 0.7777267156862745, lr: 0.04954623784746919
[batch_idx--100] train_loss: 0.001802205724761554, acc: 0.7789681311881188, lr: 0.04953516208740226
[batch_idx--150] train_loss: 0.0017852468157051416, acc: 0.7823882450331126, lr: 0.049523954047730606
[batch_idx--200] train_loss: 0.0017760966612554308, acc: 0.7828047263681592, lr: 0.04951261378888158
[batch_idx--250] train_loss: 0.001772872112001259, acc: 0.7838334163346613, lr: 0.049501141371995405
[batch_idx--300] train_loss: 0.001770095990976919, acc: 0.7844295058139535, lr: 0.0494895368589248
[batch_idx--350] train_loss: 0.0017697095520730712, acc: 0.7843660968660968, lr: 0.0494778003122347
[batch_idx--400] train_loss: 0.0017653359126350715, acc: 0.784854270573566, lr: 0.049465931795201847
[batch_idx--450] train_loss: 0.0017684164759985057, acc: 0.7851563856007221, lr: 0.049453931371814544
total time of one epoch: 420.61809635162354 s
train_loss:  0.0017684164759985057  acc:  0.7851563856007221
->>lr:0.049454
test_loss:  0.0019016180555878747  test_acc:  0.7737932745998263
best acc:  77.88807544360343

------Epoch: 10------
[batch_idx--0] train_loss: 0.0017149671912193298, acc: 0.80859375, lr: 0.049453690018345146
[batch_idx--50] train_loss: 0.0017554237730983719, acc: 0.7882199754901961, lr: 0.04944155511713453
[batch_idx--100] train_loss: 0.001752839814456604, acc: 0.7885597153465347, lr: 0.04942928844099462
[batch_idx--150] train_loss: 0.0017388898097533757, acc: 0.7896574917218543, lr: 0.0494168900560603
[batch_idx--200] train_loss: 0.0017479478273846542, acc: 0.7883045708955224, lr: 0.04940436002917662
[batch_idx--250] train_loss: 0.001747461854465365, acc: 0.7887356822709163, lr: 0.04939169842789834
[batch_idx--300] train_loss: 0.001744978521266748, acc: 0.7889457018272426, lr: 0.04937890532048959
[batch_idx--350] train_loss: 0.0017453494327185287, acc: 0.7890736289173789, lr: 0.04936598077592351
[batch_idx--400] train_loss: 0.0017432988678776377, acc: 0.7892475841645885, lr: 0.049352924863881875
[batch_idx--450] train_loss: 0.0017451572624398986, acc: 0.7892178984274656, lr: 0.04933973765475472
total time of one epoch: 416.462730884552 s
train_loss:  0.0017451572624398986  acc:  0.7892178984274656
->>lr:0.049340
test_loss:  0.0017129385245025328  test_acc:  0.8004715225214046
best acc:  77.88807544360343
Saving..

------Epoch: 11------
[batch_idx--0] train_loss: 0.0018250527791678905, acc: 0.78125, lr: 0.04933947257182901
[batch_idx--50] train_loss: 0.001731015849109812, acc: 0.7895220588235294, lr: 0.04932615151292455
[batch_idx--100] train_loss: 0.0017176896591882893, acc: 0.7927366955445545, lr: 0.04931269930128121
[batch_idx--150] train_loss: 0.0017203583038220836, acc: 0.7927876655629139, lr: 0.04929911600942565
[batch_idx--200] train_loss: 0.0017211353435269117, acc: 0.7932213930348259, lr: 0.04928540171059123
[batch_idx--250] train_loss: 0.0017128476907361848, acc: 0.7938091384462151, lr: 0.04927155647871764
[batch_idx--300] train_loss: 0.001711688867299833, acc: 0.7934359426910299, lr: 0.04925758038845046
[batch_idx--350] train_loss: 0.0017106395010488835, acc: 0.7937811609686609, lr: 0.04924347351514081
[batch_idx--400] train_loss: 0.0017100545302488634, acc: 0.793923394638404, lr: 0.049229235934844906
[batch_idx--450] train_loss: 0.0017134585708548377, acc: 0.7943295032457389, lr: 0.04921486772432365
total time of one epoch: 409.38865303993225 s
train_loss:  0.0017134585708548377  acc:  0.7943295032457389
->>lr:0.049215
test_loss:  0.0017278834110543543  test_acc:  0.7979898250403276
best acc:  80.04715225214046

------Epoch: 12------
[batch_idx--0] train_loss: 0.001597224036231637, acc: 0.828125, lr: 0.04921457902821578
[batch_idx--50] train_loss: 0.0016900274797580113, acc: 0.7977175245098039, lr: 0.04920007765467417
[batch_idx--100] train_loss: 0.0016996853150390457, acc: 0.7955987004950495, lr: 0.049185445808112044
[batch_idx--150] train_loss: 0.0016993623001760009, acc: 0.7951935016556292, lr: 0.049170683567415975
[batch_idx--200] train_loss: 0.001693491136483774, acc: 0.7962919776119403, lr: 0.04915579101217554
[batch_idx--250] train_loss: 0.0016935130737098564, acc: 0.7965170567729084, lr: 0.04914076822268292
[batch_idx--300] train_loss: 0.0016986103403533613, acc: 0.7962390988372093, lr: 0.04912561527993242
[batch_idx--350] train_loss: 0.0016991554287148166, acc: 0.7959735576923077, lr: 0.049110332265620074
[batch_idx--400] train_loss: 0.0016976824512779528, acc: 0.7959690617206983, lr: 0.049094919262143176
[batch_idx--450] train_loss: 0.0016998692247249087, acc: 0.7962214045197348, lr: 0.049079376352599846
total time of one epoch: 413.3949887752533 s
train_loss:  0.0016998692247249087  acc:  0.7962214045197348
->>lr:0.049079
test_loss:  0.0016664389212561357  test_acc:  0.8049385779873434
best acc:  80.04715225214046
Saving..

------Epoch: 13------
[batch_idx--0] train_loss: 0.0016161546809598804, acc: 0.81640625, lr: 0.049079064169941455
[batch_idx--50] train_loss: 0.00168768243690697, acc: 0.8021599264705882, lr: 0.04906338884254441
[batch_idx--100] train_loss: 0.0016760074229228614, acc: 0.8015934405940595, lr: 0.04904758377907498
[batch_idx--150] train_loss: 0.0016813803346987987, acc: 0.8010658112582781, lr: 0.04903164906474507
[batch_idx--200] train_loss: 0.001682299383295079, acc: 0.7997706778606966, lr: 0.04901558478546556
[batch_idx--250] train_loss: 0.0016775627307912921, acc: 0.8003766185258964, lr: 0.04899939102784589
[batch_idx--300] train_loss: 0.0016792788389958812, acc: 0.799781976744186, lr: 0.04898306787919357
[batch_idx--350] train_loss: 0.0016715618737965312, acc: 0.8006254451566952, lr: 0.04896661542751371
[batch_idx--400] train_loss: 0.0016729735965002096, acc: 0.8002747038653366, lr: 0.04895003376150854
[batch_idx--450] train_loss: 0.0016779029813590622, acc: 0.7999618148366716, lr: 0.04893332297057697
total time of one epoch: 404.5661668777466 s
train_loss:  0.0016779029813590622  acc:  0.7999618148366716
->>lr:0.048933
test_loss:  0.0016405798688037237  test_acc:  0.8105223973197667
best acc:  80.49385779873434
Saving..

------Epoch: 14------
[batch_idx--0] train_loss: 0.001857086201198399, acc: 0.7734375, lr: 0.048932987438301684
[batch_idx--50] train_loss: 0.0016665966775012658, acc: 0.8020833333333334, lr: 0.04891614503276587
[batch_idx--100] train_loss: 0.0016611571986191343, acc: 0.8037979579207921, lr: 0.04889917368501234
[batch_idx--150] train_loss: 0.0016528516283123107, acc: 0.8039114238410596, lr: 0.04888207348654094
[batch_idx--200] train_loss: 0.0016451249975219962, acc: 0.8052899564676617, lr: 0.048864844529546175
[batch_idx--250] train_loss: 0.0016440028594658371, acc: 0.8049053784860558, lr: 0.04884748690691675
[batch_idx--300] train_loss: 0.001646991211540403, acc: 0.8044668812292359, lr: 0.048830000712235096
[batch_idx--350] train_loss: 0.0016459499577330982, acc: 0.8044983084045584, lr: 0.048812386039776785
[batch_idx--400] train_loss: 0.0016473132197831076, acc: 0.8042881078553616, lr: 0.0487946429845101
[batch_idx--450] train_loss: 0.001653329377738084, acc: 0.8042576457111119, lr: 0.048776771642095464
total time of one epoch: 400.66906785964966 s
train_loss:  0.001653329377738084  acc:  0.8042576457111119
->>lr:0.048777
test_loss:  0.0017190005439344596  test_acc:  0.8004715225214046
best acc:  81.05223973197667

------Epoch: 15------
[batch_idx--0] train_loss: 0.0015378677053377032, acc: 0.8203125, lr: 0.048776412907378844
[batch_idx--50] train_loss: 0.0016477071159683606, acc: 0.8013174019607843, lr: 0.04875841081133997
[batch_idx--100] train_loss: 0.001628863712828053, acc: 0.8059637995049505, lr: 0.04874028062349638
[batch_idx--150] train_loss: 0.0016171081324681542, acc: 0.8093180877483444, lr: 0.0487220224415957
[batch_idx--200] train_loss: 0.0016229580943032506, acc: 0.8076026119402985, lr: 0.04870363636407563
[batch_idx--250] train_loss: 0.0016323495238826451, acc: 0.8065550298804781, lr: 0.04868512249006343
[batch_idx--300] train_loss: 0.0016256340387187577, acc: 0.8076853197674418, lr: 0.048666480919375345
[batch_idx--350] train_loss: 0.0016296203132119145, acc: 0.8071915064102564, lr: 0.0486477117525161
[batch_idx--400] train_loss: 0.0016312569306067139, acc: 0.8072299719451371, lr: 0.04862881509067834
[batch_idx--450] train_loss: 0.0016297838787172282, acc: 0.8076682750720311, lr: 0.04860979103574209
total time of one epoch: 404.61772298812866 s
train_loss:  0.0016297838787172282  acc:  0.8076682750720311
->>lr:0.048610
test_loss:  0.0017216081935221303  test_acc:  0.7940191090706042
best acc:  81.05223973197667

------Epoch: 16------
[batch_idx--0] train_loss: 0.0016584484837949276, acc: 0.81640625, lr: 0.04860940925593703
[batch_idx--50] train_loss: 0.0016429157420883283, acc: 0.8043045343137255, lr: 0.048590255365709406
[batch_idx--100] train_loss: 0.0016115243399128466, acc: 0.8086324257425742, lr: 0.04857097429027534
[batch_idx--150] train_loss: 0.0016126910121247963, acc: 0.8093180877483444, lr: 0.0485515661335874
[batch_idx--200] train_loss: 0.0016120712067792886, acc: 0.8098958333333334, lr: 0.048532031000283304
[batch_idx--250] train_loss: 0.0016150217131336787, acc: 0.8094497011952191, lr: 0.048512368995685354
[batch_idx--300] train_loss: 0.0016080884040918114, acc: 0.8107090946843853, lr: 0.04849258022579986
[batch_idx--350] train_loss: 0.0016065273590470822, acc: 0.8104634081196581, lr: 0.04847266479731658
[batch_idx--400] train_loss: 0.0016060674431248386, acc: 0.8104056265586035, lr: 0.048452622817608176
[batch_idx--450] train_loss: 0.001614000302073352, acc: 0.8100895615648974, lr: 0.04843245439472954
total time of one epoch: 405.22741770744324 s
train_loss:  0.001614000302073352  acc:  0.8100895615648974
->>lr:0.048432
test_loss:  0.00162375985444487  test_acc:  0.8108946519419282
best acc:  81.05223973197667
Saving..

------Epoch: 17------
[batch_idx--0] train_loss: 0.0016376732382923365, acc: 0.8203125, lr: 0.04843204973729729
[batch_idx--50] train_loss: 0.0016338348699112732, acc: 0.8045343137254902, lr: 0.048411752454410206
[batch_idx--100] train_loss: 0.0016268264562223512, acc: 0.8058477722772277, lr: 0.0483913289487026
[batch_idx--150] train_loss: 0.0016156678266872632, acc: 0.808645488410596, lr: 0.04837077933028638
[batch_idx--200] train_loss: 0.0016079679946994308, acc: 0.8091573383084577, lr: 0.04835010370995336
[batch_idx--250] train_loss: 0.0016027748927036189, acc: 0.8103990288844621, lr: 0.0483293021991747
[batch_idx--300] train_loss: 0.0015997475877936398, acc: 0.8110075789036545, lr: 0.04830837491010029
[batch_idx--350] train_loss: 0.0016004924842838379, acc: 0.8109753383190883, lr: 0.04828732195555814
[batch_idx--400] train_loss: 0.001596515104081714, acc: 0.8116038029925187, lr: 0.04826614344905377
[batch_idx--450] train_loss: 0.0015973414072607385, acc: 0.8118165723608846, lr: 0.04824483950476961
total time of one epoch: 403.82293343544006 s
train_loss:  0.0015973414072607385  acc:  0.8118165723608846
->>lr:0.048245
test_loss:  0.0015257855091220407  test_acc:  0.8281424494354138
best acc:  81.08946519419283
Saving..

------Epoch: 18------
[batch_idx--0] train_loss: 0.0015607911627739668, acc: 0.7890625, lr: 0.04824441214720629
[batch_idx--50] train_loss: 0.001588396282921381, acc: 0.8141850490196079, lr: 0.04822298037471885
[batch_idx--100] train_loss: 0.0015870478409941834, acc: 0.8136215965346535, lr: 0.04820142339716232
[batch_idx--150] train_loss: 0.0015751661051262096, acc: 0.8152421357615894, lr: 0.04817974133075961
[batch_idx--200] train_loss: 0.0015779081888413473, acc: 0.8146766169154229, lr: 0.04815793429240808
[batch_idx--250] train_loss: 0.0015808772356008213, acc: 0.8143986553784861, lr: 0.04813600239967885
[batch_idx--300] train_loss: 0.001580905394730749, acc: 0.8143947259136213, lr: 0.04811394577081616
[batch_idx--350] train_loss: 0.0015777493760711447, acc: 0.8152488425925926, lr: 0.04809176452473679
[batch_idx--400] train_loss: 0.0015785236816221566, acc: 0.8152567799251871, lr: 0.048069458781029376
[batch_idx--450] train_loss: 0.0015776682884710443, acc: 0.8156264102475093, lr: 0.048047028659953764
total time of one epoch: 399.2224717140198 s
train_loss:  0.0015776682884710443  acc:  0.8156264102475093
->>lr:0.048047
test_loss:  0.0015118981446118134  test_acc:  0.8267775158208215
best acc:  82.81424494354138

------Epoch: 19------
[batch_idx--0] train_loss: 0.001721608336083591, acc: 0.796875, lr: 0.04804657878971252
[batch_idx--50] train_loss: 0.0015729238329382212, acc: 0.8167892156862745, lr: 0.04802402192830846
[batch_idx--100] train_loss: 0.0015621823500749645, acc: 0.8167930074257426, lr: 0.04800134093450581
[batch_idx--150] train_loss: 0.0015582899233042601, acc: 0.8165873344370861, lr: 0.04797853593058756
[batch_idx--200] train_loss: 0.0015567606471395537, acc: 0.8155900186567164, lr: 0.04795560703950527
[batch_idx--250] train_loss: 0.0015540279172531577, acc: 0.8166396912350598, lr: 0.047932554384878465
[batch_idx--300] train_loss: 0.0015575169953842495, acc: 0.8165100705980066, lr: 0.0479093780909939
[batch_idx--350] train_loss: 0.0015583087864631728, acc: 0.8168068910256411, lr: 0.047886078282804945
[batch_idx--400] train_loss: 0.0015591176890389544, acc: 0.816883572319202, lr: 0.047862655085930884
[batch_idx--450] train_loss: 0.001561801893142004, acc: 0.8170843892109557, lr: 0.04783910862665624
total time of one epoch: 396.3934814929962 s
train_loss:  0.001561801893142004  acc:  0.8170843892109557
->>lr:0.047839
test_loss:  0.0015465557087087532  test_acc:  0.825536667080283
best acc:  82.81424494354138

------Epoch: 20------
[batch_idx--0] train_loss: 0.0015183949144557118, acc: 0.8125, lr: 0.04783863644106502
[batch_idx--50] train_loss: 0.0015311636140241342, acc: 0.8206954656862745, lr: 0.047814964384929284
[batch_idx--100] train_loss: 0.0015246293502905876, acc: 0.8217435024752475, lr: 0.047791169323514016
[batch_idx--150] train_loss: 0.0015274516741640323, acc: 0.8210885761589404, lr: 0.047767251385108636
[batch_idx--200] train_loss: 0.0015344311111370353, acc: 0.8210898631840796, lr: 0.04774321069866503
[batch_idx--250] train_loss: 0.0015320904985203804, acc: 0.821277390438247, lr: 0.04771904739379687
[batch_idx--300] train_loss: 0.001535389283470859, acc: 0.8203125, lr: 0.0476947616007789
[batch_idx--350] train_loss: 0.00153205662891481, acc: 0.820991363960114, lr: 0.0476703534505463
[batch_idx--400] train_loss: 0.0015326865761194778, acc: 0.8209262001246883, lr: 0.047645823074693894
[batch_idx--450] train_loss: 0.0015351184698668581, acc: 0.8215798243482487, lr: 0.047621170605475466
total time of one epoch: 398.3428680896759 s
train_loss:  0.0015351184698668581  acc:  0.8215798243482487
->>lr:0.047621
test_loss:  0.001531879538592755  test_acc:  0.823799478843529
best acc:  82.81424494354138

------Epoch: 21------
[batch_idx--0] train_loss: 0.0014819636708125472, acc: 0.84765625, lr: 0.04762067631165049
[batch_idx--50] train_loss: 0.0015400873894310173, acc: 0.8215379901960784, lr: 0.047595899444129244
[batch_idx--100] train_loss: 0.0015234447148914385, acc: 0.8215887995049505, lr: 0.04757100075240174
[batch_idx--150] train_loss: 0.0015147278410697121, acc: 0.8235461506622517, lr: 0.04754598037070751
[batch_idx--200] train_loss: 0.0015117580729040933, acc: 0.8247434701492538, lr: 0.047520838433942204
[batch_idx--250] train_loss: 0.0015198321089118837, acc: 0.8240319970119522, lr: 0.04749557507765681
[batch_idx--300] train_loss: 0.0015159309211270604, acc: 0.8244134136212624, lr: 0.047470190438056926
[batch_idx--350] train_loss: 0.001521450300578909, acc: 0.8237735933048433, lr: 0.047444684652002064
[batch_idx--400] train_loss: 0.0015236616655464222, acc: 0.8227965243142145, lr: 0.04741905785700488
[batch_idx--450] train_loss: 0.001527051125671613, acc: 0.8223695629534488, lr: 0.04739331019123044
total time of one epoch: 400.8423185348511 s
train_loss:  0.001527051125671613  acc:  0.8223695629534488
->>lr:0.047393
test_loss:  0.0014735042664264831  test_acc:  0.833105844397568
best acc:  82.81424494354138
Saving..

------Epoch: 22------
[batch_idx--0] train_loss: 0.0012965539935976267, acc: 0.85546875, lr: 0.047392794005985325
[batch_idx--50] train_loss: 0.0015170178969628086, acc: 0.8223805147058824, lr: 0.04736692319503155
[batch_idx--100] train_loss: 0.0015136453041825258, acc: 0.8232905321782178, lr: 0.047340931794380904
[batch_idx--150] train_loss: 0.0015301200166492666, acc: 0.8211661837748344, lr: 0.04731481994416418
[batch_idx--200] train_loss: 0.0015285880558554138, acc: 0.8216923196517413, lr: 0.04728858778516159
[batch_idx--250] train_loss: 0.001520209918373758, acc: 0.8239697460159362, lr: 0.04726223545880198
[batch_idx--300] train_loss: 0.0015205513535878092, acc: 0.823686669435216, lr: 0.04723576310716207
[batch_idx--350] train_loss: 0.001518812033538826, acc: 0.8241853632478633, lr: 0.047209170872965694
[batch_idx--400] train_loss: 0.0015136639481907398, acc: 0.8251052057356608, lr: 0.047182458899583
[batch_idx--450] train_loss: 0.0015173540353158432, acc: 0.8245565313986184, lr: 0.04715562733102973
total time of one epoch: 397.69260430336 s
train_loss:  0.0015173540353158432  acc:  0.8245565313986184
->>lr:0.047156
test_loss:  0.0015068654905168453  test_acc:  0.8321131654051371
best acc:  83.3105844397568

------Epoch: 23------
[batch_idx--0] train_loss: 0.0014805920654907823, acc: 0.8515625, lr: 0.04715508948078037
[batch_idx--50] train_loss: 0.0014838860872402495, acc: 0.8269761029411765, lr: 0.047128136074186804
[batch_idx--100] train_loss: 0.0014938206370403565, acc: 0.8249149133663366, lr: 0.04710106336530035
[batch_idx--150] train_loss: 0.0014894494096076253, acc: 0.8256674254966887, lr: 0.04707387150008163
[batch_idx--200] train_loss: 0.0014962833583243747, acc: 0.8248212064676617, lr: 0.04704656062513368
[batch_idx--250] train_loss: 0.0014949267293211533, acc: 0.8254482071713147, lr: 0.04701913088770116
[batch_idx--300] train_loss: 0.0014950646953100332, acc: 0.8259707225913622, lr: 0.04699158243566958
[batch_idx--350] train_loss: 0.001493490941854369, acc: 0.8262553418803419, lr: 0.04696391541756448
[batch_idx--400] train_loss: 0.001494449757833842, acc: 0.825845542394015, lr: 0.046936129982550645
[batch_idx--450] train_loss: 0.0014978602275624263, acc: 0.8261099732703857, lr: 0.0469082262804313
total time of one epoch: 404.15859031677246 s
train_loss:  0.0014978602275624263  acc:  0.8261099732703857
->>lr:0.046908
test_loss:  0.001432137603809467  test_acc:  0.8388137486040451
best acc:  83.3105844397568
Saving..

------Epoch: 24------
[batch_idx--0] train_loss: 0.0015445819590240717, acc: 0.8125, lr: 0.04690766700109659
[batch_idx--50] train_loss: 0.0015047963425590127, acc: 0.8214613970588235, lr: 0.04687964282151817
[batch_idx--100] train_loss: 0.0015026375496907547, acc: 0.823174504950495, lr: 0.046851500679380806
[batch_idx--150] train_loss: 0.0015030100021128918, acc: 0.824296357615894, lr: 0.046823240726410885
[batch_idx--200] train_loss: 0.0014980062274771988, acc: 0.8252876243781094, lr: 0.046794863114969956
[batch_idx--250] train_loss: 0.0014826018823332996, acc: 0.8274558017928287, lr: 0.04676636799805392
[batch_idx--300] train_loss: 0.0014827656199957594, acc: 0.8282288205980066, lr: 0.046737755529292206
[batch_idx--350] train_loss: 0.0014840824223731105, acc: 0.8280582264957265, lr: 0.046709025862946923
[batch_idx--400] train_loss: 0.0014820588317739213, acc: 0.8278717269326683, lr: 0.046680179153912066
[batch_idx--450] train_loss: 0.0014841948799238312, acc: 0.8280452667754366, lr: 0.04665121555771262
total time of one epoch: 397.7319030761719 s
train_loss:  0.0014841948799238312  acc:  0.8280452667754366
->>lr:0.046651
test_loss:  0.0014477286634351704  test_acc:  0.835587541878645
best acc:  83.88137486040452

------Epoch: 25------
[batch_idx--0] train_loss: 0.0017163704615086317, acc: 0.75390625, lr: 0.046650635094610975
[batch_idx--50] train_loss: 0.0015070879736038692, acc: 0.8246017156862745, lr: 0.04662155243437907
[batch_idx--100] train_loss: 0.00149013269761817, acc: 0.826771349009901, lr: 0.04659235320306443
[batch_idx--150] train_loss: 0.0014856807889096094, acc: 0.8274265314569537, lr: 0.046563037558092685
[batch_idx--200] train_loss: 0.0014845825661094257, acc: 0.8275419776119403, lr: 0.04653360565751704
[batch_idx--250] train_loss: 0.0014771752493582162, acc: 0.8290120766932271, lr: 0.04650405766001754
[batch_idx--300] train_loss: 0.001471768217269591, acc: 0.8291112956810631, lr: 0.04647439372490014
[batch_idx--350] train_loss: 0.0014744181808832493, acc: 0.8287148326210826, lr: 0.046444614012095875
[batch_idx--400] train_loss: 0.0014760776230150327, acc: 0.828495168329177, lr: 0.046414718682159954
[batch_idx--450] train_loss: 0.0014825103925446964, acc: 0.8281494081299684, lr: 0.04638470789627097
total time of one epoch: 396.6802091598511 s
train_loss:  0.0014825103925446964  acc:  0.8281494081299684
->>lr:0.046385
test_loss:  0.00145050311209857  test_acc:  0.8354634570045911
best acc:  83.88137486040452

------Epoch: 26------
[batch_idx--0] train_loss: 0.001478975755162537, acc: 0.83203125, lr: 0.04638410650401267
[batch_idx--50] train_loss: 0.001492025878499536, acc: 0.8262867647058824, lr: 0.04635397811974326
[batch_idx--100] train_loss: 0.0014770763515872826, acc: 0.8300587871287128, lr: 0.04632373460699926
[batch_idx--150] train_loss: 0.001468208731793558, acc: 0.8306084437086093, lr: 0.04629337612883644
[batch_idx--200] train_loss: 0.001465862562453643, acc: 0.8316425684079602, lr: 0.046262902848930414
[batch_idx--250] train_loss: 0.0014659442374876058, acc: 0.8316888695219123, lr: 0.04623231493157573
[batch_idx--300] train_loss: 0.0014641982533402766, acc: 0.8317846760797342, lr: 0.046201612541685
[batch_idx--350] train_loss: 0.001468142271678672, acc: 0.8310964209401709, lr: 0.046170795844788
[batch_idx--400] train_loss: 0.0014676019544144186, acc: 0.8313103958852868, lr: 0.04613986500703078
[batch_idx--450] train_loss: 0.001465093134824018, acc: 0.8318551046620613, lr: 0.0461088201951748
total time of one epoch: 400.1151547431946 s
train_loss:  0.001465093134824018  acc:  0.8318551046620613
->>lr:0.046109
test_loss:  0.0013900156544165748  test_acc:  0.8439012284402532
best acc:  83.88137486040452
Saving..

------Epoch: 27------
[batch_idx--0] train_loss: 0.0019014308927580714, acc: 0.78125, lr: 0.04610819813755038
[batch_idx--50] train_loss: 0.001475175959058106, acc: 0.8272824754901961, lr: 0.04607703724454855
[batch_idx--100] train_loss: 0.0014660059264630522, acc: 0.8288598391089109, lr: 0.046045762716179425
[batch_idx--150] train_loss: 0.0014667307367449663, acc: 0.8298841059602649, lr: 0.04601437472105743
[batch_idx--200] train_loss: 0.001456340799798531, acc: 0.8313899253731343, lr: 0.04598287342840873
[batch_idx--250] train_loss: 0.0014498686738891075, acc: 0.8321713147410359, lr: 0.04595125900807036
[batch_idx--300] train_loss: 0.0014516723998187983, acc: 0.8319014742524917, lr: 0.045919531630489216
[batch_idx--350] train_loss: 0.0014493308952768093, acc: 0.8324875356125356, lr: 0.045887691466721246
[batch_idx--400] train_loss: 0.001447574971150839, acc: 0.8328689993765586, lr: 0.04585573868843045
[batch_idx--450] train_loss: 0.0014509712818073879, acc: 0.8331395147012879, lr: 0.04582367346788801
total time of one epoch: 395.7180368900299 s
train_loss:  0.0014509712818073879  acc:  0.8331395147012879
->>lr:0.045824
test_loss:  0.0014825312859634266  test_acc:  0.8298796376721678
best acc:  84.39012284402531

------Epoch: 28------
[batch_idx--0] train_loss: 0.001274135080166161, acc: 0.8515625, lr: 0.04582303101775249
[batch_idx--50] train_loss: 0.001449857644426326, acc: 0.8322610294117647, lr: 0.04579085128421578
[batch_idx--100] train_loss: 0.0014515505921519776, acc: 0.833384900990099, lr: 0.04575855945826332
[batch_idx--150] train_loss: 0.0014567165180658366, acc: 0.8328849337748344, lr: 0.04572615571399419
[batch_idx--200] train_loss: 0.0014514471381087209, acc: 0.8337414490049752, lr: 0.045693640226110915
[batch_idx--250] train_loss: 0.0014464086871519982, acc: 0.8341322211155379, lr: 0.045661013169918455
[batch_idx--300] train_loss: 0.0014512102998347576, acc: 0.8339649086378738, lr: 0.04562827472132332
[batch_idx--350] train_loss: 0.0014527794252285082, acc: 0.8335336538461539, lr: 0.045595425056832534
[batch_idx--400] train_loss: 0.0014501538210690134, acc: 0.8336872662094763, lr: 0.04556246435355277
[batch_idx--450] train_loss: 0.0014536352090057257, acc: 0.8334953309959385, lr: 0.04552939278918935
total time of one epoch: 401.78362011909485 s
train_loss:  0.0014536352090057257  acc:  0.8334953309959385
->>lr:0.045529
test_loss:  0.0014185153131879046  test_acc:  0.8396823427224221
best acc:  84.39012284402531

------Epoch: 29------
[batch_idx--0] train_loss: 0.0014630521181970835, acc: 0.83203125, lr: 0.045528730228342605
[batch_idx--50] train_loss: 0.0014568076733791945, acc: 0.8331801470588235, lr: 0.04549554576936571
[batch_idx--100] train_loss: 0.001441987655540504, acc: 0.8339263613861386, lr: 0.04546225081009201
[batch_idx--150] train_loss: 0.0014345137447131094, acc: 0.836040976821192, lr: 0.04542884553002893
[batch_idx--200] train_loss: 0.0014393326174236129, acc: 0.8345382462686567, lr: 0.04539533010927871
[batch_idx--250] train_loss: 0.0014413644970613588, acc: 0.8341477838645418, lr: 0.04536170472853737
[batch_idx--300] train_loss: 0.0014423192486451612, acc: 0.8343023255813954, lr: 0.045327969569093796
[batch_idx--350] train_loss: 0.0014400026758342047, acc: 0.8346799323361823, lr: 0.04529412481282874
[batch_idx--400] train_loss: 0.001443527202862791, acc: 0.8340476932668329, lr: 0.04526017064221382
[batch_idx--450] train_loss: 0.0014429450018025116, acc: 0.8344933523102024, lr: 0.04522610724031057
total time of one epoch: 397.72528648376465 s
train_loss:  0.0014429450018025116  acc:  0.8344933523102024
->>lr:0.045226
test_loss:  0.0014671416832327119  test_acc:  0.8368283906191836
best acc:  84.39012284402531

------Epoch: 30------
[batch_idx--0] train_loss: 0.0015851621283218265, acc: 0.82421875, lr: 0.04522542485937369
[batch_idx--50] train_loss: 0.0013974440631036665, acc: 0.8408394607843137, lr: 0.04519125023075707
[batch_idx--100] train_loss: 0.0014219396404165886, acc: 0.8347772277227723, lr: 0.045156966742431685
[batch_idx--150] train_loss: 0.001428720522795292, acc: 0.8348251241721855, lr: 0.04512257457923455
[batch_idx--200] train_loss: 0.0014346108096535896, acc: 0.8348491915422885, lr: 0.04508807392658861
[batch_idx--250] train_loss: 0.0014353888763292911, acc: 0.8346769173306773, lr: 0.0450534649705017
[batch_idx--300] train_loss: 0.0014360759881451924, acc: 0.8346916528239202, lr: 0.04501874789756559
[batch_idx--350] train_loss: 0.0014416673227327418, acc: 0.8335670405982906, lr: 0.04498392289495493
[batch_idx--400] train_loss: 0.0014376091054336463, acc: 0.8341938123441397, lr: 0.04494899015042629
[batch_idx--450] train_loss: 0.0014443674631739835, acc: 0.8341982851390287, lr: 0.04491394985231711
total time of one epoch: 397.9082703590393 s
train_loss:  0.0014443674631739835  acc:  0.8341982851390287
->>lr:0.044914
test_loss:  0.001520726329148119  test_acc:  0.82801836456136
best acc:  84.39012284402531

------Epoch: 31------
[batch_idx--0] train_loss: 0.0013542547821998596, acc: 0.84765625, lr: 0.04491324795060491
[batch_idx--50] train_loss: 0.0014059033094193129, acc: 0.836703431372549, lr: 0.04487809814247016
[batch_idx--100] train_loss: 0.0014165758563316252, acc: 0.8373298267326733, lr: 0.044842841162964144
[batch_idx--150] train_loss: 0.0014142886417862397, acc: 0.8377224751655629, lr: 0.04480747720217241
[batch_idx--200] train_loss: 0.0014176534602316606, acc: 0.8372784514925373, lr: 0.04477200645075726
[batch_idx--250] train_loss: 0.001414432486266907, acc: 0.8374159611553785, lr: 0.04473642909995676
[batch_idx--300] train_loss: 0.001418901773315059, acc: 0.8366123338870431, lr: 0.044700745341583706
[batch_idx--350] train_loss: 0.0014129462615424964, acc: 0.8376736111111112, lr: 0.044664955368024575
[batch_idx--400] train_loss: 0.0014199054631012075, acc: 0.8367460255610972, lr: 0.044629059372238496
[batch_idx--450] train_loss: 0.0014220684778149474, acc: 0.8370534939424445, lr: 0.044593057547756214
total time of one epoch: 399.80100321769714 s
train_loss:  0.0014220684778149474  acc:  0.8370534939424445
->>lr:0.044593
test_loss:  0.0014225562625553195  test_acc:  0.840675021714853
best acc:  84.39012284402531

------Epoch: 32------
[batch_idx--0] train_loss: 0.0014965616865083575, acc: 0.81640625, lr: 0.044592336433146
[batch_idx--50] train_loss: 0.0014390726802030614, acc: 0.8343290441176471, lr: 0.04455622686336067
[batch_idx--100] train_loss: 0.0014276932394777489, acc: 0.8359761757425742, lr: 0.0445200118575505
[batch_idx--150] train_loss: 0.001430787480689141, acc: 0.835885761589404, lr: 0.04448369161096615
[batch_idx--200] train_loss: 0.0014288648430128299, acc: 0.8362873134328358, lr: 0.044447266319425686
[batch_idx--250] train_loss: 0.0014290536310434697, acc: 0.8364043824701195, lr: 0.044410736179313494
[batch_idx--300] train_loss: 0.00142445787903466, acc: 0.8371054817275747, lr: 0.04437410138757928
[batch_idx--350] train_loss: 0.0014217135979345552, acc: 0.8377737713675214, lr: 0.04433736214173695
[batch_idx--400] train_loss: 0.001421538800839567, acc: 0.8377493765586035, lr: 0.04430051863986356
[batch_idx--450] train_loss: 0.00142323968596256, acc: 0.8377824834241677, lr: 0.04426357108059828
total time of one epoch: 393.22829127311707 s
train_loss:  0.00142323968596256  acc:  0.8377824834241677
->>lr:0.044264
test_loss:  0.0014122832515189717  test_acc:  0.8388137486040451
best acc:  84.39012284402531

------Epoch: 33------
[batch_idx--0] train_loss: 0.001739305560477078, acc: 0.78515625, lr: 0.044262831069394735
[batch_idx--50] train_loss: 0.0014200924539609866, acc: 0.8339460784313726, lr: 0.04422577757680957
[batch_idx--100] train_loss: 0.0014061175014749908, acc: 0.8379099628712872, lr: 0.04418862042979371
[batch_idx--150] train_loss: 0.0014011524062579042, acc: 0.8388865894039735, lr: 0.044151359828677295
[batch_idx--200] train_loss: 0.001391411545241613, acc: 0.8402129975124378, lr: 0.04411399597434825
[batch_idx--250] train_loss: 0.0013886321149580922, acc: 0.8411821464143426, lr: 0.04407652906825116
[batch_idx--300] train_loss: 0.0013906536380175589, acc: 0.8410117317275747, lr: 0.04403895931238623
[batch_idx--350] train_loss: 0.0013971867250740274, acc: 0.8403111645299145, lr: 0.044001286909308164
[batch_idx--400] train_loss: 0.0013977158991759294, acc: 0.8402821072319202, lr: 0.04396351206212508
[batch_idx--450] train_loss: 0.0014044469135200798, acc: 0.8398566320685944, lr: 0.043925634974497405
total time of one epoch: 394.54252314567566 s
train_loss:  0.0014044469135200798  acc:  0.8398566320685944
->>lr:0.043926
test_loss:  0.001505329707580341  test_acc:  0.8321131654051371
best acc:  84.39012284402531

------Epoch: 34------
[batch_idx--0] train_loss: 0.0015171872219070792, acc: 0.81640625, lr: 0.043924876391293916
[batch_idx--50] train_loss: 0.0013722839249371021, acc: 0.8455116421568627, lr: 0.0438868952287954
[batch_idx--100] train_loss: 0.0014080390181982576, acc: 0.8397663985148515, lr: 0.04384881223892658
[batch_idx--150] train_loss: 0.0014188145410688902, acc: 0.8371274834437086, lr: 0.04381062762700922
[batch_idx--200] train_loss: 0.00140622966292671, acc: 0.8385611007462687, lr: 0.043772341598912995
[batch_idx--250] train_loss: 0.0013999658116358388, acc: 0.8396569970119522, lr: 0.04373395436105431
[batch_idx--300] train_loss: 0.0014028075712723689, acc: 0.8392857142857143, lr: 0.04369546612039528
[batch_idx--350] train_loss: 0.0014048944906652652, acc: 0.8389311787749287, lr: 0.04365687708444255
[batch_idx--400] train_loss: 0.0014047683466300183, acc: 0.83897677680798, lr: 0.04361818746124621
[batch_idx--450] train_loss: 0.0014083844658344148, acc: 0.8387805047384316, lr: 0.04357939745939863
total time of one epoch: 390.2665195465088 s
train_loss:  0.0014083844658344148  acc:  0.8387805047384316
->>lr:0.043579
test_loss:  0.0014522281706606814  test_acc:  0.835587541878645
best acc:  84.39012284402531

------Epoch: 35------
[batch_idx--0] train_loss: 0.0013863054336979985, acc: 0.83203125, lr: 0.04357862063693486
[batch_idx--50] train_loss: 0.001394146923249697, acc: 0.8388480392156863, lr: 0.04353972846431615
[batch_idx--100] train_loss: 0.0014109350279858798, acc: 0.8378712871287128, lr: 0.043500736336052385
[batch_idx--150] train_loss: 0.001406069272136106, acc: 0.8382398592715232, lr: 0.04346164446236689
[batch_idx--200] train_loss: 0.0014025272444743125, acc: 0.8395716728855721, lr: 0.04342245305402075
[batch_idx--250] train_loss: 0.0013986645717233182, acc: 0.8401705677290837, lr: 0.04338316232231171
[batch_idx--300] train_loss: 0.0013945298106951077, acc: 0.8406483596345515, lr: 0.043343772479072985
[batch_idx--350] train_loss: 0.0013925444982823866, acc: 0.8404669693732194, lr: 0.043304283736672146
[batch_idx--400] train_loss: 0.0013887228370479256, acc: 0.841080891521197, lr: 0.04326469630800999
[batch_idx--450] train_loss: 0.001392175577347896, acc: 0.8407852258131704, lr: 0.04322501040651934
total time of one epoch: 396.6112024784088 s
train_loss:  0.001392175577347896  acc:  0.8407852258131704
->>lr:0.043225
test_loss:  0.0015462913041612413  test_acc:  0.8219382057327211
best acc:  84.39012284402531

------Epoch: 36------
[batch_idx--0] train_loss: 0.001603800687007606, acc: 0.8359375, lr: 0.04322421568553529
[batch_idx--50] train_loss: 0.0013732064661442064, acc: 0.8471200980392157, lr: 0.04318442956218869
[batch_idx--100] train_loss: 0.0013688086269257388, acc: 0.845413056930693, lr: 0.04314454539876614
[batch_idx--150] train_loss: 0.0013799052230631377, acc: 0.8441380380794702, lr: 0.043104563410300306
[batch_idx--200] train_loss: 0.00137600294471862, acc: 0.8442552860696517, lr: 0.043064483812351256
[batch_idx--250] train_loss: 0.0013797743889722098, acc: 0.8436254980079682, lr: 0.04302430682100536
[batch_idx--300] train_loss: 0.0013784783077426255, acc: 0.8437240448504983, lr: 0.042984032652874024
[batch_idx--350] train_loss: 0.0013750283771587213, acc: 0.8444845085470085, lr: 0.04294366152509261
[batch_idx--400] train_loss: 0.0013772202744218346, acc: 0.8443831826683291, lr: 0.04290319365531922
[batch_idx--450] train_loss: 0.001378056611117649, acc: 0.8441698198354567, lr: 0.04286262926173353
total time of one epoch: 398.50977301597595 s
train_loss:  0.001378056611117649  acc:  0.8441698198354567
->>lr:0.042863
test_loss:  0.0013430787458181942  test_acc:  0.854200272986723
best acc:  84.39012284402531
Saving..

------Epoch: 37------
[batch_idx--0] train_loss: 0.0013184617273509502, acc: 0.8515625, lr: 0.04286181699082009
[batch_idx--50] train_loss: 0.0014060980288823153, acc: 0.8409926470588235, lr: 0.04282115436825425
[batch_idx--100] train_loss: 0.001390991907677438, acc: 0.84375, lr: 0.04278039566418517
[batch_idx--150] train_loss: 0.0013781184876423996, acc: 0.8446554221854304, lr: 0.04273954109836054
[batch_idx--200] train_loss: 0.001375931247939073, acc: 0.8445856654228856, lr: 0.0426985908910449
[batch_idx--250] train_loss: 0.0013793636344380648, acc: 0.8440145667330677, lr: 0.042657545263018404
[batch_idx--300] train_loss: 0.0013835512471394582, acc: 0.8430102782392026, lr: 0.042616404435575676
[batch_idx--350] train_loss: 0.001380331494229875, acc: 0.843215811965812, lr: 0.04257516863052461
[batch_idx--400] train_loss: 0.0013797074612090714, acc: 0.843165523690773, lr: 0.04253383807018514
[batch_idx--450] train_loss: 0.00138063942237312, acc: 0.8437358975249072, lr: 0.042492412977388094
total time of one epoch: 392.2269957065582 s
train_loss:  0.00138063942237312  acc:  0.8437358975249072
->>lr:0.042492
test_loss:  0.0014438053590959377  test_acc:  0.8378210696116144
best acc:  85.4200272986723

------Epoch: 38------
[batch_idx--0] train_loss: 0.0014462319668382406, acc: 0.83984375, lr: 0.042491583512834136
[batch_idx--50] train_loss: 0.0013806839820508863, acc: 0.8396905637254902, lr: 0.04245006222701923
[batch_idx--100] train_loss: 0.0013785798074954217, acc: 0.8408106435643564, lr: 0.04240844686041831
[batch_idx--150] train_loss: 0.0013753657309424799, acc: 0.8416545943708609, lr: 0.042366737637397726
[batch_idx--200] train_loss: 0.001371651637687612, acc: 0.8423701803482587, lr: 0.04232493478282982
[batch_idx--250] train_loss: 0.0013778855267214585, acc: 0.8414934013944223, lr: 0.042283038522091754
[batch_idx--300] train_loss: 0.001381308098317455, acc: 0.8407781353820598, lr: 0.04224104908106427
[batch_idx--350] train_loss: 0.0013751043069794603, acc: 0.8423700142450142, lr: 0.0421989666861305
[batch_idx--400] train_loss: 0.0013742439124844689, acc: 0.8428538029925187, lr: 0.04215679156417471
[batch_idx--450] train_loss: 0.001377784455946477, acc: 0.8428593744575971, lr: 0.04211452394258114
total time of one epoch: 399.67266154289246 s
train_loss:  0.001377784455946477  acc:  0.8428593744575971
->>lr:0.042115
test_loss:  0.0013108839503824452  test_acc:  0.8561856309715845
best acc:  85.4200272986723
Saving..

------Epoch: 39------
[batch_idx--0] train_loss: 0.0013684181030839682, acc: 0.84375, lr: 0.04211367764821722
[batch_idx--50] train_loss: 0.0013607304917611911, acc: 0.8451286764705882, lr: 0.04207131591176148
[batch_idx--100] train_loss: 0.0013524236314293773, acc: 0.8459545173267327, lr: 0.042028862136503926
[batch_idx--150] train_loss: 0.0013591043222448882, acc: 0.8454314983443708, lr: 0.0419863165513311
[batch_idx--200] train_loss: 0.0013686444191030453, acc: 0.8440803793532339, lr: 0.041943679385624544
[batch_idx--250] train_loss: 0.0013681315330870123, acc: 0.8442480079681275, lr: 0.04190095086925955
[batch_idx--300] train_loss: 0.0013656016072549199, acc: 0.8443080357142857, lr: 0.041858131232603915
[batch_idx--350] train_loss: 0.001364762483209775, acc: 0.8444733796296297, lr: 0.04181522070651669
[batch_idx--400] train_loss: 0.0013640313830222016, acc: 0.8445487842892768, lr: 0.04177221952234698
[batch_idx--450] train_loss: 0.0013645738621903844, acc: 0.8454629083208942, lr: 0.041729127911932645
total time of one epoch: 395.6484041213989 s
train_loss:  0.0013645738621903844  acc:  0.8454629083208942
->>lr:0.041729
test_loss:  0.00132735000160791  test_acc:  0.8522149150018613
best acc:  85.61856309715846

------Epoch: 40------
[batch_idx--0] train_loss: 0.00125425448641181, acc: 0.8515625, lr: 0.04172826515897146
[batch_idx--50] train_loss: 0.001366779822217045, acc: 0.8427542892156863, lr: 0.04168508155313258
[batch_idx--100] train_loss: 0.0013660866499758592, acc: 0.8433245668316832, lr: 0.04164180799084732
[batch_idx--150] train_loss: 0.001364405806614271, acc: 0.8447330298013245, lr: 0.04159844470542206
[batch_idx--200] train_loss: 0.0013497226283102487, acc: 0.8475007773631841, lr: 0.041554991930646906
[batch_idx--250] train_loss: 0.0013515996432258374, acc: 0.8469870517928287, lr: 0.041511449900794445
[batch_idx--300] train_loss: 0.0013510188678793138, acc: 0.8473188330564784, lr: 0.04146781885061848
[batch_idx--350] train_loss: 0.001353390862438244, acc: 0.8466991631054132, lr: 0.04142409901535277
[batch_idx--400] train_loss: 0.0013538770458342837, acc: 0.8465067799251871, lr: 0.04138029063070971
[batch_idx--450] train_loss: 0.0013575922584887095, acc: 0.8460877564480855, lr: 0.041336393932879134
total time of one epoch: 396.8294816017151 s
train_loss:  0.0013575922584887095  acc:  0.8460877564480855
->>lr:0.041336
test_loss:  0.0013389572684234419  test_acc:  0.8512222360094305
best acc:  85.61856309715846

------Epoch: 41------
[batch_idx--0] train_loss: 0.001172940363176167, acc: 0.875, lr: 0.04133551509975264
[batch_idx--50] train_loss: 0.001350747597148167, acc: 0.846890318627451, lr: 0.041291528566287365
[batch_idx--100] train_loss: 0.0013468614180046734, acc: 0.8476949257425742, lr: 0.041247454198189024
[batch_idx--150] train_loss: 0.0013419556468478497, acc: 0.8478114652317881, lr: 0.04120329223308148
[batch_idx--200] train_loss: 0.0013477004316185986, acc: 0.8479866293532339, lr: 0.041159042909060875
[batch_idx--250] train_loss: 0.0013516991152483747, acc: 0.846675796812749, lr: 0.04111470646469433
[batch_idx--300] train_loss: 0.0013491782505588104, acc: 0.8473318106312292, lr: 0.04107028313901867
[batch_idx--350] train_loss: 0.001346664557776061, acc: 0.8476117343304843, lr: 0.04102577317153916
[batch_idx--400] train_loss: 0.0013514738156868986, acc: 0.8471204800498753, lr: 0.04098117680222813
[batch_idx--450] train_loss: 0.0013545761493003268, acc: 0.8471291699934044, lr: 0.04093649427152381
total time of one epoch: 401.3643534183502 s
train_loss:  0.0013545761493003268  acc:  0.8471291699934044
->>lr:0.040936
test_loss:  0.0013941826433117152  test_acc:  0.8450179923067378
best acc:  85.61856309715846

------Epoch: 42------
[batch_idx--0] train_loss: 0.0012346628354862332, acc: 0.8515625, lr: 0.040935599743717244
[batch_idx--50] train_loss: 0.0013493584450699535, acc: 0.8491115196078431, lr: 0.04089082957657292
[batch_idx--100] train_loss: 0.0013498261681582668, acc: 0.8486618193069307, lr: 0.04084597373513602
[batch_idx--150] train_loss: 0.001360577056246088, acc: 0.8461558360927153, lr: 0.04080103246124366
[batch_idx--200] train_loss: 0.0013584134583616285, acc: 0.8461403917910447, lr: 0.04075600599719357
[batch_idx--250] train_loss: 0.0013556300223697406, acc: 0.8461622260956175, lr: 0.04071089458574278
[batch_idx--300] train_loss: 0.001348154208595026, acc: 0.847124169435216, lr: 0.04066569847010627
[batch_idx--350] train_loss: 0.0013472573474139782, acc: 0.8472110933048433, lr: 0.040620417893955756
[batch_idx--400] train_loss: 0.0013451459768235201, acc: 0.8474322007481296, lr: 0.04057505310141827
[batch_idx--450] train_loss: 0.0013495860330042242, acc: 0.8472246329017252, lr: 0.04052960433707492
total time of one epoch: 400.24838376045227 s
train_loss:  0.0013495860330042242  acc:  0.8472246329017252
->>lr:0.040530
test_loss:  0.0014683909104973585  test_acc:  0.8391860032262067
best acc:  85.61856309715846

------Epoch: 43------
[batch_idx--0] train_loss: 0.0011982738506048918, acc: 0.87890625, lr: 0.040528694506957764
[batch_idx--50] train_loss: 0.0013404747895786866, acc: 0.8511795343137255, lr: 0.04048316034380937
[batch_idx--100] train_loss: 0.0013404689109100417, acc: 0.8483910891089109, lr: 0.040437542704288454
[batch_idx--150] train_loss: 0.001335342299803746, acc: 0.8483029801324503, lr: 0.04039184183433934
[batch_idx--200] train_loss: 0.0013344114633573598, acc: 0.8485307835820896, lr: 0.04034605798035504
[batch_idx--250] train_loss: 0.0013357862951679238, acc: 0.848621140438247, lr: 0.04030019138917598
[batch_idx--300] train_loss: 0.0013369755866624836, acc: 0.848499792358804, lr: 0.040254242308088696
[batch_idx--350] train_loss: 0.001336142572672491, acc: 0.8489805911680912, lr: 0.040208210984824425
[batch_idx--400] train_loss: 0.0013363969055331891, acc: 0.8487472724438903, lr: 0.04016209766755781
[batch_idx--450] train_loss: 0.0013375390687894104, acc: 0.8490471066060332, lr: 0.040115902604905565
total time of one epoch: 398.39993929862976 s
train_loss:  0.0013375390687894104  acc:  0.8490471066060332
->>lr:0.040116
test_loss:  0.0012862483795974017  test_acc:  0.8606526864375232
best acc:  85.61856309715846
Saving..

------Epoch: 44------
[batch_idx--0] train_loss: 0.0014273301931098104, acc: 0.84375, lr: 0.040114977871559376
[batch_idx--50] train_loss: 0.0013303346361271014, acc: 0.8475030637254902, lr: 0.04006869968519579
[batch_idx--100] train_loss: 0.0013279450739189834, acc: 0.8491259282178217, lr: 0.04002234025699524
[batch_idx--150] train_loss: 0.0013339919792118154, acc: 0.8497257864238411, lr: 0.039975899836901335
[batch_idx--200] train_loss: 0.0013348755006219691, acc: 0.849541355721393, lr: 0.03992937867529435
[batch_idx--250] train_loss: 0.001336901615637232, acc: 0.848652265936255, lr: 0.03988277702298985
[batch_idx--300] train_loss: 0.0013380937237273964, acc: 0.8490318729235881, lr: 0.03983609513123738
[batch_idx--350] train_loss: 0.0013401060410910565, acc: 0.8490139779202279, lr: 0.03978933325171908
[batch_idx--400] train_loss: 0.001338634985159999, acc: 0.8490492518703242, lr: 0.03974249163654834
[batch_idx--450] train_loss: 0.001340459510681427, acc: 0.8489863574825564, lr: 0.03969557053826845
total time of one epoch: 395.59403252601624 s
train_loss:  0.001340459510681427  acc:  0.8489863574825564
->>lr:0.039696
test_loss:  0.0013396135703670372  test_acc:  0.8509740662613228
best acc:  86.06526864375233

------Epoch: 45------
[batch_idx--0] train_loss: 0.0013415062567219138, acc: 0.828125, lr: 0.03969463130731183
[batch_idx--50] train_loss: 0.0013705414957275578, acc: 0.8434436274509803, lr: 0.0396476293968751
[batch_idx--100] train_loss: 0.0013259833731624011, acc: 0.8508276608910891, lr: 0.03960054851477232
[batch_idx--150] train_loss: 0.0013308254523905895, acc: 0.8499586092715232, lr: 0.039553388914836764
[batch_idx--200] train_loss: 0.0013230607117438197, acc: 0.8510766480099502, lr: 0.039506150851326104
[batch_idx--250] train_loss: 0.0013229597677139053, acc: 0.8514379980079682, lr: 0.039458834578921055
[batch_idx--300] train_loss: 0.001320283583046689, acc: 0.8517182308970099, lr: 0.03941144035272397
[batch_idx--350] train_loss: 0.0013218086904068704, acc: 0.8513510505698005, lr: 0.03936396842825749
[batch_idx--400] train_loss: 0.0013252691681638472, acc: 0.8509195760598504, lr: 0.03931641906146319
[batch_idx--450] train_loss: 0.0013283236311700064, acc: 0.8505484778005346, lr: 0.03926879250870011
total time of one epoch: 393.8544833660126 s
train_loss:  0.0013283236311700064  acc:  0.8505484778005346
->>lr:0.039269
test_loss:  0.0013228272930211058  test_acc:  0.8568060553418538
best acc:  86.06526864375233

------Epoch: 46------
[batch_idx--0] train_loss: 0.001533722272142768, acc: 0.8125, lr: 0.0392678391921108
[batch_idx--50] train_loss: 0.0013180688530316249, acc: 0.8492647058823529, lr: 0.03922013417419226
[batch_idx--100] train_loss: 0.0013253130814023684, acc: 0.8497834158415841, lr: 0.03917235248941817
[batch_idx--150] train_loss: 0.0013227438853301158, acc: 0.8497775248344371, lr: 0.03912449439540013
[batch_idx--200] train_loss: 0.0013278254657631639, acc: 0.8492692786069652, lr: 0.0390765601501617
[batch_idx--250] train_loss: 0.0013232160365650527, acc: 0.84964828187251, lr: 0.03902855001213699
[batch_idx--300] train_loss: 0.0013245880668379514, acc: 0.8498105274086378, lr: 0.0389804642401693
[batch_idx--350] train_loss: 0.0013226421360534076, acc: 0.8502604166666666, lr: 0.03893230309350968
[batch_idx--400] train_loss: 0.001323631611168431, acc: 0.850325358478803, lr: 0.03888406683181559
[batch_idx--450] train_loss: 0.0013252748277000962, acc: 0.8500798417051411, lr: 0.03883575571514944
total time of one epoch: 392.637624502182 s
train_loss:  0.0013252748277000962  acc:  0.8500798417051411
->>lr:0.038836
test_loss:  0.0013164679160084377  test_acc:  0.8543243578607768
best acc:  86.06526864375233

------Epoch: 47------
[batch_idx--0] train_loss: 0.001116254017688334, acc: 0.8671875, lr: 0.038834788731083605
[batch_idx--50] train_loss: 0.0013217734168374947, acc: 0.8498774509803921, lr: 0.038786401530680796
[batch_idx--100] train_loss: 0.0013244539824323637, acc: 0.8504022277227723, lr: 0.03873794000186154
[batch_idx--150] train_loss: 0.0013186408488992725, acc: 0.8511485927152318, lr: 0.03868940440590278
[batch_idx--200] train_loss: 0.0013200050493266749, acc: 0.851445895522388, lr: 0.03864079500448077
[batch_idx--250] train_loss: 0.0013208697516140918, acc: 0.8509866782868526, lr: 0.03859211205966969
[batch_idx--300] train_loss: 0.0013175733015018567, acc: 0.85187396179402, lr: 0.038543355833940224
[batch_idx--350] train_loss: 0.00132034936050176, acc: 0.8514734686609686, lr: 0.03849452659015813
[batch_idx--400] train_loss: 0.0013215446525643535, acc: 0.8512897443890274, lr: 0.03844562459158286
[batch_idx--450] train_loss: 0.001325640821727341, acc: 0.8514597146526885, lr: 0.0383966501018661
total time of one epoch: 391.7785656452179 s
train_loss:  0.001325640821727341  acc:  0.8514597146526885
->>lr:0.038397
test_loss:  0.001301312712111889  test_acc:  0.8584191587045539
best acc:  86.06526864375233

------Epoch: 48------
[batch_idx--0] train_loss: 0.0014530173502862453, acc: 0.8203125, lr: 0.03839566987447492
[batch_idx--50] train_loss: 0.0013028481317793623, acc: 0.8534773284313726, lr: 0.038346621715813135
[batch_idx--100] train_loss: 0.0012996674303223591, acc: 0.8537283415841584, lr: 0.038297501599776934
[batch_idx--150] train_loss: 0.0012998419107610223, acc: 0.8530111754966887, lr: 0.03824830979119395
[batch_idx--200] train_loss: 0.0013094977939047327, acc: 0.8521843905472637, lr: 0.038199046555278386
[batch_idx--250] train_loss: 0.0013113096050279905, acc: 0.8516714392430279, lr: 0.038149712157629516
[batch_idx--300] train_loss: 0.0013141160176454291, acc: 0.8515235672757475, lr: 0.038100306864230285
[batch_idx--350] train_loss: 0.0013223888025489076, acc: 0.8502159009971509, lr: 0.038050830941445866
[batch_idx--400] train_loss: 0.001319820454118871, acc: 0.8508513871571073, lr: 0.03800128465602222
[batch_idx--450] train_loss: 0.0013257766874238668, acc: 0.8504096226611587, lr: 0.03795166827508467
total time of one epoch: 396.17156314849854 s
train_loss:  0.0013257766874238668  acc:  0.8504096226611587
->>lr:0.037952
test_loss:  0.0013169019855951787  test_acc:  0.8525871696240228
best acc:  86.06526864375233

------Epoch: 49------
[batch_idx--0] train_loss: 0.0013958712806925178, acc: 0.84375, lr: 0.03795067523432826
[batch_idx--50] train_loss: 0.0013109094933515379, acc: 0.8514093137254902, lr: 0.037900987631550954
[batch_idx--100] train_loss: 0.0013015583367317473, acc: 0.8534189356435643, lr: 0.03785123047400412
[batch_idx--150] train_loss: 0.0012958822933808957, acc: 0.8545374586092715, lr: 0.03780140402994997
[batch_idx--200] train_loss: 0.0012923746250467884, acc: 0.8545164800995025, lr: 0.03775150856802428
[batch_idx--250] train_loss: 0.0013035764798069321, acc: 0.8532121513944223, lr: 0.03770154435723495
[batch_idx--300] train_loss: 0.0013029490720536374, acc: 0.8534442483388704, lr: 0.037651511666960506
[batch_idx--350] train_loss: 0.0013039168404903464, acc: 0.8530537749287749, lr: 0.03760141076694869
[batch_idx--400] train_loss: 0.0013055078697767099, acc: 0.8529652431421446, lr: 0.037551241927314974
[batch_idx--450] train_loss: 0.0013097947796454105, acc: 0.852900336723713, lr: 0.03750100541854115
total time of one epoch: 402.1421649456024 s
train_loss:  0.0013097947796454105  acc:  0.852900336723713
->>lr:0.037501
test_loss:  0.001431896637296363  test_acc:  0.839806427596476
best acc:  86.06526864375233

------Epoch: 50------
[batch_idx--0] train_loss: 0.0012340762186795473, acc: 0.85546875, lr: 0.037500000000000006
[batch_idx--50] train_loss: 0.0013109618562784995, acc: 0.8546262254901961, lr: 0.037449694747731944
[batch_idx--100] train_loss: 0.001313529602634619, acc: 0.8545792079207921, lr: 0.03739932237380827
[batch_idx--150] train_loss: 0.0013064240611972448, acc: 0.8546926738410596, lr: 0.03734888314980809
[batch_idx--200] train_loss: 0.0013034250844960375, acc: 0.8548079912935324, lr: 0.037298377347670955
[batch_idx--250] train_loss: 0.001306139097819884, acc: 0.8546750498007968, lr: 0.03724780523969534
[batch_idx--300] train_loss: 0.0013046678100740443, acc: 0.8543526785714286, lr: 0.03719716709853723
[batch_idx--350] train_loss: 0.0013074074836017995, acc: 0.8538995726495726, lr: 0.037146463197208594
[batch_idx--400] train_loss: 0.0013068147223417245, acc: 0.8539783354114713, lr: 0.03709569380907597
[batch_idx--450] train_loss: 0.0013122114021146534, acc: 0.8533082236956295, lr: 0.03704485920785895
total time of one epoch: 394.859735250473 s
train_loss:  0.0013122114021146534  acc:  0.8533082236956295
->>lr:0.037045
test_loss:  0.0012881747582278575  test_acc:  0.8607767713115771
best acc:  86.06526864375233
Saving..

------Epoch: 51------
[batch_idx--0] train_loss: 0.001399520318955183, acc: 0.8359375, lr: 0.037043841852542884
[batch_idx--50] train_loss: 0.0012974683241005621, acc: 0.8531709558823529, lr: 0.03699294101633032
[batch_idx--100] train_loss: 0.001310789379023827, acc: 0.8520652846534653, lr: 0.036941975521017835
[batch_idx--150] train_loss: 0.0012933888467990897, acc: 0.8535285596026491, lr: 0.0368909456413823
[batch_idx--200] train_loss: 0.0012920281724698509, acc: 0.8548079912935324, lr: 0.03683985165254776
[batch_idx--250] train_loss: 0.001289770161580903, acc: 0.8551263695219123, lr: 0.03678869382998386
[batch_idx--300] train_loss: 0.0012895655358036936, acc: 0.8558580772425249, lr: 0.03673747244950439
[batch_idx--350] train_loss: 0.0012912249940174214, acc: 0.8557024572649573, lr: 0.03668618778726586
[batch_idx--400] train_loss: 0.0012939567192854764, acc: 0.8543290211970075, lr: 0.0366348401197659
[batch_idx--450] train_loss: 0.001298145159857091, acc: 0.8545145277189572, lr: 0.036583429723841876
total time of one epoch: 394.4596269130707 s
train_loss:  0.001298145159857091  acc:  0.8545145277189572
->>lr:0.036583
test_loss:  0.0012620536790531346  test_acc:  0.8621417049261695
best acc:  86.07767713115771
Saving..

------Epoch: 52------
[batch_idx--0] train_loss: 0.0012621504720300436, acc: 0.84765625, lr: 0.036582400877996545
[batch_idx--50] train_loss: 0.0012916973906149174, acc: 0.8587622549019608, lr: 0.03653092678462853
[batch_idx--100] train_loss: 0.0012770794461121654, acc: 0.8576345915841584, lr: 0.036479390523077894
[batch_idx--150] train_loss: 0.0012859191062446955, acc: 0.8566587334437086, lr: 0.036427792371198774
[batch_idx--200] train_loss: 0.0012949583049984047, acc: 0.8552744092039801, lr: 0.036376132607179
[batch_idx--250] train_loss: 0.00129826192510318, acc: 0.8547061752988048, lr: 0.03632441150953856
[batch_idx--300] train_loss: 0.0013003490978938548, acc: 0.8544435215946844, lr: 0.036272629357128106
[batch_idx--350] train_loss: 0.0013007873790657036, acc: 0.8544782763532763, lr: 0.0362207864291275
[batch_idx--400] train_loss: 0.001300687126541264, acc: 0.8547186720698254, lr: 0.03616888300504424
[batch_idx--450] train_loss: 0.0012983096707302557, acc: 0.8552348387544694, lr: 0.03611691936471199
total time of one epoch: 395.28296184539795 s
train_loss:  0.0012983096707302557  acc:  0.8552348387544694
->>lr:0.036117
test_loss:  0.0013275944146732492  test_acc:  0.8555652066013153
best acc:  86.21417049261694

------Epoch: 53------
[batch_idx--0] train_loss: 0.0010551658924669027, acc: 0.890625, lr: 0.036115879479623185
[batch_idx--50] train_loss: 0.0012801343931213899, acc: 0.8578431372549019, lr: 0.0360638547073383
[batch_idx--100] train_loss: 0.0012731218277153991, acc: 0.8575185643564357, lr: 0.036011770285057136
[batch_idx--150] train_loss: 0.001267959147889093, acc: 0.8580815397350994, lr: 0.03595962649358918
[batch_idx--200] train_loss: 0.0012676200733302318, acc: 0.8587531094527363, lr: 0.03590742361406404
[batch_idx--250] train_loss: 0.0012765582757575283, acc: 0.8569938994023905, lr: 0.03585516192792988
[batch_idx--300] train_loss: 0.0012793135293604702, acc: 0.8568443729235881, lr: 0.03580284171695191
[batch_idx--350] train_loss: 0.0012838629326793734, acc: 0.8562477742165242, lr: 0.03575046326321087
[batch_idx--400] train_loss: 0.0012865338854531193, acc: 0.8554103023690773, lr: 0.035698026849101526
[batch_idx--450] train_loss: 0.0012887467575537963, acc: 0.8554604783559552, lr: 0.03564553275733112
total time of one epoch: 397.4286358356476 s
train_loss:  0.0012887467575537963  acc:  0.8554604783559552
->>lr:0.035646
test_loss:  0.001265854538337574  test_acc:  0.8626380444223849
best acc:  86.21417049261694
Saving..

------Epoch: 54------
[batch_idx--0] train_loss: 0.0011892172042280436, acc: 0.875, lr: 0.03564448228912682
[batch_idx--50] train_loss: 0.0012608657604740823, acc: 0.8579197303921569, lr: 0.035591929657709624
[batch_idx--100] train_loss: 0.0012664742177665824, acc: 0.8587948638613861, lr: 0.03553931992064693
[batch_idx--150] train_loss: 0.0012696081323746518, acc: 0.8587541390728477, lr: 0.035486653361580446
[batch_idx--200] train_loss: 0.001275201432351301, acc: 0.8577231032338308, lr: 0.03543393026445823
[batch_idx--250] train_loss: 0.0012796323865177147, acc: 0.8571184013944223, lr: 0.03538115091353316
[batch_idx--300] train_loss: 0.0012862986472723047, acc: 0.8563252699335548, lr: 0.035328315593361394
[batch_idx--350] train_loss: 0.0012847296054477662, acc: 0.8567819622507122, lr: 0.03527542458880086
[batch_idx--400] train_loss: 0.0012854125987659406, acc: 0.8562967581047382, lr: 0.035222478185009704
[batch_idx--450] train_loss: 0.001289436592164604, acc: 0.8559030791127157, lr: 0.035169476667444736
total time of one epoch: 393.2390761375427 s
train_loss:  0.001289436592164604  acc:  0.8559030791127157
->>lr:0.035169
test_loss:  0.0012292318662737393  test_acc:  0.8695867973694007
best acc:  86.2638044422385
Saving..

------Epoch: 55------
[batch_idx--0] train_loss: 0.0012415227247402072, acc: 0.86328125, lr: 0.035168416076895005
[batch_idx--50] train_loss: 0.0012491400828402415, acc: 0.8607536764705882, lr: 0.03511535863766653
[batch_idx--100] train_loss: 0.001279166937658176, acc: 0.8543471534653465, lr: 0.03506224666219176
[batch_idx--150] train_loss: 0.001274552143838824, acc: 0.8553135347682119, lr: 0.03500908043682018
[batch_idx--200] train_loss: 0.0012780625120602288, acc: 0.855352145522388, lr: 0.034955860248193804
[batch_idx--250] train_loss: 0.0012799271120804833, acc: 0.855406499003984, lr: 0.034902586383245504
[batch_idx--300] train_loss: 0.001280154026518777, acc: 0.8557283014950167, lr: 0.03484925912919761
[batch_idx--350] train_loss: 0.0012778692210140901, acc: 0.8559027777777778, lr: 0.03479587877356025
[batch_idx--400] train_loss: 0.0012789930712241225, acc: 0.8559168485037406, lr: 0.034742445604129875
[batch_idx--450] train_loss: 0.0012808346086135695, acc: 0.8559117575589267, lr: 0.034688959908987675
total time of one epoch: 396.6766254901886 s
train_loss:  0.0012808346086135695  acc:  0.8559117575589267
->>lr:0.034689
test_loss:  0.0013273655073949518  test_acc:  0.854076188112669
best acc:  86.95867973694007

------Epoch: 56------
[batch_idx--0] train_loss: 0.0012469561770558357, acc: 0.8515625, lr: 0.034687889661302575
[batch_idx--50] train_loss: 0.0012626406113507554, acc: 0.856234681372549, lr: 0.034634350687009215
[batch_idx--100] train_loss: 0.0012792541909418852, acc: 0.8557394801980198, lr: 0.034580759769790186
[batch_idx--150] train_loss: 0.0012766948545703182, acc: 0.8563483029801324, lr: 0.034527117198577144
[batch_idx--200] train_loss: 0.0012852549277806646, acc: 0.8547885572139303, lr: 0.034473423262580266
[batch_idx--250] train_loss: 0.0012781292172723943, acc: 0.8562157619521913, lr: 0.03441967825128663
[batch_idx--300] train_loss: 0.0012789501876653824, acc: 0.8562993147840532, lr: 0.0343658824544587
[batch_idx--350] train_loss: 0.0012796039356746608, acc: 0.8561364850427351, lr: 0.034312036162132735
[batch_idx--400] train_loss: 0.001281093749417424, acc: 0.8559947786783042, lr: 0.034258139664617236
[batch_idx--450] train_loss: 0.0012800238855069583, acc: 0.8562936091922102, lr: 0.0342041932524914
total time of one epoch: 394.30216455459595 s
train_loss:  0.0012800238855069583  acc:  0.8562936091922102
->>lr:0.034204
test_loss:  0.0013538649714101055  test_acc:  0.8513463208834843
best acc:  86.95867973694007

------Epoch: 57------
[batch_idx--0] train_loss: 0.001244438230060041, acc: 0.84765625, lr: 0.03420311381711696
[batch_idx--50] train_loss: 0.0012883546798690862, acc: 0.8546262254901961, lr: 0.03414911679172232
[batch_idx--100] train_loss: 0.001273667967721525, acc: 0.8553527227722773, lr: 0.034095070439506506
[batch_idx--150] train_loss: 0.001277304264494767, acc: 0.8560637417218543, lr: 0.03404097505185664
[batch_idx--200] train_loss: 0.0012730768092894065, acc: 0.8565376243781094, lr: 0.0339868309204242
[batch_idx--250] train_loss: 0.0012790002805399764, acc: 0.8559667579681275, lr: 0.03393263833712346
[batch_idx--300] train_loss: 0.0012741559281778147, acc: 0.8569352159468439, lr: 0.03387839759412996
[batch_idx--350] train_loss: 0.0012781634479708058, acc: 0.8563034188034188, lr: 0.03382410898387883
[batch_idx--400] train_loss: 0.0012755768923460508, acc: 0.8565208073566085, lr: 0.033769772799063326
[batch_idx--450] train_loss: 0.001275325126432059, acc: 0.8572916305064742, lr: 0.03371538933263315
total time of one epoch: 393.9969918727875 s
train_loss:  0.001275325126432059  acc:  0.8572916305064742
->>lr:0.033715
test_loss:  0.0012450037885354194  test_acc:  0.864251147785085
best acc:  86.95867973694007

------Epoch: 58------
[batch_idx--0] train_loss: 0.0014369968557730317, acc: 0.859375, lr: 0.03371430118304538
[batch_idx--50] train_loss: 0.0012899538451878756, acc: 0.8556219362745098, lr: 0.03365986979142943
[batch_idx--100] train_loss: 0.00129790965808869, acc: 0.854424504950495, lr: 0.03360539171073317
[batch_idx--150] train_loss: 0.0012853897919890699, acc: 0.8560378725165563, lr: 0.03355086723467137
[batch_idx--200] train_loss: 0.0012822173395662091, acc: 0.8566347947761194, lr: 0.03349629665720888
[batch_idx--250] train_loss: 0.0012781280190294305, acc: 0.8565737051792829, lr: 0.03344168027255918
[batch_idx--300] train_loss: 0.0012738358303270244, acc: 0.8578566237541528, lr: 0.033387018375182646
[batch_idx--350] train_loss: 0.0012710264041831457, acc: 0.8581508190883191, lr: 0.03333231125978507
[batch_idx--400] train_loss: 0.0012727720662080533, acc: 0.857943033042394, lr: 0.03327755922131603
[batch_idx--450] train_loss: 0.001274807869609014, acc: 0.8580119415419863, lr: 0.033222762554967304
total time of one epoch: 393.29991817474365 s
train_loss:  0.001274807869609014  acc:  0.8580119415419863
->>lr:0.033223
test_loss:  0.0013405180148265397  test_acc:  0.8486164536542995
best acc:  86.95867973694007

------Epoch: 59------
[batch_idx--0] train_loss: 0.0011448741424828768, acc: 0.875, lr: 0.03322166616846458
[batch_idx--50] train_loss: 0.0013080359500485892, acc: 0.8504136029411765, lr: 0.033166824286034645
[batch_idx--100] train_loss: 0.001303062428452886, acc: 0.8516011757425742, lr: 0.03311193837274467
[batch_idx--150] train_loss: 0.001290146061774368, acc: 0.8540718129139073, lr: 0.03305700872450816
[batch_idx--200] train_loss: 0.0012891436321776713, acc: 0.8546525186567164, lr: 0.03300203563747449
[batch_idx--250] train_loss: 0.0012811528105080958, acc: 0.8558111304780877, lr: 0.0329470194080272
[batch_idx--300] train_loss: 0.001279791491415562, acc: 0.8562214493355482, lr: 0.032891960332782424
[batch_idx--350] train_loss: 0.0012786536072208375, acc: 0.8565259971509972, lr: 0.03283685870858731
[batch_idx--400] train_loss: 0.0012775076183947987, acc: 0.8566864089775561, lr: 0.03278171483251839
[batch_idx--450] train_loss: 0.0012788833315054984, acc: 0.8572742736140522, lr: 0.03272652900188
total time of one epoch: 396.0161871910095 s
train_loss:  0.0012788833315054984  acc:  0.8572742736140522
->>lr:0.032727
test_loss:  0.0012331380987155524  test_acc:  0.8638788931629234
best acc:  86.95867973694007

------Epoch: 60------
[batch_idx--0] train_loss: 0.0012709760339930654, acc: 0.859375, lr: 0.032725424859373686
[batch_idx--50] train_loss: 0.001283489284105599, acc: 0.8561580882352942, lr: 0.032670196541591943
[batch_idx--100] train_loss: 0.0012593195291863073, acc: 0.8584854579207921, lr: 0.03261492687048379
[batch_idx--150] train_loss: 0.001242979155970577, acc: 0.8606425910596026, lr: 0.03255961614403176
[batch_idx--200] train_loss: 0.0012448533740478443, acc: 0.8605604788557214, lr: 0.03250426466043975
[batch_idx--250] train_loss: 0.0012479736061536697, acc: 0.8602932021912351, lr: 0.03244887271813142
[batch_idx--300] train_loss: 0.0012521913779460117, acc: 0.8602574750830565, lr: 0.032393440615748524
[batch_idx--350] train_loss: 0.0012558005079215768, acc: 0.8596866096866097, lr: 0.03233796865214936
[batch_idx--400] train_loss: 0.0012567244057004757, acc: 0.8598718048628429, lr: 0.03228245712640712
[batch_idx--450] train_loss: 0.0012605954348920978, acc: 0.8599993057243032, lr: 0.0322269063378083
total time of one epoch: 390.28991889953613 s
train_loss:  0.0012605954348920978  acc:  0.8599993057243032
->>lr:0.032227
test_loss:  0.0013058211740865824  test_acc:  0.857426479712123
best acc:  86.95867973694007

------Epoch: 61------
[batch_idx--0] train_loss: 0.0010122236562892795, acc: 0.890625, lr: 0.03222579492361179
[batch_idx--50] train_loss: 0.0012751435587073073, acc: 0.8560814950980392, lr: 0.032170204395443734
[batch_idx--100] train_loss: 0.001275294406182769, acc: 0.8553527227722773, lr: 0.03211457520962184
[batch_idx--150] train_loss: 0.0012615249524608452, acc: 0.8578745860927153, lr: 0.032058907666066935
[batch_idx--200] train_loss: 0.0012562613559548572, acc: 0.8588308457711443, lr: 0.03200320206490668
[batch_idx--250] train_loss: 0.0012593813450632253, acc: 0.8586435507968128, lr: 0.03194745870647391
[batch_idx--300] train_loss: 0.0012596786887372575, acc: 0.8586742109634552, lr: 0.03189167789130505
[batch_idx--350] train_loss: 0.0012617720058187842, acc: 0.8581842058404558, lr: 0.031835859920138446
[batch_idx--400] train_loss: 0.001259750139346797, acc: 0.8584982855361596, lr: 0.03178000509391275
[batch_idx--450] train_loss: 0.0012656150440503984, acc: 0.8580553337730413, lr: 0.03172411371376536
total time of one epoch: 391.65723276138306 s
train_loss:  0.0012656150440503984  acc:  0.8580553337730413
->>lr:0.031724
test_loss:  0.0012760830418852634  test_acc:  0.8644993175331928
best acc:  86.95867973694007

------Epoch: 62------
[batch_idx--0] train_loss: 0.001391901751048863, acc: 0.828125, lr: 0.031722995515381644
[batch_idx--50] train_loss: 0.0012073962750625523, acc: 0.8668045343137255, lr: 0.03166706716067022
[batch_idx--100] train_loss: 0.0012269552208086715, acc: 0.8633972772277227, lr: 0.03161110286093404
[batch_idx--150] train_loss: 0.0012383032667247073, acc: 0.8618584437086093, lr: 0.031555102917900694
[batch_idx--200] train_loss: 0.0012493269831933712, acc: 0.8606382151741293, lr: 0.03149906763348994
[batch_idx--250] train_loss: 0.0012500509496804224, acc: 0.8608534611553785, lr: 0.0314429973098121
[batch_idx--300] train_loss: 0.0012508148388964962, acc: 0.8609452865448505, lr: 0.031386892249166375
[batch_idx--350] train_loss: 0.0012484868612615365, acc: 0.8611556267806267, lr: 0.03133075275403927
[batch_idx--400] train_loss: 0.0012487358019682591, acc: 0.8610310162094763, lr: 0.03127457912710293
[batch_idx--450] train_loss: 0.0012515120178002769, acc: 0.860953934807512, lr: 0.031218371671213524
total time of one epoch: 388.50996565818787 s
train_loss:  0.0012515120178002769  acc:  0.860953934807512
->>lr:0.031218
test_loss:  0.0012195373860256356  test_acc:  0.8677255242585928
best acc:  86.95867973694007

------Epoch: 63------
[batch_idx--0] train_loss: 0.0013545099645853043, acc: 0.8828125, lr: 0.031217247179121367
[batch_idx--50] train_loss: 0.0012480284021162958, acc: 0.8635110294117647, lr: 0.0311610055298914
[batch_idx--100] train_loss: 0.0012527123712565713, acc: 0.8616955445544554, lr: 0.031104730664032437
[batch_idx--150] train_loss: 0.0012506210728585473, acc: 0.8611082367549668, lr: 0.031048422884946483
[batch_idx--200] train_loss: 0.0012569408817448427, acc: 0.8598608519900498, lr: 0.030992082496212964
[batch_idx--250] train_loss: 0.0012507643856746386, acc: 0.8606200199203188, lr: 0.030935709801587143
[batch_idx--300] train_loss: 0.0012508174920829007, acc: 0.8601536544850499, lr: 0.03087930510499845
[batch_idx--350] train_loss: 0.0012514787237557909, acc: 0.8599982193732194, lr: 0.030822868710548842
[batch_idx--400] train_loss: 0.0012506669692920424, acc: 0.8597938746882793, lr: 0.030766400922511174
[batch_idx--450] train_loss: 0.0012566523973862019, acc: 0.859244280903947, lr: 0.030709902045327583
total time of one epoch: 397.88267827033997 s
train_loss:  0.0012566523973862019  acc:  0.859244280903947
->>lr:0.030710
test_loss:  0.0012722970615739132  test_acc:  0.8601563469413078
best acc:  86.95867973694007

------Epoch: 64------
[batch_idx--0] train_loss: 0.0014139247359707952, acc: 0.82421875, lr: 0.030708771752766397
[batch_idx--50] train_loss: 0.001247954925786996, acc: 0.8612132352941176, lr: 0.030652241478464032
[batch_idx--100] train_loss: 0.0012450232182048483, acc: 0.8621209777227723, lr: 0.03059568073049836
[batch_idx--150] train_loss: 0.0012442419565258092, acc: 0.8613151903973509, lr: 0.030539089813812693
[batch_idx--200] train_loss: 0.0012419680402780981, acc: 0.861279539800995, lr: 0.03048246903351297
[batch_idx--250] train_loss: 0.0012422837848047842, acc: 0.8610557768924303, lr: 0.030425818694866172
[batch_idx--300] train_loss: 0.0012466465639324853, acc: 0.8598941029900332, lr: 0.030369139103298623
[batch_idx--350] train_loss: 0.0012434186711389986, acc: 0.8603988603988604, lr: 0.030312430564394355
[batch_idx--400] train_loss: 0.0012450763368410083, acc: 0.8600568890274314, lr: 0.03025569338389348
[batch_idx--450] train_loss: 0.0012431980051250523, acc: 0.8607369736522373, lr: 0.03019892786769053
total time of one epoch: 392.37607979774475 s
train_loss:  0.0012431980051250523  acc:  0.8607369736522373
->>lr:0.030199
test_loss:  0.001355849052055374  test_acc:  0.852463084749969
best acc:  86.95867973694007

------Epoch: 65------
[batch_idx--0] train_loss: 0.0012024575844407082, acc: 0.890625, lr: 0.03019779227044398
[batch_idx--50] train_loss: 0.0012510771995556413, acc: 0.8597579656862745, lr: 0.03014099816711588
[batch_idx--100] train_loss: 0.0012514659498661462, acc: 0.8606899752475248, lr: 0.030084176346456905
[batch_idx--150] train_loss: 0.0012396688014885645, acc: 0.8626603890728477, lr: 0.030027327114817932
[batch_idx--200] train_loss: 0.0012475113599880862, acc: 0.8610851990049752, lr: 0.029970450778697578
[batch_idx--250] train_loss: 0.0012435196644711899, acc: 0.8618806025896414, lr: 0.02991354764474065
[batch_idx--300] train_loss: 0.0012453671732756534, acc: 0.861672030730897, lr: 0.02985661801973638
[batch_idx--350] train_loss: 0.0012467076638421613, acc: 0.8613559472934473, lr: 0.02979966221061685
[batch_idx--400] train_loss: 0.001244584203841736, acc: 0.8616641988778054, lr: 0.029742680524455323
[batch_idx--450] train_loss: 0.0012471735713842505, acc: 0.8613618217794287, lr: 0.02968567326846454
total time of one epoch: 394.08946204185486 s
train_loss:  0.0012471735713842505  acc:  0.8613618217794287
->>lr:0.029686
test_loss:  0.0012866842667597046  test_acc:  0.8599081771932001
best acc:  86.95867973694007

------Epoch: 66------
[batch_idx--0] train_loss: 0.0011118517722934484, acc: 0.86328125, lr: 0.02968453286464312
[batch_idx--50] train_loss: 0.0012421575991217705, acc: 0.8582261029411765, lr: 0.029627499844060053
[batch_idx--100] train_loss: 0.0012389643182332563, acc: 0.8598004331683168, lr: 0.029570441874636297
[batch_idx--150] train_loss: 0.0012329561857118067, acc: 0.8615221440397351, lr: 0.029513359263995894
[batch_idx--200] train_loss: 0.0012353355139123267, acc: 0.861337842039801, lr: 0.029456252319895716
[batch_idx--250] train_loss: 0.0012364521058205798, acc: 0.8612736553784861, lr: 0.029399121350223874
[batch_idx--300] train_loss: 0.0012358670945563958, acc: 0.8615941652823921, lr: 0.029341966662997956
[batch_idx--350] train_loss: 0.0012349052733789461, acc: 0.8616675569800569, lr: 0.02928478856636346
[batch_idx--400] train_loss: 0.001234370730863768, acc: 0.8617323877805486, lr: 0.02922758736859208
[batch_idx--450] train_loss: 0.001238924970808126, acc: 0.861925920783143, lr: 0.02917036337808005
total time of one epoch: 396.76846623420715 s
train_loss:  0.001238924970808126  acc:  0.861925920783143
->>lr:0.029170
test_loss:  0.001183795781404183  test_acc:  0.8700831368656161
best acc:  86.95867973694007
Saving..

------Epoch: 67------
[batch_idx--0] train_loss: 0.0009779756655916572, acc: 0.9140625, lr: 0.02916921866790256
[batch_idx--50] train_loss: 0.0012356172973180517, acc: 0.8609068627450981, lr: 0.029111971746632322
[batch_idx--100] train_loss: 0.0012354507862525706, acc: 0.8621596534653465, lr: 0.02905470265595496
[batch_idx--150] train_loss: 0.0012381811933098545, acc: 0.8622206125827815, lr: 0.028997411704632756
[batch_idx--200] train_loss: 0.0012344755304731726, acc: 0.8624455845771144, lr: 0.02894009920154584
[batch_idx--250] train_loss: 0.0012416373469877943, acc: 0.8615849103585658, lr: 0.02888276545569057
[batch_idx--300] train_loss: 0.0012415022499537548, acc: 0.8617369186046512, lr: 0.0288254107761778
[batch_idx--350] train_loss: 0.0012405621739597912, acc: 0.8616119123931624, lr: 0.028768035472231265
[batch_idx--400] train_loss: 0.0012390755080360168, acc: 0.8616057512468828, lr: 0.0287106398531859
[batch_idx--450] train_loss: 0.0012390274499789137, acc: 0.8623771999861145, lr: 0.02865322422848614
total time of one epoch: 392.6234817504883 s
train_loss:  0.0012390274499789137  acc:  0.8623771999861145
->>lr:0.028653
test_loss:  0.0012205983250353262  test_acc:  0.8707035612358853
best acc:  87.0083136865616
Saving..

------Epoch: 68------
[batch_idx--0] train_loss: 0.001145026064477861, acc: 0.859375, lr: 0.028652075714060296
[batch_idx--50] train_loss: 0.0012317609895641606, acc: 0.8635110294117647, lr: 0.028594640002494582
[batch_idx--100] train_loss: 0.0012110854074875318, acc: 0.8656791460396039, lr: 0.028537184910679542
[batch_idx--150] train_loss: 0.0012074196109831926, acc: 0.8661786009933775, lr: 0.028479710748380266
[batch_idx--200] train_loss: 0.0012128091114920689, acc: 0.8648359763681592, lr: 0.028422217825464665
[batch_idx--250] train_loss: 0.001220737871031214, acc: 0.8637014442231076, lr: 0.028364706451901797
[batch_idx--300] train_loss: 0.0012268559733387145, acc: 0.8632423172757475, lr: 0.028307176937760206
[batch_idx--350] train_loss: 0.0012275155247626905, acc: 0.8630475427350427, lr: 0.028249629593206222
[batch_idx--400] train_loss: 0.001230537529368223, acc: 0.8622876402743143, lr: 0.02819206472850232
[batch_idx--450] train_loss: 0.0012326114564812302, acc: 0.8625334120179123, lr: 0.02813448265400542
total time of one epoch: 391.4595305919647 s
train_loss:  0.0012326114564812302  acc:  0.8625334120179123
->>lr:0.028134
test_loss:  0.0011973084387523038  test_acc:  0.8723166645985855
best acc:  87.07035612358854
Saving..

------Epoch: 69------
[batch_idx--0] train_loss: 0.001137514365836978, acc: 0.890625, lr: 0.028133330839107608
[batch_idx--50] train_loss: 0.0012450106145229702, acc: 0.8611366421568627, lr: 0.028075731530447786
[batch_idx--100] train_loss: 0.0012528723403165984, acc: 0.8601098391089109, lr: 0.028018115639197247
[batch_idx--150] train_loss: 0.001252315685982563, acc: 0.8603838990066225, lr: 0.027960483475988025
[batch_idx--200] train_loss: 0.001245677971283428, acc: 0.861279539800995, lr: 0.02790283535153988
[batch_idx--250] train_loss: 0.0012403555523763704, acc: 0.8620984810756972, lr: 0.027845171576658636
[batch_idx--300] train_loss: 0.0012342229563250915, acc: 0.8631904069767442, lr: 0.027787492462234484
[batch_idx--350] train_loss: 0.001233593347824664, acc: 0.8626802884615384, lr: 0.02772979831924033
[batch_idx--400] train_loss: 0.0012332036659560466, acc: 0.8626578086034913, lr: 0.02767208945873009
[batch_idx--450] train_loss: 0.0012344024645062253, acc: 0.8630280834519387, lr: 0.027614366191837037
total time of one epoch: 390.66746258735657 s
train_loss:  0.0012344024645062253  acc:  0.8630280834519387
->>lr:0.027614
test_loss:  0.001216616806505868  test_acc:  0.8699590519915622
best acc:  87.23166645985854

------Epoch: 70------
[batch_idx--0] train_loss: 0.0012026268523186445, acc: 0.84765625, lr: 0.02761321158169134
[batch_idx--50] train_loss: 0.0012187853469239438, acc: 0.8678768382352942, lr: 0.027555473940897853
[batch_idx--100] train_loss: 0.0012247493982748452, acc: 0.8651763613861386, lr: 0.027497722522445946
[batch_idx--150] train_loss: 0.0012301399051797707, acc: 0.863332988410596, lr: 0.027439957637698322
[batch_idx--200] train_loss: 0.0012215792166129385, acc: 0.8644472947761194, lr: 0.027382179598090313
[batch_idx--250] train_loss: 0.0012280188535202844, acc: 0.8638570717131474, lr: 0.027324388715128153
[batch_idx--300] train_loss: 0.001229700322597105, acc: 0.8638263081395349, lr: 0.027266585300387343
[batch_idx--350] train_loss: 0.0012314541157908165, acc: 0.8634815705128205, lr: 0.027208769665510946
[batch_idx--400] train_loss: 0.0012320475429273268, acc: 0.8633202150872819, lr: 0.027150942122207884
[batch_idx--450] train_loss: 0.0012318825244915978, acc: 0.8638698927344048, lr: 0.027093102982251305
total time of one epoch: 395.00897884368896 s
train_loss:  0.0012318825244915978  acc:  0.8638698927344048
->>lr:0.027093
test_loss:  0.0012524643278932553  test_acc:  0.8631343839186003
best acc:  87.23166645985854

------Epoch: 71------
[batch_idx--0] train_loss: 0.0013987403362989426, acc: 0.7890625, lr: 0.02709194608330789
[batch_idx--50] train_loss: 0.0012101607942752832, acc: 0.8642003676470589, lr: 0.027034095436018247
[batch_idx--100] train_loss: 0.0012003910297869087, acc: 0.8659498762376238, lr: 0.026976233822045795
[batch_idx--150] train_loss: 0.0012028420498958537, acc: 0.8660751241721855, lr: 0.026918361553347366
[batch_idx--200] train_loss: 0.0012004742079150322, acc: 0.8666822139303483, lr: 0.026860478941937244
[batch_idx--250] train_loss: 0.0011985888428692948, acc: 0.8672341882470119, lr: 0.026802586299885446
[batch_idx--300] train_loss: 0.0012036888462574873, acc: 0.8668371054817275, lr: 0.026744683939316106
[batch_idx--350] train_loss: 0.001203552828577647, acc: 0.8669315349002849, lr: 0.026686772172405743
[batch_idx--400] train_loss: 0.0012061600802707813, acc: 0.8668075903990025, lr: 0.02662885131138157
[batch_idx--450] train_loss: 0.00121076277229544, acc: 0.8668379213385635, lr: 0.026570921668519862
total time of one epoch: 393.85427021980286 s
train_loss:  0.00121076277229544  acc:  0.8668379213385635
->>lr:0.026571
test_loss:  0.0012369577161933547  test_acc:  0.8662365057699466
best acc:  87.23166645985854

------Epoch: 72------
[batch_idx--0] train_loss: 0.0011280148755759, acc: 0.890625, lr: 0.026569762988232833
[batch_idx--50] train_loss: 0.0012352723199143714, acc: 0.8604473039215687, lr: 0.026511824709652916
[batch_idx--100] train_loss: 0.0012256894963747352, acc: 0.8627011138613861, lr: 0.02645387828017616
[batch_idx--150] train_loss: 0.0012183639052052617, acc: 0.8634623344370861, lr: 0.026395924012216673
[batch_idx--200] train_loss: 0.001217302068458657, acc: 0.8642723880597015, lr: 0.02633796221823084
[batch_idx--250] train_loss: 0.0012129508443566343, acc: 0.8650709661354582, lr: 0.026279993210715575
[batch_idx--300] train_loss: 0.0012063282223625659, acc: 0.8655263704318937, lr: 0.026222017302206753
[batch_idx--350] train_loss: 0.0012054080520013607, acc: 0.8655849358974359, lr: 0.02616403480527739
[batch_idx--400] train_loss: 0.0012090066726554065, acc: 0.8651028678304239, lr: 0.02610604603253605
[batch_idx--450] train_loss: 0.0012143360519467528, acc: 0.8650414829728885, lr: 0.026048051296625147
total time of one epoch: 393.34444093704224 s
train_loss:  0.0012143360519467528  acc:  0.8650414829728885
->>lr:0.026048
test_loss:  0.0011851453340324253  test_acc:  0.8714480704802084
best acc:  87.23166645985854

------Epoch: 73------
[batch_idx--0] train_loss: 0.0013177613727748394, acc: 0.84375, lr: 0.02604689134322999
[batch_idx--50] train_loss: 0.00124872812896273, acc: 0.8592984068627451, lr: 0.025988890847003655
[batch_idx--100] train_loss: 0.0012140908701538966, acc: 0.8653310643564357, lr: 0.025930885019241706
[batch_idx--150] train_loss: 0.0012169783042176375, acc: 0.8647299254966887, lr: 0.025872874172678507
[batch_idx--200] train_loss: 0.001205365882146251, acc: 0.8664101368159204, lr: 0.02581485862007545
[batch_idx--250] train_loss: 0.001207261847423026, acc: 0.8661447958167331, lr: 0.02575683867421932
[batch_idx--300] train_loss: 0.001207216970964437, acc: 0.866045473421927, lr: 0.02569881464792059
[batch_idx--350] train_loss: 0.0012050785512021315, acc: 0.8662526709401709, lr: 0.02564078685401172
[batch_idx--400] train_loss: 0.001207275826053141, acc: 0.8660964775561097, lr: 0.025582755605345495
[batch_idx--450] train_loss: 0.00120838016303145, acc: 0.866343249904537, lr: 0.02552472121479332
total time of one epoch: 393.2741947174072 s
train_loss:  0.00120838016303145  acc:  0.866343249904537
->>lr:0.025525
test_loss:  0.0012081153991278888  test_acc:  0.8714480704802084
best acc:  87.23166645985854

------Epoch: 74------
[batch_idx--0] train_loss: 0.0014044002164155245, acc: 0.83203125, lr: 0.025523560497083927
[batch_idx--50] train_loss: 0.0012050577389149397, acc: 0.8646599264705882, lr: 0.025465523224145754
[batch_idx--100] train_loss: 0.0011797937199169088, acc: 0.8684637995049505, lr: 0.02540748344137178
[batch_idx--150] train_loss: 0.0011847786838959729, acc: 0.8685844370860927, lr: 0.02534944146167944
[batch_idx--200] train_loss: 0.0011796020727201518, acc: 0.8698499689054726, lr: 0.025291397597997967
[batch_idx--250] train_loss: 0.0011897262877346836, acc: 0.8687126494023905, lr: 0.025233352163266793
[batch_idx--300] train_loss: 0.0011898459179367116, acc: 0.8689005398671097, lr: 0.025175305470433812
[batch_idx--350] train_loss: 0.001194506902692102, acc: 0.8681000712250713, lr: 0.025117257832453683
[batch_idx--400] train_loss: 0.0011990960265574814, acc: 0.8677232699501247, lr: 0.025059209562286185
[batch_idx--450] train_loss: 0.0012000831962718055, acc: 0.8677665150831395, lr: 0.02500116097289448
total time of one epoch: 389.348021030426 s
train_loss:  0.0012000831962718055  acc:  0.8677665150831395
->>lr:0.025001
test_loss:  0.0011898123133728352  test_acc:  0.8714480704802084
best acc:  87.23166645985854

------Epoch: 75------
[batch_idx--0] train_loss: 0.0014114039950072765, acc: 0.8359375, lr: 0.025
[batch_idx--50] train_loss: 0.001201045077394548, acc: 0.8676470588235294, lr: 0.024941951407416053
[batch_idx--100] train_loss: 0.0011968579279295732, acc: 0.8669941212871287, lr: 0.024883903127797022
[batch_idx--150] train_loss: 0.001201667094723451, acc: 0.8658940397350994, lr: 0.02482585547410613
[batch_idx--200] train_loss: 0.0012016348261038648, acc: 0.8656716417910447, lr: 0.024767808759303227
[batch_idx--250] train_loss: 0.0012021988425756326, acc: 0.8653199701195219, lr: 0.024709763296343102
[batch_idx--300] train_loss: 0.001200168973501722, acc: 0.865344684385382, lr: 0.024651719398173802
[batch_idx--350] train_loss: 0.0012072232267301944, acc: 0.8638599537037037, lr: 0.024593677377734924
[batch_idx--400] train_loss: 0.0012083397806619766, acc: 0.8638072786783042, lr: 0.02453563754795596
[batch_idx--450] train_loss: 0.0012089905791396124, acc: 0.8644687055229632, lr: 0.024477600221754565
total time of one epoch: 387.33865690231323 s
train_loss:  0.0012089905791396124  acc:  0.8644687055229632
->>lr:0.024478
test_loss:  0.0011841836812434355  test_acc:  0.870951730983993
best acc:  87.23166645985854

------Epoch: 76------
[batch_idx--0] train_loss: 0.0010549920843914151, acc: 0.88671875, lr: 0.02447643950291608
[batch_idx--50] train_loss: 0.0011873824097325698, acc: 0.8694852941176471, lr: 0.024418405052717584
[batch_idx--100] train_loss: 0.0011958284977832718, acc: 0.8691599628712872, lr: 0.024360373738147447
[batch_idx--150] train_loss: 0.0011888913257473105, acc: 0.8698002897350994, lr: 0.024302345872077406
[batch_idx--200] train_loss: 0.001190346359004225, acc: 0.8686061878109452, lr: 0.024244321767360646
[batch_idx--250] train_loss: 0.0011882445087611853, acc: 0.869070592629482, lr: 0.024186301736830045
[batch_idx--300] train_loss: 0.0011917757488434447, acc: 0.8683425041528239, lr: 0.024128286093296536
[batch_idx--350] train_loss: 0.0011909967354708417, acc: 0.8685897435897436, lr: 0.02407027514954738
[batch_idx--400] train_loss: 0.001192343172627708, acc: 0.8683564526184538, lr: 0.024012269218344526
[batch_idx--450] train_loss: 0.0012003389201802523, acc: 0.86724580831048, lr: 0.023954268612422863
total time of one epoch: 385.59988236427307 s
train_loss:  0.0012003389201802523  acc:  0.86724580831048
->>lr:0.023954
test_loss:  0.0012068889830836973  test_acc:  0.8692145427472391
best acc:  87.23166645985854

------Epoch: 77------
[batch_idx--0] train_loss: 0.0010378481820225716, acc: 0.88671875, lr: 0.02395310865677001
[batch_idx--50] train_loss: 0.0011810434973049983, acc: 0.8672640931372549, lr: 0.023895113804784887
[batch_idx--100] train_loss: 0.0011847125352498623, acc: 0.8668394183168316, lr: 0.02383712490971616
[batch_idx--150] train_loss: 0.0011864817344324527, acc: 0.8677824917218543, lr: 0.023779142284206876
[batch_idx--200] train_loss: 0.0011834298235605196, acc: 0.8687422263681592, lr: 0.023721166240866298
[batch_idx--250] train_loss: 0.0011842986566489525, acc: 0.8693507221115537, lr: 0.0236631970922682
[batch_idx--300] train_loss: 0.001192028417083376, acc: 0.8683554817275747, lr: 0.023605235150949158
[batch_idx--350] train_loss: 0.0011927630933747226, acc: 0.8677328169515669, lr: 0.02354728072940694
[batch_idx--400] train_loss: 0.001195910033721133, acc: 0.867275171446384, lr: 0.02348933414009873
[batch_idx--450] train_loss: 0.0011993843392088565, acc: 0.8674714479119658, lr: 0.02343139569543949
total time of one epoch: 396.796751499176 s
train_loss:  0.0011993843392088565  acc:  0.8674714479119658
->>lr:0.023431
test_loss:  0.001183916762044078  test_acc:  0.8772800595607395
best acc:  87.23166645985854
Saving..

------Epoch: 78------
[batch_idx--0] train_loss: 0.0010862993076443672, acc: 0.8828125, lr: 0.023430237011767167
[batch_idx--50] train_loss: 0.0011806267783885786, acc: 0.8688725490196079, lr: 0.02337230719645424
[batch_idx--100] train_loss: 0.001194824918177864, acc: 0.8669941212871287, lr: 0.023314386156732855
[batch_idx--150] train_loss: 0.00119994796306783, acc: 0.8648334023178808, lr: 0.023256474204880216
[batch_idx--200] train_loss: 0.0011987439930133189, acc: 0.865127487562189, lr: 0.023198571653124563
[batch_idx--250] train_loss: 0.001194370925599019, acc: 0.866129233067729, lr: 0.02314067881364343
[batch_idx--300] train_loss: 0.0011952810250129861, acc: 0.8661233388704319, lr: 0.02308279599856199
[batch_idx--350] train_loss: 0.0011921967565482667, acc: 0.8664752492877493, lr: 0.023024923519951404
[batch_idx--400] train_loss: 0.0011912471966927132, acc: 0.8667588840399002, lr: 0.02296706168982706
[batch_idx--450] train_loss: 0.0011929698657258282, acc: 0.8671763807407922, lr: 0.022909210820146964
total time of one epoch: 389.3722689151764 s
train_loss:  0.0011929698657258282  acc:  0.8671763807407922
->>lr:0.022909
test_loss:  0.001245543514177867  test_acc:  0.8682218637548083
best acc:  87.72800595607396

------Epoch: 79------
[batch_idx--0] train_loss: 0.0012376508675515652, acc: 0.859375, lr: 0.022908053916692112
[batch_idx--50] train_loss: 0.0011612506156476836, acc: 0.8730851715686274, lr: 0.022850214547982983
[batch_idx--100] train_loss: 0.0011772662009306178, acc: 0.8705909653465347, lr: 0.022792386769691267
[batch_idx--150] train_loss: 0.0011802811648955705, acc: 0.8692829056291391, lr: 0.022734570893591363
[batch_idx--200] train_loss: 0.0011782225381249368, acc: 0.8695584577114428, lr: 0.022676767231393526
[batch_idx--250] train_loss: 0.0011780037636501322, acc: 0.8692884711155379, lr: 0.02261897609474213
[batch_idx--300] train_loss: 0.0011803629333184307, acc: 0.8695104858803987, lr: 0.022561197795214035
[batch_idx--350] train_loss: 0.0011827968799925682, acc: 0.8694021545584045, lr: 0.022503432644316902
[batch_idx--400] train_loss: 0.0011835845567325497, acc: 0.8695254052369077, lr: 0.022445680953487472
[batch_idx--450] train_loss: 0.0011885691724207324, acc: 0.8693633491859617, lr: 0.022387943034089947
total time of one epoch: 390.517849445343 s
train_loss:  0.0011885691724207324  acc:  0.8693633491859617
->>lr:0.022388
test_loss:  0.0011632432767069508  test_acc:  0.8767837200645241
best acc:  87.72800595607396

------Epoch: 80------
[batch_idx--0] train_loss: 0.0012320546666160226, acc: 0.859375, lr: 0.022386788418308663
[batch_idx--50] train_loss: 0.0011888631201787468, acc: 0.8681066176470589, lr: 0.022329064866462054
[batch_idx--100] train_loss: 0.0011692027282430837, acc: 0.870784344059406, lr: 0.022271355714774788
[batch_idx--150] train_loss: 0.0011687962371479744, acc: 0.8705504966887417, lr: 0.022213661274381714
[batch_idx--200] train_loss: 0.001172310720193223, acc: 0.8714046952736318, lr: 0.022155981856338363
[batch_idx--250] train_loss: 0.0011805175484503171, acc: 0.8709692480079682, lr: 0.022098317771619257
[batch_idx--300] train_loss: 0.0011743351950950648, acc: 0.8715868978405316, lr: 0.022040669331116272
[batch_idx--350] train_loss: 0.00117961617957461, acc: 0.8710603632478633, lr: 0.021983036845636923
[batch_idx--400] train_loss: 0.0011774678123787398, acc: 0.8710840087281796, lr: 0.02192542062590272
[batch_idx--450] train_loss: 0.0011816745938902434, acc: 0.8708473634880411, lr: 0.02186782098254747
total time of one epoch: 395.9253890514374 s
train_loss:  0.0011816745938902434  acc:  0.8708473634880411
->>lr:0.021868
test_loss:  0.0011650430888421985  test_acc:  0.8749224469537163
best acc:  87.72800595607396

------Epoch: 81------
[batch_idx--0] train_loss: 0.0012071707751601934, acc: 0.86328125, lr: 0.02186666916089239
[batch_idx--50] train_loss: 0.001183687951233165, acc: 0.8661917892156863, lr: 0.021809086745365924
[batch_idx--100] train_loss: 0.0011827013481841746, acc: 0.8692759900990099, lr: 0.021751521533424346
[batch_idx--150] train_loss: 0.0011847676737819929, acc: 0.8686879139072847, lr: 0.021693973835426473
[batch_idx--200] train_loss: 0.001187632549600444, acc: 0.8685090174129353, lr: 0.021636443961636685
[batch_idx--250] train_loss: 0.0011841594294897202, acc: 0.8694752241035857, lr: 0.021578932222223245
[batch_idx--300] train_loss: 0.0011826530102782718, acc: 0.869328799833887, lr: 0.021521438927256664
[batch_idx--350] train_loss: 0.0011886567374203153, acc: 0.8687900641025641, lr: 0.021463964386708015
[batch_idx--400] train_loss: 0.0011902003336530596, acc: 0.8691454956359103, lr: 0.021406508910447243
[batch_idx--450] train_loss: 0.001190335180640291, acc: 0.8695542750026035, lr: 0.021349072808241526
total time of one epoch: 393.67018818855286 s
train_loss:  0.001190335180640291  acc:  0.8695542750026035
->>lr:0.021349
test_loss:  0.001149642295910771  test_acc:  0.8791413326715474
best acc:  87.72800595607396
Saving..

------Epoch: 82------
[batch_idx--0] train_loss: 0.0011018929071724415, acc: 0.875, lr: 0.021347924285939714
[batch_idx--50] train_loss: 0.0012008207233841805, acc: 0.8671109068627451, lr: 0.02129050826428394
[batch_idx--100] train_loss: 0.0011845208505067127, acc: 0.8690826113861386, lr: 0.021233112242092567
[batch_idx--150] train_loss: 0.0011832268688124635, acc: 0.8701365894039735, lr: 0.02117573652881221
[batch_idx--200] train_loss: 0.0011882762313445113, acc: 0.8690531716417911, lr: 0.02111838143378
[batch_idx--250] train_loss: 0.0011871320186683768, acc: 0.8692262201195219, lr: 0.021061047266221912
[batch_idx--300] train_loss: 0.0011817108765492012, acc: 0.8700295888704319, lr: 0.021003734335251087
[batch_idx--350] train_loss: 0.0011806353431478929, acc: 0.8700476317663818, lr: 0.020946442949866164
[batch_idx--400] train_loss: 0.0011774360870261981, acc: 0.8706359102244389, lr: 0.020889173418949643
[batch_idx--450] train_loss: 0.001177341065602288, acc: 0.8708300065956192, lr: 0.020831926051266162
total time of one epoch: 391.9025282859802 s
train_loss:  0.001177341065602288  acc:  0.8708300065956192
->>lr:0.020832
test_loss:  0.0011861892122387487  test_acc:  0.8715721553542624
best acc:  87.91413326715474

------Epoch: 83------
[batch_idx--0] train_loss: 0.0014541985001415014, acc: 0.83203125, lr: 0.020830781332097453
[batch_idx--50] train_loss: 0.0012019818246948952, acc: 0.8658854166666666, lr: 0.020773556888877096
[batch_idx--100] train_loss: 0.001191929797641933, acc: 0.8677289603960396, lr: 0.020716355232228204
[batch_idx--150] train_loss: 0.0011792604954888588, acc: 0.8688172599337748, lr: 0.020659176670549492
[batch_idx--200] train_loss: 0.0011746152144838217, acc: 0.8701609141791045, lr: 0.020602021512115154
[batch_idx--250] train_loss: 0.0011706741023957137, acc: 0.8707669322709163, lr: 0.02054489006507322
[batch_idx--300] train_loss: 0.0011669340888827272, acc: 0.8715609426910299, lr: 0.02048778263744388
[batch_idx--350] train_loss: 0.0011653356205013998, acc: 0.8716835826210826, lr: 0.02043069953711782
[batch_idx--400] train_loss: 0.0011684754305981342, acc: 0.8713177992518704, lr: 0.020373641071854572
[batch_idx--450] train_loss: 0.0011724417835663338, acc: 0.8713246780296455, lr: 0.020316607549280843
total time of one epoch: 392.9469394683838 s
train_loss:  0.0011724417835663338  acc:  0.8713246780296455
->>lr:0.020317
test_loss:  0.0012292570978465957  test_acc:  0.8673532696364313
best acc:  87.91413326715474

------Epoch: 84------
[batch_idx--0] train_loss: 0.0010251555358991027, acc: 0.89453125, lr: 0.020315467135356893
[batch_idx--50] train_loss: 0.001171530105684902, acc: 0.8721660539215687, lr: 0.02025845937110404
[batch_idx--100] train_loss: 0.0011723626579047356, acc: 0.8710550742574258, lr: 0.020201477170534773
[batch_idx--150] train_loss: 0.0011720424787825998, acc: 0.8703952814569537, lr: 0.020144520840864624
[batch_idx--200] train_loss: 0.0011696535885445218, acc: 0.8703163868159204, lr: 0.02008759068916964
[batch_idx--250] train_loss: 0.0011708154454382054, acc: 0.8708447460159362, lr: 0.020030687022384752
[batch_idx--300] train_loss: 0.0011731690069292347, acc: 0.8709769518272426, lr: 0.019973810147302068
[batch_idx--350] train_loss: 0.0011747582166182391, acc: 0.8708600427350427, lr: 0.01991696037056928
[batch_idx--400] train_loss: 0.0011715576356913235, acc: 0.8708307356608479, lr: 0.01986013799868798
[batch_idx--450] train_loss: 0.0011700035542323132, acc: 0.8712639289061687, lr: 0.01980334333801198
total time of one epoch: 399.4780797958374 s
train_loss:  0.0011700035542323132  acc:  0.8712639289061687
->>lr:0.019803
test_loss:  0.0011867733251842883  test_acc:  0.8710758158580469
best acc:  87.91413326715474

------Epoch: 85------
[batch_idx--0] train_loss: 0.0012842301512137055, acc: 0.8515625, lr: 0.019802207729556022
[batch_idx--50] train_loss: 0.0011828805345074072, acc: 0.8664981617647058, lr: 0.0197454416497602
[batch_idx--100] train_loss: 0.0011644725737364797, acc: 0.8708616955445545, lr: 0.019688703899547008
[batch_idx--150] train_loss: 0.0011706922730640662, acc: 0.8706022350993378, lr: 0.01963199478481404
[batch_idx--200] train_loss: 0.0011602862551576684, acc: 0.8722792288557214, lr: 0.019575314611304503
[batch_idx--250] train_loss: 0.0011584850647802134, acc: 0.8727745268924303, lr: 0.019518663684605593
[batch_idx--300] train_loss: 0.0011563577124171355, acc: 0.8730922965116279, lr: 0.01946204231014678
[batch_idx--350] train_loss: 0.001156443971450682, acc: 0.8732416310541311, lr: 0.019405450793198248
[batch_idx--400] train_loss: 0.0011615024755030703, acc: 0.8726231296758105, lr: 0.01934888943886919
[batch_idx--450] train_loss: 0.0011654394469371825, acc: 0.8724962682681293, lr: 0.019292358552106172
total time of one epoch: 394.31681513786316 s
train_loss:  0.0011654394469371825  acc:  0.8724962682681293
->>lr:0.019292
test_loss:  0.0011439326291256468  test_acc:  0.8795135872937089
best acc:  87.91413326715474
Saving..

------Epoch: 86------
[batch_idx--0] train_loss: 0.0008366333204321563, acc: 0.921875, lr: 0.019291228247233613
[batch_idx--50] train_loss: 0.001126669511637267, acc: 0.8759957107843137, lr: 0.019234728751373553
[batch_idx--100] train_loss: 0.00116134059931253, acc: 0.8723313737623762, lr: 0.01917826033856888
[batch_idx--150] train_loss: 0.0011561076277836122, acc: 0.8726976407284768, lr: 0.019121823313265066
[batch_idx--200] train_loss: 0.001154191581189484, acc: 0.8726873445273632, lr: 0.01906541797973838
[batch_idx--250] train_loss: 0.0011569353509731442, acc: 0.8725099601593626, lr: 0.01900904464209422
[batch_idx--300] train_loss: 0.0011533104234059462, acc: 0.8731312292358804, lr: 0.018952703604265476
[batch_idx--350] train_loss: 0.0011521799117061402, acc: 0.873108084045584, lr: 0.018896395170010898
[batch_idx--400] train_loss: 0.0011572715480280041, acc: 0.8722042549875312, lr: 0.01884011964291346
[batch_idx--450] train_loss: 0.001162931474354596, acc: 0.8721751657583227, lr: 0.018783877326378724
total time of one epoch: 390.51325392723083 s
train_loss:  0.001162931474354596  acc:  0.8721751657583227
->>lr:0.018784
test_loss:  0.0011959793065762546  test_acc:  0.8751706167018241
best acc:  87.9513587293709

------Epoch: 87------
[batch_idx--0] train_loss: 0.0012429490452632308, acc: 0.859375, lr: 0.018782752820878636
[batch_idx--50] train_loss: 0.0011434813712577463, acc: 0.8738511029411765, lr: 0.018726544691500546
[batch_idx--100] train_loss: 0.0011510423305075579, acc: 0.873801051980198, lr: 0.01867037038501655
[batch_idx--150] train_loss: 0.001141247725798841, acc: 0.8746378311258278, lr: 0.018614230204286455
[batch_idx--200] train_loss: 0.0011522508952048474, acc: 0.8731343283582089, lr: 0.018558124451986114
[batch_idx--250] train_loss: 0.0011541866488658278, acc: 0.8729612798804781, lr: 0.018502053430605753
[batch_idx--300] train_loss: 0.0011603424439293353, acc: 0.8716647632890365, lr: 0.01844601744244835
[batch_idx--350] train_loss: 0.0011617615865410819, acc: 0.8717392272079773, lr: 0.018390016789628004
[batch_idx--400] train_loss: 0.0011641180553262184, acc: 0.8713567643391521, lr: 0.018334051774068303
[batch_idx--450] train_loss: 0.001167542051500517, acc: 0.8711337522130038, lr: 0.0182781226975007
total time of one epoch: 390.9749207496643 s
train_loss:  0.001167542051500517  acc:  0.8711337522130038
->>lr:0.018278
test_loss:  0.0012098862225045812  test_acc:  0.8730611738429086
best acc:  87.9513587293709

------Epoch: 88------
[batch_idx--0] train_loss: 0.001056962413713336, acc: 0.8828125, lr: 0.01827700448461836
[batch_idx--50] train_loss: 0.0011555661604849294, acc: 0.8700980392156863, lr: 0.018221112376465492
[batch_idx--100] train_loss: 0.0011421050962826034, acc: 0.8742264851485149, lr: 0.018165256816209563
[batch_idx--150] train_loss: 0.0011400112910011154, acc: 0.8739393625827815, lr: 0.018109438104991903
[batch_idx--200] train_loss: 0.0011439531988265057, acc: 0.8739505597014925, lr: 0.01805365654375518
[batch_idx--250] train_loss: 0.001147455461620097, acc: 0.8740973605577689, lr: 0.017997912433241763
[batch_idx--300] train_loss: 0.0011508455033958627, acc: 0.8738060631229236, lr: 0.017942206073992117
[batch_idx--350] train_loss: 0.0011495205985337092, acc: 0.8737980769230769, lr: 0.017886537766343167
[batch_idx--400] train_loss: 0.0011515772326366322, acc: 0.8734998441396509, lr: 0.017830907810426684
[batch_idx--450] train_loss: 0.0011513178673007618, acc: 0.8740757454785295, lr: 0.017775316506167683
total time of one epoch: 391.2507379055023 s
train_loss:  0.0011513178673007618  acc:  0.8740757454785295
->>lr:0.017775
test_loss:  0.0011584183069683065  test_acc:  0.8774041444347934
best acc:  87.9513587293709

------Epoch: 89------
[batch_idx--0] train_loss: 0.0007855662261135876, acc: 0.9375, lr: 0.017774205076388213
[batch_idx--50] train_loss: 0.001108977237177611, acc: 0.8792126225490197, lr: 0.017718653505586445
[batch_idx--100] train_loss: 0.0011143978912208118, acc: 0.8779006806930693, lr: 0.01766314119165336
[batch_idx--150] train_loss: 0.0011267553196159124, acc: 0.8752069536423841, lr: 0.017607668433879703
[batch_idx--200] train_loss: 0.0011280550469704603, acc: 0.8756024564676617, lr: 0.017552235531342955
[batch_idx--250] train_loss: 0.001135663540321458, acc: 0.8744086155378487, lr: 0.017496842782905715
[batch_idx--300] train_loss: 0.001137349159538783, acc: 0.8742602782392026, lr: 0.017441490487214106
[batch_idx--350] train_loss: 0.0011403532914334425, acc: 0.8738314636752137, lr: 0.017386178942696135
[batch_idx--400] train_loss: 0.0011438110596825486, acc: 0.8731978647132169, lr: 0.01733090844756013
[batch_idx--450] train_loss: 0.001152142037635883, acc: 0.8729128336862568, lr: 0.017275679299793074
total time of one epoch: 387.00107312202454 s
train_loss:  0.001152142037635883  acc:  0.8729128336862568
->>lr:0.017276
test_loss:  0.0011637863398101197  test_acc:  0.8756669561980395
best acc:  87.9513587293709

------Epoch: 90------
[batch_idx--0] train_loss: 0.0011077725794166327, acc: 0.87890625, lr: 0.017274575140626316
[batch_idx--50] train_loss: 0.001161452789115263, acc: 0.8707873774509803, lr: 0.017219388473930602
[batch_idx--100] train_loss: 0.001147202492142926, acc: 0.8732209158415841, lr: 0.017164243755855953
[batch_idx--150] train_loss: 0.0011425968768408164, acc: 0.8742756622516556, lr: 0.017109141283711254
[batch_idx--200] train_loss: 0.0011441946552084082, acc: 0.8742226368159204, lr: 0.0170540813545776
[batch_idx--250] train_loss: 0.0011431185122341867, acc: 0.8745798057768924, lr: 0.016999064265306747
[batch_idx--300] train_loss: 0.0011487956024610446, acc: 0.8732999377076412, lr: 0.016944090312519478
[batch_idx--350] train_loss: 0.0011510854119970927, acc: 0.8732305021367521, lr: 0.01688915979260398
[batch_idx--400] train_loss: 0.0011498554670100944, acc: 0.8736362219451371, lr: 0.016834273001714316
[batch_idx--450] train_loss: 0.001150069495455296, acc: 0.873572395598292, lr: 0.016779430235768767
total time of one epoch: 386.9371256828308 s
train_loss:  0.001150069495455296  acc:  0.873572395598292
->>lr:0.016779
test_loss:  0.0011961490548208758  test_acc:  0.8713239856061546
best acc:  87.9513587293709

------Epoch: 91------
[batch_idx--0] train_loss: 0.0010078364284709096, acc: 0.8828125, lr: 0.01677833383153542
[batch_idx--50] train_loss: 0.0010885854009721502, acc: 0.8787530637254902, lr: 0.016723536275641708
[batch_idx--100] train_loss: 0.0011071135465166356, acc: 0.8768951113861386, lr: 0.01666878334172139
[batch_idx--150] train_loss: 0.0011199646049629378, acc: 0.8759571605960265, lr: 0.01661407532497108
[batch_idx--200] train_loss: 0.0011260862165682055, acc: 0.8757190609452736, lr: 0.016559412520345193
[batch_idx--250] train_loss: 0.001131010026368591, acc: 0.8747509960159362, lr: 0.016504795222554415
[batch_idx--300] train_loss: 0.001136430594884478, acc: 0.8742732558139535, lr: 0.01645022372606408
[batch_idx--350] train_loss: 0.001142302557376301, acc: 0.8739427528490028, lr: 0.01639569832509256
[batch_idx--400] train_loss: 0.0011440959260880278, acc: 0.8738602711970075, lr: 0.016341219313609757
[batch_idx--450] train_loss: 0.0011465289442257071, acc: 0.873589752490714, lr: 0.01628678698533542
total time of one epoch: 394.9677503108978 s
train_loss:  0.0011465289442257071  acc:  0.873589752490714
->>lr:0.016287
test_loss:  0.0011742185449493717  test_acc:  0.8738056830872317
best acc:  87.9513587293709

------Epoch: 92------
[batch_idx--0] train_loss: 0.001245499704964459, acc: 0.84375, lr: 0.016285698816954627
[batch_idx--50] train_loss: 0.0011356768709625683, acc: 0.8750765931372549, lr: 0.016231314407882003
[batch_idx--100] train_loss: 0.001132488232866704, acc: 0.8755801361386139, lr: 0.016176977274562434
[batch_idx--150] train_loss: 0.0011384076317803107, acc: 0.874896523178808, lr: 0.016122687709950775
[batch_idx--200] train_loss: 0.0011396191496429826, acc: 0.8745335820895522, lr: 0.01606844600674539
[batch_idx--250] train_loss: 0.0011396581743958877, acc: 0.8747354332669323, lr: 0.016014252457386614
[batch_idx--300] train_loss: 0.0011447867582802757, acc: 0.874390053986711, lr: 0.015960107354055172
[batch_idx--350] train_loss: 0.0011387919284737646, acc: 0.8754562856125356, lr: 0.01590601098867059
[batch_idx--400] train_loss: 0.0011451580729207808, acc: 0.8743765586034913, lr: 0.015851963652889624
[batch_idx--450] train_loss: 0.0011475735120303299, acc: 0.874535703127712, lr: 0.015797965638104688
total time of one epoch: 392.8211030960083 s
train_loss:  0.0011475735120303299  acc:  0.874535703127712
->>lr:0.015798
test_loss:  0.0011703699109778835  test_acc:  0.876039210820201
best acc:  87.9513587293709

------Epoch: 93------
[batch_idx--0] train_loss: 0.0011986325262114406, acc: 0.8671875, lr: 0.01579688618288306
[batch_idx--50] train_loss: 0.0011376571891756327, acc: 0.8760723039215687, lr: 0.01574293877543077
[batch_idx--100] train_loss: 0.00112550167336894, acc: 0.8777459777227723, lr: 0.015689041276774486
[batch_idx--150] train_loss: 0.001120957750626624, acc: 0.8785182119205298, lr: 0.015635193977498796
[batch_idx--200] train_loss: 0.0011189486006094114, acc: 0.8779928482587065, lr: 0.015581397167917649
[batch_idx--250] train_loss: 0.0011190502093622527, acc: 0.8776456673306773, lr: 0.01552765113807274
[batch_idx--300] train_loss: 0.0011235232587959432, acc: 0.8763756229235881, lr: 0.015473956177732033
[batch_idx--350] train_loss: 0.0011267908354637417, acc: 0.8758680555555556, lr: 0.01542031257638813
[batch_idx--400] train_loss: 0.001127209739952332, acc: 0.8758864557356608, lr: 0.015366720623256752
[batch_idx--450] train_loss: 0.0011318326768432914, acc: 0.8755597597806088, lr: 0.015313180607275165
total time of one epoch: 400.27862095832825 s
train_loss:  0.0011318326768432914  acc:  0.8755597597806088
->>lr:0.015313
test_loss:  0.0011525932638886875  test_acc:  0.8792654175456012
best acc:  87.9513587293709

------Epoch: 94------
[batch_idx--0] train_loss: 0.0010777701390907168, acc: 0.8984375, lr: 0.015312110338697428
[batch_idx--50] train_loss: 0.001126851391175068, acc: 0.8788296568627451, lr: 0.015258623595981367
[batch_idx--100] train_loss: 0.001115687634095107, acc: 0.8788675742574258, lr: 0.015205189373212608
[batch_idx--150] train_loss: 0.0011278916927461593, acc: 0.8763969370860927, lr: 0.015151807958478031
[batch_idx--200] train_loss: 0.0011304472593372844, acc: 0.8764186878109452, lr: 0.015098479639579785
[batch_idx--250] train_loss: 0.0011364635062938281, acc: 0.8753112549800797, lr: 0.015045204704033754
[batch_idx--300] train_loss: 0.001136950082787656, acc: 0.8754931478405316, lr: 0.01499198343906803
[batch_idx--350] train_loss: 0.0011363976399223201, acc: 0.8757011217948718, lr: 0.014938816131621303
[batch_idx--400] train_loss: 0.0011402557258833282, acc: 0.8750974127182045, lr: 0.014885703068341395
[batch_idx--450] train_loss: 0.0011444087499607092, acc: 0.8746572013746658, lr: 0.014832644535583656
total time of one epoch: 397.04732298851013 s
train_loss:  0.0011444087499607092  acc:  0.8746572013746658
->>lr:0.014833
test_loss:  0.0011539144952505188  test_acc:  0.878520908301278
best acc:  87.9513587293709

------Epoch: 95------
[batch_idx--0] train_loss: 0.0009171643760055304, acc: 0.90625, lr: 0.014831583923105
[batch_idx--50] train_loss: 0.0011072574050950946, acc: 0.8779105392156863, lr: 0.014778581306178257
[batch_idx--100] train_loss: 0.001112031714073244, acc: 0.8768951113861386, lr: 0.014725633797313148
[batch_idx--150] train_loss: 0.0011183340618978964, acc: 0.8764486754966887, lr: 0.014672741681972468
[batch_idx--200] train_loss: 0.001128733048646419, acc: 0.8751360385572139, lr: 0.01461990524532032
[batch_idx--250] train_loss: 0.0011347542021542313, acc: 0.8747354332669323, lr: 0.014567124772220653
[batch_idx--300] train_loss: 0.001132256326658583, acc: 0.875609946013289, lr: 0.014514400547235684
[batch_idx--350] train_loss: 0.00113290829761113, acc: 0.8755008012820513, lr: 0.014461732854624376
[batch_idx--400] train_loss: 0.0011349478819258883, acc: 0.8752240492518704, lr: 0.014409121978340905
[batch_idx--450] train_loss: 0.0011355868863451959, acc: 0.8756552226889298, lr: 0.014356568202033099
total time of one epoch: 392.02219891548157 s
train_loss:  0.0011355868863451959  acc:  0.8756552226889298
->>lr:0.014357
test_loss:  0.0011299551402328772  test_acc:  0.8824916242710014
best acc:  87.9513587293709
Saving..

------Epoch: 96------
[batch_idx--0] train_loss: 0.001063755014911294, acc: 0.90234375, lr: 0.014355517710873192
[batch_idx--50] train_loss: 0.0011487084454582894, acc: 0.8743872549019608, lr: 0.014303022468435317
[batch_idx--100] train_loss: 0.0011384230658024698, acc: 0.8750386757425742, lr: 0.014250584898001182
[batch_idx--150] train_loss: 0.0011327497168468767, acc: 0.8756725993377483, lr: 0.014198205282284266
[batch_idx--200] train_loss: 0.0011289462007568287, acc: 0.8753692475124378, lr: 0.014145883903685591
[batch_idx--250] train_loss: 0.0011271138866135175, acc: 0.8755135707171314, lr: 0.014093621044292189
[batch_idx--300] train_loss: 0.0011247637019526722, acc: 0.8758824750830565, lr: 0.014041416985875627
[batch_idx--350] train_loss: 0.0011211790476442763, acc: 0.8765024038461539, lr: 0.013989272009890398
[batch_idx--400] train_loss: 0.001120728739459495, acc: 0.8768313591022444, lr: 0.013937186397472484
[batch_idx--450] train_loss: 0.0011251947604300565, acc: 0.8765924948797167, lr: 0.01388516042943782
total time of one epoch: 389.78301644325256 s
train_loss:  0.0011251947604300565  acc:  0.8765924948797167
->>lr:0.013885
test_loss:  0.001145439887404782  test_acc:  0.8793895024196551
best acc:  88.24916242710013

------Epoch: 97------
[batch_idx--0] train_loss: 0.0010088956914842129, acc: 0.8984375, lr: 0.01388412052037681
[batch_idx--50] train_loss: 0.0011385258106861775, acc: 0.8739276960784313, lr: 0.01383215567857612
[batch_idx--100] train_loss: 0.0011247555520108874, acc: 0.8755801361386139, lr: 0.013780251047424422
[batch_idx--150] train_loss: 0.0011157030871890435, acc: 0.8772506208609272, lr: 0.013728406906761904
[batch_idx--200] train_loss: 0.0011140937280994076, acc: 0.8781483208955224, lr: 0.013676623536102595
[batch_idx--250] train_loss: 0.0011103148989572349, acc: 0.878968500996016, lr: 0.013624901214632912
[batch_idx--300] train_loss: 0.001114858505261932, acc: 0.8781016403654485, lr: 0.01357324022121012
[batch_idx--350] train_loss: 0.001121098011966922, acc: 0.8775596509971509, lr: 0.013521640834360844
[batch_idx--400] train_loss: 0.0011226180869739902, acc: 0.8772404925187033, lr: 0.013470103332279566
[batch_idx--450] train_loss: 0.0011232913697322901, acc: 0.877269413684174, lr: 0.013418627992827087
total time of one epoch: 395.35895109176636 s
train_loss:  0.0011232913697322901  acc:  0.877269413684174
->>lr:0.013419
test_loss:  0.0011296102908634196  test_acc:  0.8822434545228937
best acc:  88.24916242710013

------Epoch: 98------
[batch_idx--0] train_loss: 0.001216914039105177, acc: 0.8671875, lr: 0.013417599122003463
[batch_idx--50] train_loss: 0.001087856610241693, acc: 0.8817401960784313, lr: 0.013366187474337023
[batch_idx--100] train_loss: 0.001106218391070419, acc: 0.8799891707920792, lr: 0.013314838549554453
[batch_idx--150] train_loss: 0.0011094769980258845, acc: 0.8790355960264901, lr: 0.013263552624499875
[batch_idx--200] train_loss: 0.001107315923520526, acc: 0.8796641791044776, lr: 0.01321232997567776
[batch_idx--250] train_loss: 0.001108282805045703, acc: 0.8793575697211156, lr: 0.01316117087925142
[batch_idx--300] train_loss: 0.0011103051980304534, acc: 0.8791398463455149, lr: 0.013110075611041534
[batch_idx--350] train_loss: 0.0011112294372096871, acc: 0.8791065705128205, lr: 0.01305904444652466
[batch_idx--400] train_loss: 0.0011118971839944305, acc: 0.8790718516209476, lr: 0.013008077660831736
[batch_idx--450] train_loss: 0.0011149955012782833, acc: 0.879126601173326, lr: 0.01295717552874661
total time of one epoch: 390.43794226646423 s
train_loss:  0.0011149955012782833  acc:  0.879126601173326
->>lr:0.012957
test_loss:  0.0011578934325638178  test_acc:  0.8791413326715474
best acc:  88.24916242710013

------Epoch: 99------
[batch_idx--0] train_loss: 0.001004429766908288, acc: 0.8828125, lr: 0.012956158147457115
[batch_idx--50] train_loss: 0.0011006332922489474, acc: 0.8774509803921569, lr: 0.012905322244772761
[batch_idx--100] train_loss: 0.0011090042846424893, acc: 0.8767404084158416, lr: 0.012854551549694835
[batch_idx--150] train_loss: 0.0011112484787991702, acc: 0.8778973509933775, lr: 0.012803846335949954
[batch_idx--200] train_loss: 0.0011130529395026614, acc: 0.8776624689054726, lr: 0.012753206876911727
[batch_idx--250] train_loss: 0.0011046434169638888, acc: 0.8786261205179283, lr: 0.012702633445599246
[batch_idx--300] train_loss: 0.0011058967118460895, acc: 0.8787505191029901, lr: 0.012652126314675622
[batch_idx--350] train_loss: 0.0011107268512044685, acc: 0.8784388354700855, lr: 0.012601685756446507
[batch_idx--400] train_loss: 0.0011132599297037668, acc: 0.8779710879052369, lr: 0.012551312042858621
[batch_idx--450] train_loss: 0.0011182853893662713, acc: 0.8775905161939807, lr: 0.012501005445498313
total time of one epoch: 391.4231128692627 s
train_loss:  0.0011182853893662713  acc:  0.8775905161939807
->>lr:0.012501
test_loss:  0.0011421355868054465  test_acc:  0.8805062662861397
best acc:  88.24916242710013

------Epoch: 100------
[batch_idx--0] train_loss: 0.0010960575891658664, acc: 0.890625, lr: 0.012500000000000006
[batch_idx--50] train_loss: 0.001091963052293103, acc: 0.8813572303921569, lr: 0.012449762140604802
[batch_idx--100] train_loss: 0.0010909063598639008, acc: 0.881149443069307, lr: 0.012399591944936346
[batch_idx--150] train_loss: 0.0011019591432502678, acc: 0.8799927566225165, lr: 0.012349489683483728
[batch_idx--200] train_loss: 0.0011039340969369706, acc: 0.8801500310945274, lr: 0.012299455626369788
[batch_idx--250] train_loss: 0.001108156210108404, acc: 0.8792953187250996, lr: 0.012249490043349598
[batch_idx--300] train_loss: 0.0011107317511181028, acc: 0.8790360257475083, lr: 0.01219959320380913
[batch_idx--350] train_loss: 0.0011119318587381785, acc: 0.8789730235042735, lr: 0.012149765376763677
[batch_idx--400] train_loss: 0.0011122590360554525, acc: 0.8787893547381546, lr: 0.012100006830856476
[batch_idx--450] train_loss: 0.0011145964070374025, acc: 0.879057173603638, lr: 0.01205031783435723
total time of one epoch: 394.119065284729 s
train_loss:  0.0011145964070374025  acc:  0.879057173603638
->>lr:0.012050
test_loss:  0.001167449878764694  test_acc:  0.8766596351904703
best acc:  88.24916242710013

------Epoch: 101------
[batch_idx--0] train_loss: 0.0011723515344783664, acc: 0.8515625, lr: 0.012049324765671741
[batch_idx--50] train_loss: 0.0011290996472406037, acc: 0.8741574754901961, lr: 0.01199970698555119
[batch_idx--100] train_loss: 0.0011326955374339504, acc: 0.8745358910891089, lr: 0.011950159295598187
[batch_idx--150] train_loss: 0.0011262275187594705, acc: 0.8765262831125827, lr: 0.011900681962945607
[batch_idx--200] train_loss: 0.0011211241319177866, acc: 0.8769822761194029, lr: 0.011851275254347019
[batch_idx--250] train_loss: 0.001112215550926206, acc: 0.8786883715139442, lr: 0.011801939436175232
[batch_idx--300] train_loss: 0.001108767640733615, acc: 0.8794642857142857, lr: 0.01175267477442085
[batch_idx--350] train_loss: 0.0011081472359281935, acc: 0.8791176994301995, lr: 0.011703481534690844
[batch_idx--400] train_loss: 0.0011102255348736268, acc: 0.8789646976309227, lr: 0.011654359982207095
[batch_idx--450] train_loss: 0.001113378145422687, acc: 0.8786840004165655, lr: 0.011605310381805019
total time of one epoch: 389.62154817581177 s
train_loss:  0.001113378145422687  acc:  0.8786840004165655
->>lr:0.011605
test_loss:  0.0011183780862196663  test_acc:  0.8817471150266782
best acc:  88.24916242710013

------Epoch: 102------
[batch_idx--0] train_loss: 0.0011811666190624237, acc: 0.87109375, lr: 0.01160433012552509
[batch_idx--50] train_loss: 0.001110888966222239, acc: 0.8777573529411765, lr: 0.011555354188677439
[batch_idx--100] train_loss: 0.0010954108328955008, acc: 0.879215655940594, lr: 0.011506450737694249
[batch_idx--150] train_loss: 0.00109239081606972, acc: 0.8804842715231788, lr: 0.011457620036235043
[batch_idx--200] train_loss: 0.001097896927504323, acc: 0.8800917288557214, lr: 0.011408862347567132
[batch_idx--250] train_loss: 0.001096110436156303, acc: 0.8809138446215139, lr: 0.011360177934564142
[batch_idx--300] train_loss: 0.0011067828124828414, acc: 0.8792566445182725, lr: 0.011311567059704701
[batch_idx--350] train_loss: 0.0011091417136490664, acc: 0.879173344017094, lr: 0.01126302998507092
[batch_idx--400] train_loss: 0.0011069823250678505, acc: 0.8792569357855362, lr: 0.011214566972347026
[batch_idx--450] train_loss: 0.0011089973007622524, acc: 0.8795258096990315, lr: 0.01116617828281797
total time of one epoch: 388.5394129753113 s
train_loss:  0.0011089973007622524  acc:  0.8795258096990315
->>lr:0.011166
test_loss:  0.0011389261366549165  test_acc:  0.8800099267899243
best acc:  88.24916242710013

------Epoch: 103------
[batch_idx--0] train_loss: 0.0009951941901817918, acc: 0.890625, lr: 0.011165211268916392
[batch_idx--50] train_loss: 0.0011368003963748469, acc: 0.8735447303921569, lr: 0.011116898657806221
[batch_idx--100] train_loss: 0.001125378057586564, acc: 0.8756574876237624, lr: 0.01106866089646273
[batch_idx--150] train_loss: 0.0011175811488878303, acc: 0.8764745447019867, lr: 0.011020498244956429
[batch_idx--200] train_loss: 0.001109892184746484, acc: 0.8779734141791045, lr: 0.010972410962952879
[batch_idx--250] train_loss: 0.0011090166953511061, acc: 0.8777390438247012, lr: 0.010924399309711284
[batch_idx--300] train_loss: 0.001108993014995244, acc: 0.8780886627906976, lr: 0.010876463544083113
[batch_idx--350] train_loss: 0.0011004190978214697, acc: 0.8791399572649573, lr: 0.010828603924510663
[batch_idx--400] train_loss: 0.001098125208165738, acc: 0.8796368453865336, lr: 0.010780820709025727
[batch_idx--450] train_loss: 0.0011023149467451476, acc: 0.8794216683444996, lr: 0.010733114155248157
total time of one epoch: 388.26473331451416 s
train_loss:  0.0011023149467451476  acc:  0.8794216683444996
->>lr:0.010733
test_loss:  0.0011754363002367655  test_acc:  0.8756669561980395
best acc:  88.24916242710013

------Epoch: 104------
[batch_idx--0] train_loss: 0.0013283580774441361, acc: 0.83984375, lr: 0.010732160807889211
[batch_idx--50] train_loss: 0.00110132399005998, acc: 0.8774509803921569, lr: 0.010684532714024482
[batch_idx--100] train_loss: 0.0010926169527713024, acc: 0.8789449257425742, lr: 0.010636981800997085
[batch_idx--150] train_loss: 0.0010922598815985664, acc: 0.8795012417218543, lr: 0.01058950832517444
[batch_idx--200] train_loss: 0.001092879752922729, acc: 0.8799362562189055, lr: 0.010542112542506449
[batch_idx--250] train_loss: 0.0010896494711352238, acc: 0.8802913346613546, lr: 0.01049479470852415
[batch_idx--300] train_loss: 0.001091041087220884, acc: 0.8801131644518272, lr: 0.010447555078338317
[batch_idx--350] train_loss: 0.001092077888106593, acc: 0.8801415598290598, lr: 0.010400393906638123
[batch_idx--400] train_loss: 0.0010903070503996773, acc: 0.8803966645885287, lr: 0.010353311447689712
[batch_idx--450] train_loss: 0.0010932698678007377, acc: 0.8805672232443503, lr: 0.01030630795533484
total time of one epoch: 389.9249572753906 s
train_loss:  0.0010932698678007377  acc:  0.8805672232443503
->>lr:0.010306
test_loss:  0.0011123011970596939  test_acc:  0.8824916242710014
best acc:  88.24916242710013

------Epoch: 105------
[batch_idx--0] train_loss: 0.0010741412406787276, acc: 0.8828125, lr: 0.010305368692688175
[batch_idx--50] train_loss: 0.0011161295845465479, acc: 0.8769914215686274, lr: 0.010258446007324987
[batch_idx--100] train_loss: 0.0010979588213837752, acc: 0.8800665222772277, lr: 0.010211602800015714
[batch_idx--150] train_loss: 0.001099447674266007, acc: 0.8801221026490066, lr: 0.010164839323312217
[batch_idx--200] train_loss: 0.0010934500982266717, acc: 0.880733053482587, lr: 0.010118155829336504
[batch_idx--250] train_loss: 0.0010926216312932718, acc: 0.8810072211155379, lr: 0.010071552569779364
[batch_idx--300] train_loss: 0.001098277154409534, acc: 0.8800872093023255, lr: 0.010025029795898983
[batch_idx--350] train_loss: 0.0010971475704015894, acc: 0.8799523682336182, lr: 0.00997858775851964
[batch_idx--400] train_loss: 0.001095393654731267, acc: 0.8802797693266833, lr: 0.00993222670803032
[batch_idx--450] train_loss: 0.0010972889846652932, acc: 0.8803936543201305, lr: 0.009885946894383374
total time of one epoch: 399.3402361869812 s
train_loss:  0.0010972889846652932  acc:  0.8803936543201305
->>lr:0.009886
test_loss:  0.0011556287907329293  test_acc:  0.8775282293088472
best acc:  88.24916242710013

------Epoch: 106------
[batch_idx--0] train_loss: 0.0009679828071966767, acc: 0.91015625, lr: 0.00988502212844063
[batch_idx--50] train_loss: 0.0010889334074568515, acc: 0.8836550245098039, lr: 0.009838825433419594
[batch_idx--100] train_loss: 0.0011010270578427112, acc: 0.8808013613861386, lr: 0.009792710478807351
[batch_idx--150] train_loss: 0.0010909429355832865, acc: 0.8815707781456954, lr: 0.009746677513229449
[batch_idx--200] train_loss: 0.0010872749430451782, acc: 0.8819962686567164, lr: 0.00970072678486938
[batch_idx--250] train_loss: 0.0010848451747588696, acc: 0.8826257470119522, lr: 0.009654858541467274
[batch_idx--300] train_loss: 0.001084186379609017, acc: 0.8826567691029901, lr: 0.009609073030318542
[batch_idx--350] train_loss: 0.0010849910843294867, acc: 0.882278311965812, lr: 0.009563370498272567
[batch_idx--400] train_loss: 0.0010834682358027044, acc: 0.8823449189526185, lr: 0.009517751191731351
[batch_idx--450] train_loss: 0.001087515725332848, acc: 0.8821640573471725, lr: 0.00947221535664816
total time of one epoch: 393.53948497772217 s
train_loss:  0.001087515725332848  acc:  0.8821640573471725
->>lr:0.009472
test_loss:  0.0011603684472096944  test_acc:  0.8759151259461472
best acc:  88.24916242710013

------Epoch: 107------
[batch_idx--0] train_loss: 0.001054336316883564, acc: 0.87890625, lr: 0.009471305493042243
[batch_idx--50] train_loss: 0.001066776042731077, acc: 0.8824295343137255, lr: 0.00942585505176061
[batch_idx--100] train_loss: 0.0010692694657804943, acc: 0.8829285272277227, lr: 0.009380488577388602
[batch_idx--150] train_loss: 0.0010710256524994624, acc: 0.8825279387417219, lr: 0.009335206314516387
[batch_idx--200] train_loss: 0.0010686057164514466, acc: 0.8836287313432836, lr: 0.0092900085072801
[batch_idx--250] train_loss: 0.0010741282228020528, acc: 0.8832949452191236, lr: 0.009244895399360565
[batch_idx--300] train_loss: 0.0010751984913700394, acc: 0.8830850290697675, lr: 0.009199867233981912
[batch_idx--350] train_loss: 0.0010798953757475414, acc: 0.8820668625356125, lr: 0.009154924253910346
[batch_idx--400] train_loss: 0.001082088387927779, acc: 0.8818091490024937, lr: 0.009110066701452797
[batch_idx--450] train_loss: 0.0010834913732502153, acc: 0.8819818099767418, lr: 0.0090652948184556
total time of one epoch: 392.75484561920166 s
train_loss:  0.0010834913732502153  acc:  0.8819818099767418
->>lr:0.009065
test_loss:  0.0011363241635239853  test_acc:  0.8805062662861397
best acc:  88.24916242710013

------Epoch: 108------
[batch_idx--0] train_loss: 0.0011472732294350863, acc: 0.8828125, lr: 0.009064400256282757
[batch_idx--50] train_loss: 0.0010824499402980448, acc: 0.8818933823529411, lr: 0.009019716004806225
[batch_idx--100] train_loss: 0.001080986300810692, acc: 0.8823483910891089, lr: 0.0089751179099095
[batch_idx--150] train_loss: 0.001084515310296579, acc: 0.8821399006622517, lr: 0.008930606212040063
[batch_idx--200] train_loss: 0.0010849643743073391, acc: 0.8817436256218906, lr: 0.00888618115117962
[batch_idx--250] train_loss: 0.001082975243912097, acc: 0.8822366782868526, lr: 0.00884184296684277
[batch_idx--300] train_loss: 0.00108450913238664, acc: 0.8816964285714286, lr: 0.00879759189807571
[batch_idx--350] train_loss: 0.001084580221492001, acc: 0.8814770299145299, lr: 0.008753428183455004
[batch_idx--400] train_loss: 0.0010877671700024378, acc: 0.8812538965087282, lr: 0.008709352061086187
[batch_idx--450] train_loss: 0.0010897065816573806, acc: 0.8814003540806055, lr: 0.008665363768602597
total time of one epoch: 404.04463720321655 s
train_loss:  0.0010897065816573806  acc:  0.8814003540806055
->>lr:0.008665
test_loss:  0.0011094835962310206  test_acc:  0.882863878893163
best acc:  88.24916242710013
Saving..

------Epoch: 109------
[batch_idx--0] train_loss: 0.0012486628256738186, acc: 0.84765625, lr: 0.008664484900247363
[batch_idx--50] train_loss: 0.0010898324658674206, acc: 0.8807444852941176, lr: 0.00862058643856546
[batch_idx--100] train_loss: 0.001086439148956301, acc: 0.8813041460396039, lr: 0.0085767762853424
[batch_idx--150] train_loss: 0.0010878692449699618, acc: 0.8814414321192053, lr: 0.008533054676777554
[batch_idx--200] train_loss: 0.0010762759831859105, acc: 0.882851368159204, lr: 0.008489421848592919
[batch_idx--250] train_loss: 0.0010807153887571804, acc: 0.8822678037848606, lr: 0.008445878036031801
[batch_idx--300] train_loss: 0.001086374965420556, acc: 0.8810215946843853, lr: 0.008402423473857626
[batch_idx--350] train_loss: 0.0010854011402197416, acc: 0.8810986467236467, lr: 0.008359058396352615
[batch_idx--400] train_loss: 0.0010807667080861077, acc: 0.8818383728179551, lr: 0.008315783037316537
[batch_idx--450] train_loss: 0.0010886302783417472, acc: 0.8810358593397438, lr: 0.008272597630065468
total time of one epoch: 395.95857524871826 s
train_loss:  0.0010886302783417472  acc:  0.8810358593397438
->>lr:0.008273
test_loss:  0.0011181553194992949  test_acc:  0.882863878893163
best acc:  88.28638788931629

------Epoch: 110------
[batch_idx--0] train_loss: 0.0010373234981670976, acc: 0.90234375, lr: 0.008271734841028545
[batch_idx--50] train_loss: 0.0010792506623593177, acc: 0.8821231617647058, lr: 0.008228641424457422
[batch_idx--100] train_loss: 0.0010766219779950483, acc: 0.8822323638613861, lr: 0.00818563842948918
[batch_idx--150] train_loss: 0.0010678572873184025, acc: 0.8834592301324503, lr: 0.008142726087971458
[batch_idx--200] train_loss: 0.0010712334992762525, acc: 0.8831817475124378, lr: 0.00809990463126313
[batch_idx--250] train_loss: 0.001071919612883334, acc: 0.8829836902390438, lr: 0.008057174290233077
[batch_idx--300] train_loss: 0.0010708860623297525, acc: 0.8830980066445183, lr: 0.008014535295258926
[batch_idx--350] train_loss: 0.00107016466823977, acc: 0.8833912037037037, lr: 0.00797198787622585
[batch_idx--400] train_loss: 0.0010741807041664206, acc: 0.8829196539900249, lr: 0.007929532262525246
[batch_idx--450] train_loss: 0.001074343128063564, acc: 0.8827975839205748, lr: 0.007887168683053591
total time of one epoch: 394.1040871143341 s
train_loss:  0.001074343128063564  acc:  0.8827975839205748
->>lr:0.007887
test_loss:  0.0011282320822981898  test_acc:  0.8824916242710014
best acc:  88.28638788931629

------Epoch: 111------
[batch_idx--0] train_loss: 0.0008960723644122481, acc: 0.90234375, lr: 0.00788632235178279
[batch_idx--50] train_loss: 0.0010705759130217427, acc: 0.8828890931372549, lr: 0.00784405288251919
[batch_idx--100] train_loss: 0.0010649413049064283, acc: 0.8830832301980198, lr: 0.007801875908340622
[batch_idx--150] train_loss: 0.0010763675140969405, acc: 0.8823468543046358, lr: 0.007759791656641275
[batch_idx--200] train_loss: 0.0010776894253363546, acc: 0.8826181592039801, lr: 0.007717800354315446
[batch_idx--250] train_loss: 0.0010715790389317172, acc: 0.8826101842629482, lr: 0.007675902227756282
[batch_idx--300] train_loss: 0.00106787524341553, acc: 0.8832018272425249, lr: 0.007634097502854598
[batch_idx--350] train_loss: 0.001068467587070736, acc: 0.8833133012820513, lr: 0.007592386404997634
[batch_idx--400] train_loss: 0.0010688695809838741, acc: 0.8830755143391521, lr: 0.007550769159067847
[batch_idx--450] train_loss: 0.0010745692062548425, acc: 0.8825893012115111, lr: 0.00750924598944171
total time of one epoch: 392.5347855091095 s
train_loss:  0.0010745692062548425  acc:  0.8825893012115111
->>lr:0.007509
test_loss:  0.0011141776284178664  test_acc:  0.882863878893163
best acc:  88.28638788931629

------Epoch: 112------
[batch_idx--0] train_loss: 0.0011167353950440884, acc: 0.875, lr: 0.007508416487165862
[batch_idx--50] train_loss: 0.0010650228177124233, acc: 0.8822763480392157, lr: 0.007466989505996053
[batch_idx--100] train_loss: 0.0010692387015909179, acc: 0.8820389851485149, lr: 0.007425657052821996
[batch_idx--150] train_loss: 0.0010703828903562728, acc: 0.8824503311258278, lr: 0.007384419350484717
[batch_idx--200] train_loss: 0.001065699816554025, acc: 0.8831040111940298, lr: 0.0073432766213143985
[batch_idx--250] train_loss: 0.001059904562372462, acc: 0.8840575199203188, lr: 0.007302229087129178
[batch_idx--300] train_loss: 0.0010660246462852036, acc: 0.8836041320598007, lr: 0.007261276969233954
[batch_idx--350] train_loss: 0.0010640834543742558, acc: 0.8838474893162394, lr: 0.007220420488419194
[batch_idx--400] train_loss: 0.0010663597609968554, acc: 0.8838255922693267, lr: 0.007179659864959754
[batch_idx--450] train_loss: 0.0010676460400299772, acc: 0.8838910681431597, lr: 0.007138995318613667
total time of one epoch: 396.2099230289459 s
train_loss:  0.0010676460400299772  acc:  0.8838910681431597
->>lr:0.007139
test_loss:  0.0011235761692749092  test_acc:  0.8796376721677628
best acc:  88.28638788931629

------Epoch: 113------
[batch_idx--0] train_loss: 0.0010442769853398204, acc: 0.8828125, lr: 0.007138183009179922
[batch_idx--50] train_loss: 0.0010337901402118744, acc: 0.8871783088235294, lr: 0.007097616687346986
[batch_idx--100] train_loss: 0.0010582039335576615, acc: 0.8830445544554455, lr: 0.00705714688495745
[batch_idx--150] train_loss: 0.0010472977455298336, acc: 0.8856581125827815, lr: 0.007016773820201414
[batch_idx--200] train_loss: 0.0010514133488203385, acc: 0.8851834577114428, lr: 0.00697649771074741
[batch_idx--250] train_loss: 0.0010539899583427287, acc: 0.8852714143426295, lr: 0.006936318773741257
[batch_idx--300] train_loss: 0.001058699640111249, acc: 0.884577450166113, lr: 0.00689623722580488
[batch_idx--350] train_loss: 0.0010637807095306593, acc: 0.8839587784900285, lr: 0.006856253283035133
[batch_idx--400] train_loss: 0.0010632170338713172, acc: 0.8843516209476309, lr: 0.00681636716100264
[batch_idx--450] train_loss: 0.001067130933974648, acc: 0.884559308501406, lr: 0.006776579074750619
total time of one epoch: 397.84608817100525 s
train_loss:  0.001067130933974648  acc:  0.884559308501406
->>lr:0.006777
test_loss:  0.001107744263321668  test_acc:  0.8832361335153245
best acc:  88.28638788931629
Saving..

------Epoch: 114------
[batch_idx--0] train_loss: 0.0010813854169100523, acc: 0.89453125, lr: 0.006775784314464717
[batch_idx--50] train_loss: 0.0010572052652052806, acc: 0.8853400735294118, lr: 0.006736096445698165
[batch_idx--100] train_loss: 0.0010629587318047439, acc: 0.8849783415841584, lr: 0.0066965070454860194
[batch_idx--150] train_loss: 0.0010590258964941843, acc: 0.8853476821192053, lr: 0.006657016327271753
[batch_idx--200] train_loss: 0.0010617034882191216, acc: 0.8849891169154229, lr: 0.006617624503966805
[batch_idx--250] train_loss: 0.00105819992110712, acc: 0.8852714143426295, lr: 0.006578331787949427
[batch_idx--300] train_loss: 0.0010616508570880292, acc: 0.8849408222591362, lr: 0.006539138391063526
[batch_idx--350] train_loss: 0.001058817243613462, acc: 0.8849826388888888, lr: 0.006500044524617568
[batch_idx--400] train_loss: 0.0010588684613105756, acc: 0.8852185941396509, lr: 0.0064610503993833834
[batch_idx--450] train_loss: 0.0010628176508231807, acc: 0.885331690214184, lr: 0.006422156225595066
total time of one epoch: 395.6003007888794 s
train_loss:  0.0010628176508231807  acc:  0.885331690214184
->>lr:0.006422
test_loss:  0.0011250348134170412  test_acc:  0.8826157091450553
best acc:  88.32361335153244

------Epoch: 115------
[batch_idx--0] train_loss: 0.0009433382656425238, acc: 0.91015625, lr: 0.00642137936306515
[batch_idx--50] train_loss: 0.0010633178091808862, acc: 0.8847273284313726, lr: 0.006382587355775901
[batch_idx--100] train_loss: 0.001078820883614555, acc: 0.8813428217821783, lr: 0.006343895722960522
[batch_idx--150] train_loss: 0.001071200359131623, acc: 0.8822692466887417, lr: 0.006305304673222229
[batch_idx--200] train_loss: 0.0010664606726362338, acc: 0.8835704291044776, lr: 0.0062668144146219495
[batch_idx--250] train_loss: 0.0010642497876818585, acc: 0.8838863296812749, lr: 0.006228425154677217
[batch_idx--300] train_loss: 0.001057881299766752, acc: 0.8848629568106312, lr: 0.0061901371003610295
[batch_idx--350] train_loss: 0.001055962310246911, acc: 0.8843371616809117, lr: 0.00615195045810075
[batch_idx--400] train_loss: 0.0010583689449380554, acc: 0.8841957605985037, lr: 0.006113865433776986
[batch_idx--450] train_loss: 0.001058658635580714, acc: 0.8843423473461312, lr: 0.006075882232722457
total time of one epoch: 394.561274766922 s
train_loss:  0.001058658635580714  acc:  0.8843423473461312
->>lr:0.006076
test_loss:  0.001115787980026636  test_acc:  0.8868345948628862
best acc:  88.32361335153244
Saving..

------Epoch: 116------
[batch_idx--0] train_loss: 0.0009036982082761824, acc: 0.91015625, lr: 0.006075123608706093
[batch_idx--50] train_loss: 0.0010400142385989573, acc: 0.8890165441176471, lr: 0.006037244478350651
[batch_idx--100] train_loss: 0.0010560074657441514, acc: 0.8855584777227723, lr: 0.00599946758436096
[batch_idx--150] train_loss: 0.0010467887037304163, acc: 0.8863565811258278, lr: 0.005961793130408489
[batch_idx--200] train_loss: 0.0010435806971914436, acc: 0.8869130907960199, lr: 0.005924221319612417
[batch_idx--250] train_loss: 0.0010467088299866514, acc: 0.8869055029880478, lr: 0.005886752354538527
[batch_idx--300] train_loss: 0.0010497589803306986, acc: 0.886796615448505, lr: 0.0058493864371981065
[batch_idx--350] train_loss: 0.0010512509301007643, acc: 0.8863403668091168, lr: 0.005812123769046874
[batch_idx--400] train_loss: 0.0010520939436796913, acc: 0.8862219451371571, lr: 0.005774964550983902
[batch_idx--450] train_loss: 0.0010549160991809748, acc: 0.8858263616482105, lr: 0.005737908983350504
total time of one epoch: 387.18883204460144 s
train_loss:  0.0010549160991809748  acc:  0.8858263616482105
->>lr:0.005738
test_loss:  0.0011043450993304662  test_acc:  0.8833602183893783
best acc:  88.68345948628863

------Epoch: 117------
[batch_idx--0] train_loss: 0.001162015600129962, acc: 0.875, lr: 0.005737168930605272
[batch_idx--50] train_loss: 0.0010372854006823664, acc: 0.8910845588235294, lr: 0.005700219292222111
[batch_idx--100] train_loss: 0.0010538803203732218, acc: 0.8879563737623762, lr: 0.005663373707252357
[batch_idx--150] train_loss: 0.0010513043507551219, acc: 0.8870809188741722, lr: 0.005626632374346372
[batch_idx--200] train_loss: 0.0010426634947528406, acc: 0.8872823383084577, lr: 0.005589995491592479
[batch_idx--250] train_loss: 0.001041874140862791, acc: 0.8873101344621513, lr: 0.005553463256515865
[batch_idx--300] train_loss: 0.001042593909470841, acc: 0.8871989202657807, lr: 0.005517035866077508
[batch_idx--350] train_loss: 0.0010434276793494376, acc: 0.8870192307692307, lr: 0.0054807135166731365
[batch_idx--400] train_loss: 0.0010433839648576486, acc: 0.886913575436409, lr: 0.005444496404132135
[batch_idx--450] train_loss: 0.0010435641776380714, acc: 0.8870326656715382, lr: 0.005408384723716528
total time of one epoch: 391.75521087646484 s
train_loss:  0.0010435641776380714  acc:  0.8870326656715382
->>lr:0.005408
test_loss:  0.0011055142108967173  test_acc:  0.8846010671299168
best acc:  88.68345948628863

------Epoch: 118------
[batch_idx--0] train_loss: 0.0011175258550792933, acc: 0.88671875, lr: 0.005407663566854007
[batch_idx--50] train_loss: 0.0010528733380887583, acc: 0.8872549019607843, lr: 0.005371659627775735
[batch_idx--100] train_loss: 0.0010454524031812602, acc: 0.8872602103960396, lr: 0.005335761513517229
[batch_idx--150] train_loss: 0.0010488181026492094, acc: 0.8869515728476821, lr: 0.0052999694176206515
[batch_idx--200] train_loss: 0.0010525729577867916, acc: 0.886602145522388, lr: 0.005264283533056586
[batch_idx--250] train_loss: 0.0010524207384759686, acc: 0.8865164342629482, lr: 0.0052287040522229575
[batch_idx--300] train_loss: 0.0010579409477288566, acc: 0.8857713870431894, lr: 0.005193231166944048
[batch_idx--350] train_loss: 0.001055316176189858, acc: 0.88630698005698, lr: 0.005157865068469426
[batch_idx--400] train_loss: 0.0010566091042434672, acc: 0.8857446228179551, lr: 0.005122605947472936
[batch_idx--450] train_loss: 0.001057320725768013, acc: 0.8855486513694588, lr: 0.0050874539940516635
total time of one epoch: 393.7636671066284 s
train_loss:  0.001057320725768013  acc:  0.8855486513694588
->>lr:0.005087
test_loss:  0.0011262345020403295  test_acc:  0.8798858419158705
best acc:  88.68345948628863

------Epoch: 119------
[batch_idx--0] train_loss: 0.0009158149478025734, acc: 0.89453125, lr: 0.005086752049395094
[batch_idx--50] train_loss: 0.0010272094674006688, acc: 0.8874080882352942, lr: 0.005051709602139323
[batch_idx--100] train_loss: 0.0010424957352478316, acc: 0.8855584777227723, lr: 0.005016774704691432
[batch_idx--150] train_loss: 0.0010454044792961503, acc: 0.8862013658940397, lr: 0.004981947545400465
[batch_idx--200] train_loss: 0.001039232701046939, acc: 0.886893656716418, lr: 0.004947228312034608
[batch_idx--250] train_loss: 0.0010401222229178297, acc: 0.8870300049800797, lr: 0.004912617191780173
[batch_idx--300] train_loss: 0.0010396253034871603, acc: 0.8875103820598007, lr: 0.004878114371240583
[batch_idx--350] train_loss: 0.0010406621476433684, acc: 0.8873530982905983, lr: 0.004843720036435387
[batch_idx--400] train_loss: 0.0010428281320651479, acc: 0.8868746103491272, lr: 0.004809434372799207
[batch_idx--450] train_loss: 0.0010463138469052123, acc: 0.887154163918492, lr: 0.004775257565180805
total time of one epoch: 396.8122272491455 s
train_loss:  0.0010463138469052123  acc:  0.887154163918492
->>lr:0.004775
test_loss:  0.0011110219381955794  test_acc:  0.8837324730115399
best acc:  88.68345948628863

------Epoch: 120------
[batch_idx--0] train_loss: 0.0010925803799182177, acc: 0.8671875, lr: 0.004774575140626317
[batch_idx--50] train_loss: 0.0010504053549512343, acc: 0.8840379901960784, lr: 0.004740509555968578
[batch_idx--100] train_loss: 0.0010442983435171812, acc: 0.8854424504950495, lr: 0.004706553198931926
[batch_idx--150] train_loss: 0.0010506923877886983, acc: 0.8844939983443708, lr: 0.004672706252589681
[batch_idx--200] train_loss: 0.001044780971014418, acc: 0.8852611940298507, lr: 0.004638968899425284
[batch_idx--250] train_loss: 0.0010391544391571792, acc: 0.8864697460159362, lr: 0.004605341321331294
[batch_idx--300] train_loss: 0.0010377337811499265, acc: 0.8870691445182725, lr: 0.004571823699608443
[batch_idx--350] train_loss: 0.0010386683415632132, acc: 0.8868745548433048, lr: 0.0045384162149646355
[batch_idx--400] train_loss: 0.0010405596330566819, acc: 0.8862511689526185, lr: 0.004505119047513989
[batch_idx--450] train_loss: 0.0010464534662128816, acc: 0.8866594924844656, lr: 0.0044719323767758445
total time of one epoch: 394.34161472320557 s
train_loss:  0.0010464534662128816  acc:  0.8866594924844656
->>lr:0.004472
test_loss:  0.0011084123027725542  test_acc:  0.8813748604045167
best acc:  88.68345948628863

------Epoch: 121------
[batch_idx--0] train_loss: 0.0010654724901542068, acc: 0.890625, lr: 0.004471269771657399
[batch_idx--50] train_loss: 0.0010550273365487217, acc: 0.8839613970588235, lr: 0.004438195991889007
[batch_idx--100] train_loss: 0.001052168607112426, acc: 0.8856358292079208, lr: 0.004405233069644058
[batch_idx--150] train_loss: 0.0010450270149505248, acc: 0.886615273178808, lr: 0.004372381182639854
[batch_idx--200] train_loss: 0.001048439326267504, acc: 0.8860191231343284, lr: 0.004339640507995033
[batch_idx--250] train_loss: 0.0010480660076932129, acc: 0.8856449203187251, lr: 0.00430701122222864
[batch_idx--300] train_loss: 0.001046202978215171, acc: 0.885875207641196, lr: 0.004274493501259191
[batch_idx--350] train_loss: 0.0010458152589290018, acc: 0.8860844017094017, lr: 0.004242087520403681
[batch_idx--400] train_loss: 0.0010437989197241752, acc: 0.8865044420199502, lr: 0.004209793454376692
[batch_idx--450] train_loss: 0.0010451379764223644, acc: 0.886338389974659, lr: 0.0041776114772894115
total time of one epoch: 400.9832284450531 s
train_loss:  0.0010451379764223644  acc:  0.886338389974659
->>lr:0.004178
test_loss:  0.001108588396815068  test_acc:  0.8834843032634322
best acc:  88.68345948628863

------Epoch: 122------
[batch_idx--0] train_loss: 0.0013916273601353168, acc: 0.859375, lr: 0.004176968982247515
[batch_idx--50] train_loss: 0.001022093897393229, acc: 0.8891697303921569, lr: 0.004144901514621361
[batch_idx--100] train_loss: 0.0010163524951140332, acc: 0.8902382425742574, lr: 0.0041129464857952575
[batch_idx--150] train_loss: 0.0010197200297396506, acc: 0.8890211092715232, lr: 0.004081104068052505
[batch_idx--200] train_loss: 0.0010181712783034428, acc: 0.8890897077114428, lr: 0.00404937443306925
[batch_idx--250] train_loss: 0.001027960645172196, acc: 0.8881349601593626, lr: 0.004017757751913604
[batch_idx--300] train_loss: 0.0010297032432055157, acc: 0.8875363372093024, lr: 0.003986254195044678
[batch_idx--350] train_loss: 0.0010304037419192897, acc: 0.8877537393162394, lr: 0.003954863932311695
[batch_idx--400] train_loss: 0.0010338619251519516, acc: 0.8871863310473815, lr: 0.003923587132953052
[batch_idx--450] train_loss: 0.0010346718515021262, acc: 0.8874318741972437, lr: 0.003892423965595415
total time of one epoch: 395.47297263145447 s
train_loss:  0.0010346718515021262  acc:  0.8874318741972437
->>lr:0.003892
test_loss:  0.001110883177487929  test_acc:  0.881995284774786
best acc:  88.68345948628863

------Epoch: 123------
[batch_idx--0] train_loss: 0.0009309356100857258, acc: 0.88671875, lr: 0.003891801862449629
[batch_idx--50] train_loss: 0.001018589174183195, acc: 0.8902420343137255, lr: 0.003860754772816863
[batch_idx--100] train_loss: 0.0010403345891108534, acc: 0.8884978341584159, lr: 0.0038298216539413596
[batch_idx--150] train_loss: 0.0010394899715015678, acc: 0.8882709023178808, lr: 0.0037990026725968685
[batch_idx--200] train_loss: 0.0010329313253038632, acc: 0.8888953669154229, lr: 0.003768297994941761
[batch_idx--250] train_loss: 0.0010350772610539013, acc: 0.8880104581673307, lr: 0.0037377077865181603
[batch_idx--300] train_loss: 0.001031351765189196, acc: 0.8886264534883721, lr: 0.003707232212251013
[batch_idx--350] train_loss: 0.0010314680441240237, acc: 0.888733084045584, lr: 0.003676871436447249
[batch_idx--400] train_loss: 0.0010339521831702766, acc: 0.8884624376558603, lr: 0.0036466256227948553
[batch_idx--450] train_loss: 0.0010344084798017206, acc: 0.8884732877425626, lr: 0.003616494934362016
total time of one epoch: 396.15014004707336 s
train_loss:  0.0010344084798017206  acc:  0.8884732877425626
->>lr:0.003616
test_loss:  0.0011161300041107847  test_acc:  0.8824916242710014
best acc:  88.68345948628863

------Epoch: 124------
[batch_idx--0] train_loss: 0.0012190070701763034, acc: 0.859375, lr: 0.003615893495987335
[batch_idx--50] train_loss: 0.0010183598862175702, acc: 0.8890165441176471, lr: 0.003585880402627581
[batch_idx--100] train_loss: 0.0010461284863153971, acc: 0.885674504950495, lr: 0.0035559827619909834
[batch_idx--150] train_loss: 0.0010398345045739205, acc: 0.8854511589403974, lr: 0.0035262007352685563
[batch_idx--200] train_loss: 0.00104028997573288, acc: 0.8856498756218906, lr: 0.003496534483028016
[batch_idx--250] train_loss: 0.0010372078745622202, acc: 0.8855671065737052, lr: 0.0034669841652128805
[batch_idx--300] train_loss: 0.0010355941253556464, acc: 0.8862645348837209, lr: 0.00343754994114161
[batch_idx--350] train_loss: 0.0010332673827207453, acc: 0.8866964921652422, lr: 0.0034082319695067616
[batch_idx--400] train_loss: 0.0010316165203595549, acc: 0.8868843516209476, lr: 0.003379030408374123
[batch_idx--450] train_loss: 0.0010388405620431057, acc: 0.8868070260700525, lr: 0.00334994541518186
total time of one epoch: 397.1965842247009 s
train_loss:  0.0010388405620431057  acc:  0.8868070260700525
->>lr:0.003350
test_loss:  0.0011156451662918936  test_acc:  0.8826157091450553
best acc:  88.68345948628863

------Epoch: 125------
[batch_idx--0] train_loss: 0.0009596433374099433, acc: 0.8828125, lr: 0.003349364905389038
[batch_idx--50] train_loss: 0.0010307229913807676, acc: 0.8893229166666666, lr: 0.003320398973036992
[batch_idx--100] train_loss: 0.0010410089876807045, acc: 0.8877243193069307, lr: 0.0032915499247325843
[batch_idx--150] train_loss: 0.0010338705692236737, acc: 0.8887882864238411, lr: 0.003262817916013447
[batch_idx--200] train_loss: 0.0010263428424452594, acc: 0.8892646144278606, lr: 0.0032342031017861847
[batch_idx--250] train_loss: 0.001023728001363709, acc: 0.8895356075697212, lr: 0.003205705636325565
[batch_idx--300] train_loss: 0.0010270631786643146, acc: 0.8890028031561462, lr: 0.0031773256732736594
[batch_idx--350] train_loss: 0.0010309372798067403, acc: 0.8890892094017094, lr: 0.0031490633656390573
[batch_idx--400] train_loss: 0.0010341687384584077, acc: 0.8886767456359103, lr: 0.0031209188657960046
[batch_idx--450] train_loss: 0.0010342730596088943, acc: 0.8887336411288923, lr: 0.0030928923254835983
total time of one epoch: 393.0953152179718 s
train_loss:  0.0010342730596088943  acc:  0.8887336411288923
->>lr:0.003093
test_loss:  0.001112804071958551  test_acc:  0.8852214915001861
best acc:  88.68345948628863

------Epoch: 126------
[batch_idx--0] train_loss: 0.0009911293163895607, acc: 0.89453125, lr: 0.0030923329989034107
[batch_idx--50] train_loss: 0.0010036761283545809, acc: 0.8931525735294118, lr: 0.003064426932974329
[batch_idx--100] train_loss: 0.0010064444729440505, acc: 0.8920173267326733, lr: 0.003036639131148192
[batch_idx--150] train_loss: 0.0010124452015853778, acc: 0.8910647764900662, lr: 0.003008969743240972
[batch_idx--200] train_loss: 0.0010182744781695196, acc: 0.8899836753731343, lr: 0.002981418918430234
[batch_idx--250] train_loss: 0.0010201508490984659, acc: 0.889660109561753, lr: 0.002953986805254319
[batch_idx--300] train_loss: 0.0010202239571909645, acc: 0.8890417358803987, lr: 0.002926673551611542
[batch_idx--350] train_loss: 0.0010189704500481042, acc: 0.8892784009971509, lr: 0.002899479304759398
[batch_idx--400] train_loss: 0.0010178166036923738, acc: 0.8893586346633416, lr: 0.0028724042113137424
[batch_idx--450] train_loss: 0.0010214067575779015, acc: 0.8895841288575693, lr: 0.002845448417248059
total time of one epoch: 391.16052198410034 s
train_loss:  0.0010214067575779015  acc:  0.8895841288575693
->>lr:0.002845
test_loss:  0.0011071154820237123  test_acc:  0.8846010671299168
best acc:  88.68345948628863

------Epoch: 127------
[batch_idx--0] train_loss: 0.0009372138883918524, acc: 0.89453125, lr: 0.0028449105192196373
[batch_idx--50] train_loss: 0.0010300068077448681, acc: 0.8880974264705882, lr: 0.0028180765602363435
[batch_idx--100] train_loss: 0.0010203398812543786, acc: 0.8885365099009901, lr: 0.0027913621935367313
[batch_idx--150] train_loss: 0.0010189204014196302, acc: 0.8893574089403974, lr: 0.002764767563149445
[batch_idx--200] train_loss: 0.0010184868660509884, acc: 0.8888176305970149, lr: 0.002738292812457563
[batch_idx--250] train_loss: 0.0010244696358389469, acc: 0.8880571464143426, lr: 0.00271193808419784
[batch_idx--300] train_loss: 0.0010196570366190938, acc: 0.889171511627907, lr: 0.002685703520459948
[batch_idx--350] train_loss: 0.0010229966086149746, acc: 0.8890780804843305, lr: 0.0026595892626856965
[batch_idx--400] train_loss: 0.0010255073556302585, acc: 0.8888520885286783, lr: 0.0026335954516682747
[batch_idx--450] train_loss: 0.0010291002822697389, acc: 0.8888204255910022, lr: 0.0026077222275514957
total time of one epoch: 390.28585720062256 s
train_loss:  0.0010291002822697389  acc:  0.8888204255910022
->>lr:0.002608
test_loss:  0.0011025655726697755  test_acc:  0.8839806427596476
best acc:  88.68345948628863

------Epoch: 128------
[batch_idx--0] train_loss: 0.001042619813233614, acc: 0.890625, lr: 0.0026072059940146775
[batch_idx--50] train_loss: 0.0010322706406369951, acc: 0.8892463235294118, lr: 0.002581455912238459
[batch_idx--100] train_loss: 0.0010234580956178137, acc: 0.8891166460396039, lr: 0.0025558266984695406
[batch_idx--150] train_loss: 0.0010145512923740146, acc: 0.890676738410596, lr: 0.002530318490886033
[batch_idx--200] train_loss: 0.0010185252489355295, acc: 0.8908193407960199, lr: 0.0025049314270136516
[batch_idx--250] train_loss: 0.0010175820207223296, acc: 0.8908895667330677, lr: 0.0024796656437249655
[batch_idx--300] train_loss: 0.001021077991594743, acc: 0.8901967400332226, lr: 0.0024545212772386807
[batch_idx--350] train_loss: 0.001025461957112029, acc: 0.8893563034188035, lr: 0.0024294984631188735
[batch_idx--400] train_loss: 0.0010241477679405501, acc: 0.8898749220698254, lr: 0.0024045973362742893
[batch_idx--450] train_loss: 0.0010269892714589448, acc: 0.8901395494150727, lr: 0.0023798180309576172
total time of one epoch: 392.8575258255005 s
train_loss:  0.0010269892714589448  acc:  0.8901395494150727
->>lr:0.002380
test_loss:  0.001105918781398499  test_acc:  0.8875791041072093
best acc:  88.68345948628863
Saving..

------Epoch: 129------
[batch_idx--0] train_loss: 0.0009376436937600374, acc: 0.890625, lr: 0.0023793236883495163
[batch_idx--50] train_loss: 0.0010072237871331618, acc: 0.8891697303921569, lr: 0.002354668778617275
[batch_idx--100] train_loss: 0.0010171828717731013, acc: 0.889426051980198, lr: 0.0023301359595992556
[batch_idx--150] train_loss: 0.0010138172694845805, acc: 0.8895643625827815, lr: 0.0023057253635624278
[batch_idx--200] train_loss: 0.0010123078500509114, acc: 0.8897699004975125, lr: 0.0022814371221148186
[batch_idx--250] train_loss: 0.0010070148039149098, acc: 0.8909051294820717, lr: 0.0022572713662047635
[batch_idx--300] train_loss: 0.001012366574081249, acc: 0.8901967400332226, lr: 0.0022332282261202457
[batch_idx--350] train_loss: 0.0010171093217805666, acc: 0.8896345263532763, lr: 0.0022093078314881667
[batch_idx--400] train_loss: 0.0010201705895780012, acc: 0.8893294108478803, lr: 0.002185510311273653
[batch_idx--450] train_loss: 0.0010232864944216121, acc: 0.8893237754712396, lr: 0.0021618357937793764
total time of one epoch: 386.8917489051819 s
train_loss:  0.0010232864944216121  acc:  0.8893237754712396
->>lr:0.002162
test_loss:  0.0010970427112346223  test_acc:  0.8853455763742399
best acc:  88.75791041072094

------Epoch: 130------
[batch_idx--0] train_loss: 0.0009738910594023764, acc: 0.88671875, lr: 0.0021613635589349755
[batch_idx--50] train_loss: 0.0009916525028244244, acc: 0.8924632352941176, lr: 0.0021378146357049848
[batch_idx--100] train_loss: 0.0009975944683739528, acc: 0.8919012995049505, lr: 0.0021143889723431067
[batch_idx--150] train_loss: 0.0010016258842225451, acc: 0.8917115066225165, lr: 0.0020910866951471623
[batch_idx--200] train_loss: 0.0010068824512429943, acc: 0.8911497201492538, lr: 0.0020679079297497515
[batch_idx--250] train_loss: 0.0010136406914149207, acc: 0.8903448705179283, lr: 0.0020448528011175527
[batch_idx--300] train_loss: 0.0010109724263440928, acc: 0.8906898878737541, lr: 0.0020219214335506857
[batch_idx--350] train_loss: 0.0010135445333858076, acc: 0.8904691951566952, lr: 0.0019991139506819965
[batch_idx--400] train_loss: 0.0010119406217558222, acc: 0.8904691396508728, lr: 0.001976430475476429
[batch_idx--450] train_loss: 0.0010168629882702474, acc: 0.8902176554309716, lr: 0.0019538711302303584
total time of one epoch: 383.60429763793945 s
train_loss:  0.0010168629882702474  acc:  0.8902176554309716
->>lr:0.001954
test_loss:  0.0011050263425525504  test_acc:  0.8858419158704554
best acc:  88.75791041072094

------Epoch: 131------
[batch_idx--0] train_loss: 0.00094285246450454, acc: 0.890625, lr: 0.00195342121028749
[batch_idx--50] train_loss: 0.0010068604161086328, acc: 0.8884803921568627, lr: 0.001930988602895767
[batch_idx--100] train_loss: 0.0010053638667375366, acc: 0.8907023514851485, lr: 0.001908680370460203
[batch_idx--150] train_loss: 0.0010179759794229407, acc: 0.8908578228476821, lr: 0.0018864966332540673
[batch_idx--200] train_loss: 0.0010118142962895927, acc: 0.890663868159204, lr: 0.0018644375108794243
[batch_idx--250] train_loss: 0.0010132617328735254, acc: 0.8910451942231076, lr: 0.0018425031222664813
[batch_idx--300] train_loss: 0.0010124596229915282, acc: 0.8910921926910299, lr: 0.0018206935856729584
[batch_idx--350] train_loss: 0.001010363632640629, acc: 0.8912148326210826, lr: 0.0017990090186834396
[batch_idx--400] train_loss: 0.0010073038903552752, acc: 0.8914530081047382, lr: 0.0017774495382087503
[batch_idx--450] train_loss: 0.001010281034363559, acc: 0.8912503905300795, lr: 0.001756015260485311
total time of one epoch: 386.76402521133423 s
train_loss:  0.001010281034363559  acc:  0.8912503905300795
->>lr:0.001756
test_loss:  0.0011064784060726837  test_acc:  0.8849733217520784
best acc:  88.75791041072094

------Epoch: 132------
[batch_idx--0] train_loss: 0.0008269648533314466, acc: 0.91015625, lr: 0.0017555878527937164
[batch_idx--50] train_loss: 0.0010158544253357047, acc: 0.8880208333333334, lr: 0.0017342814009232738
[batch_idx--100] train_loss: 0.0009856750021024728, acc: 0.8932936262376238, lr: 0.0017131003845420657
[batch_idx--150] train_loss: 0.0009973792147989207, acc: 0.8924358443708609, lr: 0.0016920449178460556
[batch_idx--200] train_loss: 0.0009996858833760801, acc: 0.8922185945273632, lr: 0.0016711151143543159
[batch_idx--250] train_loss: 0.001002741396191541, acc: 0.8920256474103586, lr: 0.0016503110869084154
[batch_idx--300] train_loss: 0.0010026258385919678, acc: 0.8918189368770764, lr: 0.0016296329476718054
[batch_idx--350] train_loss: 0.0010040582146394754, acc: 0.8919382122507122, lr: 0.0016090808081292208
[batch_idx--400] train_loss: 0.0010072125191335796, acc: 0.8914335255610972, lr: 0.0015886547790860768
[batch_idx--450] train_loss: 0.0010111877587973216, acc: 0.8909900371437498, lr: 0.0015683549706678873
total time of one epoch: 393.69466948509216 s
train_loss:  0.0010111877587973216  acc:  0.8909900371437498
->>lr:0.001568
test_loss:  0.0011038086704705486  test_acc:  0.886214170492617
best acc:  88.75791041072094

------Epoch: 133------
[batch_idx--0] train_loss: 0.0011071683838963509, acc: 0.87109375, lr: 0.0015679502627027138
[batch_idx--50] train_loss: 0.0009892715036175122, acc: 0.8907015931372549, lr: 0.0015477793120675237
[batch_idx--100] train_loss: 0.0009980943234923231, acc: 0.8911664603960396, lr: 0.0015277348024344995
[batch_idx--150] train_loss: 0.0009970701614160412, acc: 0.8919184602649006, lr: 0.001507816841872195
[batch_idx--200] train_loss: 0.0009972655280395897, acc: 0.8920436878109452, lr: 0.0014880255377669072
[batch_idx--250] train_loss: 0.000998915575697009, acc: 0.8916988296812749, lr: 0.0014683609968220602
[batch_idx--300] train_loss: 0.00100342304066003, acc: 0.8913257890365448, lr: 0.0014488233250576467
[batch_idx--350] train_loss: 0.0010096573919599128, acc: 0.8906695156695157, lr: 0.0014294126278096538
[batch_idx--400] train_loss: 0.0010077087609259936, acc: 0.8908490492518704, lr: 0.0014101290097294967
[batch_idx--450] train_loss: 0.0010108808389486183, acc: 0.8907123268649981, lr: 0.0013909725747834447
total time of one epoch: 393.06017875671387 s
train_loss:  0.0010108808389486183  acc:  0.8907123268649981
->>lr:0.001391
test_loss:  0.0011011256552878584  test_acc:  0.8858419158704554
best acc:  88.75791041072094

------Epoch: 134------
[batch_idx--0] train_loss: 0.0010664197616279125, acc: 0.87890625, lr: 0.001390590744062975
[batch_idx--50] train_loss: 0.0009954860491002454, acc: 0.8918504901960784, lr: 0.0013715641423086456
[batch_idx--100] train_loss: 0.0009876575273701387, acc: 0.8937964108910891, lr: 0.0013526649316081968
[batch_idx--150] train_loss: 0.0010018495955374956, acc: 0.8922030215231788, lr: 0.0013338932138554
[batch_idx--200] train_loss: 0.0010016188048641776, acc: 0.8920825559701493, lr: 0.0013152490902566538
[batch_idx--250] train_loss: 0.0009993796832340053, acc: 0.8922590886454184, lr: 0.0012967326613304436
[batch_idx--300] train_loss: 0.0010013942633046958, acc: 0.8918708471760798, lr: 0.0012783440269067943
[batch_idx--350] train_loss: 0.001000249650902473, acc: 0.8922164351851852, lr: 0.0012600832861267342
[batch_idx--400] train_loss: 0.000999538010471684, acc: 0.8921348971321695, lr: 0.0012419505374417718
[batch_idx--450] train_loss: 0.0010036940159397752, acc: 0.8919359877807478, lr: 0.0012239458786133446
total time of one epoch: 392.77393341064453 s
train_loss:  0.0010036940159397752  acc:  0.8919359877807478
->>lr:0.001224
test_loss:  0.0011041743877523071  test_acc:  0.8867105099888324
best acc:  88.75791041072094

------Epoch: 135------
[batch_idx--0] train_loss: 0.0009945856872946024, acc: 0.890625, lr: 0.0012235870926211618
[batch_idx--50] train_loss: 0.0010219061468709626, acc: 0.8925398284313726, lr: 0.0012057131854440546
[batch_idx--100] train_loss: 0.0010232661786203337, acc: 0.8914758663366337, lr: 0.0011879675634946297
[batch_idx--150] train_loss: 0.0010129751649913408, acc: 0.8924875827814569, lr: 0.0011703503224471529
[batch_idx--200] train_loss: 0.001012933262118801, acc: 0.8913634950248757, lr: 0.001152861557283752
[batch_idx--250] train_loss: 0.0010143321103034206, acc: 0.8910451942231076, lr: 0.0011355013622938726
[batch_idx--300] train_loss: 0.0010134708358708188, acc: 0.8912479235880398, lr: 0.0011182698310737928
[batch_idx--350] train_loss: 0.0010088485064637712, acc: 0.8919382122507122, lr: 0.0011011670565261005
[batch_idx--400] train_loss: 0.0010106015199693175, acc: 0.8915309382793017, lr: 0.0010841931308592041
[batch_idx--450] train_loss: 0.0010124714592801547, acc: 0.8912677474225015, lr: 0.00106734814558683
total time of one epoch: 391.32353591918945 s
train_loss:  0.0010124714592801547  acc:  0.8912677474225015
->>lr:0.001067
test_loss:  0.0010993370056181927  test_acc:  0.8859660007445093
best acc:  88.75791041072094

------Epoch: 136------
[batch_idx--0] train_loss: 0.0010433995630592108, acc: 0.875, lr: 0.001067012561698319
[batch_idx--50] train_loss: 0.000987985051538357, acc: 0.8929993872549019, lr: 0.0010502991891848613
[batch_idx--100] train_loss: 0.000995256351929453, acc: 0.8921333539603961, lr: 0.0010337149398027378
[batch_idx--150] train_loss: 0.000991024975495302, acc: 0.8920736754966887, lr: 0.001017259902964765
[batch_idx--200] train_loss: 0.0010026213869369074, acc: 0.8908970771144279, lr: 0.0010009341673871241
[batch_idx--250] train_loss: 0.0009961538091005082, acc: 0.8922902141434262, lr: 0.000984737821088863
[batch_idx--300] train_loss: 0.0009948861910157104, acc: 0.8922212416943521, lr: 0.000968670951391451
[batch_idx--350] train_loss: 0.0009968175713312506, acc: 0.8919159544159544, lr: 0.0009527336449182884
[batch_idx--400] train_loss: 0.00099673129672166, acc: 0.8918913653366584, lr: 0.0009369259875942449
[batch_idx--450] train_loss: 0.0009990961053240083, acc: 0.8924827298920401, lr: 0.0009212480646451971
total time of one epoch: 393.2289209365845 s
train_loss:  0.0009990961053240083  acc:  0.8924827298920401
->>lr:0.000921
test_loss:  0.0011032431123274137  test_acc:  0.8860900856185631
best acc:  88.75791041072094

------Epoch: 137------
[batch_idx--0] train_loss: 0.001058458350598812, acc: 0.890625, lr: 0.0009209358300585474
[batch_idx--50] train_loss: 0.001021158459194589, acc: 0.8872549019607843, lr: 0.0009053903232463079
[batch_idx--100] train_loss: 0.0010070404450473662, acc: 0.8914371905940595, lr: 0.0008899747208313852
[batch_idx--150] train_loss: 0.001001643003828034, acc: 0.8930308360927153, lr: 0.0008746891059259105
[batch_idx--200] train_loss: 0.0010047505218164986, acc: 0.8920631218905473, lr: 0.0008595335609412142
[batch_idx--250] train_loss: 0.0010043791589416208, acc: 0.8921657121513944, lr: 0.0008445081675873518
[batch_idx--300] train_loss: 0.0010061591186412175, acc: 0.8922082641196013, lr: 0.0008296130068726787
[batch_idx--350] train_loss: 0.001004273934220826, acc: 0.8923944978632479, lr: 0.0008148481591034013
[batch_idx--400] train_loss: 0.0010031644426787881, acc: 0.8926122194513716, lr: 0.0008002137038831625
[batch_idx--450] train_loss: 0.001008558565239973, acc: 0.8925348005693061, lr: 0.000785709720112604
total time of one epoch: 392.3588788509369 s
train_loss:  0.001008558565239973  acc:  0.8925348005693061
->>lr:0.000786
test_loss:  0.0010990806072783952  test_acc:  0.8867105099888324
best acc:  88.75791041072094

------Epoch: 138------
[batch_idx--0] train_loss: 0.0009747635340318084, acc: 0.8984375, lr: 0.0007854209717842232
[batch_idx--50] train_loss: 0.0009737665029973083, acc: 0.8955269607843137, lr: 0.0007710501494462701
[batch_idx--100] train_loss: 0.000996640176249502, acc: 0.8926748143564357, lr: 0.0007568099557912517
[batch_idx--150] train_loss: 0.0009958584139906858, acc: 0.8937034354304636, lr: 0.000742700467594179
[batch_idx--200] train_loss: 0.0009977531437507243, acc: 0.8937150186567164, lr: 0.0007287217609253605
[batch_idx--250] train_loss: 0.0010028761079668464, acc: 0.8928037848605578, lr: 0.0007148739111500131
[batch_idx--300] train_loss: 0.0010023353603185832, acc: 0.8925067483388704, lr: 0.0007011569929278511
[batch_idx--350] train_loss: 0.0009996674026553638, acc: 0.8926727207977208, lr: 0.0006875710802126706
[batch_idx--400] train_loss: 0.0009994253703739095, acc: 0.8926122194513716, lr: 0.0006741162462519713
[batch_idx--450] train_loss: 0.0010008995513726155, acc: 0.8923785885375083, lr: 0.0006607925635865458
total time of one epoch: 391.9888381958008 s
train_loss:  0.0010008995513726155  acc:  0.8923785885375083
->>lr:0.000661
test_loss:  0.001098505156938662  test_acc:  0.8870827646109939
best acc:  88.75791041072094

------Epoch: 139------
[batch_idx--0] train_loss: 0.0009454793180339038, acc: 0.8828125, lr: 0.0006605274281709927
[batch_idx--50] train_loss: 0.0009975260244591126, acc: 0.8911611519607843, lr: 0.0006473375938249676
[batch_idx--100] train_loss: 0.001002790036929384, acc: 0.8901995668316832, lr: 0.0006342790551494393
[batch_idx--150] train_loss: 0.0009987300357454463, acc: 0.8913234685430463, lr: 0.0006213518825486042
[batch_idx--200] train_loss: 0.0009954616433792557, acc: 0.8914606654228856, lr: 0.0006085561457184031
[batch_idx--250] train_loss: 0.0009933111909034835, acc: 0.8923213396414342, lr: 0.0005958919136461599
[batch_idx--300] train_loss: 0.0009978768354640699, acc: 0.8915204526578073, lr: 0.000583359254610194
[batch_idx--350] train_loss: 0.0009941748849864509, acc: 0.8923833689458689, lr: 0.0005709582361794502
[batch_idx--400] train_loss: 0.0009985743665329163, acc: 0.8919985193266833, lr: 0.0005586889252131494
[batch_idx--450] train_loss: 0.0009997572070799454, acc: 0.8919880584580137, lr: 0.0005465513878604278
total time of one epoch: 397.43382573127747 s
train_loss:  0.0009997572070799454  acc:  0.8919880584580137
->>lr:0.000547
test_loss:  0.0010984615240311234  test_acc:  0.8869586797369401
best acc:  88.75791041072094

------Epoch: 140------
[batch_idx--0] train_loss: 0.001103457878343761, acc: 0.8671875, lr: 0.0005463099816548578
[batch_idx--50] train_loss: 0.0009846641675240414, acc: 0.8916973039215687, lr: 0.0005343069207980278
[batch_idx--100] train_loss: 0.0010014310407701252, acc: 0.8912824876237624, lr: 0.0005224357650086414
[batch_idx--150] train_loss: 0.000992728653209691, acc: 0.8925393211920529, lr: 0.0005106965782891965
[batch_idx--200] train_loss: 0.0009922181083519587, acc: 0.8929959577114428, lr: 0.0004990894239306987
[batch_idx--250] train_loss: 0.000996056413073909, acc: 0.8929438496015937, lr: 0.0004876143645123038
[batch_idx--300] train_loss: 0.0009964227498867905, acc: 0.8925456810631229, lr: 0.00047627146190098725
[batch_idx--350] train_loss: 0.0009949592262522406, acc: 0.8926504629629629, lr: 0.00046506077725121944
[batch_idx--400] train_loss: 0.0009954038794335917, acc: 0.8927680798004988, lr: 0.00045398237100461594
[batch_idx--450] train_loss: 0.000999217138657009, acc: 0.892682334154893, lr: 0.0004430363028896239
total time of one epoch: 399.76452469825745 s
train_loss:  0.000999217138657009  acc:  0.892682334154893
->>lr:0.000443
test_loss:  0.0011012052458677802  test_acc:  0.8855937461223476
best acc:  88.75791041072094

------Epoch: 141------
[batch_idx--0] train_loss: 0.0009573359275236726, acc: 0.91015625, lr: 0.00044281873178278475
[batch_idx--50] train_loss: 0.0009978670129260304, acc: 0.8911611519607843, lr: 0.0004320077093543484
[batch_idx--100] train_loss: 0.0010168529334616395, acc: 0.8898514851485149, lr: 0.0004213291435323757
[batch_idx--150] train_loss: 0.0010070487997951047, acc: 0.8904956539735099, lr: 0.0004107830918895994
[batch_idx--200] train_loss: 0.00099841746807432, acc: 0.8921602922885572, lr: 0.00040036961128431806
[batch_idx--250] train_loss: 0.001005389891607516, acc: 0.890687250996016, lr: 0.00039008875786008537
[batch_idx--300] train_loss: 0.0010043087870229123, acc: 0.8912089908637874, lr: 0.00037994058704539927
[batch_idx--350] train_loss: 0.0010025933760674697, acc: 0.8917712784900285, lr: 0.0003699251535534104
[batch_idx--400] train_loss: 0.0010000855414872697, acc: 0.8923297225685786, lr: 0.0003600425113816253
[batch_idx--450] train_loss: 0.001003777433759523, acc: 0.8920140937966466, lr: 0.0003502927138116147
total time of one epoch: 393.3350155353546 s
train_loss:  0.001003777433759523  acc:  0.8920140937966466
->>lr:0.000350
test_loss:  0.0010993946521627442  test_acc:  0.8860900856185631
best acc:  88.75791041072094

------Epoch: 142------
[batch_idx--0] train_loss: 0.0009273486211895943, acc: 0.89453125, lr: 0.00035009907323737546
[batch_idx--50] train_loss: 0.0010180970409647654, acc: 0.8890165441176471, lr: 0.00034048483130907914
[batch_idx--100] train_loss: 0.00101954613796131, acc: 0.8885751856435643, lr: 0.00033100353942642217
[batch_idx--150] train_loss: 0.0010066675396161215, acc: 0.8911941225165563, lr: 0.0003216552487071145
[batch_idx--200] train_loss: 0.0010032912389611574, acc: 0.8916161380597015, lr: 0.00031244000955181765
[batch_idx--250] train_loss: 0.000999939796307024, acc: 0.8921812749003984, lr: 0.00030335787164384453
[batch_idx--300] train_loss: 0.0010035787262347375, acc: 0.8919227574750831, lr: 0.00029440888394890454
[batch_idx--350] train_loss: 0.0009992972282995272, acc: 0.8920272435897436, lr: 0.00028559309471483943
[batch_idx--400] train_loss: 0.000999831751585843, acc: 0.8920374844139651, lr: 0.00027691055147135437
[batch_idx--450] train_loss: 0.0010028003616405344, acc: 0.8921442704898115, lr: 0.0002683613010297709
total time of one epoch: 397.04156708717346 s
train_loss:  0.0010028003616405344  acc:  0.8921442704898115
->>lr:0.000268
test_loss:  0.0010991181162690862  test_acc:  0.8858419158704554
best acc:  88.75791041072094

------Epoch: 143------
[batch_idx--0] train_loss: 0.0009598222095519304, acc: 0.8984375, lr: 0.0002681916759252945
[batch_idx--50] train_loss: 0.0010126907065711624, acc: 0.8904718137254902, lr: 0.00025977843162139916
[batch_idx--100] train_loss: 0.0010088281365950582, acc: 0.8907797029702971, lr: 0.0002514985724860308
[batch_idx--150] train_loss: 0.0010126591841258504, acc: 0.8909095612582781, lr: 0.00024335214315946986
[batch_idx--200] train_loss: 0.0010077210695746896, acc: 0.8909165111940298, lr: 0.00023533918756261376
[batch_idx--250] train_loss: 0.0010008447770162882, acc: 0.8928971613545816, lr: 0.00022745974889675503
[batch_idx--300] train_loss: 0.000995844100954698, acc: 0.8932075373754153, lr: 0.0002197138696433315
[batch_idx--350] train_loss: 0.0009966641448921076, acc: 0.8932180377492878, lr: 0.0002121015915637098
[batch_idx--400] train_loss: 0.0009957233343988732, acc: 0.8932454021197007, lr: 0.0002046229556989493
[batch_idx--450] train_loss: 0.0010002319323307697, acc: 0.8929166522025896, lr: 0.00019727800236959416
total time of one epoch: 386.77464723587036 s
train_loss:  0.0010002319323307697  acc:  0.8929166522025896
->>lr:0.000197
test_loss:  0.0011005677816249223  test_acc:  0.8850974066261322
best acc:  88.75791041072094

------Epoch: 144------
[batch_idx--0] train_loss: 0.0010368542280048132, acc: 0.88671875, lr: 0.0001971324671380531
[batch_idx--50] train_loss: 0.0010213633490196777, acc: 0.887484681372549, lr: 0.00018992391078557493
[batch_idx--100] train_loss: 0.0010032710091367658, acc: 0.8899288366336634, lr: 0.00018284911621737067
[batch_idx--150] train_loss: 0.0010008339412411712, acc: 0.8902628311258278, lr: 0.00017590812157669555
[batch_idx--200] train_loss: 0.0009980479962498282, acc: 0.8909165111940298, lr: 0.00016910096428543743
[batch_idx--250] train_loss: 0.0009970457401623823, acc: 0.8912630727091634, lr: 0.00016242768104390848
[batch_idx--300] train_loss: 0.000997974680995018, acc: 0.891468542358804, lr: 0.00015588830783064834
[batch_idx--350] train_loss: 0.0009964905945223325, acc: 0.891838051994302, lr: 0.0001494828799022241
[batch_idx--400] train_loss: 0.0009985662855386752, acc: 0.891949812967581, lr: 0.00014321143179305552
[batch_idx--450] train_loss: 0.0009996946993546024, acc: 0.8920401291352796, lr: 0.00013707399731520964
total time of one epoch: 395.67054533958435 s
train_loss:  0.0009996946993546024  acc:  0.8920401291352796
->>lr:0.000137
test_loss:  0.001099696177409118  test_acc:  0.8850974066261322
best acc:  88.75791041072094

------Epoch: 145------
[batch_idx--0] train_loss: 0.0010821549221873283, acc: 0.87890625, lr: 0.00013695261579316776
[batch_idx--50] train_loss: 0.0009923448464285362, acc: 0.8933823529411765, lr: 0.0001309519093031647
[batch_idx--100] train_loss: 0.0009916317758685218, acc: 0.8938737623762376, lr: 0.0001250852825408405
[batch_idx--150] train_loss: 0.0009979076798394668, acc: 0.8928238824503312, lr: 0.0001193527671357053
[batch_idx--200] train_loss: 0.0009967118049323076, acc: 0.8930348258706468, lr: 0.00011375439399421428
[batch_idx--250] train_loss: 0.0009970070313721658, acc: 0.8928349103585658, lr: 0.00010829019329959833
[batch_idx--300] train_loss: 0.0009993910012098394, acc: 0.8926105689368771, lr: 0.00010296019451171701
[batch_idx--350] train_loss: 0.0010020601764809541, acc: 0.8923833689458689, lr: 9.776442636688366e-05
[batch_idx--400] train_loss: 0.0010014328753756838, acc: 0.8924466178304239, lr: 9.270291687771548e-05
[batch_idx--450] train_loss: 0.001001120898043033, acc: 0.8929513659874336, lr: 8.77756933329893e-05
total time of one epoch: 424.03565073013306 s
train_loss:  0.001001120898043033  acc:  0.8929513659874336
->>lr:0.000088
test_loss:  0.0010998362176307956  test_acc:  0.8853455763742399
best acc:  88.75791041072094

------Epoch: 146------
[batch_idx--0] train_loss: 0.0009767466690391302, acc: 0.89453125, lr: 8.767851876239075e-05
[batch_idx--50] train_loss: 0.0009777254571079039, acc: 0.8947610294117647, lr: 8.288829424305533e-05
[batch_idx--100] train_loss: 0.0009800892935300448, acc: 0.8940671410891089, lr: 7.82324085830094e-05
[batch_idx--150] train_loss: 0.0009858074566404897, acc: 0.8936775662251656, lr: 7.371088688413186e-05
[batch_idx--200] train_loss: 0.000983618057057243, acc: 0.8935401119402985, lr: 6.93237535238922e-05
[batch_idx--250] train_loss: 0.0009874934620461408, acc: 0.8933173555776892, lr: 6.507103215520893e-05
[batch_idx--300] train_loss: 0.000996812514379076, acc: 0.8914944975083057, lr: 6.09527457063358e-05
[batch_idx--350] train_loss: 0.000999914499316789, acc: 0.8911814458689459, lr: 5.6968916380720215e-05
[batch_idx--400] train_loss: 0.000999309512306971, acc: 0.8912874064837906, lr: 5.311956565690057e-05
[batch_idx--450] train_loss: 0.001000848016746092, acc: 0.8915975283785191, lr: 4.9404714288381335e-05
total time of one epoch: 435.60195755958557 s
train_loss:  0.001000848016746092  acc:  0.8915975283785191
->>lr:0.000049
test_loss:  0.001100933173481148  test_acc:  0.8855937461223476
best acc:  88.75791041072094

------Epoch: 147------
[batch_idx--0] train_loss: 0.0010543417884036899, acc: 0.87109375, lr: 4.933178929321103e-05
[batch_idx--50] train_loss: 0.0009653004966037092, acc: 0.8944546568627451, lr: 4.57541478953355e-05
[batch_idx--100] train_loss: 0.0009698071753338791, acc: 0.8944152227722773, lr: 4.231104556289278e-05
[batch_idx--150] train_loss: 0.000994264106158266, acc: 0.8913493377483444, lr: 3.9002500859128264e-05
[batch_idx--200] train_loss: 0.000988706154343371, acc: 0.8922963308457711, lr: 3.582853162182598e-05
[batch_idx--250] train_loss: 0.0009910605856647855, acc: 0.8921657121513944, lr: 3.2789154963222546e-05
[batch_idx--300] train_loss: 0.0009906032862160292, acc: 0.8921303986710963, lr: 2.9884387269901725e-05
[batch_idx--350] train_loss: 0.0009916493366671423, acc: 0.8922164351851852, lr: 2.7114244202716688e-05
[batch_idx--400] train_loss: 0.0009940689462446086, acc: 0.8918913653366584, lr: 2.4478740696695647e-05
[batch_idx--450] train_loss: 0.0009979884923445868, acc: 0.8918578817648488, lr: 2.1977890960975244e-05
total time of one epoch: 426.41800236701965 s
train_loss:  0.0009979884923445868  acc:  0.8918578817648488
->>lr:0.000022
test_loss:  0.001099764195043524  test_acc:  0.8852214915001861
best acc:  88.75791041072094

------Epoch: 148------
[batch_idx--0] train_loss: 0.0009355779620818794, acc: 0.88671875, lr: 2.192924752854042e-05
[batch_idx--50] train_loss: 0.0009709840478357292, acc: 0.8968290441176471, lr: 1.9565758523884538e-05
[batch_idx--100] train_loss: 0.0009835507031437931, acc: 0.8939897896039604, lr: 1.7336949777524425e-05
[batch_idx--150] train_loss: 0.0009901740862710388, acc: 0.8931860513245033, lr: 1.524283330592846e-05
[batch_idx--200] train_loss: 0.0009921641133619073, acc: 0.892587842039801, lr: 1.3283420399376467e-05
[batch_idx--250] train_loss: 0.0009958355265958939, acc: 0.8928349103585658, lr: 1.14587216219042e-05
[batch_idx--300] train_loss: 0.0009932899178528656, acc: 0.8931296719269103, lr: 9.768746811253394e-06
[batch_idx--350] train_loss: 0.0009895220274195881, acc: 0.8935630341880342, lr: 8.213505078799587e-06
[batch_idx--400] train_loss: 0.0009903882181926855, acc: 0.8936253117206983, lr: 6.793004809518832e-06
[batch_idx--450] train_loss: 0.0009926131321232052, acc: 0.8936196063456798, lr: 5.507253661940492e-06
total time of one epoch: 428.96344780921936 s
train_loss:  0.0009926131321232052  acc:  0.8936196063456798
->>lr:0.000006
test_loss:  0.0010995788541084514  test_acc:  0.8852214915001861
best acc:  88.75791041072094

------Epoch: 149------
[batch_idx--0] train_loss: 0.0012012748047709465, acc: 0.859375, lr: 5.482913128862511e-06
[batch_idx--50] train_loss: 0.0009897154625779128, acc: 0.8934589460784313, lr: 4.334613221818051e-06
[batch_idx--100] train_loss: 0.0009778951361572536, acc: 0.8954594678217822, lr: 3.321075690718156e-06
[batch_idx--150] train_loss: 0.0009878571303283783, acc: 0.8935482201986755, lr: 2.4423059999861833e-06
[batch_idx--200] train_loss: 0.0009907046631233423, acc: 0.8933652052238806, lr: 1.6983088874406029e-06
[batch_idx--250] train_loss: 0.0009899938384449458, acc: 0.8933951693227091, lr: 1.089088364294999e-06
[batch_idx--300] train_loss: 0.0009946035719368346, acc: 0.893077761627907, lr: 6.146477151164343e-07
[batch_idx--350] train_loss: 0.0009943940131155577, acc: 0.8930956196581197, lr: 2.749894978198997e-07
[batch_idx--400] train_loss: 0.0009949254227669775, acc: 0.8931479894014963, lr: 7.011554364610984e-08
[batch_idx--450] train_loss: 0.0009953810907073985, acc: 0.8931249349116535, lr: 2.6957161503027296e-11
total time of one epoch: 435.966046333313 s
train_loss:  0.0009953810907073985  acc:  0.8931249349116535
->>lr:0.000000
test_loss:  0.0011018045391748288  test_acc:  0.8850974066261322
best acc:  88.75791041072094