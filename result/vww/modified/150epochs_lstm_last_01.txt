Model: mobilenet_lstm_last
Batch size: 256
Number of dataloader workers: 32

loading annotations into memory...
Done (t=2.59s)
creating index...
index created!
Len of trainloader: 451

loading annotations into memory...
Done (t=0.22s)
creating index...
index created!
Len of testloader: 32

use 4 GPUs!
DataParallel device_ids: [0, 1, 2, 3]

------Epoch: 0------
[batch_idx--0] train_loss: 0.0027120604645460844, acc: 0.46875, lr: 0.05
[batch_idx--50] train_loss: 0.0028984762052548865, acc: 0.5018382352941176, lr: 0.04999993260712715
[batch_idx--100] train_loss: 0.002824811398577277, acc: 0.5330677599009901, lr: 0.04999973042887193
[batch_idx--150] train_loss: 0.002740001535684561, acc: 0.5610254552980133, lr: 0.049999393466324364
[batch_idx--200] train_loss: 0.0026844295554919475, acc: 0.580146144278607, lr: 0.04999892172130118
[batch_idx--250] train_loss: 0.002638160848463199, acc: 0.5948238296812749, lr: 0.04999831519634575
[batch_idx--300] train_loss: 0.0026082709877197924, acc: 0.604547342192691, lr: 0.0499975738947281
[batch_idx--350] train_loss: 0.0025830781093912672, acc: 0.6127915776353277, lr: 0.04999669782044491
[batch_idx--400] train_loss: 0.002560857839027694, acc: 0.6197884195760599, lr: 0.049995686978219496
[batch_idx--450] train_loss: 0.0025421091074017744, acc: 0.6265577810948728, lr: 0.04999454137350172
total time of one epoch: 243.613831281662 s
train_loss:  0.0025421091074017744  acc:  0.6265577810948728
->>lr:0.049995
test_loss:  0.0036725713325384047  test_acc:  0.5284774785953592
best acc:  0
Saving..
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(

------Epoch: 1------
[batch_idx--0] train_loss: 0.0021910034120082855, acc: 0.71484375, lr: 0.04999451708687114
[batch_idx--50] train_loss: 0.002291875051371023, acc: 0.6915594362745098, lr: 0.04999323403077913
[batch_idx--100] train_loss: 0.002264793782430415, acc: 0.6976330445544554, lr: 0.04999181622541965
[batch_idx--150] train_loss: 0.002246622459512722, acc: 0.7024265314569537, lr: 0.0499902636784367
[batch_idx--200] train_loss: 0.002233088866168105, acc: 0.7049906716417911, lr: 0.04998857639820074
[batch_idx--250] train_loss: 0.0022163528256096037, acc: 0.7087898406374502, lr: 0.04998675439380862
[batch_idx--300] train_loss: 0.0022097936776494516, acc: 0.7099641818936877, lr: 0.04998479767508354
[batch_idx--350] train_loss: 0.0021996053553947864, acc: 0.7117610398860399, lr: 0.04998270625257502
[batch_idx--400] train_loss: 0.002193691502754899, acc: 0.713236440149626, lr: 0.04998048013755882
[batch_idx--450] train_loss: 0.0021873793428661002, acc: 0.7148870066303329, lr: 0.049978119342036866
total time of one epoch: 202.06059765815735 s
train_loss:  0.0021873793428661002  acc:  0.7148870066303329
->>lr:0.049978
test_loss:  0.002205646615685741  test_acc:  0.7179550812755925
best acc:  52.84774785953592
Saving..

------Epoch: 2------
[batch_idx--0] train_loss: 0.001963350921869278, acc: 0.7734375, lr: 0.04997807075247146
[batch_idx--50] train_loss: 0.0020559683611032133, acc: 0.7388174019607843, lr: 0.04997557259595109
[batch_idx--100] train_loss: 0.0020448559593169552, acc: 0.7400603341584159, lr: 0.04997293978538365
[batch_idx--150] train_loss: 0.0020533142740906075, acc: 0.7388503725165563, lr: 0.04997017233496374
[batch_idx--200] train_loss: 0.0020440612387940733, acc: 0.7396222014925373, lr: 0.04996727025961189
[batch_idx--250] train_loss: 0.0020409620031194976, acc: 0.7399931523904383, lr: 0.04996423357497442
[batch_idx--300] train_loss: 0.002032488070511912, acc: 0.7421226121262459, lr: 0.04996106229742341
[batch_idx--350] train_loss: 0.002028657061756294, acc: 0.7419983084045584, lr: 0.04995775644405658
[batch_idx--400] train_loss: 0.0020214247196782705, acc: 0.7432395573566085, lr: 0.049954316032697205
[batch_idx--450] train_loss: 0.002013969916212657, acc: 0.745547957093762, lr: 0.049950741081894026
total time of one epoch: 200.2861831188202 s
train_loss:  0.002013969916212657  acc:  0.745547957093762
->>lr:0.049951
test_loss:  0.002823864567559386  test_acc:  0.6954957190718452
best acc:  71.79550812755924

------Epoch: 3------
[batch_idx--0] train_loss: 0.0016931118443608284, acc: 0.7890625, lr: 0.04995066821070679
[batch_idx--50] train_loss: 0.001964667990036747, acc: 0.7522212009803921, lr: 0.04994695604953209
[batch_idx--100] train_loss: 0.0019664481906958, acc: 0.7541383044554455, lr: 0.0499431093885944
[batch_idx--150] train_loss: 0.001965738402753575, acc: 0.7545788493377483, lr: 0.04993912824863275
[batch_idx--200] train_loss: 0.001960339775281166, acc: 0.7547419154228856, lr: 0.049935012651111166
[batch_idx--250] train_loss: 0.001964234061487227, acc: 0.7546221364541833, lr: 0.0499307626182186
[batch_idx--300] train_loss: 0.001955115034452259, acc: 0.7562292358803987, lr: 0.0499263781728688
[batch_idx--350] train_loss: 0.0019527621307885248, acc: 0.7561431623931624, lr: 0.04992185933870021
[batch_idx--400] train_loss: 0.00194688727341806, acc: 0.7574325903990025, lr: 0.049917206140075804
[batch_idx--450] train_loss: 0.0019452499026131902, acc: 0.7583139514701288, lr: 0.04991241860208297
total time of one epoch: 199.06046557426453 s
train_loss:  0.0019452499026131902  acc:  0.7583139514701288
->>lr:0.049912
test_loss:  0.002370193243795921  test_acc:  0.7052984241220995
best acc:  71.79550812755924

------Epoch: 4------
[batch_idx--0] train_loss: 0.0017339434707537293, acc: 0.80859375, lr: 0.049912321481237615
[batch_idx--50] train_loss: 0.0018854198484298062, acc: 0.7712162990196079, lr: 0.04990739694368515
[batch_idx--100] train_loss: 0.001879259902467527, acc: 0.7704594678217822, lr: 0.04990233811964985
[batch_idx--150] train_loss: 0.001877792043124159, acc: 0.7702297185430463, lr: 0.049897145036406014
[batch_idx--200] train_loss: 0.001880317582952702, acc: 0.7692397388059702, lr: 0.04989181772195179
[batch_idx--250] train_loss: 0.001876694477716112, acc: 0.7701537599601593, lr: 0.04988635620500901
[batch_idx--300] train_loss: 0.0018736627254560838, acc: 0.7702579941860465, lr: 0.049880760515023076
[batch_idx--350] train_loss: 0.0018671064938092206, acc: 0.7709891381766382, lr: 0.04987503068216274
[batch_idx--400] train_loss: 0.001864374583607953, acc: 0.7713820916458853, lr: 0.04986916673732
[batch_idx--450] train_loss: 0.0018668692202988826, acc: 0.7717742215433748, lr: 0.049863168712109905
total time of one epoch: 197.64296674728394 s
train_loss:  0.0018668692202988826  acc:  0.7717742215433748
->>lr:0.049863
test_loss:  0.0018223090316184566  test_acc:  0.7829755552798114
best acc:  71.79550812755924
Saving..

------Epoch: 5------
[batch_idx--0] train_loss: 0.0017589145572856069, acc: 0.78515625, lr: 0.049863047384206834
[batch_idx--50] train_loss: 0.0018320979194386916, acc: 0.7760416666666666, lr: 0.04985691263034154
[batch_idx--100] train_loss: 0.0018195822099592574, acc: 0.7794709158415841, lr: 0.049850643862176046
[batch_idx--150] train_loss: 0.001816051349888821, acc: 0.7806550082781457, lr: 0.04984424111350797
[batch_idx--200] train_loss: 0.0018161138900745642, acc: 0.7804337686567164, lr: 0.0498377044188573
[batch_idx--250] train_loss: 0.0018182029197200303, acc: 0.7803940488047809, lr: 0.04983103381346615
[batch_idx--300] train_loss: 0.001812937646637055, acc: 0.7810942691029901, lr: 0.049824229333298636
[batch_idx--350] train_loss: 0.0018110971329362263, acc: 0.7812277421652422, lr: 0.049817291015040614
[batch_idx--400] train_loss: 0.001808586686575539, acc: 0.781551979426434, lr: 0.04981021889609956
[batch_idx--450] train_loss: 0.0018088628027822067, acc: 0.7817804700246468, lr: 0.0498030130146043
total time of one epoch: 199.65725374221802 s
train_loss:  0.0018088628027822067  acc:  0.7817804700246468
->>lr:0.049803
test_loss:  0.0017821103212392305  test_acc:  0.7947636183149274
best acc:  78.29755552798115
Saving..

------Epoch: 6------
[batch_idx--0] train_loss: 0.0016845643986016512, acc: 0.81640625, lr: 0.04980286753286195
[batch_idx--50] train_loss: 0.0018188980334967958, acc: 0.7771139705882353, lr: 0.04979552525358963
[batch_idx--100] train_loss: 0.0018047377891322173, acc: 0.7805538366336634, lr: 0.04978804929098283
[batch_idx--150] train_loss: 0.001794756172742966, acc: 0.7826986754966887, lr: 0.049780439685347705
[batch_idx--200] train_loss: 0.0017972901041865051, acc: 0.7819301927860697, lr: 0.0497726964777109
[batch_idx--250] train_loss: 0.0017847466153608435, acc: 0.7839734810756972, lr: 0.049764819709819365
[batch_idx--300] train_loss: 0.0017780846199856148, acc: 0.7847020348837209, lr: 0.04975680942414015
[batch_idx--350] train_loss: 0.0017757643398263643, acc: 0.7852452813390314, lr: 0.04974866566386016
[batch_idx--400] train_loss: 0.0017721962597118945, acc: 0.7856238310473815, lr: 0.049740388472885894
[batch_idx--450] train_loss: 0.0017751683562670189, acc: 0.7865449369944805, lr: 0.04973197789584324
total time of one epoch: 197.12228679656982 s
train_loss:  0.0017751683562670189  acc:  0.7865449369944805
->>lr:0.049732
test_loss:  0.0018649419878505125  test_acc:  0.7705670678744261
best acc:  79.47636183149274

------Epoch: 7------
[batch_idx--0] train_loss: 0.0016393231926485896, acc: 0.8203125, lr: 0.049731808324074714
[batch_idx--50] train_loss: 0.0017768857799762604, acc: 0.7840073529411765, lr: 0.04972326173996171
[batch_idx--100] train_loss: 0.0017531015956313302, acc: 0.7909576113861386, lr: 0.049714581862117906
[batch_idx--150] train_loss: 0.0017351549610631256, acc: 0.7931498344370861, lr: 0.049705768737340256
[batch_idx--200] train_loss: 0.0017365490304148612, acc: 0.7926578047263682, lr: 0.04969682241314409
[batch_idx--250] train_loss: 0.0017321770709282551, acc: 0.7937313247011952, lr: 0.0496877429377629
[batch_idx--300] train_loss: 0.0017307604503728129, acc: 0.7936435838870431, lr: 0.04967853036014805
[batch_idx--350] train_loss: 0.0017257410017348974, acc: 0.7942485754985755, lr: 0.04966918472996849
[batch_idx--400] train_loss: 0.0017243263574707277, acc: 0.7942351153366584, lr: 0.04965970609761053
[batch_idx--450] train_loss: 0.001727356690490954, acc: 0.7943468601381609, lr: 0.04965009451417756
total time of one epoch: 200.6461901664734 s
train_loss:  0.001727356690490954  acc:  0.7943468601381609
->>lr:0.049650
test_loss:  0.0017553633452201396  test_acc:  0.7902965628489887
best acc:  79.47636183149274

------Epoch: 8------
[batch_idx--0] train_loss: 0.0017008589347824454, acc: 0.78125, lr: 0.04964990092676263
[batch_idx--50] train_loss: 0.0017365016289712751, acc: 0.7885263480392157, lr: 0.0496401537866232
[batch_idx--100] train_loss: 0.0017182897824775613, acc: 0.79296875, lr: 0.04963027380082368
[batch_idx--150] train_loss: 0.0016996974914969987, acc: 0.7974441225165563, lr: 0.04962026102263131
[batch_idx--200] train_loss: 0.0017015453090946844, acc: 0.7971665111940298, lr: 0.04961011550602926
[batch_idx--250] train_loss: 0.001694814166132049, acc: 0.797902141434263, lr: 0.04959983730571641
[batch_idx--300] train_loss: 0.0016932650376420679, acc: 0.7983674210963455, lr: 0.04958942647710693
[batch_idx--350] train_loss: 0.0016930210417364737, acc: 0.7988003027065527, lr: 0.04957888307633007
[batch_idx--400] train_loss: 0.0016932068799071925, acc: 0.7988232543640897, lr: 0.04956820716022985
[batch_idx--450] train_loss: 0.0016953539639037887, acc: 0.7990071857534627, lr: 0.049557398786364705
total time of one epoch: 196.36067175865173 s
train_loss:  0.0016953539639037887  acc:  0.7990071857534627
->>lr:0.049557
test_loss:  0.0016533371931507506  test_acc:  0.810274227571659
best acc:  79.47636183149274
Saving..

------Epoch: 9------
[batch_idx--0] train_loss: 0.001634916290640831, acc: 0.80859375, lr: 0.049557181268217225
[batch_idx--50] train_loss: 0.0016902252397153015, acc: 0.8029258578431373, lr: 0.04954623784746919
[batch_idx--100] train_loss: 0.0016605993813493907, acc: 0.8046488242574258, lr: 0.04953516208740226
[batch_idx--150] train_loss: 0.0016635398369664882, acc: 0.8029801324503312, lr: 0.049523954047730606
[batch_idx--200] train_loss: 0.0016693642423187027, acc: 0.8017335199004975, lr: 0.04951261378888158
[batch_idx--250] train_loss: 0.001673587609965547, acc: 0.8009057519920318, lr: 0.049501141371995405
[batch_idx--300] train_loss: 0.001665255005325986, acc: 0.8025721553156147, lr: 0.0494895368589248
[batch_idx--350] train_loss: 0.001666553517501069, acc: 0.8025952635327636, lr: 0.0494778003122347
[batch_idx--400] train_loss: 0.0016671391906555825, acc: 0.80230088840399, lr: 0.049465931795201847
[batch_idx--450] train_loss: 0.0016690694225278472, acc: 0.8026347762696567, lr: 0.049453931371814544
total time of one epoch: 199.1605453491211 s
train_loss:  0.0016690694225278472  acc:  0.8026347762696567
->>lr:0.049454
test_loss:  0.0018471800107964216  test_acc:  0.7835959796500807
best acc:  81.02742275716591

------Epoch: 10------
[batch_idx--0] train_loss: 0.0014540888369083405, acc: 0.81640625, lr: 0.049453690018345146
[batch_idx--50] train_loss: 0.0016776887590394301, acc: 0.801547181372549, lr: 0.04944155511713453
[batch_idx--100] train_loss: 0.001643140562856109, acc: 0.8070467202970297, lr: 0.04942928844099462
[batch_idx--150] train_loss: 0.001641238159160839, acc: 0.8070157284768212, lr: 0.0494168900560603
[batch_idx--200] train_loss: 0.001637011124701494, acc: 0.8079329912935324, lr: 0.04940436002917662
[batch_idx--250] train_loss: 0.0016323401206785226, acc: 0.809652016932271, lr: 0.04939169842789834
[batch_idx--300] train_loss: 0.001629028509934108, acc: 0.8091128529900332, lr: 0.04937890532048959
[batch_idx--350] train_loss: 0.0016234109793097163, acc: 0.8094284188034188, lr: 0.04936598077592351
[batch_idx--400] train_loss: 0.0016253124086413895, acc: 0.8093243453865336, lr: 0.049352924863881875
[batch_idx--450] train_loss: 0.001629778707770657, acc: 0.8091522893741104, lr: 0.04933973765475472
total time of one epoch: 198.43222427368164 s
train_loss:  0.001629778707770657  acc:  0.8091522893741104
->>lr:0.049340
test_loss:  0.0016597922378740737  test_acc:  0.8115150763121975
best acc:  81.02742275716591
Saving..

------Epoch: 11------
[batch_idx--0] train_loss: 0.0013982047094032168, acc: 0.84765625, lr: 0.04933947257182901
[batch_idx--50] train_loss: 0.0016448546484039695, acc: 0.8079044117647058, lr: 0.04932615151292455
[batch_idx--100] train_loss: 0.0016407356839534817, acc: 0.8065052599009901, lr: 0.04931269930128121
[batch_idx--150] train_loss: 0.001631822743890992, acc: 0.808671357615894, lr: 0.04929911600942565
[batch_idx--200] train_loss: 0.001626678964873748, acc: 0.8091573383084577, lr: 0.04928540171059123
[batch_idx--250] train_loss: 0.0016257997335072058, acc: 0.8093407619521913, lr: 0.04927155647871764
[batch_idx--300] train_loss: 0.0016193967722541965, acc: 0.8105144310631229, lr: 0.04925758038845046
[batch_idx--350] train_loss: 0.0016164955174937802, acc: 0.8108084045584045, lr: 0.04924347351514081
[batch_idx--400] train_loss: 0.0016149555529209965, acc: 0.8108342425187033, lr: 0.049229235934844906
[batch_idx--450] train_loss: 0.0016188093284220325, acc: 0.8112351164647481, lr: 0.04921486772432365
total time of one epoch: 196.90026664733887 s
train_loss:  0.0016188093284220325  acc:  0.8112351164647481
->>lr:0.049215
test_loss:  0.0016349568927919677  test_acc:  0.8084129544608513
best acc:  81.15150763121976

------Epoch: 12------
[batch_idx--0] train_loss: 0.001676257699728012, acc: 0.81640625, lr: 0.04921457902821578
[batch_idx--50] train_loss: 0.0015902878036357317, acc: 0.8136488970588235, lr: 0.04920007765467417
[batch_idx--100] train_loss: 0.0016000313709702084, acc: 0.8140857054455446, lr: 0.049185445808112044
[batch_idx--150] train_loss: 0.0015917704517749564, acc: 0.8155008278145696, lr: 0.049170683567415975
[batch_idx--200] train_loss: 0.0015893440394759623, acc: 0.8159203980099502, lr: 0.04915579101217554
[batch_idx--250] train_loss: 0.001589566787363464, acc: 0.8153946713147411, lr: 0.04914076822268292
[batch_idx--300] train_loss: 0.0015817255859241583, acc: 0.8156275955149501, lr: 0.04912561527993242
[batch_idx--350] train_loss: 0.0015886312710821757, acc: 0.8138911146723646, lr: 0.049110332265620074
[batch_idx--400] train_loss: 0.0015879643716944609, acc: 0.8141170511221946, lr: 0.049094919262143176
[batch_idx--450] train_loss: 0.0015895553487994287, acc: 0.8148974207657861, lr: 0.049079376352599846
total time of one epoch: 194.94874691963196 s
train_loss:  0.0015895553487994287  acc:  0.8148974207657861
->>lr:0.049079
test_loss:  0.0016286200477994394  test_acc:  0.8152376225338132
best acc:  81.15150763121976
Saving..

------Epoch: 13------
[batch_idx--0] train_loss: 0.0015627406537532806, acc: 0.8125, lr: 0.049079064169941455
[batch_idx--50] train_loss: 0.0015767273954207114, acc: 0.8152573529411765, lr: 0.04906338884254441
[batch_idx--100] train_loss: 0.0015964766867495705, acc: 0.8125773514851485, lr: 0.04904758377907498
[batch_idx--150] train_loss: 0.0015768317601316615, acc: 0.8155266970198676, lr: 0.04903164906474507
[batch_idx--200] train_loss: 0.0015783116884010644, acc: 0.8152013370646766, lr: 0.04901558478546556
[batch_idx--250] train_loss: 0.0015749166417213906, acc: 0.8158926792828686, lr: 0.04899939102784589
[batch_idx--300] train_loss: 0.0015723856500167387, acc: 0.8162894518272426, lr: 0.04898306787919357
[batch_idx--350] train_loss: 0.0015715304155173337, acc: 0.8163951210826211, lr: 0.04896661542751371
[batch_idx--400] train_loss: 0.0015702135207716775, acc: 0.8163478023690773, lr: 0.04895003376150854
[batch_idx--450] train_loss: 0.001570780454181179, acc: 0.8170843892109557, lr: 0.04893332297057697
total time of one epoch: 200.62076711654663 s
train_loss:  0.001570780454181179  acc:  0.8170843892109557
->>lr:0.048933
test_loss:  0.0016092563817423854  test_acc:  0.8142449435413823
best acc:  81.5237622533813

------Epoch: 14------
[batch_idx--0] train_loss: 0.0014150171773508191, acc: 0.84765625, lr: 0.048932987438301684
[batch_idx--50] train_loss: 0.0015732121320587455, acc: 0.8201593137254902, lr: 0.04891614503276587
[batch_idx--100] train_loss: 0.0015536691949675136, acc: 0.8214340965346535, lr: 0.04889917368501234
[batch_idx--150] train_loss: 0.0015625290384528455, acc: 0.8188638245033113, lr: 0.04888207348654094
[batch_idx--200] train_loss: 0.0015602864050514886, acc: 0.8199238184079602, lr: 0.048864844529546175
[batch_idx--250] train_loss: 0.001557576676934542, acc: 0.8207015687250996, lr: 0.04884748690691675
[batch_idx--300] train_loss: 0.0015606458377761402, acc: 0.8193002491694352, lr: 0.048830000712235096
[batch_idx--350] train_loss: 0.001557938545276318, acc: 0.8196225071225072, lr: 0.048812386039776785
[batch_idx--400] train_loss: 0.0015561766179273849, acc: 0.8195331982543641, lr: 0.0487946429845101
[batch_idx--450] train_loss: 0.0015545169028433193, acc: 0.8201392022772243, lr: 0.048776771642095464
total time of one epoch: 197.74427485466003 s
train_loss:  0.0015545169028433193  acc:  0.8201392022772243
->>lr:0.048777
test_loss:  0.001471363746701288  test_acc:  0.8326095049013525
best acc:  81.5237622533813
Saving..

------Epoch: 15------
[batch_idx--0] train_loss: 0.0015535402344539762, acc: 0.796875, lr: 0.048776412907378844
[batch_idx--50] train_loss: 0.0015535416360031448, acc: 0.8194699754901961, lr: 0.04875841081133997
[batch_idx--100] train_loss: 0.001553414822878814, acc: 0.8179919554455446, lr: 0.04874028062349638
[batch_idx--150] train_loss: 0.0015480052517875041, acc: 0.8184757864238411, lr: 0.0487220224415957
[batch_idx--200] train_loss: 0.001547039699606338, acc: 0.8194574004975125, lr: 0.04870363636407563
[batch_idx--250] train_loss: 0.0015475170926164939, acc: 0.8195187998007968, lr: 0.04868512249006343
[batch_idx--300] train_loss: 0.0015427692262672407, acc: 0.8205720514950167, lr: 0.048666480919375345
[batch_idx--350] train_loss: 0.0015456350052601888, acc: 0.8203458867521367, lr: 0.0486477117525161
[batch_idx--400] train_loss: 0.001542760707215032, acc: 0.8206729270573566, lr: 0.04862881509067834
[batch_idx--450] train_loss: 0.001546964121757893, acc: 0.8210591175755892, lr: 0.04860979103574209
total time of one epoch: 198.15587067604065 s
train_loss:  0.001546964121757893  acc:  0.8210591175755892
->>lr:0.048610
test_loss:  0.001550634388947904  test_acc:  0.822930884725152
best acc:  83.26095049013526

------Epoch: 16------
[batch_idx--0] train_loss: 0.0015645779203623533, acc: 0.81640625, lr: 0.04860940925593703
[batch_idx--50] train_loss: 0.0015102197375038966, acc: 0.8253676470588235, lr: 0.048590255365709406
[batch_idx--100] train_loss: 0.0015110258833680413, acc: 0.8251856435643564, lr: 0.04857097429027534
[batch_idx--150] train_loss: 0.001507878087658361, acc: 0.8262106788079471, lr: 0.0485515661335874
[batch_idx--200] train_loss: 0.0015210872718749281, acc: 0.824393656716418, lr: 0.048532031000283304
[batch_idx--250] train_loss: 0.0015187675640751343, acc: 0.8245300049800797, lr: 0.048512368995685354
[batch_idx--300] train_loss: 0.0015121375611268503, acc: 0.825438642026578, lr: 0.04849258022579986
[batch_idx--350] train_loss: 0.0015146631689110712, acc: 0.825164707977208, lr: 0.04847266479731658
[batch_idx--400] train_loss: 0.001515080609145177, acc: 0.8255825280548629, lr: 0.048452622817608176
[batch_idx--450] train_loss: 0.0015148210033117952, acc: 0.8259711181310099, lr: 0.04843245439472954
total time of one epoch: 198.58501076698303 s
train_loss:  0.0015148210033117952  acc:  0.8259711181310099
->>lr:0.048432
test_loss:  0.0015624750043606549  test_acc:  0.8285147040575754
best acc:  83.26095049013526

------Epoch: 17------
[batch_idx--0] train_loss: 0.0015374384820461273, acc: 0.83203125, lr: 0.04843204973729729
[batch_idx--50] train_loss: 0.0014924091451308306, acc: 0.8277420343137255, lr: 0.048411752454410206
[batch_idx--100] train_loss: 0.001496289036061504, acc: 0.8285117574257426, lr: 0.0483913289487026
[batch_idx--150] train_loss: 0.0015047331076941842, acc: 0.8262882864238411, lr: 0.04837077933028638
[batch_idx--200] train_loss: 0.00150000203553754, acc: 0.8270561256218906, lr: 0.04835010370995336
[batch_idx--250] train_loss: 0.001503686885816969, acc: 0.8267243525896414, lr: 0.0483293021991747
[batch_idx--300] train_loss: 0.001502037415376855, acc: 0.8272684800664452, lr: 0.04830837491010029
[batch_idx--350] train_loss: 0.0015003668108525185, acc: 0.8273348468660968, lr: 0.04828732195555814
[batch_idx--400] train_loss: 0.0014999587944664638, acc: 0.8272288029925187, lr: 0.04826614344905377
[batch_idx--450] train_loss: 0.0015025288409731897, acc: 0.8274030617558232, lr: 0.04824483950476961
total time of one epoch: 199.59169054031372 s
train_loss:  0.0015025288409731897  acc:  0.8274030617558232
->>lr:0.048245
test_loss:  0.0014822440535543812  test_acc:  0.8385655788559374
best acc:  83.26095049013526
Saving..

------Epoch: 18------
[batch_idx--0] train_loss: 0.0013588403817266226, acc: 0.86328125, lr: 0.04824441214720629
[batch_idx--50] train_loss: 0.0014732303782640135, acc: 0.8314950980392157, lr: 0.04822298037471885
[batch_idx--100] train_loss: 0.0014637218889697354, acc: 0.8337329826732673, lr: 0.04820142339716232
[batch_idx--150] train_loss: 0.0014739363771918792, acc: 0.8312810430463576, lr: 0.04817974133075961
[batch_idx--200] train_loss: 0.0014738876827811794, acc: 0.8306319962686567, lr: 0.04815793429240808
[batch_idx--250] train_loss: 0.001475603896215469, acc: 0.8307862300796812, lr: 0.04813600239967885
[batch_idx--300] train_loss: 0.001477203094029174, acc: 0.8305388289036545, lr: 0.04811394577081616
[batch_idx--350] train_loss: 0.0014841217117150581, acc: 0.8295940170940171, lr: 0.04809176452473679
[batch_idx--400] train_loss: 0.001486182046480514, acc: 0.8292939526184538, lr: 0.048069458781029376
[batch_idx--450] train_loss: 0.0014888061282349778, acc: 0.829416461276773, lr: 0.048047028659953764
total time of one epoch: 199.26702904701233 s
train_loss:  0.0014888061282349778  acc:  0.829416461276773
->>lr:0.048047
test_loss:  0.001454585449676949  test_acc:  0.8378210696116144
best acc:  83.85655788559374

------Epoch: 19------
[batch_idx--0] train_loss: 0.0015826765447854996, acc: 0.8515625, lr: 0.04804657878971252
[batch_idx--50] train_loss: 0.0014765187641423122, acc: 0.8268995098039216, lr: 0.04802402192830846
[batch_idx--100] train_loss: 0.001475205955021821, acc: 0.8297493811881188, lr: 0.04800134093450581
[batch_idx--150] train_loss: 0.0014804534364294335, acc: 0.8299875827814569, lr: 0.04797853593058756
[batch_idx--200] train_loss: 0.0014784070900618214, acc: 0.8306125621890548, lr: 0.04795560703950527
[batch_idx--250] train_loss: 0.0014784760820490135, acc: 0.8301948456175299, lr: 0.047932554384878465
[batch_idx--300] train_loss: 0.0014805904275542775, acc: 0.829967815614618, lr: 0.0479093780909939
[batch_idx--350] train_loss: 0.001477415723184872, acc: 0.8306735220797721, lr: 0.047886078282804945
[batch_idx--400] train_loss: 0.0014711559289704052, acc: 0.8317000467581047, lr: 0.047862655085930884
[batch_idx--450] train_loss: 0.0014732512955627187, acc: 0.8318203908772174, lr: 0.04783910862665624
total time of one epoch: 198.49449968338013 s
train_loss:  0.0014732512955627187  acc:  0.8318203908772174
->>lr:0.047839
test_loss:  0.0014940024287577287  test_acc:  0.8322372502791909
best acc:  83.85655788559374

------Epoch: 20------
[batch_idx--0] train_loss: 0.00126453151460737, acc: 0.8671875, lr: 0.04783863644106502
[batch_idx--50] train_loss: 0.0014561202454691131, acc: 0.8321844362745098, lr: 0.047814964384929284
[batch_idx--100] train_loss: 0.0014447503432742145, acc: 0.834738551980198, lr: 0.047791169323514016
[batch_idx--150] train_loss: 0.0014510183195762386, acc: 0.8330401490066225, lr: 0.047767251385108636
[batch_idx--200] train_loss: 0.0014509507483890772, acc: 0.8343827736318408, lr: 0.04774321069866503
[batch_idx--250] train_loss: 0.0014519260419844334, acc: 0.8338209661354582, lr: 0.04771904739379687
[batch_idx--300] train_loss: 0.0014541601546362438, acc: 0.8336145141196013, lr: 0.0476947616007789
[batch_idx--350] train_loss: 0.001453433446506532, acc: 0.8338675213675214, lr: 0.0476703534505463
[batch_idx--400] train_loss: 0.001452841361963708, acc: 0.8337846789276808, lr: 0.047645823074693894
[batch_idx--450] train_loss: 0.0014550392822604858, acc: 0.8338164335057451, lr: 0.047621170605475466
total time of one epoch: 196.91320848464966 s
train_loss:  0.0014550392822604858  acc:  0.8338164335057451
->>lr:0.047621
test_loss:  0.001486659967096113  test_acc:  0.8264052611986599
best acc:  83.85655788559374

------Epoch: 21------
[batch_idx--0] train_loss: 0.0017857298953458667, acc: 0.796875, lr: 0.04762067631165049
[batch_idx--50] train_loss: 0.0014563799155510816, acc: 0.8338694852941176, lr: 0.047595899444129244
[batch_idx--100] train_loss: 0.0014617575694447255, acc: 0.8326500618811881, lr: 0.04757100075240174
[batch_idx--150] train_loss: 0.0014527088473705167, acc: 0.8342560016556292, lr: 0.04754598037070751
[batch_idx--200] train_loss: 0.001446982199298357, acc: 0.8352184390547264, lr: 0.047520838433942204
[batch_idx--250] train_loss: 0.0014483978224183577, acc: 0.8344590388446215, lr: 0.04749557507765681
[batch_idx--300] train_loss: 0.0014476205076886174, acc: 0.8349901370431894, lr: 0.047470190438056926
[batch_idx--350] train_loss: 0.0014485805388274695, acc: 0.8347912215099715, lr: 0.047444684652002064
[batch_idx--400] train_loss: 0.0014501017035842127, acc: 0.8347685473815462, lr: 0.04741905785700488
[batch_idx--450] train_loss: 0.0014500531073466068, acc: 0.8346582427882112, lr: 0.04739331019123044
total time of one epoch: 199.63380360603333 s
train_loss:  0.0014500531073466068  acc:  0.8346582427882112
->>lr:0.047393
test_loss:  0.0014548688583359824  test_acc:  0.8379451544856682
best acc:  83.85655788559374

------Epoch: 22------
[batch_idx--0] train_loss: 0.0013839021557942033, acc: 0.8515625, lr: 0.047392794005985325
[batch_idx--50] train_loss: 0.0014458249628945602, acc: 0.8362438725490197, lr: 0.04736692319503155
[batch_idx--100] train_loss: 0.00144397418503419, acc: 0.8367883663366337, lr: 0.047340931794380904
[batch_idx--150] train_loss: 0.0014293252741794614, acc: 0.8375931291390728, lr: 0.04731481994416418
[batch_idx--200] train_loss: 0.0014236223158792625, acc: 0.8387748756218906, lr: 0.04728858778516159
[batch_idx--250] train_loss: 0.0014224132004405456, acc: 0.838785483067729, lr: 0.04726223545880198
[batch_idx--300] train_loss: 0.0014313041063124606, acc: 0.8374818313953488, lr: 0.04723576310716207
[batch_idx--350] train_loss: 0.0014326667238658353, acc: 0.8367944266381766, lr: 0.047209170872965694
[batch_idx--400] train_loss: 0.0014328705286258772, acc: 0.8366388715710723, lr: 0.047182458899583
[batch_idx--450] train_loss: 0.0014343566484662674, acc: 0.8368972819106467, lr: 0.04715562733102973
total time of one epoch: 199.29563927650452 s
train_loss:  0.0014343566484662674  acc:  0.8368972819106467
->>lr:0.047156
test_loss:  0.0014265429435170959  test_acc:  0.8445216528105224
best acc:  83.85655788559374
Saving..

------Epoch: 23------
[batch_idx--0] train_loss: 0.0012259511277079582, acc: 0.84765625, lr: 0.04715508948078037
[batch_idx--50] train_loss: 0.001476719811120454, acc: 0.8304227941176471, lr: 0.047128136074186804
[batch_idx--100] train_loss: 0.001448867352688593, acc: 0.8359375, lr: 0.04710106336530035
[batch_idx--150] train_loss: 0.0014314437863287449, acc: 0.8382139900662252, lr: 0.04707387150008163
[batch_idx--200] train_loss: 0.0014255549486457784, acc: 0.8388720460199005, lr: 0.04704656062513368
[batch_idx--250] train_loss: 0.001421575850076172, acc: 0.8385364790836654, lr: 0.04701913088770116
[batch_idx--300] train_loss: 0.00142098072548072, acc: 0.8388055440199336, lr: 0.04699158243566958
[batch_idx--350] train_loss: 0.0014213687512079026, acc: 0.8384303774928775, lr: 0.04696391541756448
[batch_idx--400] train_loss: 0.001423886813980497, acc: 0.8381585099750624, lr: 0.046936129982550645
[batch_idx--450] train_loss: 0.0014256661481795558, acc: 0.8382250841809282, lr: 0.0469082262804313
total time of one epoch: 198.3680500984192 s
train_loss:  0.0014256661481795558  acc:  0.8382250841809282
->>lr:0.046908
test_loss:  0.0014199784411761582  test_acc:  0.8452661620548455
best acc:  84.45216528105225
Saving..

------Epoch: 24------
[batch_idx--0] train_loss: 0.0015129935927689075, acc: 0.8203125, lr: 0.04690766700109659
[batch_idx--50] train_loss: 0.0013944036509914725, acc: 0.8423713235294118, lr: 0.04687964282151817
[batch_idx--100] train_loss: 0.0014080461471959358, acc: 0.8399984529702971, lr: 0.046851500679380806
[batch_idx--150] train_loss: 0.0014103095252251882, acc: 0.8418615480132451, lr: 0.046823240726410885
[batch_idx--200] train_loss: 0.0014093567562794582, acc: 0.8415345149253731, lr: 0.046794863114969956
[batch_idx--250] train_loss: 0.0014131898348000776, acc: 0.8403573207171314, lr: 0.04676636799805392
[batch_idx--300] train_loss: 0.0014125847890416154, acc: 0.8405704941860465, lr: 0.046737755529292206
[batch_idx--350] train_loss: 0.0014108923911262952, acc: 0.8408230947293447, lr: 0.046709025862946923
[batch_idx--400] train_loss: 0.0014108369458452833, acc: 0.8403697786783042, lr: 0.046680179153912066
[batch_idx--450] train_loss: 0.0014137937275294971, acc: 0.8408372964904364, lr: 0.04665121555771262
total time of one epoch: 200.2569591999054 s
train_loss:  0.0014137937275294971  acc:  0.8408372964904364
->>lr:0.046651
test_loss:  0.0016061149862064352  test_acc:  0.8167266410224594
best acc:  84.52661620548456

------Epoch: 25------
[batch_idx--0] train_loss: 0.0016088050324469805, acc: 0.828125, lr: 0.046650635094610975
[batch_idx--50] train_loss: 0.0014218460704546933, acc: 0.8399969362745098, lr: 0.04662155243437907
[batch_idx--100] train_loss: 0.0014163512012709191, acc: 0.8382580445544554, lr: 0.04659235320306443
[batch_idx--150] train_loss: 0.0014212709829976029, acc: 0.8380070364238411, lr: 0.046563037558092685
[batch_idx--200] train_loss: 0.0014133175651992287, acc: 0.839804881840796, lr: 0.04653360565751704
[batch_idx--250] train_loss: 0.0014176158525747251, acc: 0.8395324950199203, lr: 0.04650405766001754
[batch_idx--300] train_loss: 0.001420026920052041, acc: 0.8389612749169435, lr: 0.04647439372490014
[batch_idx--350] train_loss: 0.001420307374808757, acc: 0.8392761752136753, lr: 0.046444614012095875
[batch_idx--400] train_loss: 0.0014115563849860483, acc: 0.8406327930174564, lr: 0.046414718682159954
[batch_idx--450] train_loss: 0.0014169583734707223, acc: 0.8400909501162912, lr: 0.04638470789627097
total time of one epoch: 201.26253175735474 s
train_loss:  0.0014169583734707223  acc:  0.8400909501162912
->>lr:0.046385
test_loss:  0.0013519359228110724  test_acc:  0.848244199032138
best acc:  84.52661620548456
Saving..

------Epoch: 26------
[batch_idx--0] train_loss: 0.0016156022902578115, acc: 0.8203125, lr: 0.04638410650401267
[batch_idx--50] train_loss: 0.001421388498890926, acc: 0.8375459558823529, lr: 0.04635397811974326
[batch_idx--100] train_loss: 0.00142465894211932, acc: 0.8372524752475248, lr: 0.04632373460699926
[batch_idx--150] train_loss: 0.0014033009150120992, acc: 0.8415769867549668, lr: 0.04629337612883644
[batch_idx--200] train_loss: 0.0013923645251203531, acc: 0.8430503731343284, lr: 0.046262902848930414
[batch_idx--250] train_loss: 0.001396090131293819, acc: 0.8420069721115537, lr: 0.04623231493157573
[batch_idx--300] train_loss: 0.0013944530752069777, acc: 0.842296511627907, lr: 0.046201612541685
[batch_idx--350] train_loss: 0.001392000652995608, acc: 0.8425258190883191, lr: 0.046170795844788
[batch_idx--400] train_loss: 0.001387745431424618, acc: 0.8434285380299252, lr: 0.04613986500703078
[batch_idx--450] train_loss: 0.001390714534192157, acc: 0.8437272190786962, lr: 0.0461088201951748
total time of one epoch: 197.58512163162231 s
train_loss:  0.001390714534192157  acc:  0.8437272190786962
->>lr:0.046109
test_loss:  0.0015069594793275917  test_acc:  0.8314927410348678
best acc:  84.8244199032138

------Epoch: 27------
[batch_idx--0] train_loss: 0.0011925549479201436, acc: 0.86328125, lr: 0.04610819813755038
[batch_idx--50] train_loss: 0.0014391965506707922, acc: 0.8354779411764706, lr: 0.04607703724454855
[batch_idx--100] train_loss: 0.0014025340004280061, acc: 0.840153155940594, lr: 0.046045762716179425
[batch_idx--150] train_loss: 0.0013993377959207688, acc: 0.8403093956953642, lr: 0.04601437472105743
[batch_idx--200] train_loss: 0.0013923066116832382, acc: 0.8421758395522388, lr: 0.04598287342840873
[batch_idx--250] train_loss: 0.0013892938989581933, acc: 0.842785109561753, lr: 0.04595125900807036
[batch_idx--300] train_loss: 0.0013841450232950556, acc: 0.8437240448504983, lr: 0.045919531630489216
[batch_idx--350] train_loss: 0.001385132909521588, acc: 0.8434050035612536, lr: 0.045887691466721246
[batch_idx--400] train_loss: 0.0013795419557814364, acc: 0.8442078397755611, lr: 0.04585573868843045
[batch_idx--450] train_loss: 0.001385262438189248, acc: 0.8441611413892457, lr: 0.04582367346788801
total time of one epoch: 200.07561445236206 s
train_loss:  0.001385262438189248  acc:  0.8441611413892457
->>lr:0.045824
test_loss:  0.0013439782959516417  test_acc:  0.8533316788683459
best acc:  84.8244199032138
Saving..

------Epoch: 28------
[batch_idx--0] train_loss: 0.0014483715640380979, acc: 0.8203125, lr: 0.04582303101775249
[batch_idx--50] train_loss: 0.0013573303768484324, acc: 0.8465839460784313, lr: 0.04579085128421578
[batch_idx--100] train_loss: 0.0013599081972318857, acc: 0.8449876237623762, lr: 0.04575855945826332
[batch_idx--150] train_loss: 0.0013671710906821668, acc: 0.8448106374172185, lr: 0.04572615571399419
[batch_idx--200] train_loss: 0.0013736418230616632, acc: 0.8442552860696517, lr: 0.045693640226110915
[batch_idx--250] train_loss: 0.0013819335778039764, acc: 0.8430808017928287, lr: 0.045661013169918455
[batch_idx--300] train_loss: 0.001375470855783832, acc: 0.8442042151162791, lr: 0.04562827472132332
[batch_idx--350] train_loss: 0.0013715636231896714, acc: 0.8449741809116809, lr: 0.045595425056832534
[batch_idx--400] train_loss: 0.0013703901287019625, acc: 0.8452209320448878, lr: 0.04556246435355277
[batch_idx--450] train_loss: 0.001379442027660288, acc: 0.8446037421460062, lr: 0.04552939278918935
total time of one epoch: 200.1868805885315 s
train_loss:  0.001379442027660288  acc:  0.8446037421460062
->>lr:0.045529
test_loss:  0.0013329873481153598  test_acc:  0.8537039334905075
best acc:  85.3331678868346
Saving..

------Epoch: 29------
[batch_idx--0] train_loss: 0.0014024436241015792, acc: 0.828125, lr: 0.045528730228342605
[batch_idx--50] train_loss: 0.0014068932756416354, acc: 0.8421415441176471, lr: 0.04549554576936571
[batch_idx--100] train_loss: 0.0013857187027812446, acc: 0.8441754331683168, lr: 0.04546225081009201
[batch_idx--150] train_loss: 0.0013753366733697669, acc: 0.8450693294701986, lr: 0.04542884553002893
[batch_idx--200] train_loss: 0.0013643161738893731, acc: 0.8468400186567164, lr: 0.04539533010927871
[batch_idx--250] train_loss: 0.0013638812671990627, acc: 0.8472360557768924, lr: 0.04536170472853737
[batch_idx--300] train_loss: 0.0013711650413383678, acc: 0.8462676495016611, lr: 0.045327969569093796
[batch_idx--350] train_loss: 0.0013686268327709956, acc: 0.8459869123931624, lr: 0.04529412481282874
[batch_idx--400] train_loss: 0.0013676875548441882, acc: 0.8459320448877805, lr: 0.04526017064221382
[batch_idx--450] train_loss: 0.001371722367225569, acc: 0.8457319401534349, lr: 0.04522610724031057
total time of one epoch: 200.7113015651703 s
train_loss:  0.001371722367225569  acc:  0.8457319401534349
->>lr:0.045226
test_loss:  0.0013370792173336393  test_acc:  0.8556892914753692
best acc:  85.37039334905074
Saving..

------Epoch: 30------
[batch_idx--0] train_loss: 0.0013615274801850319, acc: 0.85546875, lr: 0.04522542485937369
[batch_idx--50] train_loss: 0.0013729671413517173, acc: 0.8466605392156863, lr: 0.04519125023075707
[batch_idx--100] train_loss: 0.001366313675990199, acc: 0.8467667079207921, lr: 0.045156966742431685
[batch_idx--150] train_loss: 0.0013576391020432017, acc: 0.847604511589404, lr: 0.04512257457923455
[batch_idx--200] train_loss: 0.0013592134873308612, acc: 0.8471315298507462, lr: 0.04508807392658861
[batch_idx--250] train_loss: 0.001358831330319399, acc: 0.8473449950199203, lr: 0.0450534649705017
[batch_idx--300] train_loss: 0.0013562164749359197, acc: 0.8476951827242525, lr: 0.04501874789756559
[batch_idx--350] train_loss: 0.0013567448540277608, acc: 0.847923344017094, lr: 0.04498392289495493
[batch_idx--400] train_loss: 0.001357459797473982, acc: 0.8475198721945137, lr: 0.04494899015042629
[batch_idx--450] train_loss: 0.0013577479169641204, acc: 0.8478581594751275, lr: 0.04491394985231711
total time of one epoch: 198.94212198257446 s
train_loss:  0.0013577479169641204  acc:  0.8478581594751275
->>lr:0.044914
test_loss:  0.0013035426794824388  test_acc:  0.8597840923191463
best acc:  85.56892914753692
Saving..

------Epoch: 31------
[batch_idx--0] train_loss: 0.0013741467846557498, acc: 0.83984375, lr: 0.04491324795060491
[batch_idx--50] train_loss: 0.001360176326296128, acc: 0.8455882352941176, lr: 0.04487809814247016
[batch_idx--100] train_loss: 0.0013520747802386263, acc: 0.8463412747524752, lr: 0.044842841162964144
[batch_idx--150] train_loss: 0.0013479694414927025, acc: 0.8478114652317881, lr: 0.04480747720217241
[batch_idx--200] train_loss: 0.0013518619420011505, acc: 0.8474424751243781, lr: 0.04477200645075726
[batch_idx--250] train_loss: 0.0013566396708889637, acc: 0.8475317480079682, lr: 0.04473642909995676
[batch_idx--300] train_loss: 0.00135678714168323, acc: 0.8476822051495017, lr: 0.044700745341583706
[batch_idx--350] train_loss: 0.0013528686509987715, acc: 0.8477007656695157, lr: 0.044664955368024575
[batch_idx--400] train_loss: 0.0013452178583494353, acc: 0.8485621882793017, lr: 0.044629059372238496
[batch_idx--450] train_loss: 0.0013526268864638457, acc: 0.8485871489568507, lr: 0.044593057547756214
total time of one epoch: 199.9940538406372 s
train_loss:  0.0013526268864638457  acc:  0.8485871489568507
->>lr:0.044593
test_loss:  0.0013733345708741727  test_acc:  0.8525871696240228
best acc:  85.97840923191463

------Epoch: 32------
[batch_idx--0] train_loss: 0.0015538143925368786, acc: 0.8203125, lr: 0.044592336433146
[batch_idx--50] train_loss: 0.0013709180239661067, acc: 0.8420649509803921, lr: 0.04455622686336067
[batch_idx--100] train_loss: 0.0013527374179794056, acc: 0.8470761138613861, lr: 0.0445200118575505
[batch_idx--150] train_loss: 0.0013456258518831027, acc: 0.8494412251655629, lr: 0.04448369161096615
[batch_idx--200] train_loss: 0.0013401156635398962, acc: 0.8505907960199005, lr: 0.044447266319425686
[batch_idx--250] train_loss: 0.0013393765571434423, acc: 0.8499284113545816, lr: 0.044410736179313494
[batch_idx--300] train_loss: 0.0013390319151927615, acc: 0.8498235049833887, lr: 0.04437410138757928
[batch_idx--350] train_loss: 0.0013390657113217604, acc: 0.849548165954416, lr: 0.04433736214173695
[batch_idx--400] train_loss: 0.0013343748480355614, acc: 0.8504617362842892, lr: 0.04430051863986356
[batch_idx--450] train_loss: 0.0013379228387375717, acc: 0.850105877043774, lr: 0.04426357108059828
total time of one epoch: 202.60212564468384 s
train_loss:  0.0013379228387375717  acc:  0.850105877043774
->>lr:0.044264
test_loss:  0.0012591397189845488  test_acc:  0.8627621292964388
best acc:  85.97840923191463
Saving..

------Epoch: 33------
[batch_idx--0] train_loss: 0.0013227557064965367, acc: 0.859375, lr: 0.044262831069394735
[batch_idx--50] train_loss: 0.0013412820042896212, acc: 0.8490349264705882, lr: 0.04422577757680957
[batch_idx--100] train_loss: 0.0013245852262998867, acc: 0.8521426361386139, lr: 0.04418862042979371
[batch_idx--150] train_loss: 0.0013261017519117192, acc: 0.8524679221854304, lr: 0.044151359828677295
[batch_idx--200] train_loss: 0.0013302906928352306, acc: 0.851601368159204, lr: 0.04411399597434825
[batch_idx--250] train_loss: 0.0013272495016425966, acc: 0.8512979332669323, lr: 0.04407652906825116
[batch_idx--300] train_loss: 0.0013214385533779612, acc: 0.8522632890365448, lr: 0.04403895931238623
[batch_idx--350] train_loss: 0.0013250621016458355, acc: 0.8518518518518519, lr: 0.044001286909308164
[batch_idx--400] train_loss: 0.0013298703165390434, acc: 0.8512897443890274, lr: 0.04396351206212508
[batch_idx--450] train_loss: 0.001332760405748618, acc: 0.850999757003506, lr: 0.043925634974497405
total time of one epoch: 200.51930856704712 s
train_loss:  0.001332760405748618  acc:  0.850999757003506
->>lr:0.043926
test_loss:  0.0013191256515440448  test_acc:  0.854076188112669
best acc:  86.27621292964388

------Epoch: 34------
[batch_idx--0] train_loss: 0.001279383315704763, acc: 0.859375, lr: 0.043924876391293916
[batch_idx--50] train_loss: 0.0013353924960920623, acc: 0.8499540441176471, lr: 0.0438868952287954
[batch_idx--100] train_loss: 0.0013285457055167396, acc: 0.8503248762376238, lr: 0.04384881223892658
[batch_idx--150] train_loss: 0.0013307684381794653, acc: 0.8507605546357616, lr: 0.04381062762700922
[batch_idx--200] train_loss: 0.0013287339836766767, acc: 0.8518345771144279, lr: 0.043772341598912995
[batch_idx--250] train_loss: 0.0013283621538356244, acc: 0.8523095119521913, lr: 0.04373395436105431
[batch_idx--300] train_loss: 0.0013308332644347287, acc: 0.8514197466777409, lr: 0.04369546612039528
[batch_idx--350] train_loss: 0.0013285948764904271, acc: 0.8517739494301995, lr: 0.04365687708444255
[batch_idx--400] train_loss: 0.0013251025299367465, acc: 0.8522541302992519, lr: 0.04361818746124621
[batch_idx--450] train_loss: 0.0013250943635269566, acc: 0.852830909154025, lr: 0.04357939745939863
total time of one epoch: 200.0000936985016 s
train_loss:  0.0013250943635269566  acc:  0.852830909154025
->>lr:0.043579
test_loss:  0.001293470417170744  test_acc:  0.8564338007196922
best acc:  86.27621292964388

------Epoch: 35------
[batch_idx--0] train_loss: 0.001292383298277855, acc: 0.87109375, lr: 0.04357862063693486
[batch_idx--50] train_loss: 0.001364663811674451, acc: 0.84765625, lr: 0.04353972846431615
[batch_idx--100] train_loss: 0.0013415269279336132, acc: 0.8509050123762376, lr: 0.043500736336052385
[batch_idx--150] train_loss: 0.001331173512615905, acc: 0.8524161837748344, lr: 0.04346164446236689
[batch_idx--200] train_loss: 0.0013302747248231772, acc: 0.8522232587064676, lr: 0.04342245305402075
[batch_idx--250] train_loss: 0.0013285290567664452, acc: 0.852558515936255, lr: 0.04338316232231171
[batch_idx--300] train_loss: 0.001325508417945318, acc: 0.8531457641196013, lr: 0.043343772479072985
[batch_idx--350] train_loss: 0.001326412086221164, acc: 0.852363782051282, lr: 0.043304283736672146
[batch_idx--400] train_loss: 0.001322596487786593, acc: 0.8530626558603491, lr: 0.04326469630800999
[batch_idx--450] train_loss: 0.001320390952591655, acc: 0.8538462873607109, lr: 0.04322501040651934
total time of one epoch: 202.32771015167236 s
train_loss:  0.001320390952591655  acc:  0.8538462873607109
->>lr:0.043225
test_loss:  0.0013502854514113134  test_acc:  0.8537039334905075
best acc:  86.27621292964388

------Epoch: 36------
[batch_idx--0] train_loss: 0.0012921405723318458, acc: 0.87109375, lr: 0.04322421568553529
[batch_idx--50] train_loss: 0.0013004922645860444, acc: 0.8570772058823529, lr: 0.04318442956218869
[batch_idx--100] train_loss: 0.0013034536542444683, acc: 0.8560102103960396, lr: 0.04314454539876614
[batch_idx--150] train_loss: 0.001295501404034825, acc: 0.8570985099337748, lr: 0.043104563410300306
[batch_idx--200] train_loss: 0.0013029222673185132, acc: 0.8565570584577115, lr: 0.043064483812351256
[batch_idx--250] train_loss: 0.0013021824944512066, acc: 0.8565114541832669, lr: 0.04302430682100536
[batch_idx--300] train_loss: 0.0013033543298395344, acc: 0.8558970099667774, lr: 0.042984032652874024
[batch_idx--350] train_loss: 0.001303027681986459, acc: 0.8559250356125356, lr: 0.04294366152509261
[batch_idx--400] train_loss: 0.0013042251273764395, acc: 0.8558194357855362, lr: 0.04290319365531922
[batch_idx--450] train_loss: 0.001307468242421097, acc: 0.8556774395112299, lr: 0.04286262926173353
total time of one epoch: 199.9130563735962 s
train_loss:  0.001307468242421097  acc:  0.8556774395112299
->>lr:0.042863
test_loss:  0.0012166822114909666  test_acc:  0.8708276461099392
best acc:  86.27621292964388
Saving..

------Epoch: 37------
[batch_idx--0] train_loss: 0.0012500889133661985, acc: 0.84765625, lr: 0.04286181699082009
[batch_idx--50] train_loss: 0.0012666668523760403, acc: 0.8591452205882353, lr: 0.04282115436825425
[batch_idx--100] train_loss: 0.001282294964334826, acc: 0.8576732673267327, lr: 0.04278039566418517
[batch_idx--150] train_loss: 0.0012943357775074165, acc: 0.8566846026490066, lr: 0.04273954109836054
[batch_idx--200] train_loss: 0.0012892631875276936, acc: 0.857314987562189, lr: 0.0426985908910449
[batch_idx--250] train_loss: 0.0012846386720578508, acc: 0.8574763446215139, lr: 0.042657545263018404
[batch_idx--300] train_loss: 0.001289751324601521, acc: 0.856468023255814, lr: 0.042616404435575676
[batch_idx--350] train_loss: 0.0012930706093629075, acc: 0.8558471331908832, lr: 0.04257516863052461
[batch_idx--400] train_loss: 0.0012911914324067403, acc: 0.8560824501246883, lr: 0.04253383807018514
[batch_idx--450] train_loss: 0.001294163980251276, acc: 0.8558249730968167, lr: 0.042492412977388094
total time of one epoch: 200.63129019737244 s
train_loss:  0.001294163980251276  acc:  0.8558249730968167
->>lr:0.042492
test_loss:  0.0012548960627922572  test_acc:  0.8664846755180543
best acc:  87.08276461099392

------Epoch: 38------
[batch_idx--0] train_loss: 0.0014446413842961192, acc: 0.8359375, lr: 0.042491583512834136
[batch_idx--50] train_loss: 0.0013168773342234392, acc: 0.8553921568627451, lr: 0.04245006222701923
[batch_idx--100] train_loss: 0.0013236568746212317, acc: 0.8531482054455446, lr: 0.04240844686041831
[batch_idx--150] train_loss: 0.0013028164930018714, acc: 0.8550548427152318, lr: 0.042366737637397726
[batch_idx--200] train_loss: 0.0013028152749771761, acc: 0.8551383706467661, lr: 0.04232493478282982
[batch_idx--250] train_loss: 0.0013005709597020895, acc: 0.8551730577689243, lr: 0.042283038522091754
[batch_idx--300] train_loss: 0.0013011114169422697, acc: 0.8547679609634552, lr: 0.04224104908106427
[batch_idx--350] train_loss: 0.0012968256849028765, acc: 0.8556134259259259, lr: 0.0421989666861305
[batch_idx--400] train_loss: 0.001294203161522096, acc: 0.856033743765586, lr: 0.04215679156417471
[batch_idx--450] train_loss: 0.0012964543160647914, acc: 0.8561287187142014, lr: 0.04211452394258114
total time of one epoch: 200.27899837493896 s
train_loss:  0.0012964543160647914  acc:  0.8561287187142014
->>lr:0.042115
test_loss:  0.0013070525343800645  test_acc:  0.8582950738305001
best acc:  87.08276461099392

------Epoch: 39------
[batch_idx--0] train_loss: 0.0013449762482196093, acc: 0.85546875, lr: 0.04211367764821722
[batch_idx--50] train_loss: 0.0012892073479152338, acc: 0.8550857843137255, lr: 0.04207131591176148
[batch_idx--100] train_loss: 0.0012982784151468463, acc: 0.8546565594059405, lr: 0.042028862136503926
[batch_idx--150] train_loss: 0.0013004126808211355, acc: 0.8542787665562914, lr: 0.0419863165513311
[batch_idx--200] train_loss: 0.0012943836659383011, acc: 0.8556630907960199, lr: 0.041943679385624544
[batch_idx--250] train_loss: 0.001289957198332921, acc: 0.8565737051792829, lr: 0.04190095086925955
[batch_idx--300] train_loss: 0.001294341841418655, acc: 0.8559489202657807, lr: 0.041858131232603915
[batch_idx--350] train_loss: 0.0012938199781061832, acc: 0.855735844017094, lr: 0.04181522070651669
[batch_idx--400] train_loss: 0.001292158662285795, acc: 0.8557609881546134, lr: 0.04177221952234698
[batch_idx--450] train_loss: 0.0012947185996397552, acc: 0.8559551497899816, lr: 0.041729127911932645
total time of one epoch: 197.98892402648926 s
train_loss:  0.0012947185996397552  acc:  0.8559551497899816
->>lr:0.041729
test_loss:  0.0012466221833320776  test_acc:  0.8635066385407619
best acc:  87.08276461099392

------Epoch: 40------
[batch_idx--0] train_loss: 0.0012998647289350629, acc: 0.84375, lr: 0.04172826515897146
[batch_idx--50] train_loss: 0.0012687012158315995, acc: 0.8567708333333334, lr: 0.04168508155313258
[batch_idx--100] train_loss: 0.0012823503613149248, acc: 0.8562422648514851, lr: 0.04164180799084732
[batch_idx--150] train_loss: 0.0012781796734070787, acc: 0.8573313327814569, lr: 0.04159844470542206
[batch_idx--200] train_loss: 0.0012765422348160094, acc: 0.8580729166666666, lr: 0.041554991930646906
[batch_idx--250] train_loss: 0.0012827225257197312, acc: 0.8572584661354582, lr: 0.041511449900794445
[batch_idx--300] train_loss: 0.0012761083983837864, acc: 0.8587131436877077, lr: 0.04146781885061848
[batch_idx--350] train_loss: 0.0012733903026972443, acc: 0.8590300035612536, lr: 0.04142409901535277
[batch_idx--400] train_loss: 0.001274457193958687, acc: 0.8586833697007481, lr: 0.04138029063070971
[batch_idx--450] train_loss: 0.0012765748971203463, acc: 0.8590186413024612, lr: 0.041336393932879134
total time of one epoch: 199.47221279144287 s
train_loss:  0.0012765748971203463  acc:  0.8590186413024612
->>lr:0.041336
test_loss:  0.001373367065353242  test_acc:  0.8496091326467303
best acc:  87.08276461099392

------Epoch: 41------
[batch_idx--0] train_loss: 0.0013246908783912659, acc: 0.83984375, lr: 0.04133551509975264
[batch_idx--50] train_loss: 0.0012837994373494795, acc: 0.8583792892156863, lr: 0.041291528566287365
[batch_idx--100] train_loss: 0.0012836642471132891, acc: 0.8582534034653465, lr: 0.041247454198189024
[batch_idx--150] train_loss: 0.0012858341431047841, acc: 0.8572278559602649, lr: 0.04120329223308148
[batch_idx--200] train_loss: 0.001275198622745698, acc: 0.8588114116915423, lr: 0.041159042909060875
[batch_idx--250] train_loss: 0.0012809626611535885, acc: 0.8578187250996016, lr: 0.04111470646469433
[batch_idx--300] train_loss: 0.0012750294847735683, acc: 0.8584146594684385, lr: 0.04107028313901867
[batch_idx--350] train_loss: 0.0012728738196544412, acc: 0.8584958155270656, lr: 0.04102577317153916
[batch_idx--400] train_loss: 0.001274140512784409, acc: 0.858137858478803, lr: 0.04098117680222813
[batch_idx--450] train_loss: 0.001276412801019485, acc: 0.8579859062033534, lr: 0.04093649427152381
total time of one epoch: 200.98272609710693 s
train_loss:  0.001276412801019485  acc:  0.8579859062033534
->>lr:0.040936
test_loss:  0.0016319860609134798  test_acc:  0.8192083385035365
best acc:  87.08276461099392

------Epoch: 42------
[batch_idx--0] train_loss: 0.0014348230324685574, acc: 0.83203125, lr: 0.040935599743717244
[batch_idx--50] train_loss: 0.0013003415957677598, acc: 0.8563878676470589, lr: 0.04089082957657292
[batch_idx--100] train_loss: 0.0012798831869599105, acc: 0.8585628094059405, lr: 0.04084597373513602
[batch_idx--150] train_loss: 0.0012722251349319982, acc: 0.8590387003311258, lr: 0.04080103246124366
[batch_idx--200] train_loss: 0.001272499422306445, acc: 0.8588114116915423, lr: 0.04075600599719357
[batch_idx--250] train_loss: 0.0012694214910372677, acc: 0.8585968625498008, lr: 0.04071089458574278
[batch_idx--300] train_loss: 0.0012658095715159048, acc: 0.8592841569767442, lr: 0.04066569847010627
[batch_idx--350] train_loss: 0.0012669999723221863, acc: 0.8597311253561254, lr: 0.040620417893955756
[batch_idx--400] train_loss: 0.0012648348521471413, acc: 0.859676979426434, lr: 0.04057505310141827
[batch_idx--450] train_loss: 0.0012720370665257263, acc: 0.859174853334259, lr: 0.04052960433707492
total time of one epoch: 199.49450635910034 s
train_loss:  0.0012720370665257263  acc:  0.859174853334259
->>lr:0.040530
test_loss:  0.001197971983263016  test_acc:  0.8715721553542624
best acc:  87.08276461099392
Saving..

------Epoch: 43------
[batch_idx--0] train_loss: 0.0012122094631195068, acc: 0.87109375, lr: 0.040528694506957764
[batch_idx--50] train_loss: 0.001259902327814523, acc: 0.8623621323529411, lr: 0.04048316034380937
[batch_idx--100] train_loss: 0.0012690442254637729, acc: 0.8615408415841584, lr: 0.040437542704288454
[batch_idx--150] train_loss: 0.0012666727377669206, acc: 0.8611858443708609, lr: 0.04039184183433934
[batch_idx--200] train_loss: 0.0012590514173944347, acc: 0.8608908582089553, lr: 0.04034605798035504
[batch_idx--250] train_loss: 0.0012611441033153954, acc: 0.8608378984063745, lr: 0.04030019138917598
[batch_idx--300] train_loss: 0.001255550048935948, acc: 0.8612697259136213, lr: 0.040254242308088696
[batch_idx--350] train_loss: 0.0012601413866876493, acc: 0.8606548254985755, lr: 0.040208210984824425
[batch_idx--400] train_loss: 0.0012625068823279733, acc: 0.8603004208229427, lr: 0.04016209766755781
[batch_idx--450] train_loss: 0.001268394009485651, acc: 0.860042697955358, lr: 0.040115902604905565
total time of one epoch: 200.17993068695068 s
train_loss:  0.001268394009485651  acc:  0.860042697955358
->>lr:0.040116
test_loss:  0.0012172845907935524  test_acc:  0.8695867973694007
best acc:  87.15721553542623

------Epoch: 44------
[batch_idx--0] train_loss: 0.0012926708441227674, acc: 0.84765625, lr: 0.040114977871559376
[batch_idx--50] train_loss: 0.0012566209793565613, acc: 0.8612132352941176, lr: 0.04006869968519579
[batch_idx--100] train_loss: 0.0012590298423368373, acc: 0.860728650990099, lr: 0.04002234025699524
[batch_idx--150] train_loss: 0.0012587425449326487, acc: 0.8603580298013245, lr: 0.039975899836901335
[batch_idx--200] train_loss: 0.0012567597499293327, acc: 0.8603661380597015, lr: 0.03992937867529435
[batch_idx--250] train_loss: 0.0012596843052707404, acc: 0.8600908864541833, lr: 0.03988277702298985
[batch_idx--300] train_loss: 0.0012552188817671565, acc: 0.8608674210963455, lr: 0.03983609513123738
[batch_idx--350] train_loss: 0.0012554084469877354, acc: 0.8615673967236467, lr: 0.03978933325171908
[batch_idx--400] train_loss: 0.001253412926146886, acc: 0.8616836814214464, lr: 0.03974249163654834
[batch_idx--450] train_loss: 0.0012583919856198797, acc: 0.861960634567987, lr: 0.03969557053826845
total time of one epoch: 200.2417893409729 s
train_loss:  0.0012583919856198797  acc:  0.861960634567987
->>lr:0.039696
test_loss:  0.0011995650651304341  test_acc:  0.8703313066137238
best acc:  87.15721553542623

------Epoch: 45------
[batch_idx--0] train_loss: 0.001248199143446982, acc: 0.8359375, lr: 0.03969463130731183
[batch_idx--50] train_loss: 0.0012683622475129133, acc: 0.8591452205882353, lr: 0.0396476293968751
[batch_idx--100] train_loss: 0.0012646357800885296, acc: 0.8608446782178217, lr: 0.03960054851477232
[batch_idx--150] train_loss: 0.0012648195477005168, acc: 0.8610564983443708, lr: 0.039553388914836764
[batch_idx--200] train_loss: 0.0012577615981801083, acc: 0.8618431281094527, lr: 0.039506150851326104
[batch_idx--250] train_loss: 0.0012523414505890523, acc: 0.8624097360557769, lr: 0.039458834578921055
[batch_idx--300] train_loss: 0.0012562217916426963, acc: 0.8619705149501661, lr: 0.03941144035272397
[batch_idx--350] train_loss: 0.0012486828287116163, acc: 0.8627136752136753, lr: 0.03936396842825749
[batch_idx--400] train_loss: 0.001251396729043009, acc: 0.8622778990024937, lr: 0.03931641906146319
[batch_idx--450] train_loss: 0.0012526635416675832, acc: 0.8627069809421322, lr: 0.03926879250870011
total time of one epoch: 200.29513120651245 s
train_loss:  0.0012526635416675832  acc:  0.8627069809421322
->>lr:0.039269
test_loss:  0.0011860328914953795  test_acc:  0.873557513339124
best acc:  87.15721553542623
Saving..

------Epoch: 46------
[batch_idx--0] train_loss: 0.0013570406008511782, acc: 0.85546875, lr: 0.0392678391921108
[batch_idx--50] train_loss: 0.0012981349616037572, acc: 0.8556985294117647, lr: 0.03922013417419226
[batch_idx--100] train_loss: 0.0012742166020123676, acc: 0.8577892945544554, lr: 0.03917235248941817
[batch_idx--150] train_loss: 0.0012581376235512708, acc: 0.8599958609271523, lr: 0.03912449439540013
[batch_idx--200] train_loss: 0.0012467117937842375, acc: 0.8615127487562189, lr: 0.0390765601501617
[batch_idx--250] train_loss: 0.0012448474570489173, acc: 0.8619428535856574, lr: 0.03902855001213699
[batch_idx--300] train_loss: 0.0012456621389535945, acc: 0.8622300664451827, lr: 0.0389804642401693
[batch_idx--350] train_loss: 0.0012460891361364252, acc: 0.862479967948718, lr: 0.03893230309350968
[batch_idx--400] train_loss: 0.001246412519680248, acc: 0.8624435006234414, lr: 0.03888406683181559
[batch_idx--450] train_loss: 0.0012472259591277282, acc: 0.86277640851182, lr: 0.03883575571514944
total time of one epoch: 200.4080994129181 s
train_loss:  0.0012472259591277282  acc:  0.86277640851182
->>lr:0.038836
test_loss:  0.001378430586799615  test_acc:  0.8499813872688919
best acc:  87.3557513339124

------Epoch: 47------
[batch_idx--0] train_loss: 0.0014272186672315001, acc: 0.82421875, lr: 0.038834788731083605
[batch_idx--50] train_loss: 0.0012762437359995994, acc: 0.8583792892156863, lr: 0.038786401530680796
[batch_idx--100] train_loss: 0.0012617425504371082, acc: 0.8619662747524752, lr: 0.03873794000186154
[batch_idx--150] train_loss: 0.001244415301638378, acc: 0.8627638658940397, lr: 0.03868940440590278
[batch_idx--200] train_loss: 0.001243179153467978, acc: 0.863397854477612, lr: 0.03864079500448077
[batch_idx--250] train_loss: 0.001243228291530548, acc: 0.8627832420318725, lr: 0.03859211205966969
[batch_idx--300] train_loss: 0.001241752541928778, acc: 0.8624636627906976, lr: 0.038543355833940224
[batch_idx--350] train_loss: 0.001241240556885162, acc: 0.8625244836182336, lr: 0.03849452659015813
[batch_idx--400] train_loss: 0.001240736698067545, acc: 0.862696773690773, lr: 0.03844562459158286
[batch_idx--450] train_loss: 0.0012449782026051175, acc: 0.8624986982330684, lr: 0.0383966501018661
total time of one epoch: 198.3967206478119 s
train_loss:  0.0012449782026051175  acc:  0.8624986982330684
->>lr:0.038397
test_loss:  0.001227340263799101  test_acc:  0.8664846755180543
best acc:  87.3557513339124

------Epoch: 48------
[batch_idx--0] train_loss: 0.0011931487824767828, acc: 0.86328125, lr: 0.03839566987447492
[batch_idx--50] train_loss: 0.001244156580308781, acc: 0.8656556372549019, lr: 0.038346621715813135
[batch_idx--100] train_loss: 0.0012423833601619347, acc: 0.8642094678217822, lr: 0.038297501599776934
[batch_idx--150] train_loss: 0.0012339664586906056, acc: 0.8644971026490066, lr: 0.03824830979119395
[batch_idx--200] train_loss: 0.0012345918751349534, acc: 0.8639614427860697, lr: 0.038199046555278386
[batch_idx--250] train_loss: 0.0012308464861434116, acc: 0.8647441484063745, lr: 0.038149712157629516
[batch_idx--300] train_loss: 0.0012344783817903693, acc: 0.8639301287375415, lr: 0.038100306864230285
[batch_idx--350] train_loss: 0.0012284876766118441, acc: 0.8649172008547008, lr: 0.038050830941445866
[batch_idx--400] train_loss: 0.001233503226820203, acc: 0.8643430486284289, lr: 0.03800128465602222
[batch_idx--450] train_loss: 0.0012393043472750985, acc: 0.8642864581525324, lr: 0.03795166827508467
total time of one epoch: 200.89737939834595 s
train_loss:  0.0012393043472750985  acc:  0.8642864581525324
->>lr:0.037952
test_loss:  0.0013093012654910032  test_acc:  0.855813376349423
best acc:  87.3557513339124

------Epoch: 49------
[batch_idx--0] train_loss: 0.0014843059470877051, acc: 0.81640625, lr: 0.03795067523432826
[batch_idx--50] train_loss: 0.0012515401730186068, acc: 0.8589920343137255, lr: 0.037900987631550954
[batch_idx--100] train_loss: 0.0012320391078811544, acc: 0.8628171410891089, lr: 0.03785123047400412
[batch_idx--150] train_loss: 0.0012334527753120818, acc: 0.8628673427152318, lr: 0.03780140402994997
[batch_idx--200] train_loss: 0.0012267131511288793, acc: 0.8642918221393034, lr: 0.03775150856802428
[batch_idx--250] train_loss: 0.0012302918146750279, acc: 0.8636858814741036, lr: 0.03770154435723495
[batch_idx--300] train_loss: 0.0012374399376853657, acc: 0.8627361918604651, lr: 0.037651511666960506
[batch_idx--350] train_loss: 0.0012348901153412088, acc: 0.8630252849002849, lr: 0.03760141076694869
[batch_idx--400] train_loss: 0.0012294812387196891, acc: 0.8638365024937655, lr: 0.037551241927314974
[batch_idx--450] train_loss: 0.0012325849384716037, acc: 0.8639479987503037, lr: 0.03750100541854115
total time of one epoch: 200.68406176567078 s
train_loss:  0.0012325849384716037  acc:  0.8639479987503037
->>lr:0.037501
test_loss:  0.001204817048638582  test_acc:  0.8750465318277701
best acc:  87.3557513339124
Saving..

------Epoch: 50------
[batch_idx--0] train_loss: 0.0012392265489324927, acc: 0.87109375, lr: 0.037500000000000006
[batch_idx--50] train_loss: 0.0012431217850569416, acc: 0.8623621323529411, lr: 0.037449694747731944
[batch_idx--100] train_loss: 0.0012281866885933766, acc: 0.866143254950495, lr: 0.03739932237380827
[batch_idx--150] train_loss: 0.001218124976249054, acc: 0.8682481374172185, lr: 0.03734888314980809
[batch_idx--200] train_loss: 0.0012079725538343376, acc: 0.869189210199005, lr: 0.037298377347670955
[batch_idx--250] train_loss: 0.0012086940378755835, acc: 0.86917953187251, lr: 0.03724780523969534
[batch_idx--300] train_loss: 0.0012072587422129275, acc: 0.8692639119601329, lr: 0.03719716709853723
[batch_idx--350] train_loss: 0.0012109965280672147, acc: 0.868667646011396, lr: 0.037146463197208594
[batch_idx--400] train_loss: 0.0012162777525837303, acc: 0.8676258572319202, lr: 0.03709569380907597
[batch_idx--450] train_loss: 0.0012253208410679067, acc: 0.8666469955219217, lr: 0.03704485920785895
total time of one epoch: 200.60749530792236 s
train_loss:  0.0012253208410679067  acc:  0.8666469955219217
->>lr:0.037045
test_loss:  0.001186017108357031  test_acc:  0.8741779377093932
best acc:  87.50465318277702

------Epoch: 51------
[batch_idx--0] train_loss: 0.0012086231727153063, acc: 0.86328125, lr: 0.037043841852542884
[batch_idx--50] train_loss: 0.0012523707906332087, acc: 0.8618259803921569, lr: 0.03699294101633032
[batch_idx--100] train_loss: 0.0012381191176389999, acc: 0.8636293316831684, lr: 0.036941975521017835
[batch_idx--150] train_loss: 0.0012329551194708128, acc: 0.8644194950331126, lr: 0.0368909456413823
[batch_idx--200] train_loss: 0.001234705136528248, acc: 0.8643889925373134, lr: 0.03683985165254776
[batch_idx--250] train_loss: 0.0012333499443016025, acc: 0.8646040836653387, lr: 0.03678869382998386
[batch_idx--300] train_loss: 0.0012295303382428109, acc: 0.8649553571428571, lr: 0.03673747244950439
[batch_idx--350] train_loss: 0.0012259102044056601, acc: 0.8652176816239316, lr: 0.03668618778726586
[batch_idx--400] train_loss: 0.0012264834997648293, acc: 0.8650833852867831, lr: 0.0366348401197659
[batch_idx--450] train_loss: 0.001226387413522323, acc: 0.8653018363592182, lr: 0.036583429723841876
total time of one epoch: 199.59806871414185 s
train_loss:  0.001226387413522323  acc:  0.8653018363592182
->>lr:0.036583
test_loss:  0.001160107846073099  test_acc:  0.8757910410720933
best acc:  87.50465318277702
Saving..

------Epoch: 52------
[batch_idx--0] train_loss: 0.0011262742336839437, acc: 0.87890625, lr: 0.036582400877996545
[batch_idx--50] train_loss: 0.0011900065012513568, acc: 0.8716299019607843, lr: 0.03653092678462853
[batch_idx--100] train_loss: 0.0011967473512395552, acc: 0.870049504950495, lr: 0.036479390523077894
[batch_idx--150] train_loss: 0.001198598692141202, acc: 0.8694898592715232, lr: 0.036427792371198774
[batch_idx--200] train_loss: 0.0011979213273453882, acc: 0.8695195895522388, lr: 0.036376132607179
[batch_idx--250] train_loss: 0.0012009191926034442, acc: 0.8687126494023905, lr: 0.03632441150953856
[batch_idx--300] train_loss: 0.0012054032432627043, acc: 0.8683035714285714, lr: 0.036272629357128106
[batch_idx--350] train_loss: 0.00120440943440571, acc: 0.8683560363247863, lr: 0.0362207864291275
[batch_idx--400] train_loss: 0.0012039770855582284, acc: 0.8686292082294265, lr: 0.03616888300504424
[batch_idx--450] train_loss: 0.00121293235707917, acc: 0.8679834762384143, lr: 0.03611691936471199
total time of one epoch: 199.69054985046387 s
train_loss:  0.00121293235707917  acc:  0.8679834762384143
->>lr:0.036117
test_loss:  0.0012362322021557271  test_acc:  0.8666087603921082
best acc:  87.57910410720933

------Epoch: 53------
[batch_idx--0] train_loss: 0.00128081941511482, acc: 0.85546875, lr: 0.036115879479623185
[batch_idx--50] train_loss: 0.001233132592603272, acc: 0.8622089460784313, lr: 0.0360638547073383
[batch_idx--100] train_loss: 0.0012277990503531725, acc: 0.864480198019802, lr: 0.036011770285057136
[batch_idx--150] train_loss: 0.0012147584737321694, acc: 0.8674979304635762, lr: 0.03595962649358918
[batch_idx--200] train_loss: 0.0012034536791103545, acc: 0.8685673196517413, lr: 0.03590742361406404
[batch_idx--250] train_loss: 0.0012100038208638826, acc: 0.8677321962151394, lr: 0.03585516192792988
[batch_idx--300] train_loss: 0.0012113114983691182, acc: 0.8675249169435216, lr: 0.03580284171695191
[batch_idx--350] train_loss: 0.0012112848971110696, acc: 0.8670650819088319, lr: 0.03575046326321087
[batch_idx--400] train_loss: 0.0012124653178687554, acc: 0.8671875, lr: 0.035698026849101526
[batch_idx--450] train_loss: 0.0012161611202490899, acc: 0.8671069531711042, lr: 0.03564553275733112
total time of one epoch: 203.50199794769287 s
train_loss:  0.0012161611202490899  acc:  0.8671069531711042
->>lr:0.035646
test_loss:  0.0011868755069526287  test_acc:  0.8724407494726393
best acc:  87.57910410720933

------Epoch: 54------
[batch_idx--0] train_loss: 0.001290197134949267, acc: 0.84375, lr: 0.03564448228912682
[batch_idx--50] train_loss: 0.0011947940391324023, acc: 0.8684895833333334, lr: 0.035591929657709624
[batch_idx--100] train_loss: 0.0012062266007950991, acc: 0.8673035272277227, lr: 0.03553931992064693
[batch_idx--150] train_loss: 0.0012059329460769744, acc: 0.8679118377483444, lr: 0.035486653361580446
[batch_idx--200] train_loss: 0.0012066909641986574, acc: 0.8676539179104478, lr: 0.03543393026445823
[batch_idx--250] train_loss: 0.00120538591817244, acc: 0.8678100099601593, lr: 0.03538115091353316
[batch_idx--300] train_loss: 0.001198004909939569, acc: 0.8692249792358804, lr: 0.035328315593361394
[batch_idx--350] train_loss: 0.0011939756372250998, acc: 0.8696692485754985, lr: 0.03527542458880086
[batch_idx--400] train_loss: 0.0011956090120043596, acc: 0.8695643703241895, lr: 0.035222478185009704
[batch_idx--450] train_loss: 0.0012025873499371912, acc: 0.8695542750026035, lr: 0.035169476667444736
total time of one epoch: 201.51134586334229 s
train_loss:  0.0012025873499371912  acc:  0.8695542750026035
->>lr:0.035169
test_loss:  0.0011612290664647527  test_acc:  0.8755428713239856
best acc:  87.57910410720933

------Epoch: 55------
[batch_idx--0] train_loss: 0.0011718699242919683, acc: 0.87109375, lr: 0.035168416076895005
[batch_idx--50] train_loss: 0.0011858072453726303, acc: 0.8707873774509803, lr: 0.03511535863766653
[batch_idx--100] train_loss: 0.0011936997537187642, acc: 0.8712097772277227, lr: 0.03506224666219176
[batch_idx--150] train_loss: 0.001193039127338727, acc: 0.870990273178808, lr: 0.03500908043682018
[batch_idx--200] train_loss: 0.0011856856356856798, acc: 0.8715796019900498, lr: 0.034955860248193804
[batch_idx--250] train_loss: 0.0011845136444414575, acc: 0.8714361304780877, lr: 0.034902586383245504
[batch_idx--300] train_loss: 0.0011843309323519987, acc: 0.8709250415282392, lr: 0.03484925912919761
[batch_idx--350] train_loss: 0.0011915530635646287, acc: 0.8700253739316239, lr: 0.03479587877356025
[batch_idx--400] train_loss: 0.0011961244453415924, acc: 0.8693305798004988, lr: 0.034742445604129875
[batch_idx--450] train_loss: 0.0012001102461701742, acc: 0.8694240983094387, lr: 0.034688959908987675
total time of one epoch: 201.6720588207245 s
train_loss:  0.0012001102461701742  acc:  0.8694240983094387
->>lr:0.034689
test_loss:  0.0011353428909035737  test_acc:  0.8779004839310088
best acc:  87.57910410720933
Saving..

------Epoch: 56------
[batch_idx--0] train_loss: 0.0012349599273875356, acc: 0.8359375, lr: 0.034687889661302575
[batch_idx--50] train_loss: 0.0011803260844602597, acc: 0.8726256127450981, lr: 0.034634350687009215
[batch_idx--100] train_loss: 0.0011950337396021747, acc: 0.8690826113861386, lr: 0.034580759769790186
[batch_idx--150] train_loss: 0.0011997297645194938, acc: 0.8688172599337748, lr: 0.034527117198577144
[batch_idx--200] train_loss: 0.001191752281651568, acc: 0.8687810945273632, lr: 0.034473423262580266
[batch_idx--250] train_loss: 0.0011914103339236988, acc: 0.8687593376494024, lr: 0.03441967825128663
[batch_idx--300] train_loss: 0.0011850654911806813, acc: 0.8692120016611296, lr: 0.0343658824544587
[batch_idx--350] train_loss: 0.0011849809878113071, acc: 0.8694911858974359, lr: 0.034312036162132735
[batch_idx--400] train_loss: 0.0011844192243975465, acc: 0.8693987687032418, lr: 0.034258139664617236
[batch_idx--450] train_loss: 0.001190356222769319, acc: 0.8692331724927969, lr: 0.0342041932524914
total time of one epoch: 204.43195390701294 s
train_loss:  0.001190356222769319  acc:  0.8692331724927969
->>lr:0.034204
test_loss:  0.0011327465313630861  test_acc:  0.878520908301278
best acc:  87.79004839310088
Saving..

------Epoch: 57------
[batch_idx--0] train_loss: 0.0010397826554253697, acc: 0.90625, lr: 0.03420311381711696
[batch_idx--50] train_loss: 0.0012105949161409894, acc: 0.8670343137254902, lr: 0.03414911679172232
[batch_idx--100] train_loss: 0.0012042530735097087, acc: 0.8673035272277227, lr: 0.034095070439506506
[batch_idx--150] train_loss: 0.0011905117341261726, acc: 0.8695933360927153, lr: 0.03404097505185664
[batch_idx--200] train_loss: 0.0011925878300359334, acc: 0.8688393967661692, lr: 0.0339868309204242
[batch_idx--250] train_loss: 0.0011910194047797188, acc: 0.8689305278884463, lr: 0.03393263833712346
[batch_idx--300] train_loss: 0.0011880274197207362, acc: 0.8694066652823921, lr: 0.03387839759412996
[batch_idx--350] train_loss: 0.0011845901054582237, acc: 0.870414886039886, lr: 0.03382410898387883
[batch_idx--400] train_loss: 0.0011878688421978283, acc: 0.8699832450124688, lr: 0.033769772799063326
[batch_idx--450] train_loss: 0.0011943111345976292, acc: 0.8693112785086958, lr: 0.03371538933263315
total time of one epoch: 201.8493287563324 s
train_loss:  0.0011943111345976292  acc:  0.8693112785086958
->>lr:0.033715
test_loss:  0.0011759984062806388  test_acc:  0.873557513339124
best acc:  87.8520908301278

------Epoch: 58------
[batch_idx--0] train_loss: 0.00114444678183645, acc: 0.89453125, lr: 0.03371430118304538
[batch_idx--50] train_loss: 0.0012006796451340266, acc: 0.8659620098039216, lr: 0.03365986979142943
[batch_idx--100] train_loss: 0.001192000540697228, acc: 0.8667233910891089, lr: 0.03360539171073317
[batch_idx--150] train_loss: 0.001191174487709777, acc: 0.8678342301324503, lr: 0.03355086723467137
[batch_idx--200] train_loss: 0.0011938224756274725, acc: 0.8678871268656716, lr: 0.03349629665720888
[batch_idx--250] train_loss: 0.001192889318233764, acc: 0.8683235806772909, lr: 0.03344168027255918
[batch_idx--300] train_loss: 0.0011965595274711913, acc: 0.8676546926910299, lr: 0.033387018375182646
[batch_idx--350] train_loss: 0.0011939099806419274, acc: 0.8686008725071225, lr: 0.03333231125978507
[batch_idx--400] train_loss: 0.0011916178331752203, acc: 0.8689896352867831, lr: 0.03327755922131603
[batch_idx--450] train_loss: 0.001190431643765327, acc: 0.8694067414170167, lr: 0.033222762554967304
total time of one epoch: 204.48862862586975 s
train_loss:  0.001190431643765327  acc:  0.8694067414170167
->>lr:0.033223
test_loss:  0.0011480183577860005  test_acc:  0.8759151259461472
best acc:  87.8520908301278

------Epoch: 59------
[batch_idx--0] train_loss: 0.0012540599564090371, acc: 0.8671875, lr: 0.03322166616846458
[batch_idx--50] train_loss: 0.0012026634991771595, acc: 0.8704810049019608, lr: 0.033166824286034645
[batch_idx--100] train_loss: 0.0011916259778571305, acc: 0.8710550742574258, lr: 0.03311193837274467
[batch_idx--150] train_loss: 0.0011965061278878064, acc: 0.8704470198675497, lr: 0.03305700872450816
[batch_idx--200] train_loss: 0.0011939701339836923, acc: 0.8698888370646766, lr: 0.03300203563747449
[batch_idx--250] train_loss: 0.0011963212166437916, acc: 0.869210657370518, lr: 0.0329470194080272
[batch_idx--300] train_loss: 0.0011991865502088718, acc: 0.869030315614618, lr: 0.032891960332782424
[batch_idx--350] train_loss: 0.001201556796344671, acc: 0.8688123219373219, lr: 0.03283685870858731
[batch_idx--400] train_loss: 0.001196806294381377, acc: 0.8692136845386533, lr: 0.03278171483251839
[batch_idx--450] train_loss: 0.0011958083790348476, acc: 0.8696063456798695, lr: 0.03272652900188
total time of one epoch: 203.45811772346497 s
train_loss:  0.0011958083790348476  acc:  0.8696063456798695
->>lr:0.032727
test_loss:  0.001171690421226318  test_acc:  0.8754187864499318
best acc:  87.8520908301278

------Epoch: 60------
[batch_idx--0] train_loss: 0.0012421157443895936, acc: 0.87109375, lr: 0.032725424859373686
[batch_idx--50] train_loss: 0.001189975545047691, acc: 0.8692555147058824, lr: 0.032670196541591943
[batch_idx--100] train_loss: 0.0011852980968265767, acc: 0.8706296410891089, lr: 0.03261492687048379
[batch_idx--150] train_loss: 0.0011873633052617164, acc: 0.87109375, lr: 0.03255961614403176
[batch_idx--200] train_loss: 0.0011905487638374614, acc: 0.8699082711442786, lr: 0.03250426466043975
[batch_idx--250] train_loss: 0.001188131518183328, acc: 0.8702222360557769, lr: 0.03244887271813142
[batch_idx--300] train_loss: 0.0011834135426802444, acc: 0.8707433554817275, lr: 0.032393440615748524
[batch_idx--350] train_loss: 0.0011831277240455108, acc: 0.8708934294871795, lr: 0.03233796865214936
[batch_idx--400] train_loss: 0.0011826299699638828, acc: 0.8708209943890274, lr: 0.03228245712640712
[batch_idx--450] train_loss: 0.0011848300050376508, acc: 0.8706651161176103, lr: 0.0322269063378083
total time of one epoch: 205.74483513832092 s
train_loss:  0.0011848300050376508  acc:  0.8706651161176103
->>lr:0.032227
test_loss:  0.0011370171590454304  test_acc:  0.8780245688050626
best acc:  87.8520908301278

------Epoch: 61------
[batch_idx--0] train_loss: 0.0010356154525652528, acc: 0.890625, lr: 0.03222579492361179
[batch_idx--50] train_loss: 0.001179956680382876, acc: 0.8727022058823529, lr: 0.032170204395443734
[batch_idx--100] train_loss: 0.0011939590446429678, acc: 0.8697787747524752, lr: 0.03211457520962184
[batch_idx--150] train_loss: 0.0011882599237350291, acc: 0.8712230960264901, lr: 0.032058907666066935
[batch_idx--200] train_loss: 0.001177775571922035, acc: 0.8719488495024875, lr: 0.03200320206490668
[batch_idx--250] train_loss: 0.0011707402717515054, acc: 0.8731480328685259, lr: 0.03194745870647391
[batch_idx--300] train_loss: 0.0011744005953664102, acc: 0.8728197674418605, lr: 0.03189167789130505
[batch_idx--350] train_loss: 0.0011714951840343427, acc: 0.8729300213675214, lr: 0.031835859920138446
[batch_idx--400] train_loss: 0.0011731631921179258, acc: 0.8723893391521197, lr: 0.03178000509391275
[batch_idx--450] train_loss: 0.0011785878532909117, acc: 0.8720970597424237, lr: 0.03172411371376536
total time of one epoch: 207.0664484500885 s
train_loss:  0.0011785878532909117  acc:  0.8720970597424237
->>lr:0.031724
test_loss:  0.001118993963285835  test_acc:  0.8797617570418166
best acc:  87.8520908301278
Saving..

------Epoch: 62------
[batch_idx--0] train_loss: 0.0010495474562048912, acc: 0.87109375, lr: 0.031722995515381644
[batch_idx--50] train_loss: 0.0011428206058803434, acc: 0.8778339460784313, lr: 0.03166706716067022
[batch_idx--100] train_loss: 0.0011416789176551126, acc: 0.8779780321782178, lr: 0.03161110286093404
[batch_idx--150] train_loss: 0.0011466041046182397, acc: 0.8770436672185431, lr: 0.031555102917900694
[batch_idx--200] train_loss: 0.0011587349798724946, acc: 0.8740477300995025, lr: 0.03149906763348994
[batch_idx--250] train_loss: 0.001155374058711517, acc: 0.8744241782868526, lr: 0.0314429973098121
[batch_idx--300] train_loss: 0.001160383759765728, acc: 0.8738190406976745, lr: 0.031386892249166375
[batch_idx--350] train_loss: 0.0011634758792676966, acc: 0.8736867877492878, lr: 0.03133075275403927
[batch_idx--400] train_loss: 0.001165112544244801, acc: 0.8734511377805486, lr: 0.03127457912710293
[batch_idx--450] train_loss: 0.001165142972436762, acc: 0.873650501614191, lr: 0.031218371671213524
total time of one epoch: 204.8070888519287 s
train_loss:  0.001165142972436762  acc:  0.873650501614191
->>lr:0.031218
test_loss:  0.0011791090971779506  test_acc:  0.8741779377093932
best acc:  87.97617570418166

------Epoch: 63------
[batch_idx--0] train_loss: 0.0013945144601166248, acc: 0.859375, lr: 0.031217247179121367
[batch_idx--50] train_loss: 0.0011796241856691445, acc: 0.8699448529411765, lr: 0.0311610055298914
[batch_idx--100] train_loss: 0.0011776139628889022, acc: 0.871403155940594, lr: 0.031104730664032437
[batch_idx--150] train_loss: 0.0011682354672411025, acc: 0.8734478476821192, lr: 0.031048422884946483
[batch_idx--200] train_loss: 0.0011611880076613592, acc: 0.8735230099502488, lr: 0.030992082496212964
[batch_idx--250] train_loss: 0.0011659922271658968, acc: 0.873023530876494, lr: 0.030935709801587143
[batch_idx--300] train_loss: 0.0011685031752003065, acc: 0.8720540905315615, lr: 0.03087930510499845
[batch_idx--350] train_loss: 0.0011638434298012798, acc: 0.8725071225071225, lr: 0.030822868710548842
[batch_idx--400] train_loss: 0.0011645205604304976, acc: 0.872418562967581, lr: 0.030766400922511174
[batch_idx--450] train_loss: 0.0011696256538115608, acc: 0.8721578088659007, lr: 0.030709902045327583
total time of one epoch: 204.8344910144806 s
train_loss:  0.0011696256538115608  acc:  0.8721578088659007
->>lr:0.030710
test_loss:  0.0010947646437514907  test_acc:  0.882863878893163
best acc:  87.97617570418166
Saving..

------Epoch: 64------
[batch_idx--0] train_loss: 0.0011550651397556067, acc: 0.8828125, lr: 0.030708771752766397
[batch_idx--50] train_loss: 0.0011688343388503236, acc: 0.8719362745098039, lr: 0.030652241478464032
[batch_idx--100] train_loss: 0.0011733745946318353, acc: 0.8721766707920792, lr: 0.03059568073049836
[batch_idx--150] train_loss: 0.0011743760100312976, acc: 0.8720767798013245, lr: 0.030539089813812693
[batch_idx--200] train_loss: 0.00116499371343612, acc: 0.8727845149253731, lr: 0.03048246903351297
[batch_idx--250] train_loss: 0.001167987656280532, acc: 0.8723854581673307, lr: 0.030425818694866172
[batch_idx--300] train_loss: 0.001165540637510312, acc: 0.8724693729235881, lr: 0.030369139103298623
[batch_idx--350] train_loss: 0.0011670817103650835, acc: 0.8724626068376068, lr: 0.030312430564394355
[batch_idx--400] train_loss: 0.0011635053561166616, acc: 0.8728764027431422, lr: 0.03025569338389348
[batch_idx--450] train_loss: 0.0011647916001125125, acc: 0.8730430103794217, lr: 0.03019892786769053
total time of one epoch: 206.1602602005005 s
train_loss:  0.0011647916001125125  acc:  0.8730430103794217
->>lr:0.030199
test_loss:  0.0011527403063063498  test_acc:  0.8764114654423626
best acc:  88.28638788931629

------Epoch: 65------
[batch_idx--0] train_loss: 0.0013846202054992318, acc: 0.84765625, lr: 0.03019779227044398
[batch_idx--50] train_loss: 0.001179049903179939, acc: 0.8723958333333334, lr: 0.03014099816711588
[batch_idx--100] train_loss: 0.0011632267793751146, acc: 0.872756806930693, lr: 0.030084176346456905
[batch_idx--150] train_loss: 0.0011657647540274736, acc: 0.8730339403973509, lr: 0.030027327114817932
[batch_idx--200] train_loss: 0.0011648169318468897, acc: 0.8724930037313433, lr: 0.029970450778697578
[batch_idx--250] train_loss: 0.001159821043766857, acc: 0.8735371015936255, lr: 0.02991354764474065
[batch_idx--300] train_loss: 0.001155464933949996, acc: 0.8739358388704319, lr: 0.02985661801973638
[batch_idx--350] train_loss: 0.0011589245829582639, acc: 0.8736422720797721, lr: 0.02979966221061685
[batch_idx--400] train_loss: 0.0011622688699365034, acc: 0.8732173472568578, lr: 0.029742680524455323
[batch_idx--450] train_loss: 0.0011652990941325657, acc: 0.8729909397021557, lr: 0.02968567326846454
total time of one epoch: 206.16312193870544 s
train_loss:  0.0011652990941325657  acc:  0.8729909397021557
->>lr:0.029686
test_loss:  0.0011184526678349929  test_acc:  0.8833602183893783
best acc:  88.28638788931629
Saving..

------Epoch: 66------
[batch_idx--0] train_loss: 0.0011262476909905672, acc: 0.890625, lr: 0.02968453286464312
[batch_idx--50] train_loss: 0.0011640372914353421, acc: 0.8723192401960784, lr: 0.029627499844060053
[batch_idx--100] train_loss: 0.001157176660691932, acc: 0.873336943069307, lr: 0.029570441874636297
[batch_idx--150] train_loss: 0.00114140329791529, acc: 0.8757243377483444, lr: 0.029513359263995894
[batch_idx--200] train_loss: 0.001138620689888925, acc: 0.8763798196517413, lr: 0.029456252319895716
[batch_idx--250] train_loss: 0.0011367335251395209, acc: 0.8766963396414342, lr: 0.029399121350223874
[batch_idx--300] train_loss: 0.0011421068818262, acc: 0.8762458471760798, lr: 0.029341966662997956
[batch_idx--350] train_loss: 0.0011467721339439884, acc: 0.8753783831908832, lr: 0.02928478856636346
[batch_idx--400] train_loss: 0.0011473436836394808, acc: 0.8751558603491272, lr: 0.02922758736859208
[batch_idx--450] train_loss: 0.0011533968619784755, acc: 0.8748654840837297, lr: 0.02917036337808005
total time of one epoch: 205.15999746322632 s
train_loss:  0.0011533968619784755  acc:  0.8748654840837297
->>lr:0.029170
test_loss:  0.0011005509593436788  test_acc:  0.8822434545228937
best acc:  88.33602183893784

------Epoch: 67------
[batch_idx--0] train_loss: 0.0010535076726227999, acc: 0.87109375, lr: 0.02916921866790256
[batch_idx--50] train_loss: 0.0011547018315040453, acc: 0.8734681372549019, lr: 0.029111971746632322
[batch_idx--100] train_loss: 0.0011298861585114853, acc: 0.8758895420792079, lr: 0.02905470265595496
[batch_idx--150] train_loss: 0.0011326506770900544, acc: 0.8762675910596026, lr: 0.028997411704632756
[batch_idx--200] train_loss: 0.0011332279577415752, acc: 0.877060012437811, lr: 0.02894009920154584
[batch_idx--250] train_loss: 0.0011300151475215428, acc: 0.8775211653386454, lr: 0.02888276545569057
[batch_idx--300] train_loss: 0.0011339360525896556, acc: 0.8770374792358804, lr: 0.0288254107761778
[batch_idx--350] train_loss: 0.001136170800853563, acc: 0.8767249821937322, lr: 0.028768035472231265
[batch_idx--400] train_loss: 0.001144325961167239, acc: 0.8760812811720698, lr: 0.0287106398531859
[batch_idx--450] train_loss: 0.0011487347961142496, acc: 0.8759242545214705, lr: 0.02865322422848614
total time of one epoch: 204.6553189754486 s
train_loss:  0.0011487347961142496  acc:  0.8759242545214705
->>lr:0.028653
test_loss:  0.001094727669124317  test_acc:  0.8849733217520784
best acc:  88.33602183893784
Saving..

------Epoch: 68------
[batch_idx--0] train_loss: 0.0010202396661043167, acc: 0.88671875, lr: 0.028652075714060296
[batch_idx--50] train_loss: 0.0011562829125015175, acc: 0.8756893382352942, lr: 0.028594640002494582
[batch_idx--100] train_loss: 0.001136764775648123, acc: 0.8777846534653465, lr: 0.028537184910679542
[batch_idx--150] train_loss: 0.0011347437062337747, acc: 0.8778456125827815, lr: 0.028479710748380266
[batch_idx--200] train_loss: 0.0011424228516569482, acc: 0.8765158582089553, lr: 0.028422217825464665
[batch_idx--250] train_loss: 0.0011398259907927498, acc: 0.8771009711155379, lr: 0.028364706451901797
[batch_idx--300] train_loss: 0.0011414320129232846, acc: 0.8767389950166113, lr: 0.028307176937760206
[batch_idx--350] train_loss: 0.0011373340932286193, acc: 0.87715900997151, lr: 0.028249629593206222
[batch_idx--400] train_loss: 0.0011418606835403515, acc: 0.876607309850374, lr: 0.02819206472850232
[batch_idx--450] train_loss: 0.0011469099289028424, acc: 0.8760804665532683, lr: 0.02813448265400542
total time of one epoch: 203.5105230808258 s
train_loss:  0.0011469099289028424  acc:  0.8760804665532683
->>lr:0.028134
test_loss:  0.0011094034065722768  test_acc:  0.8842288125077553
best acc:  88.49733217520784

------Epoch: 69------
[batch_idx--0] train_loss: 0.0011463579721748829, acc: 0.87109375, lr: 0.028133330839107608
[batch_idx--50] train_loss: 0.0011460337600689016, acc: 0.8753829656862745, lr: 0.028075731530447786
[batch_idx--100] train_loss: 0.001149689618470424, acc: 0.8752320544554455, lr: 0.028018115639197247
[batch_idx--150] train_loss: 0.001146857571997834, acc: 0.8760088990066225, lr: 0.027960483475988025
[batch_idx--200] train_loss: 0.0011445437085963045, acc: 0.8762049129353234, lr: 0.02790283535153988
[batch_idx--250] train_loss: 0.0011445807257808181, acc: 0.8752801294820717, lr: 0.027845171576658636
[batch_idx--300] train_loss: 0.0011445457079800533, acc: 0.8751816860465116, lr: 0.027787492462234484
[batch_idx--350] train_loss: 0.0011431751175759695, acc: 0.8754896723646723, lr: 0.02772979831924033
[batch_idx--400] train_loss: 0.0011445353074147925, acc: 0.8753409445137157, lr: 0.02767208945873009
[batch_idx--450] train_loss: 0.00114467932084572, acc: 0.875490332210921, lr: 0.027614366191837037
total time of one epoch: 203.24276971817017 s
train_loss:  0.00114467932084572  acc:  0.875490332210921
->>lr:0.027614
test_loss:  0.0011100067214732698  test_acc:  0.8832361335153245
best acc:  88.49733217520784

------Epoch: 70------
[batch_idx--0] train_loss: 0.0011471310863271356, acc: 0.890625, lr: 0.02761321158169134
[batch_idx--50] train_loss: 0.0011209087085672746, acc: 0.878140318627451, lr: 0.027555473940897853
[batch_idx--100] train_loss: 0.001130992220484163, acc: 0.8776686262376238, lr: 0.027497722522445946
[batch_idx--150] train_loss: 0.001142582976774294, acc: 0.8764486754966887, lr: 0.027439957637698322
[batch_idx--200] train_loss: 0.001146499272574907, acc: 0.8762826492537313, lr: 0.027382179598090313
[batch_idx--250] train_loss: 0.0011406957199221915, acc: 0.8773188496015937, lr: 0.027324388715128153
[batch_idx--300] train_loss: 0.0011410336381449454, acc: 0.8768947259136213, lr: 0.027266585300387343
[batch_idx--350] train_loss: 0.001140477279555371, acc: 0.8771367521367521, lr: 0.027208769665510946
[batch_idx--400] train_loss: 0.0011412990833992635, acc: 0.8769190305486284, lr: 0.027150942122207884
[batch_idx--450] train_loss: 0.001145328712255641, acc: 0.8767834206963585, lr: 0.027093102982251305
total time of one epoch: 204.34498286247253 s
train_loss:  0.001145328712255641  acc:  0.8767834206963585
->>lr:0.027093
test_loss:  0.0010917330146176093  test_acc:  0.887827273855317
best acc:  88.49733217520784
Saving..

------Epoch: 71------
[batch_idx--0] train_loss: 0.0010504766833037138, acc: 0.90625, lr: 0.02709194608330789
[batch_idx--50] train_loss: 0.0011424346913711406, acc: 0.8759957107843137, lr: 0.027034095436018247
[batch_idx--100] train_loss: 0.0011439767284641541, acc: 0.8758121905940595, lr: 0.026976233822045795
[batch_idx--150] train_loss: 0.0011411252815510756, acc: 0.8761641142384106, lr: 0.026918361553347366
[batch_idx--200] train_loss: 0.0011348947430891332, acc: 0.877079446517413, lr: 0.026860478941937244
[batch_idx--250] train_loss: 0.0011352558450521048, acc: 0.8770387201195219, lr: 0.026802586299885446
[batch_idx--300] train_loss: 0.0011327094994052205, acc: 0.877374896179402, lr: 0.026744683939316106
[batch_idx--350] train_loss: 0.0011328421567932854, acc: 0.8770477207977208, lr: 0.026686772172405743
[batch_idx--400] train_loss: 0.0011314110106967407, acc: 0.8775035068578554, lr: 0.02662885131138157
[batch_idx--450] train_loss: 0.0011354511694947537, acc: 0.8777206928871455, lr: 0.026570921668519862
total time of one epoch: 205.82110357284546 s
train_loss:  0.0011354511694947537  acc:  0.8777206928871455
->>lr:0.026571
test_loss:  0.0010801420135316993  test_acc:  0.8824916242710014
best acc:  88.7827273855317

------Epoch: 72------
[batch_idx--0] train_loss: 0.001204062718898058, acc: 0.8515625, lr: 0.026569762988232833
[batch_idx--50] train_loss: 0.0011326498568843247, acc: 0.8774509803921569, lr: 0.026511824709652916
[batch_idx--100] train_loss: 0.0011391079976536924, acc: 0.8752320544554455, lr: 0.02645387828017616
[batch_idx--150] train_loss: 0.001135300191902611, acc: 0.8762158526490066, lr: 0.026395924012216673
[batch_idx--200] train_loss: 0.0011255313811443784, acc: 0.8786147388059702, lr: 0.02633796221823084
[batch_idx--250] train_loss: 0.0011324300321720658, acc: 0.877925796812749, lr: 0.026279993210715575
[batch_idx--300] train_loss: 0.0011314914037359018, acc: 0.8781795058139535, lr: 0.026222017302206753
[batch_idx--350] train_loss: 0.0011301082368221059, acc: 0.8784277065527065, lr: 0.02616403480527739
[batch_idx--400] train_loss: 0.0011309546277976765, acc: 0.8777762624688279, lr: 0.02610604603253605
[batch_idx--450] train_loss: 0.0011387209805608577, acc: 0.8769917034054223, lr: 0.026048051296625147
total time of one epoch: 205.20541787147522 s
train_loss:  0.0011387209805608577  acc:  0.8769917034054223
->>lr:0.026048
test_loss:  0.0011508173612850684  test_acc:  0.8771559746866857
best acc:  88.7827273855317

------Epoch: 73------
[batch_idx--0] train_loss: 0.0010510720312595367, acc: 0.8984375, lr: 0.02604689134322999
[batch_idx--50] train_loss: 0.0011349470062437012, acc: 0.8779105392156863, lr: 0.025988890847003655
[batch_idx--100] train_loss: 0.001134678014867598, acc: 0.8790996287128713, lr: 0.025930885019241706
[batch_idx--150] train_loss: 0.001139016290016423, acc: 0.8779232201986755, lr: 0.025872874172678507
[batch_idx--200] train_loss: 0.00113888717527543, acc: 0.8773320895522388, lr: 0.02581485862007545
[batch_idx--250] train_loss: 0.0011351065699983225, acc: 0.8770542828685259, lr: 0.02575683867421932
[batch_idx--300] train_loss: 0.0011330342627644068, acc: 0.8770504568106312, lr: 0.02569881464792059
[batch_idx--350] train_loss: 0.0011320421125599186, acc: 0.8773482015669516, lr: 0.02564078685401172
[batch_idx--400] train_loss: 0.0011304356930011005, acc: 0.8776204021197007, lr: 0.025582755605345495
[batch_idx--450] train_loss: 0.001132455888541896, acc: 0.8778335126878883, lr: 0.02552472121479332
total time of one epoch: 202.67288875579834 s
train_loss:  0.001132455888541896  acc:  0.8778335126878883
->>lr:0.025525
test_loss:  0.0010742482372513035  test_acc:  0.886214170492617
best acc:  88.7827273855317

------Epoch: 74------
[batch_idx--0] train_loss: 0.0009959357557818294, acc: 0.8828125, lr: 0.025523560497083927
[batch_idx--50] train_loss: 0.0010919201521056832, acc: 0.8825827205882353, lr: 0.025465523224145754
[batch_idx--100] train_loss: 0.0011070814550771277, acc: 0.8796024133663366, lr: 0.02540748344137178
[batch_idx--150] train_loss: 0.0011166351707035441, acc: 0.8783629966887417, lr: 0.02534944146167944
[batch_idx--200] train_loss: 0.0011201282677620612, acc: 0.8782649253731343, lr: 0.025291397597997967
[batch_idx--250] train_loss: 0.0011240099278460461, acc: 0.8784082420318725, lr: 0.025233352163266793
[batch_idx--300] train_loss: 0.0011228081817426208, acc: 0.8786207433554817, lr: 0.025175305470433812
[batch_idx--350] train_loss: 0.0011262942319125615, acc: 0.877960292022792, lr: 0.025117257832453683
[batch_idx--400] train_loss: 0.0011244777786287659, acc: 0.8782633260598504, lr: 0.025059209562286185
[batch_idx--450] train_loss: 0.0011293550561885276, acc: 0.8779636893810532, lr: 0.02500116097289448
total time of one epoch: 205.74234533309937 s
train_loss:  0.0011293550561885276  acc:  0.8779636893810532
->>lr:0.025001
test_loss:  0.001074318673389102  test_acc:  0.8901848864623403
best acc:  88.7827273855317
Saving..

------Epoch: 75------
[batch_idx--0] train_loss: 0.0010372570250183344, acc: 0.89453125, lr: 0.025
[batch_idx--50] train_loss: 0.0010894091409521505, acc: 0.8830422794117647, lr: 0.024941951407416053
[batch_idx--100] train_loss: 0.0011117436149673961, acc: 0.8797571163366337, lr: 0.024883903127797022
[batch_idx--150] train_loss: 0.0011144543004172874, acc: 0.878932119205298, lr: 0.02482585547410613
[batch_idx--200] train_loss: 0.0011104360837906376, acc: 0.8791588930348259, lr: 0.024767808759303227
[batch_idx--250] train_loss: 0.0011152239039584817, acc: 0.8784549302788844, lr: 0.024709763296343102
[batch_idx--300] train_loss: 0.001119677288545933, acc: 0.8781535506644518, lr: 0.024651719398173802
[batch_idx--350] train_loss: 0.0011211702743733562, acc: 0.8782051282051282, lr: 0.024593677377734924
[batch_idx--400] train_loss: 0.0011201938907464879, acc: 0.878516599127182, lr: 0.02453563754795596
[batch_idx--450] train_loss: 0.0011224925173271632, acc: 0.8783195056757038, lr: 0.024477600221754565
total time of one epoch: 204.6480996608734 s
train_loss:  0.0011224925173271632  acc:  0.8783195056757038
->>lr:0.024478
test_loss:  0.0010748552113405334  test_acc:  0.8894403772180172
best acc:  89.01848864623402

------Epoch: 76------
[batch_idx--0] train_loss: 0.0011543373111635447, acc: 0.875, lr: 0.02447643950291608
[batch_idx--50] train_loss: 0.001116584736497744, acc: 0.8780637254901961, lr: 0.024418405052717584
[batch_idx--100] train_loss: 0.0011165690542622884, acc: 0.8790609529702971, lr: 0.024360373738147447
[batch_idx--150] train_loss: 0.0011104304637969626, acc: 0.8806653559602649, lr: 0.024302345872077406
[batch_idx--200] train_loss: 0.0011099820533206695, acc: 0.880733053482587, lr: 0.024244321767360646
[batch_idx--250] train_loss: 0.0011114743983454676, acc: 0.8804936503984063, lr: 0.024186301736830045
[batch_idx--300] train_loss: 0.001113988022069351, acc: 0.8799185008305648, lr: 0.024128286093296536
[batch_idx--350] train_loss: 0.0011158341968410842, acc: 0.8795183404558404, lr: 0.02407027514954738
[batch_idx--400] train_loss: 0.0011153096458561104, acc: 0.8796173628428927, lr: 0.024012269218344526
[batch_idx--450] train_loss: 0.0011182249184140114, acc: 0.8797427708543063, lr: 0.023954268612422863
total time of one epoch: 205.99799180030823 s
train_loss:  0.0011182249184140114  acc:  0.8797427708543063
->>lr:0.023954
test_loss:  0.0011298922406545806  test_acc:  0.8821193696488399
best acc:  89.01848864623402

------Epoch: 77------
[batch_idx--0] train_loss: 0.0010122806997969747, acc: 0.89453125, lr: 0.02395310865677001
[batch_idx--50] train_loss: 0.0011590304362185883, acc: 0.8727022058823529, lr: 0.023895113804784887
[batch_idx--100] train_loss: 0.0011210143496973974, acc: 0.8777846534653465, lr: 0.02383712490971616
[batch_idx--150] train_loss: 0.0011154276126878497, acc: 0.8792942880794702, lr: 0.023779142284206876
[batch_idx--200] train_loss: 0.001112550363553901, acc: 0.8791005907960199, lr: 0.023721166240866298
[batch_idx--250] train_loss: 0.0011151764229722914, acc: 0.8790307519920318, lr: 0.0236631970922682
[batch_idx--300] train_loss: 0.001113106514423145, acc: 0.8794513081395349, lr: 0.023605235150949158
[batch_idx--350] train_loss: 0.0011110134763401692, acc: 0.8800413995726496, lr: 0.02354728072940694
[batch_idx--400] train_loss: 0.0011091368190742138, acc: 0.8806304551122195, lr: 0.02348933414009873
[batch_idx--450] train_loss: 0.0011147030857109903, acc: 0.8801940500572778, lr: 0.02343139569543949
total time of one epoch: 206.8852481842041 s
train_loss:  0.0011147030857109903  acc:  0.8801940500572778
->>lr:0.023431
test_loss:  0.0010840960724328053  test_acc:  0.8877031889812632
best acc:  89.01848864623402

------Epoch: 78------
[batch_idx--0] train_loss: 0.0011409524595364928, acc: 0.875, lr: 0.023430237011767167
[batch_idx--50] train_loss: 0.0011394980703663155, acc: 0.8770680147058824, lr: 0.02337230719645424
[batch_idx--100] train_loss: 0.0011141194908944245, acc: 0.8805306311881188, lr: 0.023314386156732855
[batch_idx--150] train_loss: 0.0011150117436214196, acc: 0.8813379552980133, lr: 0.023256474204880216
[batch_idx--200] train_loss: 0.0011069992393839048, acc: 0.8821128731343284, lr: 0.023198571653124563
[batch_idx--250] train_loss: 0.0011076409027882038, acc: 0.8814741035856574, lr: 0.02314067881364343
[batch_idx--300] train_loss: 0.0011083427277096606, acc: 0.8811383928571429, lr: 0.02308279599856199
[batch_idx--350] train_loss: 0.0011074631738587895, acc: 0.8810207443019943, lr: 0.023024923519951404
[batch_idx--400] train_loss: 0.001109854485857024, acc: 0.8808545043640897, lr: 0.02296706168982706
[batch_idx--450] train_loss: 0.0011137922631604656, acc: 0.8804370465511855, lr: 0.022909210820146964
total time of one epoch: 205.67337369918823 s
train_loss:  0.0011137922631604656  acc:  0.8804370465511855
->>lr:0.022909
test_loss:  0.0010420290034674343  test_acc:  0.8927906688174712
best acc:  89.01848864623402
Saving..

------Epoch: 79------
[batch_idx--0] train_loss: 0.0010563888354226947, acc: 0.89453125, lr: 0.022908053916692112
[batch_idx--50] train_loss: 0.0011069950209382702, acc: 0.8800551470588235, lr: 0.022850214547982983
[batch_idx--100] train_loss: 0.0010885804958438666, acc: 0.8835473391089109, lr: 0.022792386769691267
[batch_idx--150] train_loss: 0.0011024773995922446, acc: 0.8818812086092715, lr: 0.022734570893591363
[batch_idx--200] train_loss: 0.0011091550878151806, acc: 0.8811994713930348, lr: 0.022676767231393526
[batch_idx--250] train_loss: 0.0011108772118624108, acc: 0.880836030876494, lr: 0.02261897609474213
[batch_idx--300] train_loss: 0.0011088153410415192, acc: 0.8806841777408638, lr: 0.022561197795214035
[batch_idx--350] train_loss: 0.001113097640610117, acc: 0.8796852742165242, lr: 0.022503432644316902
[batch_idx--400] train_loss: 0.0011076881777276832, acc: 0.8804161471321695, lr: 0.022445680953487472
[batch_idx--450] train_loss: 0.0011100163975232725, acc: 0.8805672232443503, lr: 0.022387943034089947
total time of one epoch: 204.25245213508606 s
train_loss:  0.0011100163975232725  acc:  0.8805672232443503
->>lr:0.022388
test_loss:  0.001067429499910759  test_acc:  0.8889440377218017
best acc:  89.27906688174711

------Epoch: 80------
[batch_idx--0] train_loss: 0.000904938206076622, acc: 0.89453125, lr: 0.022386788418308663
[batch_idx--50] train_loss: 0.0011178140834375632, acc: 0.8779871323529411, lr: 0.022329064866462054
[batch_idx--100] train_loss: 0.001108303892029689, acc: 0.8786355198019802, lr: 0.022271355714774788
[batch_idx--150] train_loss: 0.0011022294218503927, acc: 0.8798116721854304, lr: 0.022213661274381714
[batch_idx--200] train_loss: 0.0010993590245987127, acc: 0.8802472014925373, lr: 0.022155981856338363
[batch_idx--250] train_loss: 0.0010965805833758526, acc: 0.8806337151394422, lr: 0.022098317771619257
[batch_idx--300] train_loss: 0.001097639532414794, acc: 0.8805673795681063, lr: 0.022040669331116272
[batch_idx--350] train_loss: 0.0010971530130666355, acc: 0.8805533297720798, lr: 0.021983036845636923
[batch_idx--400] train_loss: 0.001095729557352554, acc: 0.8813220854114713, lr: 0.02192542062590272
[batch_idx--450] train_loss: 0.0010997127876972157, acc: 0.8811226438018537, lr: 0.02186782098254747
total time of one epoch: 206.47667050361633 s
train_loss:  0.0010997127876972157  acc:  0.8811226438018537
->>lr:0.021868
test_loss:  0.0010478612502849876  test_acc:  0.8899367167142326
best acc:  89.27906688174711

------Epoch: 81------
[batch_idx--0] train_loss: 0.0010383914923295379, acc: 0.88671875, lr: 0.02186666916089239
[batch_idx--50] train_loss: 0.0011095642351874096, acc: 0.8812040441176471, lr: 0.021809086745365924
[batch_idx--100] train_loss: 0.0011021395681868537, acc: 0.8804532797029703, lr: 0.021751521533424346
[batch_idx--150] train_loss: 0.001101862527399219, acc: 0.8811827400662252, lr: 0.021693973835426473
[batch_idx--200] train_loss: 0.0011094169209326678, acc: 0.8803832400497512, lr: 0.021636443961636685
[batch_idx--250] train_loss: 0.001108096216330342, acc: 0.8801357071713147, lr: 0.021578932222223245
[batch_idx--300] train_loss: 0.0011074113343576236, acc: 0.8804895141196013, lr: 0.021521438927256664
[batch_idx--350] train_loss: 0.001101937339020272, acc: 0.8811542913105413, lr: 0.021463964386708015
[batch_idx--400] train_loss: 0.001096550130634859, acc: 0.8815948410224439, lr: 0.021406508910447243
[batch_idx--450] train_loss: 0.0011015598009040024, acc: 0.8810705731245878, lr: 0.021349072808241526
total time of one epoch: 205.99061608314514 s
train_loss:  0.0011015598009040024  acc:  0.8810705731245878
->>lr:0.021349
test_loss:  0.0010620120708012583  test_acc:  0.8879513587293709
best acc:  89.27906688174711

------Epoch: 82------
[batch_idx--0] train_loss: 0.001133783720433712, acc: 0.8671875, lr: 0.021347924285939714
[batch_idx--50] train_loss: 0.0010876601285702897, acc: 0.8815870098039216, lr: 0.02129050826428394
[batch_idx--100] train_loss: 0.0010866510484708787, acc: 0.8831605816831684, lr: 0.021233112242092567
[batch_idx--150] train_loss: 0.0010981868358100734, acc: 0.8818294701986755, lr: 0.02117573652881221
[batch_idx--200] train_loss: 0.0010939140703334514, acc: 0.8818990982587065, lr: 0.02111838143378
[batch_idx--250] train_loss: 0.001099932812890817, acc: 0.8810227838645418, lr: 0.021061047266221912
[batch_idx--300] train_loss: 0.0010958334540892578, acc: 0.8819819352159468, lr: 0.021003734335251087
[batch_idx--350] train_loss: 0.0010950562188951059, acc: 0.8822671830484331, lr: 0.020946442949866164
[batch_idx--400] train_loss: 0.001092354704897637, acc: 0.8827930174563591, lr: 0.020889173418949643
[batch_idx--450] train_loss: 0.001093655274538544, acc: 0.882693442566043, lr: 0.020831926051266162
total time of one epoch: 205.14874243736267 s
train_loss:  0.001093655274538544  acc:  0.882693442566043
->>lr:0.020832
test_loss:  0.0010482693172622398  test_acc:  0.8932870083136866
best acc:  89.27906688174711
Saving..

------Epoch: 83------
[batch_idx--0] train_loss: 0.0013997153146192431, acc: 0.8359375, lr: 0.020830781332097453
[batch_idx--50] train_loss: 0.0010997598440678534, acc: 0.8817401960784313, lr: 0.020773556888877096
[batch_idx--100] train_loss: 0.001101931321347077, acc: 0.8814201732673267, lr: 0.020716355232228204
[batch_idx--150] train_loss: 0.0010912903296970916, acc: 0.8835627069536424, lr: 0.020659176670549492
[batch_idx--200] train_loss: 0.0010998213089729164, acc: 0.8818990982587065, lr: 0.020602021512115154
[batch_idx--250] train_loss: 0.0010975505836656784, acc: 0.881863172310757, lr: 0.02054489006507322
[batch_idx--300] train_loss: 0.0010948974358388208, acc: 0.8817223837209303, lr: 0.02048778263744388
[batch_idx--350] train_loss: 0.0010883669049526828, acc: 0.8826789529914529, lr: 0.02043069953711782
[batch_idx--400] train_loss: 0.001090415468482426, acc: 0.8826079332917706, lr: 0.020373641071854572
[batch_idx--450] train_loss: 0.0010912855080664045, acc: 0.8829104037213177, lr: 0.020316607549280843
total time of one epoch: 203.8159077167511 s
train_loss:  0.0010912855080664045  acc:  0.8829104037213177
->>lr:0.020317
test_loss:  0.0010190836392793279  test_acc:  0.8958927906688174
best acc:  89.32870083136865
Saving..

------Epoch: 84------
[batch_idx--0] train_loss: 0.000991194392554462, acc: 0.89453125, lr: 0.020315467135356893
[batch_idx--50] train_loss: 0.001060905303650846, acc: 0.8861060049019608, lr: 0.02025845937110404
[batch_idx--100] train_loss: 0.001079094185871948, acc: 0.8846689356435643, lr: 0.020201477170534773
[batch_idx--150] train_loss: 0.001075487649792941, acc: 0.8852183360927153, lr: 0.020144520840864624
[batch_idx--200] train_loss: 0.0010810243353868525, acc: 0.8841145833333334, lr: 0.02008759068916964
[batch_idx--250] train_loss: 0.0010780926691312566, acc: 0.8843843376494024, lr: 0.020030687022384752
[batch_idx--300] train_loss: 0.0010838834723562894, acc: 0.8836819975083057, lr: 0.019973810147302068
[batch_idx--350] train_loss: 0.0010848517502801349, acc: 0.8833912037037037, lr: 0.01991696037056928
[batch_idx--400] train_loss: 0.0010844873567227916, acc: 0.8833677524937655, lr: 0.01986013799868798
[batch_idx--450] train_loss: 0.0010910621327699962, acc: 0.8828322977054188, lr: 0.01980334333801198
total time of one epoch: 203.63152170181274 s
train_loss:  0.0010910621327699962  acc:  0.8828322977054188
->>lr:0.019803
test_loss:  0.0010587523664429993  test_acc:  0.8898126318401787
best acc:  89.58927906688174

------Epoch: 85------
[batch_idx--0] train_loss: 0.0010323429014533758, acc: 0.88671875, lr: 0.019802207729556022
[batch_idx--50] train_loss: 0.0010693691198385374, acc: 0.8838082107843137, lr: 0.0197454416497602
[batch_idx--100] train_loss: 0.0010770985805936674, acc: 0.8827351485148515, lr: 0.019688703899547008
[batch_idx--150] train_loss: 0.00108000161187933, acc: 0.8823468543046358, lr: 0.01963199478481404
[batch_idx--200] train_loss: 0.0010928346390896176, acc: 0.8811217350746269, lr: 0.019575314611304503
[batch_idx--250] train_loss: 0.0010925093174084606, acc: 0.8814896663346613, lr: 0.019518663684605593
[batch_idx--300] train_loss: 0.0010901021044407398, acc: 0.8823323297342193, lr: 0.01946204231014678
[batch_idx--350] train_loss: 0.001084010157551075, acc: 0.883346688034188, lr: 0.019405450793198248
[batch_idx--400] train_loss: 0.001087719210663908, acc: 0.883007325436409, lr: 0.01934888943886919
[batch_idx--450] train_loss: 0.0010899725662466843, acc: 0.8831013295379595, lr: 0.019292358552106172
total time of one epoch: 206.76747226715088 s
train_loss:  0.0010899725662466843  acc:  0.8831013295379595
->>lr:0.019292
test_loss:  0.0010522734602622734  test_acc:  0.8872068494850478
best acc:  89.58927906688174

------Epoch: 86------
[batch_idx--0] train_loss: 0.000996410846710205, acc: 0.90234375, lr: 0.019291228247233613
[batch_idx--50] train_loss: 0.0010849748060162015, acc: 0.8834252450980392, lr: 0.019234728751373553
[batch_idx--100] train_loss: 0.0010891571141880853, acc: 0.8826964727722773, lr: 0.01917826033856888
[batch_idx--150] train_loss: 0.0010859096582380697, acc: 0.882786630794702, lr: 0.019121823313265066
[batch_idx--200] train_loss: 0.0010880366473375305, acc: 0.8825987251243781, lr: 0.01906541797973838
[batch_idx--250] train_loss: 0.001089196482884783, acc: 0.8829214392430279, lr: 0.01900904464209422
[batch_idx--300] train_loss: 0.0010863615822996882, acc: 0.8832407599667774, lr: 0.018952703604265476
[batch_idx--350] train_loss: 0.0010894326575397596, acc: 0.8830350783475783, lr: 0.018896395170010898
[batch_idx--400] train_loss: 0.0010888295711489612, acc: 0.8830170667082294, lr: 0.01884011964291346
[batch_idx--450] train_loss: 0.0010884074723072508, acc: 0.8833182906932343, lr: 0.018783877326378724
total time of one epoch: 204.6186819076538 s
train_loss:  0.0010884074723072508  acc:  0.8833182906932343
->>lr:0.018784
test_loss:  0.001032732638831706  test_acc:  0.8908053108326095
best acc:  89.58927906688174

------Epoch: 87------
[batch_idx--0] train_loss: 0.0010229109320789576, acc: 0.91796875, lr: 0.018782752820878636
[batch_idx--50] train_loss: 0.0010600965938019548, acc: 0.8866421568627451, lr: 0.018726544691500546
[batch_idx--100] train_loss: 0.001070886599084381, acc: 0.885519801980198, lr: 0.01867037038501655
[batch_idx--150] train_loss: 0.001063590468407072, acc: 0.8873396109271523, lr: 0.018614230204286455
[batch_idx--200] train_loss: 0.001063640947877638, acc: 0.8864272388059702, lr: 0.018558124451986114
[batch_idx--250] train_loss: 0.0010639117625764612, acc: 0.8863763695219123, lr: 0.018502053430605753
[batch_idx--300] train_loss: 0.0010654215882315713, acc: 0.8864591985049833, lr: 0.01844601744244835
[batch_idx--350] train_loss: 0.0010675488161241524, acc: 0.8854723112535613, lr: 0.018390016789628004
[batch_idx--400] train_loss: 0.0010727059252576396, acc: 0.8850432512468828, lr: 0.018334051774068303
[batch_idx--450] train_loss: 0.0010768709597656445, acc: 0.8849845523657445, lr: 0.0182781226975007
total time of one epoch: 204.0197069644928 s
train_loss:  0.0010768709597656445  acc:  0.8849845523657445
->>lr:0.018278
test_loss:  0.001034096232832092  test_acc:  0.8901848864623403
best acc:  89.58927906688174

------Epoch: 88------
[batch_idx--0] train_loss: 0.000990565400570631, acc: 0.8671875, lr: 0.01827700448461836
[batch_idx--50] train_loss: 0.0010866489028558135, acc: 0.8821997549019608, lr: 0.018221112376465492
[batch_idx--100] train_loss: 0.001091100419018565, acc: 0.8828898514851485, lr: 0.018165256816209563
[batch_idx--150] train_loss: 0.0010932332825298046, acc: 0.8815707781456954, lr: 0.018109438104991903
[batch_idx--200] train_loss: 0.001088106313799114, acc: 0.8823655161691543, lr: 0.01805365654375518
[batch_idx--250] train_loss: 0.0010816593864557901, acc: 0.8831704432270916, lr: 0.017997912433241763
[batch_idx--300] train_loss: 0.0010831930248787708, acc: 0.883422446013289, lr: 0.017942206073992117
[batch_idx--350] train_loss: 0.0010796947110553094, acc: 0.8838920049857549, lr: 0.017886537766343167
[batch_idx--400] train_loss: 0.0010762251462111542, acc: 0.8845756701995012, lr: 0.017830907810426684
[batch_idx--450] train_loss: 0.0010784927030244398, acc: 0.8842989551150762, lr: 0.017775316506167683
total time of one epoch: 207.6188359260559 s
train_loss:  0.0010784927030244398  acc:  0.8842989551150762
->>lr:0.017775
test_loss:  0.0010114909142888145  test_acc:  0.8941556024320635
best acc:  89.58927906688174

------Epoch: 89------
[batch_idx--0] train_loss: 0.0008894490310922265, acc: 0.9140625, lr: 0.017774205076388213
[batch_idx--50] train_loss: 0.0010484294399765192, acc: 0.8876378676470589, lr: 0.017718653505586445
[batch_idx--100] train_loss: 0.001061909540445719, acc: 0.8873762376237624, lr: 0.01766314119165336
[batch_idx--150] train_loss: 0.0010535514825609643, acc: 0.8886848096026491, lr: 0.017607668433879703
[batch_idx--200] train_loss: 0.0010581992848067365, acc: 0.8880402674129353, lr: 0.017552235531342955
[batch_idx--250] train_loss: 0.00106398204264539, acc: 0.8871545069721115, lr: 0.017496842782905715
[batch_idx--300] train_loss: 0.001069920533955518, acc: 0.8861477367109635, lr: 0.017441490487214106
[batch_idx--350] train_loss: 0.0010712329514505092, acc: 0.8857616631054132, lr: 0.017386178942696135
[batch_idx--400] train_loss: 0.0010708381857042505, acc: 0.8855303148379052, lr: 0.01733090844756013
[batch_idx--450] train_loss: 0.0010692959081507129, acc: 0.8860780365883292, lr: 0.017275679299793074
total time of one epoch: 205.67481994628906 s
train_loss:  0.0010692959081507129  acc:  0.8860780365883292
->>lr:0.017276
test_loss:  0.0010224013858700024  test_acc:  0.8962650452909791
best acc:  89.58927906688174
Saving..

------Epoch: 90------
[batch_idx--0] train_loss: 0.0010733541566878557, acc: 0.90234375, lr: 0.017274575140626316
[batch_idx--50] train_loss: 0.001073060225120143, acc: 0.8861825980392157, lr: 0.017219388473930602
[batch_idx--100] train_loss: 0.0010638101248872827, acc: 0.8887685643564357, lr: 0.017164243755855953
[batch_idx--150] train_loss: 0.0010617838101615721, acc: 0.8885295943708609, lr: 0.017109141283711254
[batch_idx--200] train_loss: 0.0010659377193727082, acc: 0.8873017723880597, lr: 0.0170540813545776
[batch_idx--250] train_loss: 0.0010685982241525325, acc: 0.8869677539840638, lr: 0.016999064265306747
[batch_idx--300] train_loss: 0.0010689830976426972, acc: 0.8869912790697675, lr: 0.016944090312519478
[batch_idx--350] train_loss: 0.0010711431172954985, acc: 0.8863181089743589, lr: 0.01688915979260398
[batch_idx--400] train_loss: 0.0010706467333045369, acc: 0.8860953086034913, lr: 0.016834273001714316
[batch_idx--450] train_loss: 0.0010728278362650036, acc: 0.8858784323254765, lr: 0.016779430235768767
total time of one epoch: 204.69702076911926 s
train_loss:  0.0010728278362650036  acc:  0.8858784323254765
->>lr:0.016779
test_loss:  0.001041569134662163  test_acc:  0.892046159573148
best acc:  89.6265045290979

------Epoch: 91------
[batch_idx--0] train_loss: 0.0009941827738657594, acc: 0.90234375, lr: 0.01677833383153542
[batch_idx--50] train_loss: 0.0010481726973974967, acc: 0.8867953431372549, lr: 0.016723536275641708
[batch_idx--100] train_loss: 0.0010385446395669686, acc: 0.8874535891089109, lr: 0.01666878334172139
[batch_idx--150] train_loss: 0.0010503685785710367, acc: 0.8861754966887417, lr: 0.01661407532497108
[batch_idx--200] train_loss: 0.0010545348768256865, acc: 0.8857859141791045, lr: 0.016559412520345193
[batch_idx--250] train_loss: 0.0010562948764309258, acc: 0.885769422310757, lr: 0.016504795222554415
[batch_idx--300] train_loss: 0.0010576922155644411, acc: 0.8855377906976745, lr: 0.01645022372606408
[batch_idx--350] train_loss: 0.0010582040002015008, acc: 0.8855724715099715, lr: 0.01639569832509256
[batch_idx--400] train_loss: 0.0010642869758856323, acc: 0.8853160068578554, lr: 0.016341219313609757
[batch_idx--450] train_loss: 0.0010626192538652672, acc: 0.8858350400944215, lr: 0.01628678698533542
total time of one epoch: 206.0992350578308 s
train_loss:  0.0010626192538652672  acc:  0.8858350400944215
->>lr:0.016287
test_loss:  0.0010139273086897653  test_acc:  0.8934110931877404
best acc:  89.6265045290979

------Epoch: 92------
[batch_idx--0] train_loss: 0.0011299479519948363, acc: 0.8828125, lr: 0.016285698816954627
[batch_idx--50] train_loss: 0.0010348524562740589, acc: 0.8929227941176471, lr: 0.016231314407882003
[batch_idx--100] train_loss: 0.0010516900196902012, acc: 0.8897354579207921, lr: 0.016176977274562434
[batch_idx--150] train_loss: 0.0010439247877448057, acc: 0.8907802152317881, lr: 0.016122687709950775
[batch_idx--200] train_loss: 0.0010560806336770974, acc: 0.8892646144278606, lr: 0.01606844600674539
[batch_idx--250] train_loss: 0.0010631401773608955, acc: 0.8881505229083665, lr: 0.016014252457386614
[batch_idx--300] train_loss: 0.0010643396224900832, acc: 0.887640157807309, lr: 0.015960107354055172
[batch_idx--350] train_loss: 0.0010664354509971187, acc: 0.8871639066951567, lr: 0.01590601098867059
[batch_idx--400] train_loss: 0.001064859664513546, acc: 0.8874493453865336, lr: 0.015851963652889624
[batch_idx--450] train_loss: 0.0010636064488111377, acc: 0.8880220085395911, lr: 0.015797965638104688
total time of one epoch: 203.90866923332214 s
train_loss:  0.0010636064488111377  acc:  0.8880220085395911
->>lr:0.015798
test_loss:  0.001021247009054161  test_acc:  0.8940315175580097
best acc:  89.6265045290979

------Epoch: 93------
[batch_idx--0] train_loss: 0.0013313025701791048, acc: 0.859375, lr: 0.01579688618288306
[batch_idx--50] train_loss: 0.0010446210713673603, acc: 0.8916973039215687, lr: 0.01574293877543077
[batch_idx--100] train_loss: 0.001021502773498766, acc: 0.891823948019802, lr: 0.015689041276774486
[batch_idx--150] train_loss: 0.0010371654786305218, acc: 0.8888917632450332, lr: 0.015635193977498796
[batch_idx--200] train_loss: 0.0010459821072374633, acc: 0.8884483830845771, lr: 0.015581397167917649
[batch_idx--250] train_loss: 0.0010456958673412046, acc: 0.8889597858565738, lr: 0.01552765113807274
[batch_idx--300] train_loss: 0.0010481619835364016, acc: 0.8884447674418605, lr: 0.015473956177732033
[batch_idx--350] train_loss: 0.0010438535824826682, acc: 0.8888221153846154, lr: 0.01542031257638813
[batch_idx--400] train_loss: 0.00104362227471471, acc: 0.8886864869077307, lr: 0.015366720623256752
[batch_idx--450] train_loss: 0.001047240793844651, acc: 0.8882302912486548, lr: 0.015313180607275165
total time of one epoch: 204.04389190673828 s
train_loss:  0.001047240793844651  acc:  0.8882302912486548
->>lr:0.015313
test_loss:  0.0010439047562394105  test_acc:  0.8916739049509865
best acc:  89.6265045290979

------Epoch: 94------
[batch_idx--0] train_loss: 0.001155796810053289, acc: 0.86328125, lr: 0.015312110338697428
[batch_idx--50] train_loss: 0.001060930386587393, acc: 0.8850337009803921, lr: 0.015258623595981367
[batch_idx--100] train_loss: 0.0010592649209008802, acc: 0.8864866955445545, lr: 0.015205189373212608
[batch_idx--150] train_loss: 0.0010636697110060036, acc: 0.8861754966887417, lr: 0.015151807958478031
[batch_idx--200] train_loss: 0.0010597948529363717, acc: 0.8865049751243781, lr: 0.015098479639579785
[batch_idx--250] train_loss: 0.0010600763999678907, acc: 0.886687624501992, lr: 0.015045204704033754
[batch_idx--300] train_loss: 0.001059937323915441, acc: 0.8871210548172758, lr: 0.01499198343906803
[batch_idx--350] train_loss: 0.0010568444428705422, acc: 0.8873197115384616, lr: 0.014938816131621303
[batch_idx--400] train_loss: 0.0010568294433198702, acc: 0.8872642612219451, lr: 0.014885703068341395
[batch_idx--450] train_loss: 0.0010596693703213474, acc: 0.8869545596556393, lr: 0.014832644535583656
total time of one epoch: 201.41382145881653 s
train_loss:  0.0010596693703213474  acc:  0.8869545596556393
->>lr:0.014833
test_loss:  0.0010229863900377402  test_acc:  0.8963891301650329
best acc:  89.6265045290979
Saving..

------Epoch: 95------
[batch_idx--0] train_loss: 0.001118105254136026, acc: 0.875, lr: 0.014831583923105
[batch_idx--50] train_loss: 0.0011154674712623306, acc: 0.8756893382352942, lr: 0.014778581306178257
[batch_idx--100] train_loss: 0.001084435376739775, acc: 0.8814201732673267, lr: 0.014725633797313148
[batch_idx--150] train_loss: 0.0010733469003897827, acc: 0.8836144453642384, lr: 0.014672741681972468
[batch_idx--200] train_loss: 0.0010617885768149438, acc: 0.8852611940298507, lr: 0.01461990524532032
[batch_idx--250] train_loss: 0.0010572812697141473, acc: 0.8859406125498008, lr: 0.014567124772220653
[batch_idx--300] train_loss: 0.0010574810573153594, acc: 0.8858103197674418, lr: 0.014514400547235684
[batch_idx--350] train_loss: 0.001058379993966364, acc: 0.88630698005698, lr: 0.014461732854624376
[batch_idx--400] train_loss: 0.0010580016080025314, acc: 0.8865434071072319, lr: 0.014409121978340905
[batch_idx--450] train_loss: 0.0010577358855576966, acc: 0.8864946020064568, lr: 0.014356568202033099
total time of one epoch: 202.32890701293945 s
train_loss:  0.0010577358855576966  acc:  0.8864946020064568
->>lr:0.014357
test_loss:  0.001019816233171306  test_acc:  0.8909293957066634
best acc:  89.6389130165033

------Epoch: 96------
[batch_idx--0] train_loss: 0.001009191619232297, acc: 0.88671875, lr: 0.014355517710873192
[batch_idx--50] train_loss: 0.0010365450905416818, acc: 0.8900122549019608, lr: 0.014303022468435317
[batch_idx--100] train_loss: 0.0010355613718851294, acc: 0.8895420792079208, lr: 0.014250584898001182
[batch_idx--150] train_loss: 0.0010468813448848314, acc: 0.8877276490066225, lr: 0.014198205282284266
[batch_idx--200] train_loss: 0.0010489337299765082, acc: 0.8879625310945274, lr: 0.014145883903685591
[batch_idx--250] train_loss: 0.0010417345964602116, acc: 0.8888664093625498, lr: 0.014093621044292189
[batch_idx--300] train_loss: 0.0010421643291980622, acc: 0.8889768480066446, lr: 0.014041416985875627
[batch_idx--350] train_loss: 0.0010415473596346791, acc: 0.8890335648148148, lr: 0.013989272009890398
[batch_idx--400] train_loss: 0.0010383854880859319, acc: 0.8892514806733167, lr: 0.013937186397472484
[batch_idx--450] train_loss: 0.0010427705149307599, acc: 0.8892456694553407, lr: 0.01388516042943782
total time of one epoch: 202.8566653728485 s
train_loss:  0.0010427705149307599  acc:  0.8892456694553407
->>lr:0.013885
test_loss:  0.001044747828401811  test_acc:  0.8932870083136866
best acc:  89.6389130165033

------Epoch: 97------
[batch_idx--0] train_loss: 0.000989770982414484, acc: 0.8984375, lr: 0.01388412052037681
[batch_idx--50] train_loss: 0.0010228151667808346, acc: 0.8915441176470589, lr: 0.01383215567857612
[batch_idx--100] train_loss: 0.0010451863716946601, acc: 0.8886138613861386, lr: 0.013780251047424422
[batch_idx--150] train_loss: 0.001044403493330376, acc: 0.8884002483443708, lr: 0.013728406906761904
[batch_idx--200] train_loss: 0.0010427602095325565, acc: 0.8889148009950248, lr: 0.013676623536102595
[batch_idx--250] train_loss: 0.0010492507796419184, acc: 0.8881660856573705, lr: 0.013624901214632912
[batch_idx--300] train_loss: 0.0010455323638861684, acc: 0.8886783637873754, lr: 0.01357324022121012
[batch_idx--350] train_loss: 0.0010457028760216557, acc: 0.8890001780626781, lr: 0.013521640834360844
[batch_idx--400] train_loss: 0.0010513027770238047, acc: 0.8884721789276808, lr: 0.013470103332279566
[batch_idx--450] train_loss: 0.0010583347762459067, acc: 0.888152185232756, lr: 0.013418627992827087
total time of one epoch: 202.83094906806946 s
train_loss:  0.0010583347762459067  acc:  0.888152185232756
->>lr:0.013419
test_loss:  0.0010242983190367515  test_acc:  0.8955205360466559
best acc:  89.6389130165033

------Epoch: 98------
[batch_idx--0] train_loss: 0.0009187153191305697, acc: 0.921875, lr: 0.013417599122003463
[batch_idx--50] train_loss: 0.0010507882563579902, acc: 0.8871783088235294, lr: 0.013366187474337023
[batch_idx--100] train_loss: 0.0010428402491033742, acc: 0.8890779702970297, lr: 0.013314838549554453
[batch_idx--150] train_loss: 0.0010405966637360043, acc: 0.8885295943708609, lr: 0.013263552624499875
[batch_idx--200] train_loss: 0.0010419469749536458, acc: 0.8875932835820896, lr: 0.01321232997567776
[batch_idx--250] train_loss: 0.0010427058763909655, acc: 0.8883684013944223, lr: 0.01316117087925142
[batch_idx--300] train_loss: 0.0010425579889624865, acc: 0.8885745431893688, lr: 0.013110075611041534
[batch_idx--350] train_loss: 0.001043251340981955, acc: 0.8885216346153846, lr: 0.01305904444652466
[batch_idx--400] train_loss: 0.0010424266461029816, acc: 0.8886182980049875, lr: 0.013008077660831736
[batch_idx--450] train_loss: 0.001044667282947693, acc: 0.8887336411288923, lr: 0.01295717552874661
total time of one epoch: 203.92457222938538 s
train_loss:  0.001044667282947693  acc:  0.8887336411288923
->>lr:0.012957
test_loss:  0.0010183298076733064  test_acc:  0.8955205360466559
best acc:  89.6389130165033

------Epoch: 99------
[batch_idx--0] train_loss: 0.001127118244767189, acc: 0.8828125, lr: 0.012956158147457115
[batch_idx--50] train_loss: 0.0010582983822507016, acc: 0.8868719362745098, lr: 0.012905322244772761
[batch_idx--100] train_loss: 0.0010448566143456293, acc: 0.8886912128712872, lr: 0.012854551549694835
[batch_idx--150] train_loss: 0.0010464207754186693, acc: 0.8880639486754967, lr: 0.012803846335949954
[batch_idx--200] train_loss: 0.0010407882176724202, acc: 0.8897115982587065, lr: 0.012753206876911727
[batch_idx--250] train_loss: 0.001046686576803649, acc: 0.8889909113545816, lr: 0.012702633445599246
[batch_idx--300] train_loss: 0.001049282437304895, acc: 0.8886653862126246, lr: 0.012652126314675622
[batch_idx--350] train_loss: 0.0010523635201206553, acc: 0.8878205128205128, lr: 0.012601685756446507
[batch_idx--400] train_loss: 0.0010450871194192578, acc: 0.8885403678304239, lr: 0.012551312042858621
[batch_idx--450] train_loss: 0.0010508123781248454, acc: 0.8883170757107648, lr: 0.012501005445498313
total time of one epoch: 203.57171726226807 s
train_loss:  0.0010508123781248454  acc:  0.8883170757107648
->>lr:0.012501
test_loss:  0.0010167164680664614  test_acc:  0.8981263184017868
best acc:  89.6389130165033
Saving..

------Epoch: 100------
[batch_idx--0] train_loss: 0.001196502591483295, acc: 0.87109375, lr: 0.012500000000000006
[batch_idx--50] train_loss: 0.0010785741946093884, acc: 0.8830422794117647, lr: 0.012449762140604802
[batch_idx--100] train_loss: 0.0010428492251857377, acc: 0.8879950495049505, lr: 0.012399591944936346
[batch_idx--150] train_loss: 0.001050787991366121, acc: 0.8878569950331126, lr: 0.012349489683483728
[batch_idx--200] train_loss: 0.0010482179028774375, acc: 0.8883900808457711, lr: 0.012299455626369788
[batch_idx--250] train_loss: 0.0010438072411677395, acc: 0.88863296812749, lr: 0.012249490043349598
[batch_idx--300] train_loss: 0.0010476552692173897, acc: 0.8877699335548173, lr: 0.01219959320380913
[batch_idx--350] train_loss: 0.0010464892655006077, acc: 0.8882545405982906, lr: 0.012149765376763677
[batch_idx--400] train_loss: 0.001044962383595358, acc: 0.8883358011221946, lr: 0.012100006830856476
[batch_idx--450] train_loss: 0.0010443096187404224, acc: 0.8889072100531121, lr: 0.01205031783435723
total time of one epoch: 206.9146444797516 s
train_loss:  0.0010443096187404224  acc:  0.8889072100531121
->>lr:0.012050
test_loss:  0.00101845807155851  test_acc:  0.8942796873061174
best acc:  89.81263184017868

------Epoch: 101------
[batch_idx--0] train_loss: 0.0007509292918257415, acc: 0.9375, lr: 0.012049324765671741
[batch_idx--50] train_loss: 0.0010379015116532351, acc: 0.8890931372549019, lr: 0.01199970698555119
[batch_idx--100] train_loss: 0.001032144222569901, acc: 0.8898128094059405, lr: 0.011950159295598187
[batch_idx--150] train_loss: 0.0010320157404766967, acc: 0.8897454470198676, lr: 0.011900681962945607
[batch_idx--200] train_loss: 0.001035761481106967, acc: 0.8889925373134329, lr: 0.011851275254347019
[batch_idx--250] train_loss: 0.0010417419923116932, acc: 0.8883995268924303, lr: 0.011801939436175232
[batch_idx--300] train_loss: 0.0010428727846948486, acc: 0.888782184385382, lr: 0.01175267477442085
[batch_idx--350] train_loss: 0.0010405148374861334, acc: 0.8893229166666666, lr: 0.011703481534690844
[batch_idx--400] train_loss: 0.0010377337707280928, acc: 0.8898944046134664, lr: 0.011654359982207095
[batch_idx--450] train_loss: 0.001047304179386863, acc: 0.8893150970250286, lr: 0.011605310381805019
total time of one epoch: 205.90120315551758 s
train_loss:  0.001047304179386863  acc:  0.8893150970250286
->>lr:0.011605
test_loss:  0.0010032018489200996  test_acc:  0.8975058940315176
best acc:  89.81263184017868

------Epoch: 102------
[batch_idx--0] train_loss: 0.0011656524147838354, acc: 0.86328125, lr: 0.01160433012552509
[batch_idx--50] train_loss: 0.0010224640946926585, acc: 0.8908547794117647, lr: 0.011555354188677439
[batch_idx--100] train_loss: 0.0010265888776491848, acc: 0.8904702970297029, lr: 0.011506450737694249
[batch_idx--150] train_loss: 0.0010251088132650055, acc: 0.8909095612582781, lr: 0.011457620036235043
[batch_idx--200] train_loss: 0.0010278456096087967, acc: 0.8903334888059702, lr: 0.011408862347567132
[batch_idx--250] train_loss: 0.0010309044524018033, acc: 0.8898779880478087, lr: 0.011360177934564142
[batch_idx--300] train_loss: 0.0010350906066565568, acc: 0.889392130398671, lr: 0.011311567059704701
[batch_idx--350] train_loss: 0.001032418982680367, acc: 0.8898904914529915, lr: 0.01126302998507092
[batch_idx--400] train_loss: 0.001034532230059405, acc: 0.8897385442643392, lr: 0.011214566972347026
[batch_idx--450] train_loss: 0.001035995146853692, acc: 0.8903131183392925, lr: 0.01116617828281797
total time of one epoch: 202.86877131462097 s
train_loss:  0.001035995146853692  acc:  0.8903131183392925
->>lr:0.011166
test_loss:  0.0009976386532089465  test_acc:  0.8987467427720561
best acc:  89.81263184017868
Saving..

------Epoch: 103------
[batch_idx--0] train_loss: 0.0010260975686833262, acc: 0.88671875, lr: 0.011165211268916392
[batch_idx--50] train_loss: 0.0010673153173068866, acc: 0.8868719362745098, lr: 0.011116898657806221
[batch_idx--100] train_loss: 0.0010507662814009087, acc: 0.8884978341584159, lr: 0.01106866089646273
[batch_idx--150] train_loss: 0.0010389696809753085, acc: 0.8895902317880795, lr: 0.011020498244956429
[batch_idx--200] train_loss: 0.0010387635606211327, acc: 0.8896921641791045, lr: 0.010972410962952879
[batch_idx--250] train_loss: 0.0010281708849820335, acc: 0.8909518177290837, lr: 0.010924399309711284
[batch_idx--300] train_loss: 0.0010338727030145048, acc: 0.8900799418604651, lr: 0.010876463544083113
[batch_idx--350] train_loss: 0.0010332835418970837, acc: 0.89021323005698, lr: 0.010828603924510663
[batch_idx--400] train_loss: 0.001032980229616156, acc: 0.8900697475062345, lr: 0.010780820709025727
[batch_idx--450] train_loss: 0.001033930931389425, acc: 0.8900093727219078, lr: 0.010733114155248157
total time of one epoch: 203.39594149589539 s
train_loss:  0.001033930931389425  acc:  0.8900093727219078
->>lr:0.010733
test_loss:  0.0010481338015648756  test_acc:  0.8889440377218017
best acc:  89.87467427720561

------Epoch: 104------
[batch_idx--0] train_loss: 0.0009039657306857407, acc: 0.92578125, lr: 0.010732160807889211
[batch_idx--50] train_loss: 0.0009953069087464874, acc: 0.8960631127450981, lr: 0.010684532714024482
[batch_idx--100] train_loss: 0.0010123929737301746, acc: 0.8924814356435643, lr: 0.010636981800997085
[batch_idx--150] train_loss: 0.0010082990247972112, acc: 0.8923841059602649, lr: 0.01058950832517444
[batch_idx--200] train_loss: 0.001015021512342793, acc: 0.8914412313432836, lr: 0.010542112542506449
[batch_idx--250] train_loss: 0.001019850922878312, acc: 0.8908428784860558, lr: 0.01049479470852415
[batch_idx--300] train_loss: 0.0010240616561516972, acc: 0.8904043812292359, lr: 0.010447555078338317
[batch_idx--350] train_loss: 0.001027809374234732, acc: 0.8900574252136753, lr: 0.010400393906638123
[batch_idx--400] train_loss: 0.0010271313113388036, acc: 0.8903619856608479, lr: 0.010353311447689712
[batch_idx--450] train_loss: 0.0010302303999752405, acc: 0.8906949699725761, lr: 0.01030630795533484
total time of one epoch: 203.71882796287537 s
train_loss:  0.0010302303999752405  acc:  0.8906949699725761
->>lr:0.010306
test_loss:  0.0010058417063904897  test_acc:  0.8965132150390868
best acc:  89.87467427720561

------Epoch: 105------
[batch_idx--0] train_loss: 0.0009568420937284827, acc: 0.88671875, lr: 0.010305368692688175
[batch_idx--50] train_loss: 0.001019914616264549, acc: 0.8892463235294118, lr: 0.010258446007324987
[batch_idx--100] train_loss: 0.0010135203938802133, acc: 0.8916305693069307, lr: 0.010211602800015714
[batch_idx--150] train_loss: 0.0010108891442812832, acc: 0.8922547599337748, lr: 0.010164839323312217
[batch_idx--200] train_loss: 0.0010163689527975682, acc: 0.8920048196517413, lr: 0.010118155829336504
[batch_idx--250] train_loss: 0.0010176425928665525, acc: 0.8918388944223108, lr: 0.010071552569779364
[batch_idx--300] train_loss: 0.0010121282442639957, acc: 0.8927533222591362, lr: 0.010025029795898983
[batch_idx--350] train_loss: 0.0010147028877280462, acc: 0.8921385327635327, lr: 0.00997858775851964
[batch_idx--400] train_loss: 0.0010134894635988182, acc: 0.8923589463840399, lr: 0.00993222670803032
[batch_idx--450] train_loss: 0.0010193179265147268, acc: 0.891736383517895, lr: 0.009885946894383374
total time of one epoch: 204.15978002548218 s
train_loss:  0.0010193179265147268  acc:  0.891736383517895
->>lr:0.009886
test_loss:  0.0009937589651361739  test_acc:  0.8991189973942176
best acc:  89.87467427720561
Saving..

------Epoch: 106------
[batch_idx--0] train_loss: 0.0013043798971921206, acc: 0.86328125, lr: 0.00988502212844063
[batch_idx--50] train_loss: 0.0010207634220611962, acc: 0.8928462009803921, lr: 0.009838825433419594
[batch_idx--100] train_loss: 0.001010867233369684, acc: 0.8941058168316832, lr: 0.009792710478807351
[batch_idx--150] train_loss: 0.0010169512728716414, acc: 0.8925651903973509, lr: 0.009746677513229449
[batch_idx--200] train_loss: 0.0010121044426558733, acc: 0.8929959577114428, lr: 0.00970072678486938
[batch_idx--250] train_loss: 0.001013177112616836, acc: 0.8926792828685259, lr: 0.009654858541467274
[batch_idx--300] train_loss: 0.001016934081661419, acc: 0.8923510174418605, lr: 0.009609073030318542
[batch_idx--350] train_loss: 0.0010129857867720014, acc: 0.8928730413105413, lr: 0.009563370498272567
[batch_idx--400] train_loss: 0.0010114911154894962, acc: 0.8930603179551122, lr: 0.009517751191731351
[batch_idx--450] train_loss: 0.0010157246948929311, acc: 0.8929774013260666, lr: 0.00947221535664816
total time of one epoch: 205.23230385780334 s
train_loss:  0.0010157246948929311  acc:  0.8929774013260666
->>lr:0.009472
test_loss:  0.0010010673310771772  test_acc:  0.8965132150390868
best acc:  89.91189973942177

------Epoch: 107------
[batch_idx--0] train_loss: 0.000999454758130014, acc: 0.87890625, lr: 0.009471305493042243
[batch_idx--50] train_loss: 0.0010268073517591784, acc: 0.8901654411764706, lr: 0.00942585505176061
[batch_idx--100] train_loss: 0.0010141144641490636, acc: 0.8917079207920792, lr: 0.009380488577388602
[batch_idx--150] train_loss: 0.0010100867686367637, acc: 0.8928756208609272, lr: 0.009335206314516387
[batch_idx--200] train_loss: 0.0010093168879103899, acc: 0.8934040733830846, lr: 0.0092900085072801
[batch_idx--250] train_loss: 0.0010080121249327828, acc: 0.8931928535856574, lr: 0.009244895399360565
[batch_idx--300] train_loss: 0.001010850777167307, acc: 0.8928571428571429, lr: 0.009199867233981912
[batch_idx--350] train_loss: 0.0010145576009089048, acc: 0.8923611111111112, lr: 0.009154924253910346
[batch_idx--400] train_loss: 0.0010129273107026859, acc: 0.8924855829177057, lr: 0.009110066701452797
[batch_idx--450] train_loss: 0.0010152547493989272, acc: 0.8923178394140313, lr: 0.0090652948184556
total time of one epoch: 204.05431509017944 s
train_loss:  0.0010152547493989272  acc:  0.8923178394140313
->>lr:0.009065
test_loss:  0.0009722315317674138  test_acc:  0.9003598461347562
best acc:  89.91189973942177
Saving..

------Epoch: 108------
[batch_idx--0] train_loss: 0.001104486407712102, acc: 0.8828125, lr: 0.009064400256282757
[batch_idx--50] train_loss: 0.0010184266481219845, acc: 0.8917738970588235, lr: 0.009019716004806225
[batch_idx--100] train_loss: 0.0010122073892651514, acc: 0.891978650990099, lr: 0.0089751179099095
[batch_idx--150] train_loss: 0.0010043937224888594, acc: 0.8920478062913907, lr: 0.008930606212040063
[batch_idx--200] train_loss: 0.0010059936150482193, acc: 0.892529539800995, lr: 0.00888618115117962
[batch_idx--250] train_loss: 0.0010084649441259137, acc: 0.8926637201195219, lr: 0.00884184296684277
[batch_idx--300] train_loss: 0.0010067055066057366, acc: 0.8928571428571429, lr: 0.00879759189807571
[batch_idx--350] train_loss: 0.0010083381309136854, acc: 0.8925503027065527, lr: 0.008753428183455004
[batch_idx--400] train_loss: 0.001008109341548556, acc: 0.8924368765586035, lr: 0.008709352061086187
[batch_idx--450] train_loss: 0.001011531580189488, acc: 0.8920054153504356, lr: 0.008665363768602597
total time of one epoch: 209.89978075027466 s
train_loss:  0.001011531580189488  acc:  0.8920054153504356
->>lr:0.008665
test_loss:  0.0009882424809320614  test_acc:  0.8986226578980022
best acc:  90.03598461347562

------Epoch: 109------
[batch_idx--0] train_loss: 0.001055594184435904, acc: 0.88671875, lr: 0.008664484900247363
[batch_idx--50] train_loss: 0.0009635253113183175, acc: 0.9000459558823529, lr: 0.00862058643856546
[batch_idx--100] train_loss: 0.0009918550183849021, acc: 0.8950727103960396, lr: 0.0085767762853424
[batch_idx--150] train_loss: 0.0010020925893929375, acc: 0.8935482201986755, lr: 0.008533054676777554
[batch_idx--200] train_loss: 0.0010017819348745864, acc: 0.8935012437810945, lr: 0.008489421848592919
[batch_idx--250] train_loss: 0.0010065116768376344, acc: 0.8932706673306773, lr: 0.008445878036031801
[batch_idx--300] train_loss: 0.0010060643658515351, acc: 0.8931296719269103, lr: 0.008402423473857626
[batch_idx--350] train_loss: 0.0010061031356692696, acc: 0.8930622329059829, lr: 0.008359058396352615
[batch_idx--400] train_loss: 0.0010079860549647723, acc: 0.8925537718204489, lr: 0.008315783037316537
[batch_idx--450] train_loss: 0.00101142185670179, acc: 0.892586871246572, lr: 0.008272597630065468
total time of one epoch: 208.3028531074524 s
train_loss:  0.00101142185670179  acc:  0.892586871246572
->>lr:0.008273
test_loss:  0.000979084730932295  test_acc:  0.8983744881498945
best acc:  90.03598461347562

------Epoch: 110------
[batch_idx--0] train_loss: 0.0011381440563127398, acc: 0.8671875, lr: 0.008271734841028545
[batch_idx--50] train_loss: 0.0010257680573975486, acc: 0.8916207107843137, lr: 0.008228641424457422
[batch_idx--100] train_loss: 0.001018399585932862, acc: 0.8923267326732673, lr: 0.00818563842948918
[batch_idx--150] train_loss: 0.0010120789505023238, acc: 0.8937810430463576, lr: 0.008142726087971458
[batch_idx--200] train_loss: 0.0010078913481229572, acc: 0.8933069029850746, lr: 0.00809990463126313
[batch_idx--250] train_loss: 0.0010010288634979393, acc: 0.8939243027888446, lr: 0.008057174290233077
[batch_idx--300] train_loss: 0.0010003841204021089, acc: 0.8940381021594684, lr: 0.008014535295258926
[batch_idx--350] train_loss: 0.001002534178544653, acc: 0.8937077101139601, lr: 0.00797198787622585
[batch_idx--400] train_loss: 0.0009973324654435744, acc: 0.8942877182044888, lr: 0.007929532262525246
[batch_idx--450] train_loss: 0.001001470025390729, acc: 0.8940535286562293, lr: 0.007887168683053591
total time of one epoch: 206.7365210056305 s
train_loss:  0.001001470025390729  acc:  0.8940535286562293
->>lr:0.007887
test_loss:  0.0009828034406087582  test_acc:  0.897133639409356
best acc:  90.03598461347562

------Epoch: 111------
[batch_idx--0] train_loss: 0.0010317109990864992, acc: 0.90234375, lr: 0.00788632235178279
[batch_idx--50] train_loss: 0.0010286404879069795, acc: 0.8903952205882353, lr: 0.00784405288251919
[batch_idx--100] train_loss: 0.0009962837419260552, acc: 0.8937577351485149, lr: 0.007801875908340622
[batch_idx--150] train_loss: 0.0009989349706567183, acc: 0.8941173427152318, lr: 0.007759791656641275
[batch_idx--200] train_loss: 0.0009962749129985991, acc: 0.8943174751243781, lr: 0.007717800354315446
[batch_idx--250] train_loss: 0.0009982306129889065, acc: 0.8938776145418327, lr: 0.007675902227756282
[batch_idx--300] train_loss: 0.0009990609717010783, acc: 0.8934541112956811, lr: 0.007634097502854598
[batch_idx--350] train_loss: 0.0010039063264745847, acc: 0.8925725605413105, lr: 0.007592386404997634
[batch_idx--400] train_loss: 0.001003708835851466, acc: 0.8928070448877805, lr: 0.007550769159067847
[batch_idx--450] train_loss: 0.0010051166278384769, acc: 0.892691012601104, lr: 0.00750924598944171
total time of one epoch: 210.12855887413025 s
train_loss:  0.0010051166278384769  acc:  0.892691012601104
->>lr:0.007509
test_loss:  0.0009747087726197773  test_acc:  0.9004839310088101
best acc:  90.03598461347562
Saving..

------Epoch: 112------
[batch_idx--0] train_loss: 0.0008975598029792309, acc: 0.90234375, lr: 0.007508416487165862
[batch_idx--50] train_loss: 0.0010093947867954186, acc: 0.8905484068627451, lr: 0.007466989505996053
[batch_idx--100] train_loss: 0.0010018499543899579, acc: 0.893487004950495, lr: 0.007425657052821996
[batch_idx--150] train_loss: 0.0010092898444673478, acc: 0.8931860513245033, lr: 0.007384419350484717
[batch_idx--200] train_loss: 0.0010069331275276024, acc: 0.8927238805970149, lr: 0.0073432766213143985
[batch_idx--250] train_loss: 0.00100657660110605, acc: 0.8928193476095617, lr: 0.007302229087129178
[batch_idx--300] train_loss: 0.000997803432316182, acc: 0.8938564161129569, lr: 0.007261276969233954
[batch_idx--350] train_loss: 0.0009977451405896569, acc: 0.8939302884615384, lr: 0.007220420488419194
[batch_idx--400] train_loss: 0.000996861882052591, acc: 0.8941123753117207, lr: 0.007179659864959754
[batch_idx--450] train_loss: 0.001001781263715644, acc: 0.8942704898115041, lr: 0.007138995318613667
total time of one epoch: 207.96690249443054 s
train_loss:  0.001001781263715644  acc:  0.8942704898115041
->>lr:0.007139
test_loss:  0.001006153939246303  test_acc:  0.8963891301650329
best acc:  90.048393100881

------Epoch: 113------
[batch_idx--0] train_loss: 0.001093139755539596, acc: 0.87109375, lr: 0.007138183009179922
[batch_idx--50] train_loss: 0.0010090303349345193, acc: 0.8918504901960784, lr: 0.007097616687346986
[batch_idx--100] train_loss: 0.0010096289766122503, acc: 0.8915145420792079, lr: 0.00705714688495745
[batch_idx--150] train_loss: 0.0010117058829552438, acc: 0.8915821605960265, lr: 0.007016773820201414
[batch_idx--200] train_loss: 0.0010034628128470732, acc: 0.8927821828358209, lr: 0.00697649771074741
[batch_idx--250] train_loss: 0.0010063309559646802, acc: 0.892508092629482, lr: 0.006936318773741257
[batch_idx--300] train_loss: 0.0009997405766964305, acc: 0.8932724252491694, lr: 0.00689623722580488
[batch_idx--350] train_loss: 0.0009965972317862947, acc: 0.8936965811965812, lr: 0.006856253283035133
[batch_idx--400] train_loss: 0.0009969648905969375, acc: 0.8937811720698254, lr: 0.00681636716100264
[batch_idx--450] train_loss: 0.001001029857389879, acc: 0.8936890339153678, lr: 0.006776579074750619
total time of one epoch: 208.21768736839294 s
train_loss:  0.001001029857389879  acc:  0.8936890339153678
->>lr:0.006777
test_loss:  0.0009796822972652087  test_acc:  0.8983744881498945
best acc:  90.048393100881

------Epoch: 114------
[batch_idx--0] train_loss: 0.0009976726723834872, acc: 0.890625, lr: 0.006775784314464717
[batch_idx--50] train_loss: 0.0009805892272304524, acc: 0.8961397058823529, lr: 0.006736096445698165
[batch_idx--100] train_loss: 0.0009854116470156477, acc: 0.8954207920792079, lr: 0.0066965070454860194
[batch_idx--150] train_loss: 0.0009917500367178428, acc: 0.8942466887417219, lr: 0.006657016327271753
[batch_idx--200] train_loss: 0.0009885915567801886, acc: 0.8952891791044776, lr: 0.006617624503966805
[batch_idx--250] train_loss: 0.0009962797530859975, acc: 0.8942355577689243, lr: 0.006578331787949427
[batch_idx--300] train_loss: 0.0010005742716804097, acc: 0.8932594476744186, lr: 0.006539138391063526
[batch_idx--350] train_loss: 0.0010001237318118732, acc: 0.8935964209401709, lr: 0.006500044524617568
[batch_idx--400] train_loss: 0.000997023989226985, acc: 0.8941903054862843, lr: 0.0064610503993833834
[batch_idx--450] train_loss: 0.0009968145612576705, acc: 0.894418023397091, lr: 0.006422156225595066
total time of one epoch: 208.5757133960724 s
train_loss:  0.0009968145612576705  acc:  0.894418023397091
->>lr:0.006422
test_loss:  0.0009646755558250116  test_acc:  0.9019729494974562
best acc:  90.048393100881
Saving..

------Epoch: 115------
[batch_idx--0] train_loss: 0.0011042385594919324, acc: 0.90625, lr: 0.00642137936306515
[batch_idx--50] train_loss: 0.0009672538738003841, acc: 0.8982077205882353, lr: 0.006382587355775901
[batch_idx--100] train_loss: 0.0009970227677126111, acc: 0.89453125, lr: 0.006343895722960522
[batch_idx--150] train_loss: 0.0009993207236190654, acc: 0.8937551738410596, lr: 0.006305304673222229
[batch_idx--200] train_loss: 0.0010038117029060104, acc: 0.8928210509950248, lr: 0.0062668144146219495
[batch_idx--250] train_loss: 0.0010002893184690154, acc: 0.8930994770916335, lr: 0.006228425154677217
[batch_idx--300] train_loss: 0.0010006131617463754, acc: 0.8933762458471761, lr: 0.0061901371003610295
[batch_idx--350] train_loss: 0.0009961341211885385, acc: 0.8936965811965812, lr: 0.00615195045810075
[batch_idx--400] train_loss: 0.0009964852494552285, acc: 0.8933525561097256, lr: 0.006113865433776986
[batch_idx--450] train_loss: 0.0009982074191992626, acc: 0.8934286805290381, lr: 0.006075882232722457
total time of one epoch: 208.53168034553528 s
train_loss:  0.0009982074191992626  acc:  0.8934286805290381
->>lr:0.006076
test_loss:  0.0009721000265699416  test_acc:  0.9007321007569178
best acc:  90.19729494974563

------Epoch: 116------
[batch_idx--0] train_loss: 0.0009391898638568819, acc: 0.90625, lr: 0.006075123608706093
[batch_idx--50] train_loss: 0.0009899228987028347, acc: 0.8950674019607843, lr: 0.006037244478350651
[batch_idx--100] train_loss: 0.0009803025214471807, acc: 0.895575495049505, lr: 0.00599946758436096
[batch_idx--150] train_loss: 0.0009836846193921635, acc: 0.8958764486754967, lr: 0.005961793130408489
[batch_idx--200] train_loss: 0.0009827526313465887, acc: 0.8959110696517413, lr: 0.005924221319612417
[batch_idx--250] train_loss: 0.0009823732666645302, acc: 0.8958073954183267, lr: 0.005886752354538527
[batch_idx--300] train_loss: 0.0009804304108639369, acc: 0.896374065614618, lr: 0.0058493864371981065
[batch_idx--350] train_loss: 0.0009845070465616457, acc: 0.8957665598290598, lr: 0.005812123769046874
[batch_idx--400] train_loss: 0.0009879809400726324, acc: 0.8953300342892768, lr: 0.005774964550983902
[batch_idx--450] train_loss: 0.0009877499492067785, acc: 0.8956763980976846, lr: 0.005737908983350504
total time of one epoch: 210.10492706298828 s
train_loss:  0.0009877499492067785  acc:  0.8956763980976846
->>lr:0.005738
test_loss:  0.0009740846619178231  test_acc:  0.8977540637796253
best acc:  90.19729494974563

------Epoch: 117------
[batch_idx--0] train_loss: 0.0008595376275479794, acc: 0.91015625, lr: 0.005737168930605272
[batch_idx--50] train_loss: 0.0009973743398600788, acc: 0.8927696078431373, lr: 0.005700219292222111
[batch_idx--100] train_loss: 0.0009972528499173055, acc: 0.8940671410891089, lr: 0.005663373707252357
[batch_idx--150] train_loss: 0.0010059479950150067, acc: 0.8926427980132451, lr: 0.005626632374346372
[batch_idx--200] train_loss: 0.0010028422195626544, acc: 0.8932680348258707, lr: 0.005589995491592479
[batch_idx--250] train_loss: 0.0009958332340025242, acc: 0.894562375498008, lr: 0.005553463256515865
[batch_idx--300] train_loss: 0.0009963940699473394, acc: 0.8947648463455149, lr: 0.005517035866077508
[batch_idx--350] train_loss: 0.0009926336063231286, acc: 0.8951767272079773, lr: 0.0054807135166731365
[batch_idx--400] train_loss: 0.0009899530301400068, acc: 0.8954664120947631, lr: 0.005444496404132135
[batch_idx--450] train_loss: 0.0009941183899369861, acc: 0.8954941507272538, lr: 0.005408384723716528
total time of one epoch: 210.53965735435486 s
train_loss:  0.0009941183899369861  acc:  0.8954941507272538
->>lr:0.005408
test_loss:  0.0009749497354348639  test_acc:  0.9004839310088101
best acc:  90.19729494974563

------Epoch: 118------
[batch_idx--0] train_loss: 0.0009508796501904726, acc: 0.8984375, lr: 0.005407663566854007
[batch_idx--50] train_loss: 0.0010149678621696784, acc: 0.8900122549019608, lr: 0.005371659627775735
[batch_idx--100] train_loss: 0.0009934062513956192, acc: 0.8952660891089109, lr: 0.005335761513517229
[batch_idx--150] train_loss: 0.0009848616658000658, acc: 0.8961351407284768, lr: 0.0052999694176206515
[batch_idx--200] train_loss: 0.0009890376408908756, acc: 0.8957944651741293, lr: 0.005264283533056586
[batch_idx--250] train_loss: 0.0009906664117335887, acc: 0.8950448207171314, lr: 0.0052287040522229575
[batch_idx--300] train_loss: 0.0009851764496555087, acc: 0.8960106935215947, lr: 0.005193231166944048
[batch_idx--350] train_loss: 0.000983352269917631, acc: 0.895744301994302, lr: 0.005157865068469426
[batch_idx--400] train_loss: 0.000982179820881297, acc: 0.8959437344139651, lr: 0.005122605947472936
[batch_idx--450] train_loss: 0.0009877447324813076, acc: 0.8956156489742076, lr: 0.0050874539940516635
total time of one epoch: 206.70254158973694 s
train_loss:  0.0009877447324813076  acc:  0.8956156489742076
->>lr:0.005087
test_loss:  0.000967474901390691  test_acc:  0.8998635066385408
best acc:  90.19729494974563

------Epoch: 119------
[batch_idx--0] train_loss: 0.0008289770339615643, acc: 0.8984375, lr: 0.005086752049395094
[batch_idx--50] train_loss: 0.0009425483420308606, acc: 0.899203431372549, lr: 0.005051709602139323
[batch_idx--100] train_loss: 0.0009473395040535395, acc: 0.8991723391089109, lr: 0.005016774704691432
[batch_idx--150] train_loss: 0.0009583210139319498, acc: 0.8977649006622517, lr: 0.004981947545400465
[batch_idx--200] train_loss: 0.0009625279156384591, acc: 0.8973297574626866, lr: 0.004947228312034608
[batch_idx--250] train_loss: 0.0009639015782112442, acc: 0.8976749252988048, lr: 0.004912617191780173
[batch_idx--300] train_loss: 0.000965232939801281, acc: 0.8978794642857143, lr: 0.004878114371240583
[batch_idx--350] train_loss: 0.0009676105615767807, acc: 0.8978031517094017, lr: 0.004843720036435387
[batch_idx--400] train_loss: 0.0009687495524727942, acc: 0.8978822475062345, lr: 0.004809434372799207
[batch_idx--450] train_loss: 0.0009732537657476644, acc: 0.8975075502482036, lr: 0.004775257565180805
total time of one epoch: 207.7314591407776 s
train_loss:  0.0009732537657476644  acc:  0.8975075502482036
->>lr:0.004775
test_loss:  0.0009658276454170787  test_acc:  0.9017247797493485
best acc:  90.19729494974563

------Epoch: 120------
[batch_idx--0] train_loss: 0.0008219006704166532, acc: 0.9296875, lr: 0.004774575140626317
[batch_idx--50] train_loss: 0.0009584646813534931, acc: 0.9004289215686274, lr: 0.004740509555968578
[batch_idx--100] train_loss: 0.0009593686958000359, acc: 0.8990949876237624, lr: 0.004706553198931926
[batch_idx--150] train_loss: 0.0009642782434512744, acc: 0.8981529387417219, lr: 0.004672706252589681
[batch_idx--200] train_loss: 0.0009702622635053721, acc: 0.8969022077114428, lr: 0.004638968899425284
[batch_idx--250] train_loss: 0.0009730511873244378, acc: 0.8969123505976095, lr: 0.004605341321331294
[batch_idx--300] train_loss: 0.0009734551884478385, acc: 0.896906146179402, lr: 0.004571823699608443
[batch_idx--350] train_loss: 0.0009718604232954057, acc: 0.8968683226495726, lr: 0.0045384162149646355
[batch_idx--400] train_loss: 0.0009729935515595325, acc: 0.8967717425187033, lr: 0.004505119047513989
[batch_idx--450] train_loss: 0.0009790225732403891, acc: 0.8965529211649946, lr: 0.0044719323767758445
total time of one epoch: 209.2794508934021 s
train_loss:  0.0009790225732403891  acc:  0.8965529211649946
->>lr:0.004472
test_loss:  0.0009755621992309538  test_acc:  0.9006080158828639
best acc:  90.19729494974563

------Epoch: 121------
[batch_idx--0] train_loss: 0.0009732210310176015, acc: 0.89453125, lr: 0.004471269771657399
[batch_idx--50] train_loss: 0.0009793250424349133, acc: 0.8975183823529411, lr: 0.004438195991889007
[batch_idx--100] train_loss: 0.0009778265531248606, acc: 0.8979347153465347, lr: 0.004405233069644058
[batch_idx--150] train_loss: 0.0009786925357242195, acc: 0.8978942466887417, lr: 0.004372381182639854
[batch_idx--200] train_loss: 0.0009740778191168028, acc: 0.8977961753731343, lr: 0.004339640507995033
[batch_idx--250] train_loss: 0.000979267682488711, acc: 0.8969434760956175, lr: 0.00430701122222864
[batch_idx--300] train_loss: 0.0009765423417781353, acc: 0.8972435631229236, lr: 0.004274493501259191
[batch_idx--350] train_loss: 0.0009777149836601759, acc: 0.8970018696581197, lr: 0.004242087520403681
[batch_idx--400] train_loss: 0.000974079523470132, acc: 0.8972782886533666, lr: 0.004209793454376692
[batch_idx--450] train_loss: 0.0009709471180327926, acc: 0.8977679036345333, lr: 0.0041776114772894115
total time of one epoch: 206.77976322174072 s
train_loss:  0.0009709471180327926  acc:  0.8977679036345333
->>lr:0.004178
test_loss:  0.0009770417593596133  test_acc:  0.8986226578980022
best acc:  90.19729494974563

------Epoch: 122------
[batch_idx--0] train_loss: 0.0007292498485185206, acc: 0.91015625, lr: 0.004176968982247515
[batch_idx--50] train_loss: 0.0009859572529938875, acc: 0.8955269607843137, lr: 0.004144901514621361
[batch_idx--100] train_loss: 0.0009759150682902424, acc: 0.8982054455445545, lr: 0.0041129464857952575
[batch_idx--150] train_loss: 0.0009782974602845775, acc: 0.8977907698675497, lr: 0.004081104068052505
[batch_idx--200] train_loss: 0.0009781360132179561, acc: 0.8973880597014925, lr: 0.00404937443306925
[batch_idx--250] train_loss: 0.0009775040594701362, acc: 0.8970524153386454, lr: 0.004017757751913604
[batch_idx--300] train_loss: 0.0009771783794028889, acc: 0.8973214285714286, lr: 0.003986254195044678
[batch_idx--350] train_loss: 0.0009783092429171557, acc: 0.8967125178062678, lr: 0.003954863932311695
[batch_idx--400] train_loss: 0.0009779053145933646, acc: 0.896723036159601, lr: 0.003923587132953052
[batch_idx--450] train_loss: 0.0009751636964914704, acc: 0.8972558753080848, lr: 0.003892423965595415
total time of one epoch: 208.868008852005 s
train_loss:  0.0009751636964914704  acc:  0.8972558753080848
->>lr:0.003892
test_loss:  0.0009600385156336339  test_acc:  0.9020970343715101
best acc:  90.19729494974563
Saving..

------Epoch: 123------
[batch_idx--0] train_loss: 0.0008752220310270786, acc: 0.90234375, lr: 0.003891801862449629
[batch_idx--50] train_loss: 0.0009252641706124824, acc: 0.90234375, lr: 0.003860754772816863
[batch_idx--100] train_loss: 0.0009521250918479913, acc: 0.899636448019802, lr: 0.0038298216539413596
[batch_idx--150] train_loss: 0.0009616597525510222, acc: 0.8990066225165563, lr: 0.0037990026725968685
[batch_idx--200] train_loss: 0.000964270376157831, acc: 0.8983597636815921, lr: 0.003768297994941761
[batch_idx--250] train_loss: 0.0009646861126601874, acc: 0.8982818725099602, lr: 0.0037377077865181603
[batch_idx--300] train_loss: 0.0009622518460504538, acc: 0.8981130606312292, lr: 0.003707232212251013
[batch_idx--350] train_loss: 0.0009627816948225123, acc: 0.8982816951566952, lr: 0.003676871436447249
[batch_idx--400] train_loss: 0.0009632398471052751, acc: 0.8980088840399002, lr: 0.0036466256227948553
[batch_idx--450] train_loss: 0.0009651523500243309, acc: 0.898062970805707, lr: 0.003616494934362016
total time of one epoch: 208.1138994693756 s
train_loss:  0.0009651523500243309  acc:  0.898062970805707
->>lr:0.003616
test_loss:  0.0009626582854733986  test_acc:  0.9016006948752947
best acc:  90.209703437151

------Epoch: 124------
[batch_idx--0] train_loss: 0.0009619625052437186, acc: 0.89453125, lr: 0.003615893495987335
[batch_idx--50] train_loss: 0.0009944744764224572, acc: 0.8961397058823529, lr: 0.003585880402627581
[batch_idx--100] train_loss: 0.0009866281191237493, acc: 0.8968904702970297, lr: 0.0035559827619909834
[batch_idx--150] train_loss: 0.0009766970348655437, acc: 0.8979459850993378, lr: 0.0035262007352685563
[batch_idx--200] train_loss: 0.0009729163923917051, acc: 0.898456934079602, lr: 0.003496534483028016
[batch_idx--250] train_loss: 0.0009742504998251232, acc: 0.8982351842629482, lr: 0.0034669841652128805
[batch_idx--300] train_loss: 0.0009768335139023084, acc: 0.897217607973422, lr: 0.00343754994114161
[batch_idx--350] train_loss: 0.0009721112192112242, acc: 0.8978142806267806, lr: 0.0034082319695067616
[batch_idx--400] train_loss: 0.0009702637180816058, acc: 0.8977750935162094, lr: 0.003379030408374123
[batch_idx--450] train_loss: 0.0009731101755730565, acc: 0.8975769778178915, lr: 0.00334994541518186
total time of one epoch: 208.03351259231567 s
train_loss:  0.0009731101755730565  acc:  0.8975769778178915
->>lr:0.003350
test_loss:  0.0009586566145980102  test_acc:  0.8994912520163793
best acc:  90.209703437151

------Epoch: 125------
[batch_idx--0] train_loss: 0.00100775808095932, acc: 0.8984375, lr: 0.003349364905389038
[batch_idx--50] train_loss: 0.0009610737655677047, acc: 0.899203431372549, lr: 0.003320398973036992
[batch_idx--100] train_loss: 0.000961816827028916, acc: 0.899791150990099, lr: 0.0032915499247325843
[batch_idx--150] train_loss: 0.0009645380932430656, acc: 0.898463369205298, lr: 0.003262817916013447
[batch_idx--200] train_loss: 0.00096707139685472, acc: 0.898418065920398, lr: 0.0032342031017861847
[batch_idx--250] train_loss: 0.0009660902001757724, acc: 0.8979550547808764, lr: 0.003205705636325565
[batch_idx--300] train_loss: 0.0009622966450642163, acc: 0.8985283430232558, lr: 0.0031773256732736594
[batch_idx--350] train_loss: 0.0009590412924222733, acc: 0.8990829772079773, lr: 0.0031490633656390573
[batch_idx--400] train_loss: 0.0009587549192522028, acc: 0.8991291302992519, lr: 0.0031209188657960046
[batch_idx--450] train_loss: 0.0009644388609128729, acc: 0.898913458534384, lr: 0.0030928923254835983
total time of one epoch: 207.7874391078949 s
train_loss:  0.0009644388609128729  acc:  0.898913458534384
->>lr:0.003093
test_loss:  0.0009578481225965041  test_acc:  0.9037101377342102
best acc:  90.209703437151
Saving..

------Epoch: 126------
[batch_idx--0] train_loss: 0.0008142091101035476, acc: 0.90625, lr: 0.0030923329989034107
[batch_idx--50] train_loss: 0.0009480620067858813, acc: 0.9005821078431373, lr: 0.003064426932974329
[batch_idx--100] train_loss: 0.0009503800515315985, acc: 0.9006033415841584, lr: 0.003036639131148192
[batch_idx--150] train_loss: 0.000958793340574654, acc: 0.8986185844370861, lr: 0.003008969743240972
[batch_idx--200] train_loss: 0.0009607054042370425, acc: 0.8980876865671642, lr: 0.002981418918430234
[batch_idx--250] train_loss: 0.000963836473754173, acc: 0.8980328685258964, lr: 0.002953986805254319
[batch_idx--300] train_loss: 0.0009634477319195867, acc: 0.8977626661129569, lr: 0.002926673551611542
[batch_idx--350] train_loss: 0.0009589200904738805, acc: 0.8980925035612536, lr: 0.002899479304759398
[batch_idx--400] train_loss: 0.0009587329362073165, acc: 0.8979699189526185, lr: 0.0028724042113137424
[batch_idx--450] train_loss: 0.0009591162686326111, acc: 0.8982799319609817, lr: 0.002845448417248059
total time of one epoch: 210.77725052833557 s
train_loss:  0.0009591162686326111  acc:  0.8982799319609817
->>lr:0.002845
test_loss:  0.0009544872904048692  test_acc:  0.9025933738677255
best acc:  90.37101377342103

------Epoch: 127------
[batch_idx--0] train_loss: 0.0008145248866640031, acc: 0.921875, lr: 0.0028449105192196373
[batch_idx--50] train_loss: 0.0009728884495630422, acc: 0.8988204656862745, lr: 0.0028180765602363435
[batch_idx--100] train_loss: 0.0009591147928305044, acc: 0.9003712871287128, lr: 0.0027913621935367313
[batch_idx--150] train_loss: 0.0009587894907739285, acc: 0.8997050910596026, lr: 0.002764767563149445
[batch_idx--200] train_loss: 0.0009533221293611461, acc: 0.900516946517413, lr: 0.002738292812457563
[batch_idx--250] train_loss: 0.0009528626295908603, acc: 0.900413969123506, lr: 0.00271193808419784
[batch_idx--300] train_loss: 0.0009486605177333337, acc: 0.9007215531561462, lr: 0.002685703520459948
[batch_idx--350] train_loss: 0.0009492168899829847, acc: 0.9002849002849003, lr: 0.0026595892626856965
[batch_idx--400] train_loss: 0.0009499630891367273, acc: 0.9000350685785536, lr: 0.0026335954516682747
[batch_idx--450] train_loss: 0.0009530868749691446, acc: 0.8995643420002083, lr: 0.0026077222275514957
total time of one epoch: 209.00098371505737 s
train_loss:  0.0009530868749691446  acc:  0.8995643420002083
->>lr:0.002608
test_loss:  0.0009633168931308552  test_acc:  0.9016006948752947
best acc:  90.37101377342103

------Epoch: 128------
[batch_idx--0] train_loss: 0.0009020993602462113, acc: 0.9140625, lr: 0.0026072059940146775
[batch_idx--50] train_loss: 0.0009323003400555428, acc: 0.9039522058823529, lr: 0.002581455912238459
[batch_idx--100] train_loss: 0.0009382248684385847, acc: 0.9030399133663366, lr: 0.0025558266984695406
[batch_idx--150] train_loss: 0.0009515583164379346, acc: 0.9007398592715232, lr: 0.002530318490886033
[batch_idx--200] train_loss: 0.0009441346066786134, acc: 0.9015469527363185, lr: 0.0025049314270136516
[batch_idx--250] train_loss: 0.0009467644773264122, acc: 0.901285483067729, lr: 0.0024796656437249655
[batch_idx--300] train_loss: 0.0009507620324260026, acc: 0.9005268895348837, lr: 0.0024545212772386807
[batch_idx--350] train_loss: 0.0009506809907604508, acc: 0.9005631232193733, lr: 0.0024294984631188735
[batch_idx--400] train_loss: 0.0009539899627615389, acc: 0.9000253273067331, lr: 0.0024045973362742893
[batch_idx--450] train_loss: 0.0009555810461186831, acc: 0.899850730725171, lr: 0.0023798180309576172
total time of one epoch: 209.1317720413208 s
train_loss:  0.0009555810461186831  acc:  0.899850730725171
->>lr:0.002380
test_loss:  0.0009575195722388251  test_acc:  0.903089713363941
best acc:  90.37101377342103

------Epoch: 129------
[batch_idx--0] train_loss: 0.0007974280742928386, acc: 0.91796875, lr: 0.0023793236883495163
[batch_idx--50] train_loss: 0.0009866343975505408, acc: 0.8962928921568627, lr: 0.002354668778617275
[batch_idx--100] train_loss: 0.000982042082175059, acc: 0.8953047648514851, lr: 0.0023301359595992556
[batch_idx--150] train_loss: 0.0009770460545535612, acc: 0.8962644867549668, lr: 0.0023057253635624278
[batch_idx--200] train_loss: 0.0009620867531158179, acc: 0.8986512748756219, lr: 0.0022814371221148186
[batch_idx--250] train_loss: 0.0009576041465699376, acc: 0.8990288844621513, lr: 0.0022572713662047635
[batch_idx--300] train_loss: 0.0009646485432010899, acc: 0.8978145764119602, lr: 0.0022332282261202457
[batch_idx--350] train_loss: 0.0009629868755005619, acc: 0.8978699252136753, lr: 0.0022093078314881667
[batch_idx--400] train_loss: 0.0009587230888065275, acc: 0.8985543952618454, lr: 0.002185510311273653
[batch_idx--450] train_loss: 0.0009604972059556138, acc: 0.8986964973791093, lr: 0.0021618357937793764
total time of one epoch: 206.98619723320007 s
train_loss:  0.0009604972059556138  acc:  0.8986964973791093
->>lr:0.002162
test_loss:  0.0009570255929208716  test_acc:  0.903089713363941
best acc:  90.37101377342103

------Epoch: 130------
[batch_idx--0] train_loss: 0.0008675529388710856, acc: 0.91015625, lr: 0.0021613635589349755
[batch_idx--50] train_loss: 0.0009610196130405016, acc: 0.8980545343137255, lr: 0.0021378146357049848
[batch_idx--100] train_loss: 0.0009441452866217287, acc: 0.8998685024752475, lr: 0.0021143889723431067
[batch_idx--150] train_loss: 0.0009536972525375371, acc: 0.8992653145695364, lr: 0.0020910866951471623
[batch_idx--200] train_loss: 0.0009588504213589563, acc: 0.8989233519900498, lr: 0.0020679079297497515
[batch_idx--250] train_loss: 0.0009571335960710161, acc: 0.8992000747011952, lr: 0.0020448528011175527
[batch_idx--300] train_loss: 0.0009584708641704011, acc: 0.8986710963455149, lr: 0.0020219214335506857
[batch_idx--350] train_loss: 0.0009589897366864156, acc: 0.8986155626780626, lr: 0.0019991139506819965
[batch_idx--400] train_loss: 0.0009549286478069004, acc: 0.8993239557356608, lr: 0.001976430475476429
[batch_idx--450] train_loss: 0.0009628488041532157, acc: 0.8992519179366126, lr: 0.0019538711302303584
total time of one epoch: 210.26251196861267 s
train_loss:  0.0009628488041532157  acc:  0.8992519179366126
->>lr:0.001954
test_loss:  0.0009459374297536444  test_acc:  0.9035860528601564
best acc:  90.37101377342103

------Epoch: 131------
[batch_idx--0] train_loss: 0.0007525577093474567, acc: 0.9296875, lr: 0.00195342121028749
[batch_idx--50] train_loss: 0.0009221498381949085, acc: 0.9041053921568627, lr: 0.001930988602895767
[batch_idx--100] train_loss: 0.0009337980980237964, acc: 0.9019569925742574, lr: 0.001908680370460203
[batch_idx--150] train_loss: 0.0009365816872770473, acc: 0.9015159354304636, lr: 0.0018864966332540673
[batch_idx--200] train_loss: 0.0009391334400725416, acc: 0.9008278917910447, lr: 0.0018644375108794243
[batch_idx--250] train_loss: 0.0009454348610632448, acc: 0.90035171812749, lr: 0.0018425031222664813
[batch_idx--300] train_loss: 0.000946575838784715, acc: 0.9000596968438538, lr: 0.0018206935856729584
[batch_idx--350] train_loss: 0.0009463216291549496, acc: 0.9001736111111112, lr: 0.0017990090186834396
[batch_idx--400] train_loss: 0.0009488199205785766, acc: 0.9000350685785536, lr: 0.0017774495382087503
[batch_idx--450] train_loss: 0.0009481746030410616, acc: 0.9001457978963446, lr: 0.001756015260485311
total time of one epoch: 207.07513213157654 s
train_loss:  0.0009481746030410616  acc:  0.9001457978963446
->>lr:0.001756
test_loss:  0.0009425966962866872  test_acc:  0.9025933738677255
best acc:  90.37101377342103

------Epoch: 132------
[batch_idx--0] train_loss: 0.0008543800213374197, acc: 0.890625, lr: 0.0017555878527937164
[batch_idx--50] train_loss: 0.0009557249255058374, acc: 0.8982843137254902, lr: 0.0017342814009232738
[batch_idx--100] train_loss: 0.000922554166812339, acc: 0.9028078589108911, lr: 0.0017131003845420657
[batch_idx--150] train_loss: 0.0009324188997185734, acc: 0.9018263658940397, lr: 0.0016920449178460556
[batch_idx--200] train_loss: 0.0009345213276802085, acc: 0.9013137437810945, lr: 0.0016711151143543159
[batch_idx--250] train_loss: 0.0009385805973130097, acc: 0.9013321713147411, lr: 0.0016503110869084154
[batch_idx--300] train_loss: 0.0009411400428855562, acc: 0.9010070598006644, lr: 0.0016296329476718054
[batch_idx--350] train_loss: 0.0009400541894137859, acc: 0.9015981125356125, lr: 0.0016090808081292208
[batch_idx--400] train_loss: 0.0009361662341054167, acc: 0.9021878896508728, lr: 0.0015886547790860768
[batch_idx--450] train_loss: 0.0009415434145096064, acc: 0.9018814871385428, lr: 0.0015683549706678873
total time of one epoch: 207.77725195884705 s
train_loss:  0.0009415434145096064  acc:  0.9018814871385428
->>lr:0.001568
test_loss:  0.0009553853798214356  test_acc:  0.9019729494974562
best acc:  90.37101377342103

------Epoch: 133------
[batch_idx--0] train_loss: 0.0008977364632301033, acc: 0.9140625, lr: 0.0015679502627027138
[batch_idx--50] train_loss: 0.0009337307020163565, acc: 0.9013480392156863, lr: 0.0015477793120675237
[batch_idx--100] train_loss: 0.0009261337166541431, acc: 0.9028852103960396, lr: 0.0015277348024344995
[batch_idx--150] train_loss: 0.0009377777440757151, acc: 0.9015159354304636, lr: 0.001507816841872195
[batch_idx--200] train_loss: 0.0009419799971148668, acc: 0.9011777052238806, lr: 0.0014880255377669072
[batch_idx--250] train_loss: 0.0009428505807562149, acc: 0.9006318476095617, lr: 0.0014683609968220602
[batch_idx--300] train_loss: 0.0009395094641385309, acc: 0.9009940822259136, lr: 0.0014488233250576467
[batch_idx--350] train_loss: 0.0009358368304550138, acc: 0.9013532763532763, lr: 0.0014294126278096538
[batch_idx--400] train_loss: 0.0009409871236583742, acc: 0.9008630766832918, lr: 0.0014101290097294967
[batch_idx--450] train_loss: 0.0009454376808051064, acc: 0.9008313951470128, lr: 0.0013909725747834447
total time of one epoch: 208.4717915058136 s
train_loss:  0.0009454376808051064  acc:  0.9008313951470128
->>lr:0.001391
test_loss:  0.0009526838449675062  test_acc:  0.9018488646234024
best acc:  90.37101377342103

------Epoch: 134------
[batch_idx--0] train_loss: 0.0008237074362114072, acc: 0.90234375, lr: 0.001390590744062975
[batch_idx--50] train_loss: 0.0009519588533222821, acc: 0.9010416666666666, lr: 0.0013715641423086456
[batch_idx--100] train_loss: 0.0009382380602540135, acc: 0.9019183168316832, lr: 0.0013526649316081968
[batch_idx--150] train_loss: 0.000938691682990221, acc: 0.9016711506622517, lr: 0.0013338932138554
[batch_idx--200] train_loss: 0.0009380277180789381, acc: 0.9019939365671642, lr: 0.0013152490902566538
[batch_idx--250] train_loss: 0.0009391253607243715, acc: 0.9016123007968128, lr: 0.0012967326613304436
[batch_idx--300] train_loss: 0.0009403424472872947, acc: 0.9014093646179402, lr: 0.0012783440269067943
[batch_idx--350] train_loss: 0.0009409612102070532, acc: 0.9015090811965812, lr: 0.0012600832861267342
[batch_idx--400] train_loss: 0.0009471804138442543, acc: 0.900999454488778, lr: 0.0012419505374417718
[batch_idx--450] train_loss: 0.0009454914161811109, acc: 0.9012479605651404, lr: 0.0012239458786133446
total time of one epoch: 208.6871531009674 s
train_loss:  0.0009454914161811109  acc:  0.9012479605651404
->>lr:0.001224
test_loss:  0.0009557607544756865  test_acc:  0.8998635066385408
best acc:  90.37101377342103

------Epoch: 135------
[batch_idx--0] train_loss: 0.000898726808372885, acc: 0.8984375, lr: 0.0012235870926211618
[batch_idx--50] train_loss: 0.0009460235927619186, acc: 0.8992800245098039, lr: 0.0012057131854440546
[batch_idx--100] train_loss: 0.0009276478800295603, acc: 0.9019569925742574, lr: 0.0011879675634946297
[batch_idx--150] train_loss: 0.0009257400332061907, acc: 0.9027059188741722, lr: 0.0011703503224471529
[batch_idx--200] train_loss: 0.0009322701834619453, acc: 0.9020522388059702, lr: 0.001152861557283752
[batch_idx--250] train_loss: 0.0009358168062030438, acc: 0.9018613047808764, lr: 0.0011355013622938726
[batch_idx--300] train_loss: 0.0009372494567535273, acc: 0.901344476744186, lr: 0.0011182698310737928
[batch_idx--350] train_loss: 0.0009372196856095453, acc: 0.9015090811965812, lr: 0.0011011670565261005
[batch_idx--400] train_loss: 0.0009363495291586957, acc: 0.9017105673316709, lr: 0.0010841931308592041
[batch_idx--450] train_loss: 0.0009401075240142741, acc: 0.9015256708438921, lr: 0.00106734814558683
total time of one epoch: 204.76790022850037 s
train_loss:  0.0009401075240142741  acc:  0.9015256708438921
->>lr:0.001067
test_loss:  0.0009481493119700018  test_acc:  0.9012284402531331
best acc:  90.37101377342103

------Epoch: 136------
[batch_idx--0] train_loss: 0.0012338506057858467, acc: 0.87890625, lr: 0.001067012561698319
[batch_idx--50] train_loss: 0.0009965141858522069, acc: 0.8938419117647058, lr: 0.0010502991891848613
[batch_idx--100] train_loss: 0.0009711675511875956, acc: 0.8980507425742574, lr: 0.0010337149398027378
[batch_idx--150] train_loss: 0.0009649167028533307, acc: 0.898463369205298, lr: 0.001017259902964765
[batch_idx--200] train_loss: 0.0009580420976532484, acc: 0.8989816542288557, lr: 0.0010009341673871241
[batch_idx--250] train_loss: 0.0009545639022327663, acc: 0.8996825199203188, lr: 0.000984737821088863
[batch_idx--300] train_loss: 0.00094954167323286, acc: 0.9001245847176079, lr: 0.000968670951391451
[batch_idx--350] train_loss: 0.000947407303023765, acc: 0.9005186075498576, lr: 0.0009527336449182884
[batch_idx--400] train_loss: 0.000945871652909868, acc: 0.9006779925187033, lr: 0.0009369259875942449
[batch_idx--450] train_loss: 0.0009470396868921549, acc: 0.900701218453848, lr: 0.0009212480646451971
total time of one epoch: 208.72039079666138 s
train_loss:  0.0009470396868921549  acc:  0.900701218453848
->>lr:0.000921
test_loss:  0.0009518205779319751  test_acc:  0.9011043553790793
best acc:  90.37101377342103

------Epoch: 137------
[batch_idx--0] train_loss: 0.0010529388673603535, acc: 0.875, lr: 0.0009209358300585474
[batch_idx--50] train_loss: 0.0009286885375759619, acc: 0.901577818627451, lr: 0.0009053903232463079
[batch_idx--100] train_loss: 0.0009341784585774461, acc: 0.901144801980198, lr: 0.0008899747208313852
[batch_idx--150] train_loss: 0.0009361646201350535, acc: 0.9006105132450332, lr: 0.0008746891059259105
[batch_idx--200] train_loss: 0.0009366844283226896, acc: 0.9017801616915423, lr: 0.0008595335609412142
[batch_idx--250] train_loss: 0.0009371275873019905, acc: 0.9007096613545816, lr: 0.0008445081675873518
[batch_idx--300] train_loss: 0.0009343089637164014, acc: 0.9012795888704319, lr: 0.0008296130068726787
[batch_idx--350] train_loss: 0.0009389191141559018, acc: 0.9009748931623932, lr: 0.0008148481591034013
[batch_idx--400] train_loss: 0.0009367388948633282, acc: 0.9013598815461347, lr: 0.0008002137038831625
[batch_idx--450] train_loss: 0.0009419921522170381, acc: 0.9010743916409206, lr: 0.000785709720112604
total time of one epoch: 209.29464602470398 s
train_loss:  0.0009419921522170381  acc:  0.9010743916409206
->>lr:0.000786
test_loss:  0.0009504340266394459  test_acc:  0.9008561856309716
best acc:  90.37101377342103

------Epoch: 138------
[batch_idx--0] train_loss: 0.001016243826597929, acc: 0.88671875, lr: 0.0007854209717842232
[batch_idx--50] train_loss: 0.0009380565686881834, acc: 0.9003523284313726, lr: 0.0007710501494462701
[batch_idx--100] train_loss: 0.0009325346229413506, acc: 0.9028852103960396, lr: 0.0007568099557912517
[batch_idx--150] train_loss: 0.0009248690357407099, acc: 0.9041545943708609, lr: 0.000742700467594179
[batch_idx--200] train_loss: 0.0009345307303893737, acc: 0.9030239427860697, lr: 0.0007287217609253605
[batch_idx--250] train_loss: 0.0009388346776952485, acc: 0.9023281872509961, lr: 0.0007148739111500131
[batch_idx--300] train_loss: 0.0009414635134932037, acc: 0.9022399294019934, lr: 0.0007011569929278511
[batch_idx--350] train_loss: 0.0009436162742202374, acc: 0.9015758547008547, lr: 0.0006875710802126706
[batch_idx--400] train_loss: 0.0009444544985692976, acc: 0.9011845386533666, lr: 0.0006741162462519713
[batch_idx--450] train_loss: 0.0009450867131197759, acc: 0.9009789287325997, lr: 0.0006607925635865458
total time of one epoch: 209.41395711898804 s
train_loss:  0.0009450867131197759  acc:  0.9009789287325997
->>lr:0.000661
test_loss:  0.0009494148419444445  test_acc:  0.9023452041196178
best acc:  90.37101377342103

------Epoch: 139------
[batch_idx--0] train_loss: 0.0006376547389663756, acc: 0.92578125, lr: 0.0006605274281709927
[batch_idx--50] train_loss: 0.0009286272540396335, acc: 0.9034926470588235, lr: 0.0006473375938249676
[batch_idx--100] train_loss: 0.0009260582455231042, acc: 0.9037747524752475, lr: 0.0006342790551494393
[batch_idx--150] train_loss: 0.0009271026510338219, acc: 0.9037665562913907, lr: 0.0006213518825486042
[batch_idx--200] train_loss: 0.0009305099620766456, acc: 0.9030045087064676, lr: 0.0006085561457184031
[batch_idx--250] train_loss: 0.0009392286797862989, acc: 0.9022192480079682, lr: 0.0005958919136461599
[batch_idx--300] train_loss: 0.0009391566296030715, acc: 0.9022399294019934, lr: 0.000583359254610194
[batch_idx--350] train_loss: 0.000937442129419485, acc: 0.9020989138176638, lr: 0.0005709582361794502
[batch_idx--400] train_loss: 0.0009399160771500644, acc: 0.9016326371571073, lr: 0.0005586889252131494
[batch_idx--450] train_loss: 0.000938995276503186, acc: 0.9019162009233866, lr: 0.0005465513878604278
total time of one epoch: 206.24841284751892 s
train_loss:  0.000938995276503186  acc:  0.9019162009233866
->>lr:0.000547
test_loss:  0.0009494592440396063  test_acc:  0.9034619679861025
best acc:  90.37101377342103

------Epoch: 140------
[batch_idx--0] train_loss: 0.0007477949257008731, acc: 0.9375, lr: 0.0005463099816548578
[batch_idx--50] train_loss: 0.000915293507597537, acc: 0.903109681372549, lr: 0.0005343069207980278
[batch_idx--100] train_loss: 0.0009359203343565512, acc: 0.9002939356435643, lr: 0.0005224357650086414
[batch_idx--150] train_loss: 0.0009413767380127992, acc: 0.9007139900662252, lr: 0.0005106965782891965
[batch_idx--200] train_loss: 0.0009438091540356997, acc: 0.9007501554726368, lr: 0.0004990894239306987
[batch_idx--250] train_loss: 0.0009455150533634501, acc: 0.9006629731075697, lr: 0.0004876143645123038
[batch_idx--300] train_loss: 0.0009461768059310599, acc: 0.9003971137873754, lr: 0.00047627146190098725
[batch_idx--350] train_loss: 0.0009476007444935286, acc: 0.9002403846153846, lr: 0.00046506077725121944
[batch_idx--400] train_loss: 0.0009438257743987694, acc: 0.9009604894014963, lr: 0.00045398237100461594
[batch_idx--450] train_loss: 0.0009448456834622415, acc: 0.9012826743499843, lr: 0.0004430363028896239
total time of one epoch: 206.39467859268188 s
train_loss:  0.0009448456834622415  acc:  0.9012826743499843
->>lr:0.000443
test_loss:  0.000954325398598257  test_acc:  0.9019729494974562
best acc:  90.37101377342103

------Epoch: 141------
[batch_idx--0] train_loss: 0.0008315475424751639, acc: 0.9140625, lr: 0.00044281873178278475
[batch_idx--50] train_loss: 0.0009204489897991367, acc: 0.9039522058823529, lr: 0.0004320077093543484
[batch_idx--100] train_loss: 0.0009232511228678914, acc: 0.904586943069307, lr: 0.0004213291435323757
[batch_idx--150] train_loss: 0.0009409662201963611, acc: 0.9021626655629139, lr: 0.0004107830918895994
[batch_idx--200] train_loss: 0.0009360882237586031, acc: 0.9018773320895522, lr: 0.00040036961128431806
[batch_idx--250] train_loss: 0.0009374686315529553, acc: 0.9014722360557769, lr: 0.00039008875786008537
[batch_idx--300] train_loss: 0.0009368047892870969, acc: 0.901655938538206, lr: 0.00037994058704539927
[batch_idx--350] train_loss: 0.0009367681560146376, acc: 0.9021211716524217, lr: 0.0003699251535534104
[batch_idx--400] train_loss: 0.0009386254784574458, acc: 0.9019638403990025, lr: 0.0003600425113816253
[batch_idx--450] train_loss: 0.0009439060597764534, acc: 0.901586419967369, lr: 0.0003502927138116147
total time of one epoch: 206.73058009147644 s
train_loss:  0.0009439060597764534  acc:  0.901586419967369
->>lr:0.000350
test_loss:  0.0009511450851269788  test_acc:  0.9020970343715101
best acc:  90.37101377342103

------Epoch: 142------
[batch_idx--0] train_loss: 0.0008889574673958123, acc: 0.91015625, lr: 0.00035009907323737546
[batch_idx--50] train_loss: 0.0009466210989665021, acc: 0.9005821078431373, lr: 0.00034048483130907914
[batch_idx--100] train_loss: 0.0009317490696390667, acc: 0.9013381806930693, lr: 0.00033100353942642217
[batch_idx--150] train_loss: 0.0009318403140271687, acc: 0.9009726821192053, lr: 0.0003216552487071145
[batch_idx--200] train_loss: 0.0009289548668051277, acc: 0.9011194029850746, lr: 0.00031244000955181765
[batch_idx--250] train_loss: 0.0009257292395375995, acc: 0.9018768675298805, lr: 0.00030335787164384453
[batch_idx--300] train_loss: 0.0009243972382919733, acc: 0.9021880191029901, lr: 0.00029440888394890454
[batch_idx--350] train_loss: 0.0009280622933800212, acc: 0.9018318198005698, lr: 0.00028559309471483943
[batch_idx--400] train_loss: 0.0009284619566522298, acc: 0.9018859102244389, lr: 0.00027691055147135437
[batch_idx--450] train_loss: 0.0009311881959572815, acc: 0.9018554517999098, lr: 0.0002683613010297709
total time of one epoch: 206.43108320236206 s
train_loss:  0.0009311881959572815  acc:  0.9018554517999098
->>lr:0.000268
test_loss:  0.0009525474953672137  test_acc:  0.9032137982379947
best acc:  90.37101377342103

------Epoch: 143------
[batch_idx--0] train_loss: 0.001071467180736363, acc: 0.8828125, lr: 0.0002681916759252945
[batch_idx--50] train_loss: 0.000938659690220055, acc: 0.9019607843137255, lr: 0.00025977843162139916
[batch_idx--100] train_loss: 0.0009391988716364865, acc: 0.9008353960396039, lr: 0.0002514985724860308
[batch_idx--150] train_loss: 0.0009388667037895579, acc: 0.9004294288079471, lr: 0.00024335214315946986
[batch_idx--200] train_loss: 0.0009474676367085408, acc: 0.8998756218905473, lr: 0.00023533918756261376
[batch_idx--250] train_loss: 0.0009488777268633424, acc: 0.9000249003984063, lr: 0.00022745974889675503
[batch_idx--300] train_loss: 0.000944701214460192, acc: 0.900578799833887, lr: 0.0002197138696433315
[batch_idx--350] train_loss: 0.0009436100902781422, acc: 0.9007634437321937, lr: 0.0002121015915637098
[batch_idx--400] train_loss: 0.0009375992042367855, acc: 0.9012916926433915, lr: 0.0002046229556989493
[batch_idx--450] train_loss: 0.0009420566325732768, acc: 0.9012045683340855, lr: 0.00019727800236959416
total time of one epoch: 205.10910630226135 s
train_loss:  0.0009420566325732768  acc:  0.9012045683340855
->>lr:0.000197
test_loss:  0.000951997901565281  test_acc:  0.9028415436158332
best acc:  90.37101377342103

------Epoch: 144------
[batch_idx--0] train_loss: 0.0010654596844688058, acc: 0.890625, lr: 0.0001971324671380531
[batch_idx--50] train_loss: 0.0009731497905472768, acc: 0.8975183823529411, lr: 0.00018992391078557493
[batch_idx--100] train_loss: 0.000942971903743167, acc: 0.9008353960396039, lr: 0.00018284911621737067
[batch_idx--150] train_loss: 0.0009243890711735465, acc: 0.9026800496688742, lr: 0.00017590812157669555
[batch_idx--200] train_loss: 0.000917476746983437, acc: 0.9036069651741293, lr: 0.00016910096428543743
[batch_idx--250] train_loss: 0.0009219373425142283, acc: 0.9026705677290837, lr: 0.00016242768104390848
[batch_idx--300] train_loss: 0.0009248620227901296, acc: 0.9023307724252492, lr: 0.00015588830783064834
[batch_idx--350] train_loss: 0.0009244027548533283, acc: 0.9023660078347578, lr: 0.0001494828799022241
[batch_idx--400] train_loss: 0.0009253443356085466, acc: 0.9025775405236908, lr: 0.00014321143179305552
[batch_idx--450] train_loss: 0.0009310582905700505, acc: 0.9023067310028813, lr: 0.00013707399731520964
total time of one epoch: 208.48743271827698 s
train_loss:  0.0009310582905700505  acc:  0.9023067310028813
->>lr:0.000137
test_loss:  0.0009504746475117957  test_acc:  0.9023452041196178
best acc:  90.37101377342103

------Epoch: 145------
[batch_idx--0] train_loss: 0.000990656903013587, acc: 0.90234375, lr: 0.00013695261579316776
[batch_idx--50] train_loss: 0.0009327110498869682, acc: 0.9002757352941176, lr: 0.0001309519093031647
[batch_idx--100] train_loss: 0.0009481116038940773, acc: 0.8986308787128713, lr: 0.0001250852825408405
[batch_idx--150] train_loss: 0.0009407652746300084, acc: 0.8996792218543046, lr: 0.0001193527671357053
[batch_idx--200] train_loss: 0.0009377683033304873, acc: 0.900400342039801, lr: 0.00011375439399421428
[batch_idx--250] train_loss: 0.0009371965357837123, acc: 0.9010209163346613, lr: 0.00010829019329959833
[batch_idx--300] train_loss: 0.0009359532638075468, acc: 0.9007864410299004, lr: 0.00010296019451171701
[batch_idx--350] train_loss: 0.0009344831807870535, acc: 0.9010750534188035, lr: 9.776442636688366e-05
[batch_idx--400] train_loss: 0.0009336016640796366, acc: 0.9012429862842892, lr: 9.270291687771548e-05
[batch_idx--450] train_loss: 0.0009364091471827142, acc: 0.9013521019196723, lr: 8.77756933329893e-05
total time of one epoch: 206.29094886779785 s
train_loss:  0.0009364091471827142  acc:  0.9013521019196723
->>lr:0.000088
test_loss:  0.0009515166804074265  test_acc:  0.9024692889936716
best acc:  90.37101377342103

------Epoch: 146------
[batch_idx--0] train_loss: 0.0009603744838386774, acc: 0.890625, lr: 8.767851876239075e-05
[batch_idx--50] train_loss: 0.0009315831497695078, acc: 0.90234375, lr: 8.288829424305533e-05
[batch_idx--100] train_loss: 0.0009404552505711223, acc: 0.9011061262376238, lr: 7.82324085830094e-05
[batch_idx--150] train_loss: 0.0009311516672860066, acc: 0.902317880794702, lr: 7.371088688413186e-05
[batch_idx--200] train_loss: 0.0009303538262524378, acc: 0.9025380907960199, lr: 6.93237535238922e-05
[batch_idx--250] train_loss: 0.0009344632925643805, acc: 0.9015656125498008, lr: 6.507103215520893e-05
[batch_idx--300] train_loss: 0.0009314750336293144, acc: 0.902265884551495, lr: 6.09527457063358e-05
[batch_idx--350] train_loss: 0.0009307900508016645, acc: 0.9023882656695157, lr: 5.6968916380720215e-05
[batch_idx--400] train_loss: 0.0009295625138639977, acc: 0.9026165056109726, lr: 5.311956565690057e-05
[batch_idx--450] train_loss: 0.0009355396407358259, acc: 0.902497656819523, lr: 4.9404714288381335e-05
total time of one epoch: 208.53580498695374 s
train_loss:  0.0009355396407358259  acc:  0.902497656819523
->>lr:0.000049
test_loss:  0.0009511327910680661  test_acc:  0.9028415436158332
best acc:  90.37101377342103

------Epoch: 147------
[batch_idx--0] train_loss: 0.0007788583170622587, acc: 0.94140625, lr: 4.933178929321103e-05
[batch_idx--50] train_loss: 0.0009287085039449819, acc: 0.9016544117647058, lr: 4.57541478953355e-05
[batch_idx--100] train_loss: 0.0009171671567180443, acc: 0.9039294554455446, lr: 4.231104556289278e-05
[batch_idx--150] train_loss: 0.0009135681590749974, acc: 0.9048530629139073, lr: 3.9002500859128264e-05
[batch_idx--200] train_loss: 0.0009229610009762963, acc: 0.9039956467661692, lr: 3.582853162182598e-05
[batch_idx--250] train_loss: 0.0009280457704020033, acc: 0.9030751992031872, lr: 3.2789154963222546e-05
[batch_idx--300] train_loss: 0.0009295731072044897, acc: 0.9026033014950167, lr: 2.9884387269901725e-05
[batch_idx--350] train_loss: 0.0009355298507138768, acc: 0.9017761752136753, lr: 2.7114244202716688e-05
[batch_idx--400] train_loss: 0.0009369182532787917, acc: 0.9015936720698254, lr: 2.4478740696695647e-05
[batch_idx--450] train_loss: 0.000935475021232423, acc: 0.9018207380150658, lr: 2.1977890960975244e-05
total time of one epoch: 207.41805577278137 s
train_loss:  0.000935475021232423  acc:  0.9018207380150658
->>lr:0.000022
test_loss:  0.0009525563225347952  test_acc:  0.9028415436158332
best acc:  90.37101377342103

------Epoch: 148------
[batch_idx--0] train_loss: 0.0009123085765168071, acc: 0.89453125, lr: 2.192924752854042e-05
[batch_idx--50] train_loss: 0.0009624113970180499, acc: 0.8962928921568627, lr: 1.9565758523884538e-05
[batch_idx--100] train_loss: 0.0009482815420245844, acc: 0.8988242574257426, lr: 1.7336949777524425e-05
[batch_idx--150] train_loss: 0.0009446775491367902, acc: 0.8995240066225165, lr: 1.524283330592846e-05
[batch_idx--200] train_loss: 0.0009439933769386354, acc: 0.8996229788557214, lr: 1.3283420399376467e-05
[batch_idx--250] train_loss: 0.0009436898125498834, acc: 0.8995424551792829, lr: 1.14587216219042e-05
[batch_idx--300] train_loss: 0.0009433644020425595, acc: 0.8998520556478405, lr: 9.768746811253394e-06
[batch_idx--350] train_loss: 0.0009458734298342483, acc: 0.8996839387464387, lr: 8.213505078799587e-06
[batch_idx--400] train_loss: 0.0009444094729839715, acc: 0.9000740336658354, lr: 6.793004809518832e-06
[batch_idx--450] train_loss: 0.0009442938515432103, acc: 0.900779324469747, lr: 5.507253661940492e-06
total time of one epoch: 205.2458233833313 s
train_loss:  0.0009442938515432103  acc:  0.900779324469747
->>lr:0.000006
test_loss:  0.0009527236282389104  test_acc:  0.9024692889936716
best acc:  90.37101377342103

------Epoch: 149------
[batch_idx--0] train_loss: 0.0008613414247520268, acc: 0.90625, lr: 5.482913128862511e-06
[batch_idx--50] train_loss: 0.0009421191803709257, acc: 0.9030330882352942, lr: 4.334613221818051e-06
[batch_idx--100] train_loss: 0.0009486284112732969, acc: 0.9013381806930693, lr: 3.321075690718156e-06
[batch_idx--150] train_loss: 0.000935450252160948, acc: 0.9025765728476821, lr: 2.4423059999861833e-06
[batch_idx--200] train_loss: 0.0009370446784319865, acc: 0.9024409203980099, lr: 1.6983088874406029e-06
[batch_idx--250] train_loss: 0.0009371990236394345, acc: 0.9022192480079682, lr: 1.089088364294999e-06
[batch_idx--300] train_loss: 0.0009328123128685197, acc: 0.9025513911960132, lr: 6.146477151164343e-07
[batch_idx--350] train_loss: 0.0009322811931005528, acc: 0.9026331018518519, lr: 2.749894978198997e-07
[batch_idx--400] train_loss: 0.0009344480085497876, acc: 0.9018956514962594, lr: 7.011554364610984e-08
[batch_idx--450] train_loss: 0.0009379731544552133, acc: 0.9020463776165515, lr: 2.6957161503027296e-11
total time of one epoch: 206.55084872245789 s
train_loss:  0.0009379731544552133  acc:  0.9020463776165515
->>lr:0.000000
test_loss:  0.0009511177660232887  test_acc:  0.9025933738677255
best acc:  90.37101377342103