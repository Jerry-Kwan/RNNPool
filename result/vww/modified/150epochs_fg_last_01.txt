Model: mobilenet_fg_last
Batch size: 256
Number of dataloader workers: 32

loading annotations into memory...
Done (t=4.53s)
creating index...
index created!
Len of trainloader: 451

loading annotations into memory...
Done (t=0.81s)
creating index...
index created!
Len of testloader: 32

use 4 GPUs!
DataParallel device_ids: [0, 1, 2, 3]

------Epoch: 0------
[batch_idx--0] train_loss: 0.002693600719794631, acc: 0.53515625, lr: 0.05
[batch_idx--50] train_loss: 0.0030436898472116273, acc: 0.5054381127450981, lr: 0.04999993260712715
[batch_idx--100] train_loss: 0.0028564038981526794, acc: 0.537708849009901, lr: 0.04999973042887193
[batch_idx--150] train_loss: 0.002781540382073711, acc: 0.5576883278145696, lr: 0.049999393466324364
[batch_idx--200] train_loss: 0.002714723901155947, acc: 0.5782027363184079, lr: 0.04999892172130118
[batch_idx--250] train_loss: 0.0026648487799255495, acc: 0.5932208665338645, lr: 0.04999831519634575
[batch_idx--300] train_loss: 0.002622283710494786, acc: 0.6047420058139535, lr: 0.0499975738947281
[batch_idx--350] train_loss: 0.0025836402176218666, acc: 0.6161079950142451, lr: 0.04999669782044491
[batch_idx--400] train_loss: 0.002550409770596243, acc: 0.6251363778054863, lr: 0.049995686978219496
[batch_idx--450] train_loss: 0.0025244836495726857, acc: 0.6331447217690145, lr: 0.04999454137350172
total time of one epoch: 1435.2362232208252 s
train_loss:  0.0025244836495726857  acc:  0.6331447217690145
->>lr:0.049995
test_loss:  0.004385475862971428  test_acc:  0.5284774785953592
best acc:  0
Saving..
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(

------Epoch: 1------
[batch_idx--0] train_loss: 0.002271909499540925, acc: 0.6953125, lr: 0.04999451708687114
[batch_idx--50] train_loss: 0.002241569292713322, acc: 0.7093290441176471, lr: 0.04999323403077913
[batch_idx--100] train_loss: 0.002233627028671084, acc: 0.7101639851485149, lr: 0.04999181622541965
[batch_idx--150] train_loss: 0.0022315967177343092, acc: 0.7093077400662252, lr: 0.0499902636784367
[batch_idx--200] train_loss: 0.0022280730031412187, acc: 0.7093244713930348, lr: 0.04998857639820074
[batch_idx--250] train_loss: 0.0022161208989239663, acc: 0.7110620019920318, lr: 0.04998675439380862
[batch_idx--300] train_loss: 0.0022030989388065825, acc: 0.7127543604651163, lr: 0.04998479767508354
[batch_idx--350] train_loss: 0.002189191120299922, acc: 0.7152666488603988, lr: 0.04998270625257502
[batch_idx--400] train_loss: 0.0021794186675679543, acc: 0.7168504519950125, lr: 0.04998048013755882
[batch_idx--450] train_loss: 0.0021776600375879632, acc: 0.7181501024056652, lr: 0.049978119342036866
total time of one epoch: 263.1619784832001 s
train_loss:  0.0021776600375879632  acc:  0.7181501024056652
->>lr:0.049978
test_loss:  0.0021945838819353025  test_acc:  0.7193200148901849
best acc:  52.84774785953592
Saving..

------Epoch: 2------
[batch_idx--0] train_loss: 0.001969078788533807, acc: 0.765625, lr: 0.04997807075247146
[batch_idx--50] train_loss: 0.0020901909732606774, acc: 0.7313878676470589, lr: 0.04997557259595109
[batch_idx--100] train_loss: 0.0020764179488570234, acc: 0.7347230816831684, lr: 0.04997293978538365
[batch_idx--150] train_loss: 0.0020696709228568517, acc: 0.7369101821192053, lr: 0.04997017233496374
[batch_idx--200] train_loss: 0.002058938223247727, acc: 0.7390974813432836, lr: 0.04996727025961189
[batch_idx--250] train_loss: 0.0020505417638321025, acc: 0.7407868525896414, lr: 0.04996423357497442
[batch_idx--300] train_loss: 0.002040144698879994, acc: 0.7429012666112956, lr: 0.04996106229742341
[batch_idx--350] train_loss: 0.0020375323605901453, acc: 0.7435674857549858, lr: 0.04995775644405658
[batch_idx--400] train_loss: 0.0020336592448015984, acc: 0.7435025716957606, lr: 0.049954316032697205
[batch_idx--450] train_loss: 0.002027578923733442, acc: 0.7449231089665707, lr: 0.049950741081894026
total time of one epoch: 228.0538411140442 s
train_loss:  0.002027578923733442  acc:  0.7449231089665707
->>lr:0.049951
test_loss:  0.0019588900834251713  test_acc:  0.7616329569425487
best acc:  71.93200148901849
Saving..

------Epoch: 3------
[batch_idx--0] train_loss: 0.0018455522367730737, acc: 0.7734375, lr: 0.04995066821070679
[batch_idx--50] train_loss: 0.0019713471342316445, acc: 0.7555912990196079, lr: 0.04994695604953209
[batch_idx--100] train_loss: 0.0019531138794551981, acc: 0.757503094059406, lr: 0.0499431093885944
[batch_idx--150] train_loss: 0.001949586499241853, acc: 0.7575538079470199, lr: 0.04993912824863275
[batch_idx--200] train_loss: 0.00194805738891461, acc: 0.7580457089552238, lr: 0.049935012651111166
[batch_idx--250] train_loss: 0.00194836184484476, acc: 0.7576257470119522, lr: 0.0499307626182186
[batch_idx--300] train_loss: 0.0019495814065588174, acc: 0.757124688538206, lr: 0.0499263781728688
[batch_idx--350] train_loss: 0.0019466788859565628, acc: 0.7578347578347578, lr: 0.04992185933870021
[batch_idx--400] train_loss: 0.0019444396560825872, acc: 0.7578514650872819, lr: 0.049917206140075804
[batch_idx--450] train_loss: 0.001944964847232565, acc: 0.758999548720797, lr: 0.04991241860208297
total time of one epoch: 223.06337237358093 s
train_loss:  0.001944964847232565  acc:  0.758999548720797
->>lr:0.049912
test_loss:  0.00196471248981837  test_acc:  0.7616329569425487
best acc:  76.16329569425487

------Epoch: 4------
[batch_idx--0] train_loss: 0.001935055130161345, acc: 0.76171875, lr: 0.049912321481237615
[batch_idx--50] train_loss: 0.0019180542314607724, acc: 0.7618719362745098, lr: 0.04990739694368515
[batch_idx--100] train_loss: 0.001900227785359441, acc: 0.7641166460396039, lr: 0.04990233811964985
[batch_idx--150] train_loss: 0.001897867875395725, acc: 0.7644350165562914, lr: 0.049897145036406014
[batch_idx--200] train_loss: 0.0018893813190805674, acc: 0.7652751865671642, lr: 0.04989181772195179
[batch_idx--250] train_loss: 0.0018818382390837864, acc: 0.7667299551792829, lr: 0.04988635620500901
[batch_idx--300] train_loss: 0.001876149945381868, acc: 0.7680518064784053, lr: 0.049880760515023076
[batch_idx--350] train_loss: 0.0018704084057939315, acc: 0.7692307692307693, lr: 0.04987503068216274
[batch_idx--400] train_loss: 0.0018643146750059658, acc: 0.7702813279301746, lr: 0.04986916673732
[batch_idx--450] train_loss: 0.0018648082495757855, acc: 0.7709931613843858, lr: 0.049863168712109905
total time of one epoch: 223.29905462265015 s
train_loss:  0.0018648082495757855  acc:  0.7709931613843858
->>lr:0.049863
test_loss:  0.0018528403367841194  test_acc:  0.7791289241841419
best acc:  76.16329569425487
Saving..

------Epoch: 5------
[batch_idx--0] train_loss: 0.0015630883863195777, acc: 0.8359375, lr: 0.049863047384206834
[batch_idx--50] train_loss: 0.0018569578293382244, acc: 0.7712928921568627, lr: 0.04985691263034154
[batch_idx--100] train_loss: 0.0018300608326081592, acc: 0.7758353960396039, lr: 0.049850643862176046
[batch_idx--150] train_loss: 0.0018247128063381113, acc: 0.777240273178808, lr: 0.04984424111350797
[batch_idx--200] train_loss: 0.0018243728743041333, acc: 0.7776158271144279, lr: 0.0498377044188573
[batch_idx--250] train_loss: 0.0018174445216703522, acc: 0.7788533366533864, lr: 0.04983103381346615
[batch_idx--300] train_loss: 0.0018150822736749865, acc: 0.7793552740863787, lr: 0.049824229333298636
[batch_idx--350] train_loss: 0.0018113386967190225, acc: 0.7798811431623932, lr: 0.049817291015040614
[batch_idx--400] train_loss: 0.001812876034946067, acc: 0.7797595854114713, lr: 0.04981021889609956
[batch_idx--450] train_loss: 0.0018106370742224924, acc: 0.7808171624952268, lr: 0.0498030130146043
total time of one epoch: 233.30764174461365 s
train_loss:  0.0018106370742224924  acc:  0.7808171624952268
->>lr:0.049803
test_loss:  0.0018309147508228103  test_acc:  0.779997518302519
best acc:  77.9128924184142
Saving..

------Epoch: 6------
[batch_idx--0] train_loss: 0.0018000411801040173, acc: 0.76953125, lr: 0.04980286753286195
[batch_idx--50] train_loss: 0.0017828955018308525, acc: 0.7809436274509803, lr: 0.04979552525358963
[batch_idx--100] train_loss: 0.0017801596711638687, acc: 0.7832611386138614, lr: 0.04978804929098283
[batch_idx--150] train_loss: 0.0017705498909306348, acc: 0.7856218956953642, lr: 0.049780439685347705
[batch_idx--200] train_loss: 0.001765950486777508, acc: 0.7869636194029851, lr: 0.0497726964777109
[batch_idx--250] train_loss: 0.0017582035834058764, acc: 0.7884244272908366, lr: 0.049764819709819365
[batch_idx--300] train_loss: 0.0017591588790110773, acc: 0.7879464285714286, lr: 0.04975680942414015
[batch_idx--350] train_loss: 0.0017585195587719777, acc: 0.7877826745014245, lr: 0.04974866566386016
[batch_idx--400] train_loss: 0.001758638808870702, acc: 0.7878935473815462, lr: 0.049740388472885894
[batch_idx--450] train_loss: 0.0017598531282870496, acc: 0.7881417710973028, lr: 0.04973197789584324
total time of one epoch: 234.6391899585724 s
train_loss:  0.0017598531282870496  acc:  0.7881417710973028
->>lr:0.049732
test_loss:  0.0017405138860078408  test_acc:  0.7929023452041196
best acc:  77.9997518302519
Saving..

------Epoch: 7------
[batch_idx--0] train_loss: 0.0017591953510418534, acc: 0.7734375, lr: 0.049731808324074714
[batch_idx--50] train_loss: 0.0017313709866036387, acc: 0.7918964460784313, lr: 0.04972326173996171
[batch_idx--100] train_loss: 0.0017358514740786488, acc: 0.7916924504950495, lr: 0.049714581862117906
[batch_idx--150] train_loss: 0.001739489933821243, acc: 0.7910026903973509, lr: 0.049705768737340256
[batch_idx--200] train_loss: 0.0017335147206527898, acc: 0.7921525186567164, lr: 0.04969682241314409
[batch_idx--250] train_loss: 0.0017291259153215475, acc: 0.7926730577689243, lr: 0.0496877429377629
[batch_idx--300] train_loss: 0.0017308350896116259, acc: 0.7922549833887044, lr: 0.04967853036014805
[batch_idx--350] train_loss: 0.0017268328530782903, acc: 0.7931468126780626, lr: 0.04966918472996849
[batch_idx--400] train_loss: 0.00172174196955086, acc: 0.7944494233167082, lr: 0.04965970609761053
[batch_idx--450] train_loss: 0.001718879039069401, acc: 0.7952841323289478, lr: 0.04965009451417756
total time of one epoch: 232.55292010307312 s
train_loss:  0.001718879039069401  acc:  0.7952841323289478
->>lr:0.049650
test_loss:  0.0017853685260514258  test_acc:  0.7896761384787194
best acc:  79.29023452041196

------Epoch: 8------
[batch_idx--0] train_loss: 0.0016102754743769765, acc: 0.828125, lr: 0.04964990092676263
[batch_idx--50] train_loss: 0.001727566926502714, acc: 0.7939644607843137, lr: 0.0496401537866232
[batch_idx--100] train_loss: 0.001707052353234722, acc: 0.7974551361386139, lr: 0.04963027380082368
[batch_idx--150] train_loss: 0.0017019438824079783, acc: 0.7970819536423841, lr: 0.04962026102263131
[batch_idx--200] train_loss: 0.001703463721816516, acc: 0.7967195273631841, lr: 0.04961011550602926
[batch_idx--250] train_loss: 0.0016987457049572729, acc: 0.7976998256972112, lr: 0.04959983730571641
[batch_idx--300] train_loss: 0.0016993489917027347, acc: 0.7980819144518272, lr: 0.04958942647710693
[batch_idx--350] train_loss: 0.001696111579316846, acc: 0.798355146011396, lr: 0.04957888307633007
[batch_idx--400] train_loss: 0.0016944739312058932, acc: 0.7985602400249376, lr: 0.04956820716022985
[batch_idx--450] train_loss: 0.0016966049235502807, acc: 0.7989204012913528, lr: 0.049557398786364705
total time of one epoch: 229.97763633728027 s
train_loss:  0.0016966049235502807  acc:  0.7989204012913528
->>lr:0.049557
test_loss:  0.0016608572927771527  test_acc:  0.8082888695867974
best acc:  79.29023452041196
Saving..

------Epoch: 9------
[batch_idx--0] train_loss: 0.0015464534517377615, acc: 0.83203125, lr: 0.049557181268217225
[batch_idx--50] train_loss: 0.0016854830319061875, acc: 0.8030790441176471, lr: 0.04954623784746919
[batch_idx--100] train_loss: 0.0016721428399628932, acc: 0.8046101485148515, lr: 0.04953516208740226
[batch_idx--150] train_loss: 0.0016682013577861798, acc: 0.8036009933774835, lr: 0.049523954047730606
[batch_idx--200] train_loss: 0.0016680991060485071, acc: 0.8035214552238806, lr: 0.04951261378888158
[batch_idx--250] train_loss: 0.0016636647162513725, acc: 0.8040183017928287, lr: 0.049501141371995405
[batch_idx--300] train_loss: 0.0016643055157729756, acc: 0.8038180024916943, lr: 0.0494895368589248
[batch_idx--350] train_loss: 0.0016640126977137096, acc: 0.8041199252136753, lr: 0.0494778003122347
[batch_idx--400] train_loss: 0.0016597747658158738, acc: 0.8045706047381546, lr: 0.049465931795201847
[batch_idx--450] train_loss: 0.0016593113251928695, acc: 0.8047002464678724, lr: 0.049453931371814544
total time of one epoch: 250.90423321723938 s
train_loss:  0.0016593113251928695  acc:  0.8047002464678724
->>lr:0.049454
test_loss:  0.0016155963515596334  test_acc:  0.8148653679116515
best acc:  80.82888695867973
Saving..

------Epoch: 10------
[batch_idx--0] train_loss: 0.0017658515134826303, acc: 0.81640625, lr: 0.049453690018345146
[batch_idx--50] train_loss: 0.001604118614968862, acc: 0.8098192401960784, lr: 0.04944155511713453
[batch_idx--100] train_loss: 0.0016350463058080265, acc: 0.805731745049505, lr: 0.04942928844099462
[batch_idx--150] train_loss: 0.0016353477682264535, acc: 0.8066276903973509, lr: 0.0494168900560603
[batch_idx--200] train_loss: 0.0016329374016072619, acc: 0.8073499689054726, lr: 0.04940436002917662
[batch_idx--250] train_loss: 0.0016377048735762853, acc: 0.80660171812749, lr: 0.04939169842789834
[batch_idx--300] train_loss: 0.0016329376064890691, acc: 0.8079189161129569, lr: 0.04937890532048959
[batch_idx--350] train_loss: 0.0016355408595057678, acc: 0.8072360220797721, lr: 0.04936598077592351
[batch_idx--400] train_loss: 0.0016318441858106383, acc: 0.8075806577306733, lr: 0.049352924863881875
[batch_idx--450] train_loss: 0.001634055285684791, acc: 0.8081455896136356, lr: 0.04933973765475472
total time of one epoch: 241.35753774642944 s
train_loss:  0.001634055285684791  acc:  0.8081455896136356
->>lr:0.049340
test_loss:  0.0015586531366392526  test_acc:  0.8216900359846134
best acc:  81.48653679116515
Saving..

------Epoch: 11------
[batch_idx--0] train_loss: 0.0016657795058563352, acc: 0.8125, lr: 0.04933947257182901
[batch_idx--50] train_loss: 0.0016037632104045913, acc: 0.8149509803921569, lr: 0.04932615151292455
[batch_idx--100] train_loss: 0.0016116554731281825, acc: 0.8133895420792079, lr: 0.04931269930128121
[batch_idx--150] train_loss: 0.0016127658440478591, acc: 0.8128362996688742, lr: 0.04929911600942565
[batch_idx--200] train_loss: 0.001621285397837411, acc: 0.8108675373134329, lr: 0.04928540171059123
[batch_idx--250] train_loss: 0.0016215786660661498, acc: 0.8102589641434262, lr: 0.04927155647871764
[batch_idx--300] train_loss: 0.0016190274019085144, acc: 0.8101770141196013, lr: 0.04925758038845046
[batch_idx--350] train_loss: 0.0016162506446635028, acc: 0.8104077635327636, lr: 0.04924347351514081
[batch_idx--400] train_loss: 0.0016163282474953486, acc: 0.8105420043640897, lr: 0.049229235934844906
[batch_idx--450] train_loss: 0.0016221908934122902, acc: 0.8108098726004096, lr: 0.04921486772432365
total time of one epoch: 247.82324123382568 s
train_loss:  0.0016221908934122902  acc:  0.8108098726004096
->>lr:0.049215
test_loss:  0.0015418743218924749  test_acc:  0.8276461099391984
best acc:  82.16900359846134
Saving..

------Epoch: 12------
[batch_idx--0] train_loss: 0.001599812414497137, acc: 0.8046875, lr: 0.04921457902821578
[batch_idx--50] train_loss: 0.001690146447086305, acc: 0.7998621323529411, lr: 0.04920007765467417
[batch_idx--100] train_loss: 0.001639791227194785, acc: 0.8063892326732673, lr: 0.049185445808112044
[batch_idx--150] train_loss: 0.0016251612995868388, acc: 0.8077918046357616, lr: 0.049170683567415975
[batch_idx--200] train_loss: 0.0016168650594164632, acc: 0.808768656716418, lr: 0.04915579101217554
[batch_idx--250] train_loss: 0.0016101196689338264, acc: 0.8097298306772909, lr: 0.04914076822268292
[batch_idx--300] train_loss: 0.0016122017959999137, acc: 0.8088662790697675, lr: 0.04912561527993242
[batch_idx--350] train_loss: 0.0016083144456774336, acc: 0.8099180911680912, lr: 0.049110332265620074
[batch_idx--400] train_loss: 0.0016045584860130066, acc: 0.8102302836658354, lr: 0.049094919262143176
[batch_idx--450] train_loss: 0.001606261051373186, acc: 0.8111049397715833, lr: 0.049079376352599846
total time of one epoch: 230.37293148040771 s
train_loss:  0.001606261051373186  acc:  0.8111049397715833
->>lr:0.049079
test_loss:  0.0017575714794958418  test_acc:  0.7906688174711503
best acc:  82.76461099391985

------Epoch: 13------
[batch_idx--0] train_loss: 0.0015536496648564935, acc: 0.80859375, lr: 0.049079064169941455
[batch_idx--50] train_loss: 0.0015886302640223328, acc: 0.8146446078431373, lr: 0.04906338884254441
[batch_idx--100] train_loss: 0.0015623006764522726, acc: 0.8175665222772277, lr: 0.04904758377907498
[batch_idx--150] train_loss: 0.0015647408540132425, acc: 0.8168977649006622, lr: 0.04903164906474507
[batch_idx--200] train_loss: 0.0015778507335361704, acc: 0.8147349191542289, lr: 0.04901558478546556
[batch_idx--250] train_loss: 0.0015732028143131639, acc: 0.8158926792828686, lr: 0.04899939102784589
[batch_idx--300] train_loss: 0.001576782506271776, acc: 0.8153031561461794, lr: 0.04898306787919357
[batch_idx--350] train_loss: 0.001575365850630288, acc: 0.815727386039886, lr: 0.04896661542751371
[batch_idx--400] train_loss: 0.0015693764072236722, acc: 0.8163965087281796, lr: 0.04895003376150854
[batch_idx--450] train_loss: 0.0015743761519148916, acc: 0.8165376470996633, lr: 0.04893332297057697
total time of one epoch: 246.77367615699768 s
train_loss:  0.0015743761519148916  acc:  0.8165376470996633
->>lr:0.048933
test_loss:  0.001543880407590401  test_acc:  0.8256607519543367
best acc:  82.76461099391985

------Epoch: 14------
[batch_idx--0] train_loss: 0.0014666938222944736, acc: 0.8515625, lr: 0.048932987438301684
[batch_idx--50] train_loss: 0.0015393814400714986, acc: 0.8235294117647058, lr: 0.04891614503276587
[batch_idx--100] train_loss: 0.0015594788658718514, acc: 0.8204672029702971, lr: 0.04889917368501234
[batch_idx--150] train_loss: 0.0015759053270005628, acc: 0.8167684188741722, lr: 0.04888207348654094
[batch_idx--200] train_loss: 0.0015654025607468997, acc: 0.8184468283582089, lr: 0.048864844529546175
[batch_idx--250] train_loss: 0.0015640299409197503, acc: 0.8183049053784861, lr: 0.04884748690691675
[batch_idx--300] train_loss: 0.0015590340494676385, acc: 0.819170473421927, lr: 0.048830000712235096
[batch_idx--350] train_loss: 0.0015572393996285492, acc: 0.8193220263532763, lr: 0.048812386039776785
[batch_idx--400] train_loss: 0.0015515672560302805, acc: 0.8203125, lr: 0.0487946429845101
[batch_idx--450] train_loss: 0.0015535160628109823, acc: 0.8207206581733606, lr: 0.048776771642095464
total time of one epoch: 223.30797934532166 s
train_loss:  0.0015535160628109823  acc:  0.8207206581733606
->>lr:0.048777
test_loss:  0.0015825954142124484  test_acc:  0.8262811763246061
best acc:  82.76461099391985

------Epoch: 15------
[batch_idx--0] train_loss: 0.001558133284561336, acc: 0.80078125, lr: 0.048776412907378844
[batch_idx--50] train_loss: 0.0015216585061531148, acc: 0.8246017156862745, lr: 0.04875841081133997
[batch_idx--100] train_loss: 0.0015272483480909822, acc: 0.8234065594059405, lr: 0.04874028062349638
[batch_idx--150] train_loss: 0.0015242228489554185, acc: 0.8246067880794702, lr: 0.0487220224415957
[batch_idx--200] train_loss: 0.0015401086597402224, acc: 0.8218866604477612, lr: 0.04870363636407563
[batch_idx--250] train_loss: 0.001537202602341415, acc: 0.822242280876494, lr: 0.04868512249006343
[batch_idx--300] train_loss: 0.0015369180061597613, acc: 0.8224278446843853, lr: 0.048666480919375345
[batch_idx--350] train_loss: 0.0015400043022725997, acc: 0.8220374821937322, lr: 0.0486477117525161
[batch_idx--400] train_loss: 0.0015343732915893012, acc: 0.822611440149626, lr: 0.04862881509067834
[batch_idx--450] train_loss: 0.0015383842307935217, acc: 0.8225084180928247, lr: 0.04860979103574209
total time of one epoch: 242.3184244632721 s
train_loss:  0.0015383842307935217  acc:  0.8225084180928247
->>lr:0.048610
test_loss:  0.0016311829106981368  test_acc:  0.815361707407867
best acc:  82.76461099391985

------Epoch: 16------
[batch_idx--0] train_loss: 0.0014888409059494734, acc: 0.82421875, lr: 0.04860940925593703
[batch_idx--50] train_loss: 0.0015365038838639272, acc: 0.8207720588235294, lr: 0.048590255365709406
[batch_idx--100] train_loss: 0.001530469496651451, acc: 0.821975556930693, lr: 0.04857097429027534
[batch_idx--150] train_loss: 0.0015231399482350475, acc: 0.8236237582781457, lr: 0.0485515661335874
[batch_idx--200] train_loss: 0.00152229171348226, acc: 0.8244908271144279, lr: 0.048532031000283304
[batch_idx--250] train_loss: 0.0015184568520449843, acc: 0.8247790089641435, lr: 0.048512368995685354
[batch_idx--300] train_loss: 0.0015227097288498105, acc: 0.8236607142857143, lr: 0.04849258022579986
[batch_idx--350] train_loss: 0.0015178912168665871, acc: 0.8242855235042735, lr: 0.04847266479731658
[batch_idx--400] train_loss: 0.0015134559633637641, acc: 0.8246278834164589, lr: 0.048452622817608176
[batch_idx--450] train_loss: 0.0015209194043991397, acc: 0.824009789287326, lr: 0.04843245439472954
total time of one epoch: 233.41683220863342 s
train_loss:  0.0015209194043991397  acc:  0.824009789287326
->>lr:0.048432
test_loss:  0.0015264435565298582  test_acc:  0.8302518922943293
best acc:  82.76461099391985
Saving..

------Epoch: 17------
[batch_idx--0] train_loss: 0.001328737591393292, acc: 0.86328125, lr: 0.04843204973729729
[batch_idx--50] train_loss: 0.0015191073123109983, acc: 0.8224571078431373, lr: 0.048411752454410206
[batch_idx--100] train_loss: 0.001524438147921816, acc: 0.8213180693069307, lr: 0.0483913289487026
[batch_idx--150] train_loss: 0.0015138509044954121, acc: 0.8237789735099338, lr: 0.04837077933028638
[batch_idx--200] train_loss: 0.0015100531357650955, acc: 0.8246657338308457, lr: 0.04835010370995336
[batch_idx--250] train_loss: 0.001512411973008745, acc: 0.8244677539840638, lr: 0.0483293021991747
[batch_idx--300] train_loss: 0.0015121662573102997, acc: 0.8252699335548173, lr: 0.04830837491010029
[batch_idx--350] train_loss: 0.001511144843164757, acc: 0.8256321225071225, lr: 0.04828732195555814
[batch_idx--400] train_loss: 0.0015127419963237502, acc: 0.8256312344139651, lr: 0.04826614344905377
[batch_idx--450] train_loss: 0.0015139710110908258, acc: 0.8256847294060471, lr: 0.04824483950476961
total time of one epoch: 238.01590609550476 s
train_loss:  0.0015139710110908258  acc:  0.8256847294060471
->>lr:0.048245
test_loss:  0.001884207005594871  test_acc:  0.7803697729246805
best acc:  83.02518922943293

------Epoch: 18------
[batch_idx--0] train_loss: 0.0014280794421210885, acc: 0.8515625, lr: 0.04824441214720629
[batch_idx--50] train_loss: 0.0015076265222959075, acc: 0.8229932598039216, lr: 0.04822298037471885
[batch_idx--100] train_loss: 0.0015120548634135192, acc: 0.823909344059406, lr: 0.04820142339716232
[batch_idx--150] train_loss: 0.0014978871011600786, acc: 0.8260037251655629, lr: 0.04817974133075961
[batch_idx--200] train_loss: 0.0015066176113111907, acc: 0.8252098880597015, lr: 0.04815793429240808
[batch_idx--250] train_loss: 0.0015010418949196064, acc: 0.8256505229083665, lr: 0.04813600239967885
[batch_idx--300] train_loss: 0.0015010099287185064, acc: 0.8262432516611296, lr: 0.04811394577081616
[batch_idx--350] train_loss: 0.0014978190943694268, acc: 0.8270566239316239, lr: 0.04809176452473679
[batch_idx--400] train_loss: 0.0014951718547857574, acc: 0.8275015586034913, lr: 0.048069458781029376
[batch_idx--450] train_loss: 0.0014984861875468442, acc: 0.8281060158989134, lr: 0.048047028659953764
total time of one epoch: 214.00321459770203 s
train_loss:  0.0014984861875468442  acc:  0.8281060158989134
->>lr:0.048047
test_loss:  0.0016277658131714568  test_acc:  0.8130040948008438
best acc:  83.02518922943293

------Epoch: 19------
[batch_idx--0] train_loss: 0.001465272274799645, acc: 0.83984375, lr: 0.04804657878971252
[batch_idx--50] train_loss: 0.0014662930408638774, acc: 0.8300398284313726, lr: 0.04802402192830846
[batch_idx--100] train_loss: 0.0014624808463129667, acc: 0.8329594678217822, lr: 0.04800134093450581
[batch_idx--150] train_loss: 0.0014696066909229125, acc: 0.8317466887417219, lr: 0.04797853593058756
[batch_idx--200] train_loss: 0.0014709966472669768, acc: 0.8321672885572139, lr: 0.04795560703950527
[batch_idx--250] train_loss: 0.0014760505043497063, acc: 0.831004108565737, lr: 0.047932554384878465
[batch_idx--300] train_loss: 0.0014784647851093266, acc: 0.8303182101328903, lr: 0.0479093780909939
[batch_idx--350] train_loss: 0.001482563936735299, acc: 0.8301059472934473, lr: 0.047886078282804945
[batch_idx--400] train_loss: 0.0014792640006606307, acc: 0.8306966957605985, lr: 0.047862655085930884
[batch_idx--450] train_loss: 0.001480545769852791, acc: 0.8307008713159996, lr: 0.04783910862665624
total time of one epoch: 225.28781127929688 s
train_loss:  0.001480545769852791  acc:  0.8307008713159996
->>lr:0.047839
test_loss:  0.0014622750812139534  test_acc:  0.8388137486040451
best acc:  83.02518922943293
Saving..

------Epoch: 20------
[batch_idx--0] train_loss: 0.0014908051816746593, acc: 0.8125, lr: 0.04783863644106502
[batch_idx--50] train_loss: 0.0014620947117424186, acc: 0.8337162990196079, lr: 0.047814964384929284
[batch_idx--100] train_loss: 0.0014514303535665615, acc: 0.8351253094059405, lr: 0.047791169323514016
[batch_idx--150] train_loss: 0.0014632483743846614, acc: 0.8319019039735099, lr: 0.047767251385108636
[batch_idx--200] train_loss: 0.0014562036243234923, acc: 0.8324782338308457, lr: 0.04774321069866503
[batch_idx--250] train_loss: 0.001451516771165884, acc: 0.8327160109561753, lr: 0.04771904739379687
[batch_idx--300] train_loss: 0.0014550162408117242, acc: 0.8325114202657807, lr: 0.0476947616007789
[batch_idx--350] train_loss: 0.0014594873341140032, acc: 0.8325209223646723, lr: 0.0476703534505463
[batch_idx--400] train_loss: 0.0014610727871547538, acc: 0.8325377961346634, lr: 0.047645823074693894
[batch_idx--450] train_loss: 0.001461951526014891, acc: 0.8324625958968306, lr: 0.047621170605475466
total time of one epoch: 233.81367301940918 s
train_loss:  0.001461951526014891  acc:  0.8324625958968306
->>lr:0.047621
test_loss:  0.001420296792401793  test_acc:  0.8411713612110684
best acc:  83.88137486040452
Saving..

------Epoch: 21------
[batch_idx--0] train_loss: 0.0015494456747546792, acc: 0.80859375, lr: 0.04762067631165049
[batch_idx--50] train_loss: 0.0014405769099682278, acc: 0.8318014705882353, lr: 0.047595899444129244
[batch_idx--100] train_loss: 0.0014576764839544598, acc: 0.8325727103960396, lr: 0.04757100075240174
[batch_idx--150] train_loss: 0.0014509037252675916, acc: 0.8335834023178808, lr: 0.04754598037070751
[batch_idx--200] train_loss: 0.0014520586446270494, acc: 0.833916355721393, lr: 0.047520838433942204
[batch_idx--250] train_loss: 0.0014550685265706294, acc: 0.8333852091633466, lr: 0.04749557507765681
[batch_idx--300] train_loss: 0.0014510931496653841, acc: 0.8341206395348837, lr: 0.047470190438056926
[batch_idx--350] train_loss: 0.001453334122346953, acc: 0.8338118767806267, lr: 0.047444684652002064
[batch_idx--400] train_loss: 0.0014567252604448773, acc: 0.8332781327930174, lr: 0.04741905785700488
[batch_idx--450] train_loss: 0.001460761991823651, acc: 0.8332262991633977, lr: 0.04739331019123044
total time of one epoch: 224.25333666801453 s
train_loss:  0.001460761991823651  acc:  0.8332262991633977
->>lr:0.047393
test_loss:  0.001433109061891646  test_acc:  0.844893907432684
best acc:  84.11713612110684
Saving..

------Epoch: 22------
[batch_idx--0] train_loss: 0.0016118193743750453, acc: 0.8125, lr: 0.047392794005985325
[batch_idx--50] train_loss: 0.0014500954215798307, acc: 0.8324908088235294, lr: 0.04736692319503155
[batch_idx--100] train_loss: 0.001449509731281807, acc: 0.8349706064356436, lr: 0.047340931794380904
[batch_idx--150] train_loss: 0.0014438913118970018, acc: 0.8352907698675497, lr: 0.04731481994416418
[batch_idx--200] train_loss: 0.0014464092082969511, acc: 0.8346937189054726, lr: 0.04728858778516159
[batch_idx--250] train_loss: 0.0014416066771076317, acc: 0.8352060507968128, lr: 0.04726223545880198
[batch_idx--300] train_loss: 0.0014363258575828765, acc: 0.83624896179402, lr: 0.04723576310716207
[batch_idx--350] train_loss: 0.0014345611125878204, acc: 0.8364494301994302, lr: 0.047209170872965694
[batch_idx--400] train_loss: 0.0014371309400956493, acc: 0.8358595698254364, lr: 0.047182458899583
[batch_idx--450] train_loss: 0.0014452549515468374, acc: 0.8349272746207519, lr: 0.04715562733102973
total time of one epoch: 226.43972396850586 s
train_loss:  0.0014452549515468374  acc:  0.8349272746207519
->>lr:0.047156
test_loss:  0.001537210496960924  test_acc:  0.8270256855689292
best acc:  84.4893907432684

------Epoch: 23------
[batch_idx--0] train_loss: 0.001489891903474927, acc: 0.8046875, lr: 0.04715508948078037
[batch_idx--50] train_loss: 0.001461740389155845, acc: 0.8303462009803921, lr: 0.047128136074186804
[batch_idx--100] train_loss: 0.0014525849953072496, acc: 0.833075495049505, lr: 0.04710106336530035
[batch_idx--150] train_loss: 0.001442942281087108, acc: 0.8351096854304636, lr: 0.04707387150008163
[batch_idx--200] train_loss: 0.001432915557574351, acc: 0.8367537313432836, lr: 0.04704656062513368
[batch_idx--250] train_loss: 0.0014360211302611636, acc: 0.8367312001992032, lr: 0.04701913088770116
[batch_idx--300] train_loss: 0.0014345327255306797, acc: 0.8366901993355482, lr: 0.04699158243566958
[batch_idx--350] train_loss: 0.0014341212547068455, acc: 0.8365941061253561, lr: 0.04696391541756448
[batch_idx--400] train_loss: 0.001432095413059089, acc: 0.8366778366583542, lr: 0.046936129982550645
[batch_idx--450] train_loss: 0.0014333820599172506, acc: 0.836584857847051, lr: 0.0469082262804313
total time of one epoch: 220.71326875686646 s
train_loss:  0.0014333820599172506  acc:  0.836584857847051
->>lr:0.046908
test_loss:  0.0014233812754496495  test_acc:  0.8432808040699838
best acc:  84.4893907432684

------Epoch: 24------
[batch_idx--0] train_loss: 0.001470700604841113, acc: 0.828125, lr: 0.04690766700109659
[batch_idx--50] train_loss: 0.0014512754917400434, acc: 0.8357077205882353, lr: 0.04687964282151817
[batch_idx--100] train_loss: 0.0014264655304095238, acc: 0.8382967202970297, lr: 0.046851500679380806
[batch_idx--150] train_loss: 0.0014219361732078605, acc: 0.8390676738410596, lr: 0.046823240726410885
[batch_idx--200] train_loss: 0.0014176479956617032, acc: 0.840018656716418, lr: 0.046794863114969956
[batch_idx--250] train_loss: 0.0014258422879539281, acc: 0.8384742280876494, lr: 0.04676636799805392
[batch_idx--300] train_loss: 0.001427485770391195, acc: 0.8379620016611296, lr: 0.046737755529292206
[batch_idx--350] train_loss: 0.001424438569845998, acc: 0.8384081196581197, lr: 0.046709025862946923
[batch_idx--400] train_loss: 0.0014267101116882557, acc: 0.8378565305486284, lr: 0.046680179153912066
[batch_idx--450] train_loss: 0.0014276843489956516, acc: 0.8378779463324886, lr: 0.04665121555771262
total time of one epoch: 228.0416407585144 s
train_loss:  0.0014276843489956516  acc:  0.8378779463324886
->>lr:0.046651
test_loss:  0.00132551844384212  test_acc:  0.8532075939942921
best acc:  84.4893907432684
Saving..

------Epoch: 25------
[batch_idx--0] train_loss: 0.0014597470872104168, acc: 0.80859375, lr: 0.046650635094610975
[batch_idx--50] train_loss: 0.0014413258736478347, acc: 0.8331801470588235, lr: 0.04662155243437907
[batch_idx--100] train_loss: 0.0014163042467069066, acc: 0.8383740717821783, lr: 0.04659235320306443
[batch_idx--150] train_loss: 0.0014050594740701431, acc: 0.8396885347682119, lr: 0.046563037558092685
[batch_idx--200] train_loss: 0.0014011874199562257, acc: 0.8406599813432836, lr: 0.04653360565751704
[batch_idx--250] train_loss: 0.0014015086815206417, acc: 0.8406685756972112, lr: 0.04650405766001754
[batch_idx--300] train_loss: 0.0014005419585476336, acc: 0.8405704941860465, lr: 0.04647439372490014
[batch_idx--350] train_loss: 0.0014030285726203198, acc: 0.8401664886039886, lr: 0.046444614012095875
[batch_idx--400] train_loss: 0.0014008035934983086, acc: 0.8404379675810474, lr: 0.046414718682159954
[batch_idx--450] train_loss: 0.0014016076042530714, acc: 0.8409327593987572, lr: 0.04638470789627097
total time of one epoch: 207.87622356414795 s
train_loss:  0.0014016076042530714  acc:  0.8409327593987572
->>lr:0.046385
test_loss:  0.0014255632573461573  test_acc:  0.8420399553294453
best acc:  85.3207593994292

------Epoch: 26------
[batch_idx--0] train_loss: 0.0014425963163375854, acc: 0.87109375, lr: 0.04638410650401267
[batch_idx--50] train_loss: 0.001408556731892567, acc: 0.8396905637254902, lr: 0.04635397811974326
[batch_idx--100] train_loss: 0.001399711150178077, acc: 0.841042698019802, lr: 0.04632373460699926
[batch_idx--150] train_loss: 0.0014045742958697755, acc: 0.8402317880794702, lr: 0.04629337612883644
[batch_idx--200] train_loss: 0.0014074053476328282, acc: 0.8402324315920398, lr: 0.046262902848930414
[batch_idx--250] train_loss: 0.001405538700287234, acc: 0.8401705677290837, lr: 0.04623231493157573
[batch_idx--300] train_loss: 0.0013993775040418701, acc: 0.8408300456810631, lr: 0.046201612541685
[batch_idx--350] train_loss: 0.0013993988330993387, acc: 0.8411569622507122, lr: 0.046170795844788
[batch_idx--400] train_loss: 0.001400038625805771, acc: 0.8413926122194514, lr: 0.04613986500703078
[batch_idx--450] train_loss: 0.0014035291076182376, acc: 0.8412972541396189, lr: 0.0461088201951748
total time of one epoch: 211.66283106803894 s
train_loss:  0.0014035291076182376  acc:  0.8412972541396189
->>lr:0.046109
test_loss:  0.00137072885904763  test_acc:  0.8484923687802457
best acc:  85.3207593994292

------Epoch: 27------
[batch_idx--0] train_loss: 0.001314179040491581, acc: 0.8515625, lr: 0.04610819813755038
[batch_idx--50] train_loss: 0.0013811933493022533, acc: 0.8458180147058824, lr: 0.04607703724454855
[batch_idx--100] train_loss: 0.0013845839669079621, acc: 0.8455677599009901, lr: 0.046045762716179425
[batch_idx--150] train_loss: 0.001382484571046091, acc: 0.8452762831125827, lr: 0.04601437472105743
[batch_idx--200] train_loss: 0.0013839372414029875, acc: 0.8447994402985075, lr: 0.04598287342840873
[batch_idx--250] train_loss: 0.0013865702906141124, acc: 0.8444814492031872, lr: 0.04595125900807036
[batch_idx--300] train_loss: 0.0013866124920658396, acc: 0.844437811461794, lr: 0.045919531630489216
[batch_idx--350] train_loss: 0.0013874298992415525, acc: 0.8440504807692307, lr: 0.045887691466721246
[batch_idx--400] train_loss: 0.001391802054534938, acc: 0.8431557824189526, lr: 0.04585573868843045
[batch_idx--450] train_loss: 0.0013922682503938518, acc: 0.8434147950151005, lr: 0.04582367346788801
total time of one epoch: 217.110356092453 s
train_loss:  0.0013922682503938518  acc:  0.8434147950151005
->>lr:0.045824
test_loss:  0.0013815091086433905  test_acc:  0.8484923687802457
best acc:  85.3207593994292

------Epoch: 28------
[batch_idx--0] train_loss: 0.0013025474036112428, acc: 0.83984375, lr: 0.04582303101775249
[batch_idx--50] train_loss: 0.0013883208225974266, acc: 0.8419883578431373, lr: 0.04579085128421578
[batch_idx--100] train_loss: 0.0013860029175342752, acc: 0.8427444306930693, lr: 0.04575855945826332
[batch_idx--150] train_loss: 0.0013864856631192841, acc: 0.8435947847682119, lr: 0.04572615571399419
[batch_idx--200] train_loss: 0.001384575519970252, acc: 0.8434584888059702, lr: 0.045693640226110915
[batch_idx--250] train_loss: 0.0013799004778970937, acc: 0.8445748256972112, lr: 0.045661013169918455
[batch_idx--300] train_loss: 0.0013808509512058772, acc: 0.8443988787375415, lr: 0.04562827472132332
[batch_idx--350] train_loss: 0.0013785072336334235, acc: 0.8447961182336182, lr: 0.045595425056832534
[batch_idx--400] train_loss: 0.0013815397832152479, acc: 0.8442565461346634, lr: 0.04556246435355277
[batch_idx--450] train_loss: 0.0013836072299081266, acc: 0.8443520672058875, lr: 0.04552939278918935
total time of one epoch: 221.58414721488953 s
train_loss:  0.0013836072299081266  acc:  0.8443520672058875
->>lr:0.045529
test_loss:  0.0013719045290477756  test_acc:  0.8504777267651074
best acc:  85.3207593994292

------Epoch: 29------
[batch_idx--0] train_loss: 0.0017029175069183111, acc: 0.80859375, lr: 0.045528730228342605
[batch_idx--50] train_loss: 0.0014089302150715217, acc: 0.8393075980392157, lr: 0.04549554576936571
[batch_idx--100] train_loss: 0.0013885515751224933, acc: 0.8436726485148515, lr: 0.04546225081009201
[batch_idx--150] train_loss: 0.0013872488642370465, acc: 0.8428704470198676, lr: 0.04542884553002893
[batch_idx--200] train_loss: 0.0013839242167872799, acc: 0.8434196206467661, lr: 0.04539533010927871
[batch_idx--250] train_loss: 0.001373762203161549, acc: 0.8449172061752988, lr: 0.04536170472853737
[batch_idx--300] train_loss: 0.0013780075263083477, acc: 0.84375, lr: 0.045327969569093796
[batch_idx--350] train_loss: 0.0013801708881825505, acc: 0.8436275819088319, lr: 0.04529412481282874
[batch_idx--400] train_loss: 0.0013801751332009151, acc: 0.8439837905236908, lr: 0.04526017064221382
[batch_idx--450] train_loss: 0.001384160686460824, acc: 0.8443954594369424, lr: 0.04522610724031057
total time of one epoch: 217.95353198051453 s
train_loss:  0.001384160686460824  acc:  0.8443954594369424
->>lr:0.045226
test_loss:  0.0013450944075322296  test_acc:  0.8532075939942921
best acc:  85.3207593994292

------Epoch: 30------
[batch_idx--0] train_loss: 0.0012887039920315146, acc: 0.8359375, lr: 0.04522542485937369
[batch_idx--50] train_loss: 0.0014056591842067884, acc: 0.8412990196078431, lr: 0.04519125023075707
[batch_idx--100] train_loss: 0.0013928581225123293, acc: 0.8428217821782178, lr: 0.045156966742431685
[batch_idx--150] train_loss: 0.0013857771016484656, acc: 0.843775869205298, lr: 0.04512257457923455
[batch_idx--200] train_loss: 0.0013928381269751348, acc: 0.8427005597014925, lr: 0.04508807392658861
[batch_idx--250] train_loss: 0.0013822767414167463, acc: 0.8437966882470119, lr: 0.0450534649705017
[batch_idx--300] train_loss: 0.0013758482293928184, acc: 0.8446584302325582, lr: 0.04501874789756559
[batch_idx--350] train_loss: 0.0013748468981095274, acc: 0.8441840277777778, lr: 0.04498392289495493
[batch_idx--400] train_loss: 0.0013721195491439573, acc: 0.8445780081047382, lr: 0.04494899015042629
[batch_idx--450] train_loss: 0.0013739332053932564, acc: 0.8452546256118305, lr: 0.04491394985231711
total time of one epoch: 209.78686499595642 s
train_loss:  0.0013739332053932564  acc:  0.8452546256118305
->>lr:0.044914
test_loss:  0.0013578745504957464  test_acc:  0.8507258965132151
best acc:  85.3207593994292

------Epoch: 31------
[batch_idx--0] train_loss: 0.0015952830435708165, acc: 0.80078125, lr: 0.04491324795060491
[batch_idx--50] train_loss: 0.001399409523525951, acc: 0.8426776960784313, lr: 0.04487809814247016
[batch_idx--100] train_loss: 0.0013866736818713568, acc: 0.8440980816831684, lr: 0.044842841162964144
[batch_idx--150] train_loss: 0.0013767755096963305, acc: 0.8456125827814569, lr: 0.04480747720217241
[batch_idx--200] train_loss: 0.0013717710062518568, acc: 0.8464513370646766, lr: 0.04477200645075726
[batch_idx--250] train_loss: 0.0013696555761561035, acc: 0.8467380478087649, lr: 0.04473642909995676
[batch_idx--300] train_loss: 0.0013634392413839798, acc: 0.8473188330564784, lr: 0.044700745341583706
[batch_idx--350] train_loss: 0.001366750268196618, acc: 0.8465990028490028, lr: 0.044664955368024575
[batch_idx--400] train_loss: 0.00136734854442734, acc: 0.8463216957605985, lr: 0.044629059372238496
[batch_idx--450] train_loss: 0.0013685911049650657, acc: 0.8463828236192592, lr: 0.044593057547756214
total time of one epoch: 202.5536048412323 s
train_loss:  0.0013685911049650657  acc:  0.8463828236192592
->>lr:0.044593
test_loss:  0.0016004484364554195  test_acc:  0.8209455267402903
best acc:  85.3207593994292

------Epoch: 32------
[batch_idx--0] train_loss: 0.0013848993694409728, acc: 0.84375, lr: 0.044592336433146
[batch_idx--50] train_loss: 0.0013850678794779907, acc: 0.84375, lr: 0.04455622686336067
[batch_idx--100] train_loss: 0.0013754795856386571, acc: 0.8441754331683168, lr: 0.0445200118575505
[batch_idx--150] train_loss: 0.0013669165940677734, acc: 0.8455349751655629, lr: 0.04448369161096615
[batch_idx--200] train_loss: 0.001359449272954475, acc: 0.8469566231343284, lr: 0.044447266319425686
[batch_idx--250] train_loss: 0.0013592925571569378, acc: 0.8468625498007968, lr: 0.044410736179313494
[batch_idx--300] train_loss: 0.0013552891046808185, acc: 0.8471111918604651, lr: 0.04437410138757928
[batch_idx--350] train_loss: 0.0013558411033110338, acc: 0.8471331908831908, lr: 0.04433736214173695
[batch_idx--400] train_loss: 0.001355817797680866, acc: 0.8472178927680798, lr: 0.04430051863986356
[batch_idx--450] train_loss: 0.001353352755664037, acc: 0.8477887319054397, lr: 0.04426357108059828
total time of one epoch: 211.31749033927917 s
train_loss:  0.001353352755664037  acc:  0.8477887319054397
->>lr:0.044264
test_loss:  0.0013053193827068292  test_acc:  0.8573023948380692
best acc:  85.3207593994292
Saving..

------Epoch: 33------
[batch_idx--0] train_loss: 0.0014696894213557243, acc: 0.8125, lr: 0.044262831069394735
[batch_idx--50] train_loss: 0.0013418767062545406, acc: 0.8498008578431373, lr: 0.04422577757680957
[batch_idx--100] train_loss: 0.0013400975725438335, acc: 0.8493579826732673, lr: 0.04418862042979371
[batch_idx--150] train_loss: 0.0013298675377810042, acc: 0.8507605546357616, lr: 0.044151359828677295
[batch_idx--200] train_loss: 0.00133088373941652, acc: 0.8512709888059702, lr: 0.04411399597434825
[batch_idx--250] train_loss: 0.0013338476064637215, acc: 0.8507687998007968, lr: 0.04407652906825116
[batch_idx--300] train_loss: 0.0013338236002471188, acc: 0.8501609219269103, lr: 0.04403895931238623
[batch_idx--350] train_loss: 0.0013354224866943332, acc: 0.8497373575498576, lr: 0.044001286909308164
[batch_idx--400] train_loss: 0.0013354280872091633, acc: 0.8498967425187033, lr: 0.04396351206212508
[batch_idx--450] train_loss: 0.001341674474534213, acc: 0.8494549935779498, lr: 0.043925634974497405
total time of one epoch: 215.43779850006104 s
train_loss:  0.001341674474534213  acc:  0.8494549935779498
->>lr:0.043926
test_loss:  0.0013749487850621374  test_acc:  0.8491127931505149
best acc:  85.73023948380693

------Epoch: 34------
[batch_idx--0] train_loss: 0.0015090717934072018, acc: 0.83203125, lr: 0.043924876391293916
[batch_idx--50] train_loss: 0.0013406560585067114, acc: 0.8493412990196079, lr: 0.0438868952287954
[batch_idx--100] train_loss: 0.0013420851710990145, acc: 0.8488165222772277, lr: 0.04384881223892658
[batch_idx--150] train_loss: 0.0013345537452021034, acc: 0.8504242549668874, lr: 0.04381062762700922
[batch_idx--200] train_loss: 0.0013339725089611587, acc: 0.8503964552238806, lr: 0.043772341598912995
[batch_idx--250] train_loss: 0.001337995174557965, acc: 0.849617156374502, lr: 0.04373395436105431
[batch_idx--300] train_loss: 0.0013381612366854378, acc: 0.8493563122923588, lr: 0.04369546612039528
[batch_idx--350] train_loss: 0.0013387512468382653, acc: 0.8496483262108262, lr: 0.04365687708444255
[batch_idx--400] train_loss: 0.0013412209252357725, acc: 0.8492343360349127, lr: 0.04361818746124621
[batch_idx--450] train_loss: 0.0013426353969177784, acc: 0.8496112056097477, lr: 0.04357939745939863
total time of one epoch: 215.70852184295654 s
train_loss:  0.0013426353969177784  acc:  0.8496112056097477
->>lr:0.043579
test_loss:  0.0013694454879881446  test_acc:  0.8493609628986226
best acc:  85.73023948380693

------Epoch: 35------
[batch_idx--0] train_loss: 0.0013200719840824604, acc: 0.86328125, lr: 0.04357862063693486
[batch_idx--50] train_loss: 0.001348696633095981, acc: 0.8465073529411765, lr: 0.04353972846431615
[batch_idx--100] train_loss: 0.0013359654141534673, acc: 0.849319306930693, lr: 0.043500736336052385
[batch_idx--150] train_loss: 0.0013380635449576456, acc: 0.8494153559602649, lr: 0.04346164446236689
[batch_idx--200] train_loss: 0.0013303127034395858, acc: 0.8500466417910447, lr: 0.04342245305402075
[batch_idx--250] train_loss: 0.0013262204412163134, acc: 0.8509399900398407, lr: 0.04338316232231171
[batch_idx--300] train_loss: 0.0013312462139472465, acc: 0.8500700789036545, lr: 0.043343772479072985
[batch_idx--350] train_loss: 0.001332833826677221, acc: 0.8503271901709402, lr: 0.043304283736672146
[batch_idx--400] train_loss: 0.0013326402208384618, acc: 0.8505883728179551, lr: 0.04326469630800999
[batch_idx--450] train_loss: 0.0013418977432718263, acc: 0.850218696844517, lr: 0.04322501040651934
total time of one epoch: 207.5131630897522 s
train_loss:  0.0013418977432718263  acc:  0.850218696844517
->>lr:0.043225
test_loss:  0.0013381985794715394  test_acc:  0.8544484427348307
best acc:  85.73023948380693

------Epoch: 36------
[batch_idx--0] train_loss: 0.0014568696497008204, acc: 0.82421875, lr: 0.04322421568553529
[batch_idx--50] train_loss: 0.001363071740842333, acc: 0.8441329656862745, lr: 0.04318442956218869
[batch_idx--100] train_loss: 0.0013552642459658407, acc: 0.845413056930693, lr: 0.04314454539876614
[batch_idx--150] train_loss: 0.001343490849619127, acc: 0.8479925496688742, lr: 0.043104563410300306
[batch_idx--200] train_loss: 0.0013357156920084609, acc: 0.8484336131840796, lr: 0.043064483812351256
[batch_idx--250] train_loss: 0.0013268886846434548, acc: 0.8502707918326693, lr: 0.04302430682100536
[batch_idx--300] train_loss: 0.0013209977968475252, acc: 0.8510563745847176, lr: 0.042984032652874024
[batch_idx--350] train_loss: 0.0013233343539945251, acc: 0.8508168625356125, lr: 0.04294366152509261
[batch_idx--400] train_loss: 0.0013263098706266009, acc: 0.8502766521197007, lr: 0.04290319365531922
[batch_idx--450] train_loss: 0.0013288830270823326, acc: 0.850166626167251, lr: 0.04286262926173353
total time of one epoch: 212.64371538162231 s
train_loss:  0.0013288830270823326  acc:  0.850166626167251
->>lr:0.042863
test_loss:  0.0012695694704892425  test_acc:  0.8621417049261695
best acc:  85.73023948380693
Saving..

------Epoch: 37------
[batch_idx--0] train_loss: 0.0014225681079551578, acc: 0.83984375, lr: 0.04286181699082009
[batch_idx--50] train_loss: 0.0013247842503273312, acc: 0.8506433823529411, lr: 0.04282115436825425
[batch_idx--100] train_loss: 0.0013170308170674166, acc: 0.8507116336633663, lr: 0.04278039566418517
[batch_idx--150] train_loss: 0.0013111201724012858, acc: 0.8531922599337748, lr: 0.04273954109836054
[batch_idx--200] train_loss: 0.0013233526385115896, acc: 0.851543065920398, lr: 0.0426985908910449
[batch_idx--250] train_loss: 0.0013210288985480232, acc: 0.8511578685258964, lr: 0.042657545263018404
[batch_idx--300] train_loss: 0.0013206279712831262, acc: 0.8511731727574751, lr: 0.042616404435575676
[batch_idx--350] train_loss: 0.0013210110139483826, acc: 0.8514957264957265, lr: 0.04257516863052461
[batch_idx--400] train_loss: 0.001327096191385849, acc: 0.8505981140897756, lr: 0.04253383807018514
[batch_idx--450] train_loss: 0.0013316422581908546, acc: 0.8502360537369389, lr: 0.042492412977388094
total time of one epoch: 205.8431692123413 s
train_loss:  0.0013316422581908546  acc:  0.8502360537369389
->>lr:0.042492
test_loss:  0.0013628902787649834  test_acc:  0.8533316788683459
best acc:  86.21417049261694

------Epoch: 38------
[batch_idx--0] train_loss: 0.0012923182221129537, acc: 0.84765625, lr: 0.042491583512834136
[batch_idx--50] train_loss: 0.0013761651592657847, acc: 0.8413756127450981, lr: 0.04245006222701923
[batch_idx--100] train_loss: 0.0013407048968699677, acc: 0.8465733292079208, lr: 0.04240844686041831
[batch_idx--150] train_loss: 0.0013290293771459024, acc: 0.8481995033112583, lr: 0.042366737637397726
[batch_idx--200] train_loss: 0.0013315559261181944, acc: 0.8480449315920398, lr: 0.04232493478282982
[batch_idx--250] train_loss: 0.0013265480717321286, acc: 0.8493525896414342, lr: 0.042283038522091754
[batch_idx--300] train_loss: 0.0013196545570278138, acc: 0.8508357558139535, lr: 0.04224104908106427
[batch_idx--350] train_loss: 0.0013241420570957313, acc: 0.8504384793447294, lr: 0.0421989666861305
[batch_idx--400] train_loss: 0.001322784624817291, acc: 0.8510267300498753, lr: 0.04215679156417471
[batch_idx--450] train_loss: 0.0013201538659974902, acc: 0.8518328878397612, lr: 0.04211452394258114
total time of one epoch: 221.28339076042175 s
train_loss:  0.0013201538659974902  acc:  0.8518328878397612
->>lr:0.042115
test_loss:  0.001257559933338764  test_acc:  0.8612731108077926
best acc:  86.21417049261694

------Epoch: 39------
[batch_idx--0] train_loss: 0.0013881656341254711, acc: 0.828125, lr: 0.04211367764821722
[batch_idx--50] train_loss: 0.0013116224184997526, acc: 0.8518688725490197, lr: 0.04207131591176148
[batch_idx--100] train_loss: 0.0013170504924094322, acc: 0.8530321782178217, lr: 0.042028862136503926
[batch_idx--150] train_loss: 0.0013111884303279961, acc: 0.8537613824503312, lr: 0.0419863165513311
[batch_idx--200] train_loss: 0.0013120850537722902, acc: 0.8538362873134329, lr: 0.041943679385624544
[batch_idx--250] train_loss: 0.0013063302295156327, acc: 0.8542859810756972, lr: 0.04190095086925955
[batch_idx--300] train_loss: 0.001299762028962547, acc: 0.8549496470099668, lr: 0.041858131232603915
[batch_idx--350] train_loss: 0.0013020977781199323, acc: 0.8540442485754985, lr: 0.04181522070651669
[batch_idx--400] train_loss: 0.0013041868660729054, acc: 0.8534425654613467, lr: 0.04177221952234698
[batch_idx--450] train_loss: 0.0013083846988799477, acc: 0.853802895129656, lr: 0.041729127911932645
total time of one epoch: 218.7336061000824 s
train_loss:  0.0013083846988799477  acc:  0.853802895129656
->>lr:0.041729
test_loss:  0.0012263211438194046  test_acc:  0.8678496091326467
best acc:  86.21417049261694
Saving..

------Epoch: 40------
[batch_idx--0] train_loss: 0.0012001489521935582, acc: 0.84375, lr: 0.04172826515897146
[batch_idx--50] train_loss: 0.001316361704512554, acc: 0.8517156862745098, lr: 0.04168508155313258
[batch_idx--100] train_loss: 0.0013012536674608837, acc: 0.8543858292079208, lr: 0.04164180799084732
[batch_idx--150] train_loss: 0.0013117594127882493, acc: 0.8522350993377483, lr: 0.04159844470542206
[batch_idx--200] train_loss: 0.0013021970334560124, acc: 0.8532143967661692, lr: 0.041554991930646906
[batch_idx--250] train_loss: 0.0013010160124626946, acc: 0.8534300298804781, lr: 0.041511449900794445
[batch_idx--300] train_loss: 0.00129940938142645, acc: 0.8541969476744186, lr: 0.04146781885061848
[batch_idx--350] train_loss: 0.0012982931264020779, acc: 0.8544115028490028, lr: 0.04142409901535277
[batch_idx--400] train_loss: 0.0012978348550630589, acc: 0.8547284133416458, lr: 0.04138029063070971
[batch_idx--450] train_loss: 0.0012981698176139686, acc: 0.8553129447703683, lr: 0.041336393932879134
total time of one epoch: 217.93903017044067 s
train_loss:  0.0012981698176139686  acc:  0.8553129447703683
->>lr:0.041336
test_loss:  0.0012415874620453715  test_acc:  0.8669810150142697
best acc:  86.78496091326467

------Epoch: 41------
[batch_idx--0] train_loss: 0.0013577024219557643, acc: 0.84765625, lr: 0.04133551509975264
[batch_idx--50] train_loss: 0.001308270202785292, acc: 0.8556219362745098, lr: 0.041291528566287365
[batch_idx--100] train_loss: 0.0013117710045437412, acc: 0.854115099009901, lr: 0.041247454198189024
[batch_idx--150] train_loss: 0.0013049615227882535, acc: 0.855520488410596, lr: 0.04120329223308148
[batch_idx--200] train_loss: 0.001298236240174121, acc: 0.8559546019900498, lr: 0.041159042909060875
[batch_idx--250] train_loss: 0.0012993885731079663, acc: 0.8558889442231076, lr: 0.04111470646469433
[batch_idx--300] train_loss: 0.001296777781748841, acc: 0.8559359426910299, lr: 0.04107028313901867
[batch_idx--350] train_loss: 0.0013018822034773154, acc: 0.8555243945868946, lr: 0.04102577317153916
[batch_idx--400] train_loss: 0.0013017481378165823, acc: 0.855273924563591, lr: 0.04098117680222813
[batch_idx--450] train_loss: 0.0013073258639648248, acc: 0.8548095948901309, lr: 0.04093649427152381
total time of one epoch: 219.7898325920105 s
train_loss:  0.0013073258639648248  acc:  0.8548095948901309
->>lr:0.040936
test_loss:  0.0012477984930892368  test_acc:  0.863382553666708
best acc:  86.78496091326467

------Epoch: 42------
[batch_idx--0] train_loss: 0.0011869114823639393, acc: 0.8671875, lr: 0.040935599743717244
[batch_idx--50] train_loss: 0.0012810987593861773, acc: 0.8537837009803921, lr: 0.04089082957657292
[batch_idx--100] train_loss: 0.0012884401199915031, acc: 0.8539603960396039, lr: 0.04084597373513602
[batch_idx--150] train_loss: 0.0012823537251116424, acc: 0.8552359271523179, lr: 0.04080103246124366
[batch_idx--200] train_loss: 0.0012881246132461068, acc: 0.8547496890547264, lr: 0.04075600599719357
[batch_idx--250] train_loss: 0.0012909288168421007, acc: 0.8548773655378487, lr: 0.04071089458574278
[batch_idx--300] train_loss: 0.0012888028870407875, acc: 0.8553000415282392, lr: 0.04066569847010627
[batch_idx--350] train_loss: 0.0012867219760706197, acc: 0.8555577813390314, lr: 0.040620417893955756
[batch_idx--400] train_loss: 0.0012851312110302715, acc: 0.85612141521197, lr: 0.04057505310141827
[batch_idx--450] train_loss: 0.0012901151596053544, acc: 0.8560419342520915, lr: 0.04052960433707492
total time of one epoch: 209.55820989608765 s
train_loss:  0.0012901151596053544  acc:  0.8560419342520915
->>lr:0.040530
test_loss:  0.0014107194745905983  test_acc:  0.8447698225586301
best acc:  86.78496091326467

------Epoch: 43------
[batch_idx--0] train_loss: 0.0011104297591373324, acc: 0.87890625, lr: 0.040528694506957764
[batch_idx--50] train_loss: 0.0012707803238585008, acc: 0.8599111519607843, lr: 0.04048316034380937
[batch_idx--100] train_loss: 0.001287220445885738, acc: 0.8563582920792079, lr: 0.040437542704288454
[batch_idx--150] train_loss: 0.001286882582577007, acc: 0.8571761175496688, lr: 0.04039184183433934
[batch_idx--200] train_loss: 0.0012849232335968767, acc: 0.8570817786069652, lr: 0.04034605798035504
[batch_idx--250] train_loss: 0.0012810016217904975, acc: 0.8580832918326693, lr: 0.04030019138917598
[batch_idx--300] train_loss: 0.0012896606912124792, acc: 0.8571947674418605, lr: 0.040254242308088696
[batch_idx--350] train_loss: 0.0012888105458810797, acc: 0.8575498575498576, lr: 0.040208210984824425
[batch_idx--400] train_loss: 0.001286634216445064, acc: 0.8574949345386533, lr: 0.04016209766755781
[batch_idx--450] train_loss: 0.0012878272533065, acc: 0.8574565209844829, lr: 0.040115902604905565
total time of one epoch: 205.0314018726349 s
train_loss:  0.0012878272533065  acc:  0.8574565209844829
->>lr:0.040116
test_loss:  0.0014248437267007153  test_acc:  0.8429085494478223
best acc:  86.78496091326467

------Epoch: 44------
[batch_idx--0] train_loss: 0.0013269835617393255, acc: 0.85546875, lr: 0.040114977871559376
[batch_idx--50] train_loss: 0.0013011661540789931, acc: 0.8532475490196079, lr: 0.04006869968519579
[batch_idx--100] train_loss: 0.0012845061828917132, acc: 0.8555461014851485, lr: 0.04002234025699524
[batch_idx--150] train_loss: 0.0012794490691601292, acc: 0.8560637417218543, lr: 0.039975899836901335
[batch_idx--200] train_loss: 0.0012768837052805173, acc: 0.8566930970149254, lr: 0.03992937867529435
[batch_idx--250] train_loss: 0.0012743601413625497, acc: 0.8566048306772909, lr: 0.03988277702298985
[batch_idx--300] train_loss: 0.001272388589467878, acc: 0.8571558347176079, lr: 0.03983609513123738
[batch_idx--350] train_loss: 0.0012728417143981871, acc: 0.8573161502849003, lr: 0.03978933325171908
[batch_idx--400] train_loss: 0.0012715490961080402, acc: 0.8576800187032418, lr: 0.03974249163654834
[batch_idx--450] train_loss: 0.0012715476851730728, acc: 0.8580553337730413, lr: 0.03969557053826845
total time of one epoch: 217.44393634796143 s
train_loss:  0.0012715476851730728  acc:  0.8580553337730413
->>lr:0.039696
test_loss:  0.0012249194435985144  test_acc:  0.8653679116515697
best acc:  86.78496091326467

------Epoch: 45------
[batch_idx--0] train_loss: 0.0013881793711334467, acc: 0.8515625, lr: 0.03969463130731183
[batch_idx--50] train_loss: 0.0012927444848031097, acc: 0.8555453431372549, lr: 0.0396476293968751
[batch_idx--100] train_loss: 0.001288624182988954, acc: 0.85546875, lr: 0.03960054851477232
[batch_idx--150] train_loss: 0.0012804428215712211, acc: 0.8574089403973509, lr: 0.039553388914836764
[batch_idx--200] train_loss: 0.0012783717181051697, acc: 0.8578785758706468, lr: 0.039506150851326104
[batch_idx--250] train_loss: 0.001276402778281604, acc: 0.8574763446215139, lr: 0.039458834578921055
[batch_idx--300] train_loss: 0.0012778498896048017, acc: 0.8569481935215947, lr: 0.03941144035272397
[batch_idx--350] train_loss: 0.0012778691672839415, acc: 0.8569043803418803, lr: 0.03936396842825749
[batch_idx--400] train_loss: 0.001280735039263685, acc: 0.8565013248129676, lr: 0.03931641906146319
[batch_idx--450] train_loss: 0.0012872071897478275, acc: 0.8562415385149443, lr: 0.03926879250870011
total time of one epoch: 212.79009413719177 s
train_loss:  0.0012872071897478275  acc:  0.8562415385149443
->>lr:0.039269
test_loss:  0.0012622944606653676  test_acc:  0.8641270629110311
best acc:  86.78496091326467

------Epoch: 46------
[batch_idx--0] train_loss: 0.0011425636475905776, acc: 0.8828125, lr: 0.0392678391921108
[batch_idx--50] train_loss: 0.0013078794467682932, acc: 0.8569240196078431, lr: 0.03922013417419226
[batch_idx--100] train_loss: 0.001297941302308942, acc: 0.8581373762376238, lr: 0.03917235248941817
[batch_idx--150] train_loss: 0.0012892989483384402, acc: 0.8582108857615894, lr: 0.03912449439540013
[batch_idx--200] train_loss: 0.001279726029670246, acc: 0.8588502798507462, lr: 0.0390765601501617
[batch_idx--250] train_loss: 0.0012794900657720418, acc: 0.8585812998007968, lr: 0.03902855001213699
[batch_idx--300] train_loss: 0.001277232798476985, acc: 0.858765053986711, lr: 0.0389804642401693
[batch_idx--350] train_loss: 0.001277416880989442, acc: 0.858573717948718, lr: 0.03893230309350968
[batch_idx--400] train_loss: 0.0012709664960654263, acc: 0.8591022443890274, lr: 0.03888406683181559
[batch_idx--450] train_loss: 0.0012753542830650497, acc: 0.859209567119103, lr: 0.03883575571514944
total time of one epoch: 229.14298248291016 s
train_loss:  0.0012753542830650497  acc:  0.859209567119103
->>lr:0.038836
test_loss:  0.001208270934042556  test_acc:  0.8708276461099392
best acc:  86.78496091326467
Saving..

------Epoch: 47------
[batch_idx--0] train_loss: 0.0012380280531942844, acc: 0.8515625, lr: 0.038834788731083605
[batch_idx--50] train_loss: 0.0012454647278668835, acc: 0.8635110294117647, lr: 0.038786401530680796
[batch_idx--100] train_loss: 0.0012749315407772613, acc: 0.8586401608910891, lr: 0.03873794000186154
[batch_idx--150] train_loss: 0.0012628015578687438, acc: 0.8605908526490066, lr: 0.03868940440590278
[batch_idx--200] train_loss: 0.0012638261182632167, acc: 0.8604244402985075, lr: 0.03864079500448077
[batch_idx--250] train_loss: 0.0012696680498765819, acc: 0.8599196962151394, lr: 0.03859211205966969
[batch_idx--300] train_loss: 0.0012689680909193383, acc: 0.8597773048172758, lr: 0.038543355833940224
[batch_idx--350] train_loss: 0.0012691867178932172, acc: 0.8597645121082621, lr: 0.03849452659015813
[batch_idx--400] train_loss: 0.0012660688753158523, acc: 0.8603199033665836, lr: 0.03844562459158286
[batch_idx--450] train_loss: 0.0012726414580530876, acc: 0.8602596591106328, lr: 0.0383966501018661
total time of one epoch: 221.18916988372803 s
train_loss:  0.0012726414580530876  acc:  0.8602596591106328
->>lr:0.038397
test_loss:  0.0013556272542155667  test_acc:  0.8517185755056459
best acc:  87.08276461099392

------Epoch: 48------
[batch_idx--0] train_loss: 0.00142957572825253, acc: 0.82421875, lr: 0.03839566987447492
[batch_idx--50] train_loss: 0.001311719006694415, acc: 0.8538602941176471, lr: 0.038346621715813135
[batch_idx--100] train_loss: 0.0012811760897609857, acc: 0.8575959158415841, lr: 0.038297501599776934
[batch_idx--150] train_loss: 0.0012780046753511326, acc: 0.8577969784768212, lr: 0.03824830979119395
[batch_idx--200] train_loss: 0.0012744178083859644, acc: 0.8580923507462687, lr: 0.038199046555278386
[batch_idx--250] train_loss: 0.0012690130963483714, acc: 0.8590481822709163, lr: 0.038149712157629516
[batch_idx--300] train_loss: 0.0012672212968063712, acc: 0.8596994393687708, lr: 0.038100306864230285
[batch_idx--350] train_loss: 0.0012682482833706076, acc: 0.8593416132478633, lr: 0.038050830941445866
[batch_idx--400] train_loss: 0.001267267046774972, acc: 0.8595503428927681, lr: 0.03800128465602222
[batch_idx--450] train_loss: 0.0012698921643281077, acc: 0.8594178498281667, lr: 0.03795166827508467
total time of one epoch: 208.55070877075195 s
train_loss:  0.0012698921643281077  acc:  0.8594178498281667
->>lr:0.037952
test_loss:  0.001232570543643011  test_acc:  0.865119741903462
best acc:  87.08276461099392

------Epoch: 49------
[batch_idx--0] train_loss: 0.000948959612287581, acc: 0.90625, lr: 0.03795067523432826
[batch_idx--50] train_loss: 0.0012759262280465633, acc: 0.8585324754901961, lr: 0.037900987631550954
[batch_idx--100] train_loss: 0.0012511998181010016, acc: 0.8612701113861386, lr: 0.03785123047400412
[batch_idx--150] train_loss: 0.0012566520287408587, acc: 0.8612117135761589, lr: 0.03780140402994997
[batch_idx--200] train_loss: 0.0012599763437869279, acc: 0.861376710199005, lr: 0.03775150856802428
[batch_idx--250] train_loss: 0.0012568192082490638, acc: 0.8615537848605578, lr: 0.03770154435723495
[batch_idx--300] train_loss: 0.0012521772464409323, acc: 0.8617888289036545, lr: 0.037651511666960506
[batch_idx--350] train_loss: 0.0012518575025637477, acc: 0.8619346509971509, lr: 0.03760141076694869
[batch_idx--400] train_loss: 0.0012592319201705907, acc: 0.860631624064838, lr: 0.037551241927314974
[batch_idx--450] train_loss: 0.0012609885371405467, acc: 0.8603464435727427, lr: 0.03750100541854115
total time of one epoch: 230.26588106155396 s
train_loss:  0.0012609885371405467  acc:  0.8603464435727427
->>lr:0.037501
test_loss:  0.0012169268723234731  test_acc:  0.867601439384539
best acc:  87.08276461099392

------Epoch: 50------
[batch_idx--0] train_loss: 0.0011929685715585947, acc: 0.8515625, lr: 0.037500000000000006
[batch_idx--50] train_loss: 0.0012716273617401136, acc: 0.8585324754901961, lr: 0.037449694747731944
[batch_idx--100] train_loss: 0.0012414357492395926, acc: 0.8617728960396039, lr: 0.03739932237380827
[batch_idx--150] train_loss: 0.0012484208124825447, acc: 0.8621171357615894, lr: 0.03734888314980809
[batch_idx--200] train_loss: 0.0012483337464909167, acc: 0.8616682213930348, lr: 0.037298377347670955
[batch_idx--250] train_loss: 0.0012481420115842317, acc: 0.8617249750996016, lr: 0.03724780523969534
[batch_idx--300] train_loss: 0.0012548578153921297, acc: 0.8607246677740864, lr: 0.03719716709853723
[batch_idx--350] train_loss: 0.0012573806081097201, acc: 0.8606214387464387, lr: 0.037146463197208594
[batch_idx--400] train_loss: 0.0012547915394678063, acc: 0.8606024002493765, lr: 0.03709569380907597
[batch_idx--450] train_loss: 0.0012568849379028454, acc: 0.8608324365605582, lr: 0.03704485920785895
total time of one epoch: 224.26788592338562 s
train_loss:  0.0012568849379028454  acc:  0.8608324365605582
->>lr:0.037045
test_loss:  0.0012376316059077995  test_acc:  0.864251147785085
best acc:  87.08276461099392

------Epoch: 51------
[batch_idx--0] train_loss: 0.0012672325829043984, acc: 0.859375, lr: 0.037043841852542884
[batch_idx--50] train_loss: 0.0012855167859051303, acc: 0.8570006127450981, lr: 0.03699294101633032
[batch_idx--100] train_loss: 0.001276280749981098, acc: 0.8580600247524752, lr: 0.036941975521017835
[batch_idx--150] train_loss: 0.0012652629532308522, acc: 0.859426738410596, lr: 0.0368909456413823
[batch_idx--200] train_loss: 0.0012551167613794258, acc: 0.8606965174129353, lr: 0.03683985165254776
[batch_idx--250] train_loss: 0.0012523761910545933, acc: 0.86128921812749, lr: 0.03678869382998386
[batch_idx--300] train_loss: 0.0012504697508144615, acc: 0.8615033222591362, lr: 0.03673747244950439
[batch_idx--350] train_loss: 0.0012465734903745757, acc: 0.8618567485754985, lr: 0.03668618778726586
[batch_idx--400] train_loss: 0.0012539565398304391, acc: 0.8608361907730673, lr: 0.0366348401197659
[batch_idx--450] train_loss: 0.0012591278353961343, acc: 0.8608758287916132, lr: 0.036583429723841876
total time of one epoch: 217.28438115119934 s
train_loss:  0.0012591278353961343  acc:  0.8608758287916132
->>lr:0.036583
test_loss:  0.001190787132952849  test_acc:  0.8720684948504778
best acc:  87.08276461099392
Saving..

------Epoch: 52------
[batch_idx--0] train_loss: 0.001140593085438013, acc: 0.8671875, lr: 0.036582400877996545
[batch_idx--50] train_loss: 0.0012504677459433237, acc: 0.8602175245098039, lr: 0.03653092678462853
[batch_idx--100] train_loss: 0.0012274288144746408, acc: 0.864325495049505, lr: 0.036479390523077894
[batch_idx--150] train_loss: 0.0012295815345078757, acc: 0.8648334023178808, lr: 0.036427792371198774
[batch_idx--200] train_loss: 0.0012268290599571792, acc: 0.8656327736318408, lr: 0.036376132607179
[batch_idx--250] train_loss: 0.001234645488907572, acc: 0.8645107071713147, lr: 0.03632441150953856
[batch_idx--300] train_loss: 0.0012317764616503297, acc: 0.8646309177740864, lr: 0.036272629357128106
[batch_idx--350] train_loss: 0.0012299409925544957, acc: 0.8650062321937322, lr: 0.0362207864291275
[batch_idx--400] train_loss: 0.0012328561498177355, acc: 0.8645476153366584, lr: 0.03616888300504424
[batch_idx--450] train_loss: 0.0012381681602444475, acc: 0.8642083521366335, lr: 0.03611691936471199
total time of one epoch: 215.17031407356262 s
train_loss:  0.0012381681602444475  acc:  0.8642083521366335
->>lr:0.036117
test_loss:  0.0011705219013428538  test_acc:  0.8752947015758779
best acc:  87.20684948504777
Saving..

------Epoch: 53------
[batch_idx--0] train_loss: 0.0011418589856475592, acc: 0.89453125, lr: 0.036115879479623185
[batch_idx--50] train_loss: 0.0012737352026662991, acc: 0.8587622549019608, lr: 0.0360638547073383
[batch_idx--100] train_loss: 0.0012511471718651159, acc: 0.8602258663366337, lr: 0.036011770285057136
[batch_idx--150] train_loss: 0.0012442887242612064, acc: 0.8617032284768212, lr: 0.03595962649358918
[batch_idx--200] train_loss: 0.0012406361065179442, acc: 0.8626399253731343, lr: 0.03590742361406404
[batch_idx--250] train_loss: 0.0012402179065639102, acc: 0.8628454930278885, lr: 0.03585516192792988
[batch_idx--300] train_loss: 0.001244788335797151, acc: 0.862048380398671, lr: 0.03580284171695191
[batch_idx--350] train_loss: 0.0012453930620621475, acc: 0.862068198005698, lr: 0.03575046326321087
[batch_idx--400] train_loss: 0.0012439187867810805, acc: 0.8622097100997507, lr: 0.035698026849101526
[batch_idx--450] train_loss: 0.0012432490694186421, acc: 0.862828479189086, lr: 0.03564553275733112
total time of one epoch: 213.03993344306946 s
train_loss:  0.0012432490694186421  acc:  0.862828479189086
->>lr:0.035646
test_loss:  0.0012150172937861565  test_acc:  0.8685941183769699
best acc:  87.5294701575878

------Epoch: 54------
[batch_idx--0] train_loss: 0.0012232467997819185, acc: 0.8515625, lr: 0.03564448228912682
[batch_idx--50] train_loss: 0.0012566452724950424, acc: 0.8580729166666666, lr: 0.035591929657709624
[batch_idx--100] train_loss: 0.0012404137189583023, acc: 0.8605352722772277, lr: 0.03553931992064693
[batch_idx--150] train_loss: 0.0012261745121348526, acc: 0.8636951572847682, lr: 0.035486653361580446
[batch_idx--200] train_loss: 0.001227755862605568, acc: 0.863242381840796, lr: 0.03543393026445823
[batch_idx--250] train_loss: 0.0012224109547001225, acc: 0.8646352091633466, lr: 0.03538115091353316
[batch_idx--300] train_loss: 0.0012257610889773605, acc: 0.8644362541528239, lr: 0.035328315593361394
[batch_idx--350] train_loss: 0.0012249245837017723, acc: 0.8647947827635327, lr: 0.03527542458880086
[batch_idx--400] train_loss: 0.001224278472509105, acc: 0.8648690773067331, lr: 0.035222478185009704
[batch_idx--450] train_loss: 0.0012285206735249995, acc: 0.8649460200645677, lr: 0.035169476667444736
total time of one epoch: 215.0507709980011 s
train_loss:  0.0012285206735249995  acc:  0.8649460200645677
->>lr:0.035169
test_loss:  0.0011718900346596227  test_acc:  0.8744261074575009
best acc:  87.5294701575878

------Epoch: 55------
[batch_idx--0] train_loss: 0.001294306362979114, acc: 0.83984375, lr: 0.035168416076895005
[batch_idx--50] train_loss: 0.0012180199606946723, acc: 0.8639705882352942, lr: 0.03511535863766653
[batch_idx--100] train_loss: 0.0012249916989015102, acc: 0.8645188737623762, lr: 0.03506224666219176
[batch_idx--150] train_loss: 0.0012250756147157227, acc: 0.8648851407284768, lr: 0.03500908043682018
[batch_idx--200] train_loss: 0.0012276522715029246, acc: 0.8638448383084577, lr: 0.034955860248193804
[batch_idx--250] train_loss: 0.0012249824694409758, acc: 0.864339516932271, lr: 0.034902586383245504
[batch_idx--300] train_loss: 0.0012265634941528135, acc: 0.8640858596345515, lr: 0.03484925912919761
[batch_idx--350] train_loss: 0.0012258261731066913, acc: 0.8641826923076923, lr: 0.03479587877356025
[batch_idx--400] train_loss: 0.001220836267984261, acc: 0.8649470074812967, lr: 0.034742445604129875
[batch_idx--450] train_loss: 0.001221673896183643, acc: 0.8651890165584754, lr: 0.034688959908987675
total time of one epoch: 208.88651609420776 s
train_loss:  0.001221673896183643  acc:  0.8651890165584754
->>lr:0.034689
test_loss:  0.0011826379691301586  test_acc:  0.8703313066137238
best acc:  87.5294701575878

------Epoch: 56------
[batch_idx--0] train_loss: 0.001206100219860673, acc: 0.87890625, lr: 0.034687889661302575
[batch_idx--50] train_loss: 0.0012393757899510948, acc: 0.8632046568627451, lr: 0.034634350687009215
[batch_idx--100] train_loss: 0.0012205098588526765, acc: 0.8652537128712872, lr: 0.034580759769790186
[batch_idx--150] train_loss: 0.0012262743799052885, acc: 0.863177773178808, lr: 0.034527117198577144
[batch_idx--200] train_loss: 0.001226058323341723, acc: 0.8641363495024875, lr: 0.034473423262580266
[batch_idx--250] train_loss: 0.0012210347600173635, acc: 0.8651020916334662, lr: 0.03441967825128663
[batch_idx--300] train_loss: 0.0012208038486193778, acc: 0.8654874377076412, lr: 0.0343658824544587
[batch_idx--350] train_loss: 0.0012199144133504618, acc: 0.865707353988604, lr: 0.034312036162132735
[batch_idx--400] train_loss: 0.001219519546245018, acc: 0.8656386377805486, lr: 0.034258139664617236
[batch_idx--450] train_loss: 0.0012216407424319716, acc: 0.8659353629326205, lr: 0.0342041932524914
total time of one epoch: 212.95867037773132 s
train_loss:  0.0012216407424319716  acc:  0.8659353629326205
->>lr:0.034204
test_loss:  0.0012453823490316776  test_acc:  0.8682218637548083
best acc:  87.5294701575878

------Epoch: 57------
[batch_idx--0] train_loss: 0.0010096797486767173, acc: 0.8984375, lr: 0.03420311381711696
[batch_idx--50] train_loss: 0.0012478672410817999, acc: 0.8621323529411765, lr: 0.03414911679172232
[batch_idx--100] train_loss: 0.0012368208205438044, acc: 0.8654084158415841, lr: 0.034095070439506506
[batch_idx--150] train_loss: 0.0012386309658331388, acc: 0.8643418874172185, lr: 0.03404097505185664
[batch_idx--200] train_loss: 0.0012317174157725453, acc: 0.8640780472636815, lr: 0.0339868309204242
[batch_idx--250] train_loss: 0.0012290391092841695, acc: 0.8646818974103586, lr: 0.03393263833712346
[batch_idx--300] train_loss: 0.0012259417879890242, acc: 0.8652668189368771, lr: 0.03387839759412996
[batch_idx--350] train_loss: 0.0012241061196458178, acc: 0.8658854166666666, lr: 0.03382410898387883
[batch_idx--400] train_loss: 0.0012219918622087195, acc: 0.8658237219451371, lr: 0.033769772799063326
[batch_idx--450] train_loss: 0.0012235529738887883, acc: 0.8658832922553547, lr: 0.03371538933263315
total time of one epoch: 207.42496156692505 s
train_loss:  0.0012235529738887883  acc:  0.8658832922553547
->>lr:0.033715
test_loss:  0.0012794023582843326  test_acc:  0.8586673284526616
best acc:  87.5294701575878

------Epoch: 58------
[batch_idx--0] train_loss: 0.0011272428091615438, acc: 0.88671875, lr: 0.03371430118304538
[batch_idx--50] train_loss: 0.0012245541826511424, acc: 0.8674172794117647, lr: 0.03365986979142943
[batch_idx--100] train_loss: 0.0012089416446938817, acc: 0.8690826113861386, lr: 0.03360539171073317
[batch_idx--150] train_loss: 0.0012009105157871909, acc: 0.8694122516556292, lr: 0.03355086723467137
[batch_idx--200] train_loss: 0.0012039796890000538, acc: 0.869014303482587, lr: 0.03349629665720888
[batch_idx--250] train_loss: 0.0012046097155356133, acc: 0.8688371513944223, lr: 0.03344168027255918
[batch_idx--300] train_loss: 0.0012088355266386983, acc: 0.8681478405315615, lr: 0.033387018375182646
[batch_idx--350] train_loss: 0.0012059030247430324, acc: 0.8683894230769231, lr: 0.03333231125978507
[batch_idx--400] train_loss: 0.0012103421519222457, acc: 0.8676258572319202, lr: 0.03327755922131603
[batch_idx--450] train_loss: 0.0012142815119483914, acc: 0.8679314055611483, lr: 0.033222762554967304
total time of one epoch: 230.3483099937439 s
train_loss:  0.0012142815119483914  acc:  0.8679314055611483
->>lr:0.033223
test_loss:  0.0012230487330732902  test_acc:  0.8646234024072466
best acc:  87.5294701575878

------Epoch: 59------
[batch_idx--0] train_loss: 0.0011581818107515574, acc: 0.87890625, lr: 0.03322166616846458
[batch_idx--50] train_loss: 0.0011838125373127267, acc: 0.8726256127450981, lr: 0.033166824286034645
[batch_idx--100] train_loss: 0.001180033620197953, acc: 0.8725247524752475, lr: 0.03311193837274467
[batch_idx--150] train_loss: 0.0011800031824537017, acc: 0.8718439569536424, lr: 0.03305700872450816
[batch_idx--200] train_loss: 0.0011891149426347099, acc: 0.8700443097014925, lr: 0.03300203563747449
[batch_idx--250] train_loss: 0.0011953288648440781, acc: 0.8692729083665338, lr: 0.0329470194080272
[batch_idx--300] train_loss: 0.0011947182304167074, acc: 0.8697700373754153, lr: 0.032891960332782424
[batch_idx--350] train_loss: 0.0012015342338281309, acc: 0.8683226495726496, lr: 0.03283685870858731
[batch_idx--400] train_loss: 0.0012033201459135646, acc: 0.86805447319202, lr: 0.03278171483251839
[batch_idx--450] train_loss: 0.0012076802388287246, acc: 0.8675495539278647, lr: 0.03272652900188
total time of one epoch: 207.9177951812744 s
train_loss:  0.0012076802388287246  acc:  0.8675495539278647
->>lr:0.032727
test_loss:  0.0011718634218772597  test_acc:  0.8739297679612855
best acc:  87.5294701575878

------Epoch: 60------
[batch_idx--0] train_loss: 0.0009162806090898812, acc: 0.92578125, lr: 0.032725424859373686
[batch_idx--50] train_loss: 0.001195901453577201, acc: 0.8687193627450981, lr: 0.032670196541591943
[batch_idx--100] train_loss: 0.0011801921905451778, acc: 0.8708230198019802, lr: 0.03261492687048379
[batch_idx--150] train_loss: 0.0011835630392557047, acc: 0.8709126655629139, lr: 0.03255961614403176
[batch_idx--200] train_loss: 0.0011904285905016262, acc: 0.8703163868159204, lr: 0.03250426466043975
[batch_idx--250] train_loss: 0.0011924383466120855, acc: 0.8695841633466136, lr: 0.03244887271813142
[batch_idx--300] train_loss: 0.0011936138529853393, acc: 0.869484530730897, lr: 0.032393440615748524
[batch_idx--350] train_loss: 0.0011949103527590951, acc: 0.8690237713675214, lr: 0.03233796865214936
[batch_idx--400] train_loss: 0.0011989790991243634, acc: 0.8688629987531172, lr: 0.03228245712640712
[batch_idx--450] train_loss: 0.001201579185539529, acc: 0.8689207484292012, lr: 0.0322269063378083
total time of one epoch: 214.60792517662048 s
train_loss:  0.001201579185539529  acc:  0.8689207484292012
->>lr:0.032227
test_loss:  0.001215665559937898  test_acc:  0.8695867973694007
best acc:  87.5294701575878

------Epoch: 61------
[batch_idx--0] train_loss: 0.0010545662371441722, acc: 0.89453125, lr: 0.03222579492361179
[batch_idx--50] train_loss: 0.0011468423888835982, acc: 0.8765318627450981, lr: 0.032170204395443734
[batch_idx--100] train_loss: 0.0011900788389773358, acc: 0.8710163985148515, lr: 0.03211457520962184
[batch_idx--150] train_loss: 0.0011990477210712552, acc: 0.8696192052980133, lr: 0.032058907666066935
[batch_idx--200] train_loss: 0.0011970599437368782, acc: 0.8696361940298507, lr: 0.03200320206490668
[batch_idx--250] train_loss: 0.0012006661126508834, acc: 0.8690861553784861, lr: 0.03194745870647391
[batch_idx--300] train_loss: 0.001201399703134173, acc: 0.8692639119601329, lr: 0.03189167789130505
[batch_idx--350] train_loss: 0.0012027158674205577, acc: 0.8693353810541311, lr: 0.031835859920138446
[batch_idx--400] train_loss: 0.0012025306309907792, acc: 0.869466957605985, lr: 0.03178000509391275
[batch_idx--450] train_loss: 0.001206789783103797, acc: 0.8688947130905683, lr: 0.03172411371376536
total time of one epoch: 212.66797161102295 s
train_loss:  0.001206789783103797  acc:  0.8688947130905683
->>lr:0.031724
test_loss:  0.0011537284849742933  test_acc:  0.8765355503164164
best acc:  87.5294701575878
Saving..

------Epoch: 62------
[batch_idx--0] train_loss: 0.0012210863642394543, acc: 0.859375, lr: 0.031722995515381644
[batch_idx--50] train_loss: 0.0011876394034034626, acc: 0.8711703431372549, lr: 0.03166706716067022
[batch_idx--100] train_loss: 0.0011944503927981426, acc: 0.8682704207920792, lr: 0.03161110286093404
[batch_idx--150] train_loss: 0.0011910693357630774, acc: 0.8676014072847682, lr: 0.031555102917900694
[batch_idx--200] train_loss: 0.0011916971899828507, acc: 0.867362406716418, lr: 0.03149906763348994
[batch_idx--250] train_loss: 0.0011845226972400993, acc: 0.8696152888446215, lr: 0.0314429973098121
[batch_idx--300] train_loss: 0.0011782729011988174, acc: 0.8708990863787376, lr: 0.031386892249166375
[batch_idx--350] train_loss: 0.0011805527992122024, acc: 0.8710492343304843, lr: 0.03133075275403927
[batch_idx--400] train_loss: 0.001179850512059949, acc: 0.8712009039900249, lr: 0.03127457912710293
[batch_idx--450] train_loss: 0.0011882336977893197, acc: 0.8703006213767487, lr: 0.031218371671213524
total time of one epoch: 210.42522382736206 s
train_loss:  0.0011882336977893197  acc:  0.8703006213767487
->>lr:0.031218
test_loss:  0.0011310441009695677  test_acc:  0.8787690780493858
best acc:  87.65355503164164
Saving..

------Epoch: 63------
[batch_idx--0] train_loss: 0.0013908675173297524, acc: 0.86328125, lr: 0.031217247179121367
[batch_idx--50] train_loss: 0.0011872673640027642, acc: 0.8711703431372549, lr: 0.0311610055298914
[batch_idx--100] train_loss: 0.0011962126804478835, acc: 0.8699721534653465, lr: 0.031104730664032437
[batch_idx--150] train_loss: 0.001188244051161216, acc: 0.871171357615894, lr: 0.031048422884946483
[batch_idx--200] train_loss: 0.0011810245631211692, acc: 0.8721431902985075, lr: 0.030992082496212964
[batch_idx--250] train_loss: 0.0011821467423833818, acc: 0.8718718874501992, lr: 0.030935709801587143
[batch_idx--300] train_loss: 0.0011777622579593843, acc: 0.8723915074750831, lr: 0.03087930510499845
[batch_idx--350] train_loss: 0.0011815202519950322, acc: 0.8715277777777778, lr: 0.030822868710548842
[batch_idx--400] train_loss: 0.0011804173032792652, acc: 0.8716002961346634, lr: 0.030766400922511174
[batch_idx--450] train_loss: 0.0011857591584166034, acc: 0.8710990384281598, lr: 0.030709902045327583
total time of one epoch: 214.33437323570251 s
train_loss:  0.0011857591584166034  acc:  0.8710990384281598
->>lr:0.030710
test_loss:  0.0011379001734939842  test_acc:  0.880258096538032
best acc:  87.87690780493858
Saving..

------Epoch: 64------
[batch_idx--0] train_loss: 0.0013164659030735493, acc: 0.8359375, lr: 0.030708771752766397
[batch_idx--50] train_loss: 0.001210312503983504, acc: 0.8672640931372549, lr: 0.030652241478464032
[batch_idx--100] train_loss: 0.0011853870467771546, acc: 0.8699334777227723, lr: 0.03059568073049836
[batch_idx--150] train_loss: 0.0011957549152353051, acc: 0.8698520281456954, lr: 0.030539089813812693
[batch_idx--200] train_loss: 0.0011912046370457913, acc: 0.8703552549751243, lr: 0.03048246903351297
[batch_idx--250] train_loss: 0.0011903777304828997, acc: 0.8702066733067729, lr: 0.030425818694866172
[batch_idx--300] train_loss: 0.001194491440413266, acc: 0.8693677325581395, lr: 0.030369139103298623
[batch_idx--350] train_loss: 0.0011937590854897819, acc: 0.8695468304843305, lr: 0.030312430564394355
[batch_idx--400] train_loss: 0.001193205269455371, acc: 0.8697202306733167, lr: 0.03025569338389348
[batch_idx--450] train_loss: 0.0011935399383379956, acc: 0.8694848474329157, lr: 0.03019892786769053
total time of one epoch: 219.97577381134033 s
train_loss:  0.0011935399383379956  acc:  0.8694848474329157
->>lr:0.030199
test_loss:  0.0011642129375526635  test_acc:  0.8771559746866857
best acc:  88.02580965380321

------Epoch: 65------
[batch_idx--0] train_loss: 0.0012668377021327615, acc: 0.859375, lr: 0.03019779227044398
[batch_idx--50] train_loss: 0.001188238249525574, acc: 0.8713235294117647, lr: 0.03014099816711588
[batch_idx--100] train_loss: 0.00118120175401339, acc: 0.8722540222772277, lr: 0.030084176346456905
[batch_idx--150] train_loss: 0.0011765308125370139, acc: 0.8722837334437086, lr: 0.030027327114817932
[batch_idx--200] train_loss: 0.0011754434767749105, acc: 0.8723569651741293, lr: 0.029970450778697578
[batch_idx--250] train_loss: 0.001182184557651218, acc: 0.8712960657370518, lr: 0.02991354764474065
[batch_idx--300] train_loss: 0.0011814659505083142, acc: 0.8712884136212624, lr: 0.02985661801973638
[batch_idx--350] train_loss: 0.0011813835925130742, acc: 0.8712829415954416, lr: 0.02979966221061685
[batch_idx--400] train_loss: 0.0011832580881070188, acc: 0.8707430642144638, lr: 0.029742680524455323
[batch_idx--450] train_loss: 0.0011865757685086784, acc: 0.8705262609782345, lr: 0.02968567326846454
total time of one epoch: 216.6208050251007 s
train_loss:  0.0011865757685086784  acc:  0.8705262609782345
->>lr:0.029686
test_loss:  0.0011560157531247657  test_acc:  0.8780245688050626
best acc:  88.02580965380321

------Epoch: 66------
[batch_idx--0] train_loss: 0.0012151701375842094, acc: 0.87109375, lr: 0.02968453286464312
[batch_idx--50] train_loss: 0.0011572028446358209, acc: 0.874234068627451, lr: 0.029627499844060053
[batch_idx--100] train_loss: 0.0011619509308423736, acc: 0.8733756188118812, lr: 0.029570441874636297
[batch_idx--150] train_loss: 0.0011642596519410315, acc: 0.8729822019867549, lr: 0.029513359263995894
[batch_idx--200] train_loss: 0.001171337484917256, acc: 0.8722403606965174, lr: 0.029456252319895716
[batch_idx--250] train_loss: 0.0011768844231417723, acc: 0.8714050049800797, lr: 0.029399121350223874
[batch_idx--300] train_loss: 0.001170746729155365, acc: 0.8721968438538206, lr: 0.029341966662997956
[batch_idx--350] train_loss: 0.0011715308225453643, acc: 0.8721843839031339, lr: 0.02928478856636346
[batch_idx--400] train_loss: 0.001170691373604733, acc: 0.8721555486284289, lr: 0.02922758736859208
[batch_idx--450] train_loss: 0.001175913691663459, acc: 0.8714461762765995, lr: 0.02917036337808005
total time of one epoch: 214.4158070087433 s
train_loss:  0.001175913691663459  acc:  0.8714461762765995
->>lr:0.029170
test_loss:  0.0012232133743558544  test_acc:  0.8697108822434545
best acc:  88.02580965380321

------Epoch: 67------
[batch_idx--0] train_loss: 0.0009665068355388939, acc: 0.90625, lr: 0.02916921866790256
[batch_idx--50] train_loss: 0.0011707158455643437, acc: 0.8730085784313726, lr: 0.029111971746632322
[batch_idx--100] train_loss: 0.0011695312741811913, acc: 0.8719832920792079, lr: 0.02905470265595496
[batch_idx--150] train_loss: 0.0011738800884699388, acc: 0.8718439569536424, lr: 0.028997411704632756
[batch_idx--200] train_loss: 0.0011787383990311318, acc: 0.8713852611940298, lr: 0.02894009920154584
[batch_idx--250] train_loss: 0.0011756400168647031, acc: 0.8718563247011952, lr: 0.02888276545569057
[batch_idx--300] train_loss: 0.0011736906666936742, acc: 0.8722227990033222, lr: 0.0288254107761778
[batch_idx--350] train_loss: 0.0011738032484665895, acc: 0.8720842236467237, lr: 0.028768035472231265
[batch_idx--400] train_loss: 0.0011736669059740634, acc: 0.8725062344139651, lr: 0.0287106398531859
[batch_idx--450] train_loss: 0.0011742762744335687, acc: 0.8729215121324678, lr: 0.02865322422848614
total time of one epoch: 214.69432663917542 s
train_loss:  0.0011742762744335687  acc:  0.8729215121324678
->>lr:0.028653
test_loss:  0.0011354171230562539  test_acc:  0.8822434545228937
best acc:  88.02580965380321
Saving..

------Epoch: 68------
[batch_idx--0] train_loss: 0.0014051725156605244, acc: 0.8203125, lr: 0.028652075714060296
[batch_idx--50] train_loss: 0.0011554562393119377, acc: 0.8733149509803921, lr: 0.028594640002494582
[batch_idx--100] train_loss: 0.0011826649390041164, acc: 0.8696240717821783, lr: 0.028537184910679542
[batch_idx--150] train_loss: 0.0011811845292898498, acc: 0.8700072433774835, lr: 0.028479710748380266
[batch_idx--200] train_loss: 0.001178198200082916, acc: 0.8706078980099502, lr: 0.028422217825464665
[batch_idx--250] train_loss: 0.0011718976383275571, acc: 0.8717473854581673, lr: 0.028364706451901797
[batch_idx--300] train_loss: 0.0011722674348509168, acc: 0.8715998754152824, lr: 0.028307176937760206
[batch_idx--350] train_loss: 0.0011654510136237342, acc: 0.8726740562678063, lr: 0.028249629593206222
[batch_idx--400] train_loss: 0.0011662062526938326, acc: 0.8725062344139651, lr: 0.02819206472850232
[batch_idx--450] train_loss: 0.001169269145198212, acc: 0.872756621654459, lr: 0.02813448265400542
total time of one epoch: 206.0924208164215 s
train_loss:  0.001169269145198212  acc:  0.872756621654459
->>lr:0.028134
test_loss:  0.0011225777914749214  test_acc:  0.876907804938578
best acc:  88.22434545228937

------Epoch: 69------
[batch_idx--0] train_loss: 0.0011443868279457092, acc: 0.90234375, lr: 0.028133330839107608
[batch_idx--50] train_loss: 0.0011481636468613264, acc: 0.8786764705882353, lr: 0.028075731530447786
[batch_idx--100] train_loss: 0.0011406145577254419, acc: 0.8778233292079208, lr: 0.028018115639197247
[batch_idx--150] train_loss: 0.001145354898828421, acc: 0.8767849751655629, lr: 0.027960483475988025
[batch_idx--200] train_loss: 0.0011532372321275558, acc: 0.8750971703980099, lr: 0.02790283535153988
[batch_idx--250] train_loss: 0.0011550549812433105, acc: 0.8745175547808764, lr: 0.027845171576658636
[batch_idx--300] train_loss: 0.0011610504966136379, acc: 0.8737411752491694, lr: 0.027787492462234484
[batch_idx--350] train_loss: 0.0011619564696039972, acc: 0.8737758190883191, lr: 0.02772979831924033
[batch_idx--400] train_loss: 0.0011609259726040697, acc: 0.8738407886533666, lr: 0.02767208945873009
[batch_idx--450] train_loss: 0.001164795618698135, acc: 0.873685215399035, lr: 0.027614366191837037
total time of one epoch: 219.94555068016052 s
train_loss:  0.001164795618698135  acc:  0.873685215399035
->>lr:0.027614
test_loss:  0.001131560127867379  test_acc:  0.880258096538032
best acc:  88.22434545228937

------Epoch: 70------
[batch_idx--0] train_loss: 0.0010918325278908014, acc: 0.8828125, lr: 0.02761321158169134
[batch_idx--50] train_loss: 0.0011590160246865422, acc: 0.8747702205882353, lr: 0.027555473940897853
[batch_idx--100] train_loss: 0.0011322753046325749, acc: 0.876353650990099, lr: 0.027497722522445946
[batch_idx--150] train_loss: 0.001135520563408461, acc: 0.8769401903973509, lr: 0.027439957637698322
[batch_idx--200] train_loss: 0.001146671702779496, acc: 0.8756218905472637, lr: 0.027382179598090313
[batch_idx--250] train_loss: 0.0011515642650354937, acc: 0.8753890687250996, lr: 0.027324388715128153
[batch_idx--300] train_loss: 0.0011502988021542316, acc: 0.8752206187707641, lr: 0.027266585300387343
[batch_idx--350] train_loss: 0.0011559009681020643, acc: 0.8746216168091168, lr: 0.027208769665510946
[batch_idx--400] train_loss: 0.0011599118272051625, acc: 0.8742596633416458, lr: 0.027150942122207884
[batch_idx--450] train_loss: 0.0011619375580575518, acc: 0.8744228833269692, lr: 0.027093102982251305
total time of one epoch: 223.99032497406006 s
train_loss:  0.0011619375580575518  acc:  0.8744228833269692
->>lr:0.027093
test_loss:  0.0011006032289709016  test_acc:  0.8823675393969476
best acc:  88.22434545228937
Saving..

------Epoch: 71------
[batch_idx--0] train_loss: 0.0013756223488599062, acc: 0.8359375, lr: 0.02709194608330789
[batch_idx--50] train_loss: 0.0011682660083797778, acc: 0.8731617647058824, lr: 0.027034095436018247
[batch_idx--100] train_loss: 0.0011571368892990643, acc: 0.8731435643564357, lr: 0.026976233822045795
[batch_idx--150] train_loss: 0.0011485149025368129, acc: 0.8739393625827815, lr: 0.026918361553347366
[batch_idx--200] train_loss: 0.0011505782149560675, acc: 0.8741060323383084, lr: 0.026860478941937244
[batch_idx--250] train_loss: 0.0011547924700263605, acc: 0.8738327938247012, lr: 0.026802586299885446
[batch_idx--300] train_loss: 0.0011574042724303134, acc: 0.8736503322259136, lr: 0.026744683939316106
[batch_idx--350] train_loss: 0.0011582960294389784, acc: 0.8732861467236467, lr: 0.026686772172405743
[batch_idx--400] train_loss: 0.00116032141433829, acc: 0.8733829488778054, lr: 0.02662885131138157
[batch_idx--450] train_loss: 0.0011621978333455957, acc: 0.8738240705384108, lr: 0.026570921668519862
total time of one epoch: 222.3401279449463 s
train_loss:  0.0011621978333455957  acc:  0.8738240705384108
->>lr:0.026571
test_loss:  0.0010927322891868215  test_acc:  0.8834843032634322
best acc:  88.23675393969475
Saving..

------Epoch: 72------
[batch_idx--0] train_loss: 0.0010221701813861728, acc: 0.89453125, lr: 0.026569762988232833
[batch_idx--50] train_loss: 0.0011940485359553028, acc: 0.8686427696078431, lr: 0.026511824709652916
[batch_idx--100] train_loss: 0.0011793331497828338, acc: 0.8707069925742574, lr: 0.02645387828017616
[batch_idx--150] train_loss: 0.0011672339655014853, acc: 0.8724130794701986, lr: 0.026395924012216673
[batch_idx--200] train_loss: 0.0011561309509859675, acc: 0.8739894278606966, lr: 0.02633796221823084
[batch_idx--250] train_loss: 0.0011561377480926653, acc: 0.8739261703187251, lr: 0.026279993210715575
[batch_idx--300] train_loss: 0.0011534160797861698, acc: 0.8744549418604651, lr: 0.026222017302206753
[batch_idx--350] train_loss: 0.0011538861057737, acc: 0.8745325854700855, lr: 0.02616403480527739
[batch_idx--400] train_loss: 0.0011571590475705535, acc: 0.8741135442643392, lr: 0.02610604603253605
[batch_idx--450] train_loss: 0.0011596809702161723, acc: 0.8742666712951713, lr: 0.026048051296625147
total time of one epoch: 219.10720562934875 s
train_loss:  0.0011596809702161723  acc:  0.8742666712951713
->>lr:0.026048
test_loss:  0.0011191204502736683  test_acc:  0.8842288125077553
best acc:  88.34843032634322
Saving..

------Epoch: 73------
[batch_idx--0] train_loss: 0.0012849140912294388, acc: 0.84375, lr: 0.02604689134322999
[batch_idx--50] train_loss: 0.0011668199349158242, acc: 0.8743872549019608, lr: 0.025988890847003655
[batch_idx--100] train_loss: 0.0011501774856922133, acc: 0.8749226485148515, lr: 0.025930885019241706
[batch_idx--150] train_loss: 0.0011579488764134611, acc: 0.8735254552980133, lr: 0.025872874172678507
[batch_idx--200] train_loss: 0.0011554413804650047, acc: 0.8740088619402985, lr: 0.02581485862007545
[batch_idx--250] train_loss: 0.001151272813247821, acc: 0.874937749003984, lr: 0.02575683867421932
[batch_idx--300] train_loss: 0.0011510666741361452, acc: 0.8754282599667774, lr: 0.02569881464792059
[batch_idx--350] train_loss: 0.0011482892046878884, acc: 0.8757678952991453, lr: 0.02564078685401172
[batch_idx--400] train_loss: 0.0011498757496945318, acc: 0.875564993765586, lr: 0.025582755605345495
[batch_idx--450] train_loss: 0.001154384925818209, acc: 0.875525045995765, lr: 0.02552472121479332
total time of one epoch: 212.66807317733765 s
train_loss:  0.001154384925818209  acc:  0.875525045995765
->>lr:0.025525
test_loss:  0.0012755900832201177  test_acc:  0.860900856185631
best acc:  88.42288125077553

------Epoch: 74------
[batch_idx--0] train_loss: 0.0009751840261742473, acc: 0.9140625, lr: 0.025523560497083927
[batch_idx--50] train_loss: 0.0011256980543097883, acc: 0.8780637254901961, lr: 0.025465523224145754
[batch_idx--100] train_loss: 0.0011237655515035632, acc: 0.8783647896039604, lr: 0.02540748344137178
[batch_idx--150] train_loss: 0.0011315070954614028, acc: 0.8774058360927153, lr: 0.02534944146167944
[batch_idx--200] train_loss: 0.0011396234752540824, acc: 0.8758745335820896, lr: 0.025291397597997967
[batch_idx--250] train_loss: 0.0011447618186262352, acc: 0.875062250996016, lr: 0.025233352163266793
[batch_idx--300] train_loss: 0.0011498027365496907, acc: 0.8745976951827242, lr: 0.025175305470433812
[batch_idx--350] train_loss: 0.0011512022694318085, acc: 0.874321136039886, lr: 0.025117257832453683
[batch_idx--400] train_loss: 0.0011511879728960705, acc: 0.874522677680798, lr: 0.025059209562286185
[batch_idx--450] train_loss: 0.0011545251467175216, acc: 0.8743447773110702, lr: 0.02500116097289448
total time of one epoch: 226.17692375183105 s
train_loss:  0.0011545251467175216  acc:  0.8743447773110702
->>lr:0.025001
test_loss:  0.0010904096901779184  test_acc:  0.8884476982255863
best acc:  88.42288125077553
Saving..

------Epoch: 75------
[batch_idx--0] train_loss: 0.0010742486920207739, acc: 0.890625, lr: 0.025
[batch_idx--50] train_loss: 0.0011284066405256882, acc: 0.8792126225490197, lr: 0.024941951407416053
[batch_idx--100] train_loss: 0.0011482943860251494, acc: 0.8768177599009901, lr: 0.024883903127797022
[batch_idx--150] train_loss: 0.0011474119467716295, acc: 0.8758536837748344, lr: 0.02482585547410613
[batch_idx--200] train_loss: 0.0011469936198137923, acc: 0.8763215174129353, lr: 0.024767808759303227
[batch_idx--250] train_loss: 0.0011447921689354862, acc: 0.8760427041832669, lr: 0.024709763296343102
[batch_idx--300] train_loss: 0.0011445563897626641, acc: 0.8758694975083057, lr: 0.024651719398173802
[batch_idx--350] train_loss: 0.001143033849572938, acc: 0.8762575676638177, lr: 0.024593677377734924
[batch_idx--400] train_loss: 0.001142948998998795, acc: 0.876237141521197, lr: 0.02453563754795596
[batch_idx--450] train_loss: 0.001146442732858522, acc: 0.8762193216926442, lr: 0.024477600221754565
total time of one epoch: 214.44430232048035 s
train_loss:  0.001146442732858522  acc:  0.8762193216926442
->>lr:0.024478
test_loss:  0.0010890311192069816  test_acc:  0.8854696612482938
best acc:  88.84476982255863

------Epoch: 76------
[batch_idx--0] train_loss: 0.0012110067764297128, acc: 0.8828125, lr: 0.02447643950291608
[batch_idx--50] train_loss: 0.001130325176442663, acc: 0.8775275735294118, lr: 0.024418405052717584
[batch_idx--100] train_loss: 0.0011317035999370388, acc: 0.8770111386138614, lr: 0.024360373738147447
[batch_idx--150] train_loss: 0.0011397896300606577, acc: 0.8771471440397351, lr: 0.024302345872077406
[batch_idx--200] train_loss: 0.001140851662980754, acc: 0.8773126554726368, lr: 0.024244321767360646
[batch_idx--250] train_loss: 0.0011328814353652862, acc: 0.8780191733067729, lr: 0.024186301736830045
[batch_idx--300] train_loss: 0.0011294870258330605, acc: 0.8784001245847176, lr: 0.024128286093296536
[batch_idx--350] train_loss: 0.0011344666080682026, acc: 0.877960292022792, lr: 0.02407027514954738
[batch_idx--400] train_loss: 0.0011372865247946614, acc: 0.8772404925187033, lr: 0.024012269218344526
[batch_idx--450] train_loss: 0.0011436667358098948, acc: 0.8765230673100288, lr: 0.023954268612422863
total time of one epoch: 223.10996413230896 s
train_loss:  0.0011436667358098948  acc:  0.8765230673100288
->>lr:0.023954
test_loss:  0.0010919086353138934  test_acc:  0.883608388137486
best acc:  88.84476982255863

------Epoch: 77------
[batch_idx--0] train_loss: 0.0011416218476369977, acc: 0.86328125, lr: 0.02395310865677001
[batch_idx--50] train_loss: 0.0011303469141506974, acc: 0.8738511029411765, lr: 0.023895113804784887
[batch_idx--100] train_loss: 0.0011241175764526176, acc: 0.8765470297029703, lr: 0.02383712490971616
[batch_idx--150] train_loss: 0.0011276250897092584, acc: 0.8772247516556292, lr: 0.023779142284206876
[batch_idx--200] train_loss: 0.0011210242183230335, acc: 0.8781677549751243, lr: 0.023721166240866298
[batch_idx--250] train_loss: 0.001123914430177663, acc: 0.8777234810756972, lr: 0.0236631970922682
[batch_idx--300] train_loss: 0.0011244920589821878, acc: 0.8777512458471761, lr: 0.023605235150949158
[batch_idx--350] train_loss: 0.0011340309058162157, acc: 0.8762575676638177, lr: 0.02354728072940694
[batch_idx--400] train_loss: 0.0011376128608925253, acc: 0.8755162874064838, lr: 0.02348933414009873
[batch_idx--450] train_loss: 0.001134891385367012, acc: 0.8762366785850662, lr: 0.02343139569543949
total time of one epoch: 210.35996294021606 s
train_loss:  0.001134891385367012  acc:  0.8762366785850662
->>lr:0.023431
test_loss:  0.0010856810242089257  test_acc:  0.8842288125077553
best acc:  88.84476982255863

------Epoch: 78------
[batch_idx--0] train_loss: 0.0013106826227158308, acc: 0.84375, lr: 0.023430237011767167
[batch_idx--50] train_loss: 0.0011121718174157043, acc: 0.8808976715686274, lr: 0.02337230719645424
[batch_idx--100] train_loss: 0.001111038626830951, acc: 0.8796797648514851, lr: 0.023314386156732855
[batch_idx--150] train_loss: 0.0011142812698573762, acc: 0.8795529801324503, lr: 0.023256474204880216
[batch_idx--200] train_loss: 0.001117451826228635, acc: 0.8796058768656716, lr: 0.023198571653124563
[batch_idx--250] train_loss: 0.0011173247626845343, acc: 0.8794353834661355, lr: 0.02314067881364343
[batch_idx--300] train_loss: 0.0011198625851892852, acc: 0.8788673172757475, lr: 0.02308279599856199
[batch_idx--350] train_loss: 0.001123020404709657, acc: 0.8785612535612536, lr: 0.023024923519951404
[batch_idx--400] train_loss: 0.0011234237180158793, acc: 0.87825358478803, lr: 0.02296706168982706
[batch_idx--450] train_loss: 0.00112497788522014, acc: 0.8779810462734752, lr: 0.022909210820146964
total time of one epoch: 214.65524673461914 s
train_loss:  0.00112497788522014  acc:  0.8779810462734752
->>lr:0.022909
test_loss:  0.0010860933383591849  test_acc:  0.8846010671299168
best acc:  88.84476982255863

------Epoch: 79------
[batch_idx--0] train_loss: 0.0010048812255263329, acc: 0.88671875, lr: 0.022908053916692112
[batch_idx--50] train_loss: 0.0011076484464437647, acc: 0.8803615196078431, lr: 0.022850214547982983
[batch_idx--100] train_loss: 0.0011026133923782127, acc: 0.8820776608910891, lr: 0.022792386769691267
[batch_idx--150] train_loss: 0.0010957266173220628, acc: 0.8826055463576159, lr: 0.022734570893591363
[batch_idx--200] train_loss: 0.0011032611807571975, acc: 0.8815104166666666, lr: 0.022676767231393526
[batch_idx--250] train_loss: 0.0011087443113263948, acc: 0.8803224601593626, lr: 0.02261897609474213
[batch_idx--300] train_loss: 0.0011164003298958249, acc: 0.8788543397009967, lr: 0.022561197795214035
[batch_idx--350] train_loss: 0.001116505553720365, acc: 0.8792957621082621, lr: 0.022503432644316902
[batch_idx--400] train_loss: 0.0011199538500461625, acc: 0.8784873753117207, lr: 0.022445680953487472
[batch_idx--450] train_loss: 0.0011217373720032937, acc: 0.8786840004165655, lr: 0.022387943034089947
total time of one epoch: 232.61077046394348 s
train_loss:  0.0011217373720032937  acc:  0.8786840004165655
->>lr:0.022388
test_loss:  0.0011090449318576353  test_acc:  0.8839806427596476
best acc:  88.84476982255863

------Epoch: 80------
[batch_idx--0] train_loss: 0.0012120968895033002, acc: 0.890625, lr: 0.022386788418308663
[batch_idx--50] train_loss: 0.0011446083845643728, acc: 0.8730085784313726, lr: 0.022329064866462054
[batch_idx--100] train_loss: 0.0011367825491556732, acc: 0.8756574876237624, lr: 0.022271355714774788
[batch_idx--150] train_loss: 0.0011282162937422018, acc: 0.8780525662251656, lr: 0.022213661274381714
[batch_idx--200] train_loss: 0.0011173087541148327, acc: 0.8787507773631841, lr: 0.022155981856338363
[batch_idx--250] train_loss: 0.0011244062445612542, acc: 0.8784082420318725, lr: 0.022098317771619257
[batch_idx--300] train_loss: 0.001125972350189877, acc: 0.8785688330564784, lr: 0.022040669331116272
[batch_idx--350] train_loss: 0.0011313183599966246, acc: 0.8778490028490028, lr: 0.021983036845636923
[batch_idx--400] train_loss: 0.0011305175061184364, acc: 0.8779028990024937, lr: 0.02192542062590272
[batch_idx--450] train_loss: 0.0011303544425468185, acc: 0.8783715763529698, lr: 0.02186782098254747
total time of one epoch: 218.99080681800842 s
train_loss:  0.0011303544425468185  acc:  0.8783715763529698
->>lr:0.021868
test_loss:  0.0010876274923190155  test_acc:  0.8869586797369401
best acc:  88.84476982255863

------Epoch: 81------
[batch_idx--0] train_loss: 0.0009264657273888588, acc: 0.91015625, lr: 0.02186666916089239
[batch_idx--50] train_loss: 0.0011141702176674323, acc: 0.8816636029411765, lr: 0.021809086745365924
[batch_idx--100] train_loss: 0.0011174383176730412, acc: 0.8809173886138614, lr: 0.021751521533424346
[batch_idx--150] train_loss: 0.001108625082265191, acc: 0.8813638245033113, lr: 0.021693973835426473
[batch_idx--200] train_loss: 0.001113556612419678, acc: 0.8802860696517413, lr: 0.021636443961636685
[batch_idx--250] train_loss: 0.0011126224011409123, acc: 0.8801357071713147, lr: 0.021578932222223245
[batch_idx--300] train_loss: 0.0011164035885579315, acc: 0.8796200166112956, lr: 0.021521438927256664
[batch_idx--350] train_loss: 0.00111523062137335, acc: 0.8790731837606838, lr: 0.021463964386708015
[batch_idx--400] train_loss: 0.0011148266453630386, acc: 0.8791497817955112, lr: 0.021406508910447243
[batch_idx--450] train_loss: 0.0011203042806161125, acc: 0.8787447495400423, lr: 0.021349072808241526
total time of one epoch: 241.55936241149902 s
train_loss:  0.0011203042806161125  acc:  0.8787447495400423
->>lr:0.021349
test_loss:  0.001097262689649859  test_acc:  0.883608388137486
best acc:  88.84476982255863

------Epoch: 82------
[batch_idx--0] train_loss: 0.0011693956330418587, acc: 0.89453125, lr: 0.021347924285939714
[batch_idx--50] train_loss: 0.0011080684386851156, acc: 0.8814338235294118, lr: 0.02129050826428394
[batch_idx--100] train_loss: 0.0011153137219129222, acc: 0.8795637376237624, lr: 0.021233112242092567
[batch_idx--150] train_loss: 0.0011114447480931088, acc: 0.8798892798013245, lr: 0.02117573652881221
[batch_idx--200] train_loss: 0.0011041781222748926, acc: 0.8806164490049752, lr: 0.02111838143378
[batch_idx--250] train_loss: 0.00110515264285899, acc: 0.8806181523904383, lr: 0.021061047266221912
[batch_idx--300] train_loss: 0.0011128806143587584, acc: 0.8795810838870431, lr: 0.021003734335251087
[batch_idx--350] train_loss: 0.0011176242054628468, acc: 0.8785389957264957, lr: 0.020946442949866164
[batch_idx--400] train_loss: 0.0011165666455191623, acc: 0.878818578553616, lr: 0.020889173418949643
[batch_idx--450] train_loss: 0.001114541268680371, acc: 0.8794997743603985, lr: 0.020831926051266162
total time of one epoch: 220.5799858570099 s
train_loss:  0.001114541268680371  acc:  0.8794997743603985
->>lr:0.020832
test_loss:  0.0010568014607120054  test_acc:  0.8868345948628862
best acc:  88.84476982255863

------Epoch: 83------
[batch_idx--0] train_loss: 0.0011022054823115468, acc: 0.86328125, lr: 0.020830781332097453
[batch_idx--50] train_loss: 0.0011009805408927302, acc: 0.8810508578431373, lr: 0.020773556888877096
[batch_idx--100] train_loss: 0.0011137513487627453, acc: 0.8795637376237624, lr: 0.020716355232228204
[batch_idx--150] train_loss: 0.0011131299705096577, acc: 0.8796823261589404, lr: 0.020659176670549492
[batch_idx--200] train_loss: 0.001121446905849937, acc: 0.87890625, lr: 0.020602021512115154
[batch_idx--250] train_loss: 0.0011114443659752725, acc: 0.8802446464143426, lr: 0.02054489006507322
[batch_idx--300] train_loss: 0.0011087261266817658, acc: 0.8808528862126246, lr: 0.02048778263744388
[batch_idx--350] train_loss: 0.0011080312676942693, acc: 0.8808426816239316, lr: 0.02043069953711782
[batch_idx--400] train_loss: 0.0011111542855695986, acc: 0.8804745947630923, lr: 0.020373641071854572
[batch_idx--450] train_loss: 0.001110253983676448, acc: 0.8805411879057173, lr: 0.020316607549280843
total time of one epoch: 219.890371799469 s
train_loss:  0.001110253983676448  acc:  0.8805411879057173
->>lr:0.020317
test_loss:  0.0010780467353516203  test_acc:  0.8843528973818091
best acc:  88.84476982255863

------Epoch: 84------
[batch_idx--0] train_loss: 0.0011955687077715993, acc: 0.859375, lr: 0.020315467135356893
[batch_idx--50] train_loss: 0.001114207890578637, acc: 0.8790594362745098, lr: 0.02025845937110404
[batch_idx--100] train_loss: 0.001128541496997275, acc: 0.87890625, lr: 0.020201477170534773
[batch_idx--150] train_loss: 0.0011172377872928384, acc: 0.8799927566225165, lr: 0.020144520840864624
[batch_idx--200] train_loss: 0.001108520200930128, acc: 0.8813938121890548, lr: 0.02008759068916964
[batch_idx--250] train_loss: 0.001105292625558299, acc: 0.881816484063745, lr: 0.020030687022384752
[batch_idx--300] train_loss: 0.0011099269509197915, acc: 0.881281146179402, lr: 0.019973810147302068
[batch_idx--350] train_loss: 0.0011071319289855722, acc: 0.8813657407407407, lr: 0.01991696037056928
[batch_idx--400] train_loss: 0.0011032889240033498, acc: 0.8816240648379052, lr: 0.01986013799868798
[batch_idx--450] train_loss: 0.0011044419466772592, acc: 0.8816693859131461, lr: 0.01980334333801198
total time of one epoch: 222.5813524723053 s
train_loss:  0.0011044419466772592  acc:  0.8816693859131461
->>lr:0.019803
test_loss:  0.0010673753479926694  test_acc:  0.8869586797369401
best acc:  88.84476982255863

------Epoch: 85------
[batch_idx--0] train_loss: 0.001078123925253749, acc: 0.8828125, lr: 0.019802207729556022
[batch_idx--50] train_loss: 0.0011248013630107629, acc: 0.8784466911764706, lr: 0.0197454416497602
[batch_idx--100] train_loss: 0.001101282315725221, acc: 0.8804146039603961, lr: 0.019688703899547008
[batch_idx--150] train_loss: 0.0010978839185169053, acc: 0.8801479718543046, lr: 0.01963199478481404
[batch_idx--200] train_loss: 0.0010994678651056813, acc: 0.8800528606965174, lr: 0.019575314611304503
[batch_idx--250] train_loss: 0.0011014454732315088, acc: 0.8804469621513944, lr: 0.019518663684605593
[batch_idx--300] train_loss: 0.0010988723323835164, acc: 0.8810215946843853, lr: 0.01946204231014678
[batch_idx--350] train_loss: 0.0010988861554570262, acc: 0.8809650997150997, lr: 0.019405450793198248
[batch_idx--400] train_loss: 0.001098587428088395, acc: 0.8809616583541147, lr: 0.01934888943886919
[batch_idx--450] train_loss: 0.0011055918126759354, acc: 0.8802721560731767, lr: 0.019292358552106172
total time of one epoch: 224.94605803489685 s
train_loss:  0.0011055918126759354  acc:  0.8802721560731767
->>lr:0.019292
test_loss:  0.0010701746195980006  test_acc:  0.8873309343591016
best acc:  88.84476982255863

------Epoch: 86------
[batch_idx--0] train_loss: 0.0010116816265508533, acc: 0.90625, lr: 0.019291228247233613
[batch_idx--50] train_loss: 0.001094226020059603, acc: 0.8841911764705882, lr: 0.019234728751373553
[batch_idx--100] train_loss: 0.0010852741595071805, acc: 0.8849009900990099, lr: 0.01917826033856888
[batch_idx--150] train_loss: 0.0010939874772648542, acc: 0.8844939983443708, lr: 0.019121823313265066
[batch_idx--200] train_loss: 0.0010990362735442002, acc: 0.8832206156716418, lr: 0.01906541797973838
[batch_idx--250] train_loss: 0.001099664019652646, acc: 0.8830615039840638, lr: 0.01900904464209422
[batch_idx--300] train_loss: 0.001099473720786171, acc: 0.8827086794019934, lr: 0.018952703604265476
[batch_idx--350] train_loss: 0.0011010527248597806, acc: 0.8820668625356125, lr: 0.018896395170010898
[batch_idx--400] train_loss: 0.0011022479945162029, acc: 0.881555875935162, lr: 0.01884011964291346
[batch_idx--450] train_loss: 0.0011005392919803114, acc: 0.8821293435623286, lr: 0.018783877326378724
total time of one epoch: 220.5126085281372 s
train_loss:  0.0011005392919803114  acc:  0.8821293435623286
->>lr:0.018784
test_loss:  0.0010526142640006736  test_acc:  0.8880754436034247
best acc:  88.84476982255863

------Epoch: 87------
[batch_idx--0] train_loss: 0.0012366714654490352, acc: 0.84765625, lr: 0.018782752820878636
[batch_idx--50] train_loss: 0.0011072586502825074, acc: 0.8798253676470589, lr: 0.018726544691500546
[batch_idx--100] train_loss: 0.0010970641823144316, acc: 0.881458849009901, lr: 0.01867037038501655
[batch_idx--150] train_loss: 0.0010903135800906859, acc: 0.8820622930463576, lr: 0.018614230204286455
[batch_idx--200] train_loss: 0.0010935758476247502, acc: 0.8814132462686567, lr: 0.018558124451986114
[batch_idx--250] train_loss: 0.0010976424840542366, acc: 0.88082046812749, lr: 0.018502053430605753
[batch_idx--300] train_loss: 0.0010966209840165618, acc: 0.8812162583056479, lr: 0.01844601744244835
[batch_idx--350] train_loss: 0.0011015205078246204, acc: 0.8812655804843305, lr: 0.018390016789628004
[batch_idx--400] train_loss: 0.0011041471402235144, acc: 0.8806401963840399, lr: 0.018334051774068303
[batch_idx--450] train_loss: 0.0011026227175123834, acc: 0.8812181067101746, lr: 0.0182781226975007
total time of one epoch: 249.227956533432 s
train_loss:  0.0011026227175123834  acc:  0.8812181067101746
->>lr:0.018278
test_loss:  0.0010802700093106399  test_acc:  0.8872068494850478
best acc:  88.84476982255863

------Epoch: 88------
[batch_idx--0] train_loss: 0.0009369285544380546, acc: 0.91015625, lr: 0.01827700448461836
[batch_idx--50] train_loss: 0.0010950603538338898, acc: 0.8818933823529411, lr: 0.018221112376465492
[batch_idx--100] train_loss: 0.0011012188296091955, acc: 0.8808400371287128, lr: 0.018165256816209563
[batch_idx--150] train_loss: 0.0010917265178629549, acc: 0.8812603476821192, lr: 0.018109438104991903
[batch_idx--200] train_loss: 0.0010899575091249758, acc: 0.8818019278606966, lr: 0.01805365654375518
[batch_idx--250] train_loss: 0.0010909800138510022, acc: 0.8818009213147411, lr: 0.017997912433241763
[batch_idx--300] train_loss: 0.0010951776200583657, acc: 0.8819300249169435, lr: 0.017942206073992117
[batch_idx--350] train_loss: 0.0010978294675108417, acc: 0.8814325142450142, lr: 0.017886537766343167
[batch_idx--400] train_loss: 0.0010988600804653957, acc: 0.8812149314214464, lr: 0.017830907810426684
[batch_idx--450] train_loss: 0.0010993260944947344, acc: 0.881764848821467, lr: 0.017775316506167683
total time of one epoch: 229.689692735672 s
train_loss:  0.0010993260944947344  acc:  0.881764848821467
->>lr:0.017775
test_loss:  0.0010484178370378614  test_acc:  0.8890681225958555
best acc:  88.84476982255863
Saving..

------Epoch: 89------
[batch_idx--0] train_loss: 0.0008993814699351788, acc: 0.921875, lr: 0.017774205076388213
[batch_idx--50] train_loss: 0.0010920264929368654, acc: 0.8828890931372549, lr: 0.017718653505586445
[batch_idx--100] train_loss: 0.0010978614272881704, acc: 0.8816522277227723, lr: 0.01766314119165336
[batch_idx--150] train_loss: 0.0010861105428983933, acc: 0.8828125, lr: 0.017607668433879703
[batch_idx--200] train_loss: 0.0010911686512738912, acc: 0.8827153296019901, lr: 0.017552235531342955
[batch_idx--250] train_loss: 0.0010947960167306946, acc: 0.8816919820717132, lr: 0.017496842782905715
[batch_idx--300] train_loss: 0.0010907165638474358, acc: 0.8821895764119602, lr: 0.017441490487214106
[batch_idx--350] train_loss: 0.0010906461141393267, acc: 0.8820000890313391, lr: 0.017386178942696135
[batch_idx--400] train_loss: 0.0010938128936069638, acc: 0.8819357855361596, lr: 0.01733090844756013
[batch_idx--450] train_loss: 0.0010948617232573352, acc: 0.8823029124865485, lr: 0.017275679299793074
total time of one epoch: 242.97484421730042 s
train_loss:  0.0010948617232573352  acc:  0.8823029124865485
->>lr:0.017276
test_loss:  0.0010493792476067103  test_acc:  0.8896885469661249
best acc:  88.90681225958555
Saving..

------Epoch: 90------
[batch_idx--0] train_loss: 0.0012060076696798205, acc: 0.8828125, lr: 0.017274575140626316
[batch_idx--50] train_loss: 0.0011030223891686868, acc: 0.8807444852941176, lr: 0.017219388473930602
[batch_idx--100] train_loss: 0.0010912063765560857, acc: 0.881613551980198, lr: 0.017164243755855953
[batch_idx--150] train_loss: 0.0010916827796242934, acc: 0.8817777317880795, lr: 0.017109141283711254
[batch_idx--200] train_loss: 0.0010869970310025325, acc: 0.8831234452736318, lr: 0.0170540813545776
[batch_idx--250] train_loss: 0.0010895340532283354, acc: 0.8827346862549801, lr: 0.016999064265306747
[batch_idx--300] train_loss: 0.001087904317757777, acc: 0.8829163205980066, lr: 0.016944090312519478
[batch_idx--350] train_loss: 0.0010892118584693666, acc: 0.8831352386039886, lr: 0.01688915979260398
[batch_idx--400] train_loss: 0.0010873260338816262, acc: 0.883289822319202, lr: 0.016834273001714316
[batch_idx--450] train_loss: 0.0010905496497551008, acc: 0.8831360433228035, lr: 0.016779430235768767
total time of one epoch: 232.50013494491577 s
train_loss:  0.0010905496497551008  acc:  0.8831360433228035
->>lr:0.016779
test_loss:  0.001080075770945655  test_acc:  0.8857178309964016
best acc:  88.96885469661248

------Epoch: 91------
[batch_idx--0] train_loss: 0.0011257330188527703, acc: 0.87109375, lr: 0.01677833383153542
[batch_idx--50] train_loss: 0.001110248815487413, acc: 0.8818167892156863, lr: 0.016723536275641708
[batch_idx--100] train_loss: 0.0011043204052263115, acc: 0.8806853341584159, lr: 0.01666878334172139
[batch_idx--150] train_loss: 0.0010936875293333552, acc: 0.8819329470198676, lr: 0.01661407532497108
[batch_idx--200] train_loss: 0.0010977825975226267, acc: 0.8817436256218906, lr: 0.016559412520345193
[batch_idx--250] train_loss: 0.0010927564715428567, acc: 0.8825479332669323, lr: 0.016504795222554415
[batch_idx--300] train_loss: 0.0010937325195393888, acc: 0.8823323297342193, lr: 0.01645022372606408
[batch_idx--350] train_loss: 0.0010882314714799474, acc: 0.8830573361823362, lr: 0.01639569832509256
[batch_idx--400] train_loss: 0.0010894769576245784, acc: 0.8827053460099751, lr: 0.016341219313609757
[batch_idx--450] train_loss: 0.0010930445975941084, acc: 0.88275419168952, lr: 0.01628678698533542
total time of one epoch: 239.71188688278198 s
train_loss:  0.0010930445975941084  acc:  0.88275419168952
->>lr:0.016287
test_loss:  0.00104430994615911  test_acc:  0.8914257352028788
best acc:  88.96885469661248
Saving..

------Epoch: 92------
[batch_idx--0] train_loss: 0.0013131961459293962, acc: 0.84765625, lr: 0.016285698816954627
[batch_idx--50] train_loss: 0.001104816829776574, acc: 0.8806678921568627, lr: 0.016231314407882003
[batch_idx--100] train_loss: 0.0010832573182299955, acc: 0.884475556930693, lr: 0.016176977274562434
[batch_idx--150] train_loss: 0.0010794871918462364, acc: 0.8846233443708609, lr: 0.016122687709950775
[batch_idx--200] train_loss: 0.0010800640972155095, acc: 0.8840951492537313, lr: 0.01606844600674539
[batch_idx--250] train_loss: 0.0010693756556435232, acc: 0.8855204183266933, lr: 0.016014252457386614
[batch_idx--300] train_loss: 0.0010744308978566696, acc: 0.8844346968438538, lr: 0.015960107354055172
[batch_idx--350] train_loss: 0.0010738879176217563, acc: 0.8845152243589743, lr: 0.01590601098867059
[batch_idx--400] train_loss: 0.0010769594317892022, acc: 0.8841957605985037, lr: 0.015851963652889624
[batch_idx--450] train_loss: 0.0010830425068704523, acc: 0.8842208490991773, lr: 0.015797965638104688
total time of one epoch: 236.90914273262024 s
train_loss:  0.0010830425068704523  acc:  0.8842208490991773
->>lr:0.015798
test_loss:  0.0010623807169128135  test_acc:  0.8891922074699095
best acc:  89.14257352028788

------Epoch: 93------
[batch_idx--0] train_loss: 0.0010812683030962944, acc: 0.87890625, lr: 0.01579688618288306
[batch_idx--50] train_loss: 0.0010750985409900108, acc: 0.8828890931372549, lr: 0.01574293877543077
[batch_idx--100] train_loss: 0.0010821804551794977, acc: 0.881768254950495, lr: 0.015689041276774486
[batch_idx--150] train_loss: 0.0010703395985048388, acc: 0.8841835678807947, lr: 0.015635193977498796
[batch_idx--200] train_loss: 0.001077684758587819, acc: 0.8838230721393034, lr: 0.015581397167917649
[batch_idx--250] train_loss: 0.001079696866700359, acc: 0.8833260707171314, lr: 0.01552765113807274
[batch_idx--300] train_loss: 0.0010764029250631844, acc: 0.8838636835548173, lr: 0.015473956177732033
[batch_idx--350] train_loss: 0.001077684484610594, acc: 0.8836916844729344, lr: 0.01542031257638813
[batch_idx--400] train_loss: 0.0010800578312407203, acc: 0.8836697319201995, lr: 0.015366720623256752
[batch_idx--450] train_loss: 0.001081947973853791, acc: 0.88354393029472, lr: 0.015313180607275165
total time of one epoch: 239.02310585975647 s
train_loss:  0.001081947973853791  acc:  0.88354393029472
->>lr:0.015313
test_loss:  0.0010542615144272598  test_acc:  0.8898126318401787
best acc:  89.14257352028788

------Epoch: 94------
[batch_idx--0] train_loss: 0.0011399082140997052, acc: 0.8671875, lr: 0.015312110338697428
[batch_idx--50] train_loss: 0.0010469216218802566, acc: 0.8869485294117647, lr: 0.015258623595981367
[batch_idx--100] train_loss: 0.001069824355377788, acc: 0.8845142326732673, lr: 0.015205189373212608
[batch_idx--150] train_loss: 0.0010741669457214607, acc: 0.8848302980132451, lr: 0.015151807958478031
[batch_idx--200] train_loss: 0.001073445372146772, acc: 0.8851640236318408, lr: 0.015098479639579785
[batch_idx--250] train_loss: 0.0010757152034262885, acc: 0.8846644671314741, lr: 0.015045204704033754
[batch_idx--300] train_loss: 0.0010719583068117251, acc: 0.8850576204318937, lr: 0.01499198343906803
[batch_idx--350] train_loss: 0.0010733566403805551, acc: 0.88455974002849, lr: 0.014938816131621303
[batch_idx--400] train_loss: 0.0010757549438553577, acc: 0.8842347256857855, lr: 0.014885703068341395
[batch_idx--450] train_loss: 0.0010807097558717493, acc: 0.8837088207727288, lr: 0.014832644535583656
total time of one epoch: 228.8908498287201 s
train_loss:  0.0010807097558717493  acc:  0.8837088207727288
->>lr:0.014833
test_loss:  0.0010581768255018393  test_acc:  0.8927906688174712
best acc:  89.14257352028788
Saving..

------Epoch: 95------
[batch_idx--0] train_loss: 0.0012524069752544165, acc: 0.85546875, lr: 0.014831583923105
[batch_idx--50] train_loss: 0.0010500930788397205, acc: 0.8901654411764706, lr: 0.014778581306178257
[batch_idx--100] train_loss: 0.0010502136768865409, acc: 0.8887685643564357, lr: 0.014725633797313148
[batch_idx--150] train_loss: 0.0010570210500293418, acc: 0.8876759105960265, lr: 0.014672741681972468
[batch_idx--200] train_loss: 0.0010664308955082068, acc: 0.8857859141791045, lr: 0.01461990524532032
[batch_idx--250] train_loss: 0.0010703186195184183, acc: 0.8854892928286853, lr: 0.014567124772220653
[batch_idx--300] train_loss: 0.0010757857279626163, acc: 0.8850057101328903, lr: 0.014514400547235684
[batch_idx--350] train_loss: 0.0010750589983808433, acc: 0.8848490918803419, lr: 0.014461732854624376
[batch_idx--400] train_loss: 0.0010730661054088402, acc: 0.8850432512468828, lr: 0.014409121978340905
[batch_idx--450] train_loss: 0.0010727254962413799, acc: 0.885323011767973, lr: 0.014356568202033099
total time of one epoch: 230.79048895835876 s
train_loss:  0.0010727254962413799  acc:  0.885323011767973
->>lr:0.014357
test_loss:  0.0010714043231796783  test_acc:  0.8860900856185631
best acc:  89.27906688174711

------Epoch: 96------
[batch_idx--0] train_loss: 0.0008110670023597777, acc: 0.91796875, lr: 0.014355517710873192
[batch_idx--50] train_loss: 0.0010585705475772127, acc: 0.8872549019607843, lr: 0.014303022468435317
[batch_idx--100] train_loss: 0.0010500767713154454, acc: 0.8872215346534653, lr: 0.014250584898001182
[batch_idx--150] train_loss: 0.0010552617234782322, acc: 0.8870550496688742, lr: 0.014198205282284266
[batch_idx--200] train_loss: 0.0010600590137811146, acc: 0.8863495024875622, lr: 0.014145883903685591
[batch_idx--250] train_loss: 0.001067215778987365, acc: 0.8844154631474104, lr: 0.014093621044292189
[batch_idx--300] train_loss: 0.0010693883442125002, acc: 0.8841621677740864, lr: 0.014041416985875627
[batch_idx--350] train_loss: 0.0010722485399789088, acc: 0.8838808760683761, lr: 0.013989272009890398
[batch_idx--400] train_loss: 0.001071871183272637, acc: 0.8838450748129676, lr: 0.013937186397472484
[batch_idx--450] train_loss: 0.0010717752928449448, acc: 0.884463845593085, lr: 0.01388516042943782
total time of one epoch: 243.95115208625793 s
train_loss:  0.0010717752928449448  acc:  0.884463845593085
->>lr:0.013885
test_loss:  0.001033493677873679  test_acc:  0.8922943293212557
best acc:  89.27906688174711

------Epoch: 97------
[batch_idx--0] train_loss: 0.0008308927644975483, acc: 0.9140625, lr: 0.01388412052037681
[batch_idx--50] train_loss: 0.0010675744909117474, acc: 0.8833486519607843, lr: 0.01383215567857612
[batch_idx--100] train_loss: 0.0010622612881879922, acc: 0.885055693069307, lr: 0.013780251047424422
[batch_idx--150] train_loss: 0.001055374392693776, acc: 0.8865376655629139, lr: 0.013728406906761904
[batch_idx--200] train_loss: 0.0010539128512273826, acc: 0.886679881840796, lr: 0.013676623536102595
[batch_idx--250] train_loss: 0.001053585951259189, acc: 0.8870144422310757, lr: 0.013624901214632912
[batch_idx--300] train_loss: 0.0010526866125688576, acc: 0.8878867317275747, lr: 0.01357324022121012
[batch_idx--350] train_loss: 0.001059963323104267, acc: 0.8866408475783476, lr: 0.013521640834360844
[batch_idx--400] train_loss: 0.0010602523477230119, acc: 0.8867771976309227, lr: 0.013470103332279566
[batch_idx--450] train_loss: 0.0010647789570019123, acc: 0.8864946020064568, lr: 0.013418627992827087
total time of one epoch: 234.25394129753113 s
train_loss:  0.0010647789570019123  acc:  0.8864946020064568
->>lr:0.013419
test_loss:  0.0010510031764864375  test_acc:  0.8877031889812632
best acc:  89.27906688174711

------Epoch: 98------
[batch_idx--0] train_loss: 0.0011140126734972, acc: 0.87109375, lr: 0.013417599122003463
[batch_idx--50] train_loss: 0.001041615744778777, acc: 0.8910079656862745, lr: 0.013366187474337023
[batch_idx--100] train_loss: 0.0010596739357604766, acc: 0.887028155940594, lr: 0.013314838549554453
[batch_idx--150] train_loss: 0.0010552650409294232, acc: 0.8879087334437086, lr: 0.013263552624499875
[batch_idx--200] train_loss: 0.0010629525209489784, acc: 0.8865049751243781, lr: 0.01321232997567776
[batch_idx--250] train_loss: 0.001069515623037232, acc: 0.8854270418326693, lr: 0.01316117087925142
[batch_idx--300] train_loss: 0.0010663289694731245, acc: 0.8859400955149501, lr: 0.013110075611041534
[batch_idx--350] train_loss: 0.001066852835248466, acc: 0.8861289173789174, lr: 0.01305904444652466
[batch_idx--400] train_loss: 0.001067418918191244, acc: 0.8858128117206983, lr: 0.013008077660831736
[batch_idx--450] train_loss: 0.0010713414131061857, acc: 0.8856354358315687, lr: 0.01295717552874661
total time of one epoch: 241.00302267074585 s
train_loss:  0.0010713414131061857  acc:  0.8856354358315687
->>lr:0.012957
test_loss:  0.0010148838027444545  test_acc:  0.8942796873061174
best acc:  89.27906688174711
Saving..

------Epoch: 99------
[batch_idx--0] train_loss: 0.0008098235120996833, acc: 0.92578125, lr: 0.012956158147457115
[batch_idx--50] train_loss: 0.0010355720193782711, acc: 0.8893995098039216, lr: 0.012905322244772761
[batch_idx--100] train_loss: 0.0010423735550623202, acc: 0.8881884282178217, lr: 0.012854551549694835
[batch_idx--150] train_loss: 0.0010471203351325497, acc: 0.8875724337748344, lr: 0.012803846335949954
[batch_idx--200] train_loss: 0.0010484921460999037, acc: 0.8873989427860697, lr: 0.012753206876911727
[batch_idx--250] train_loss: 0.001051520175751358, acc: 0.8869833167330677, lr: 0.012702633445599246
[batch_idx--300] train_loss: 0.001056498199302171, acc: 0.886796615448505, lr: 0.012652126314675622
[batch_idx--350] train_loss: 0.0010548312290959018, acc: 0.8872640669515669, lr: 0.012601685756446507
[batch_idx--400] train_loss: 0.001055451868592002, acc: 0.8870986596009975, lr: 0.012551312042858621
[batch_idx--450] train_loss: 0.0010592468041781397, acc: 0.8870239872253272, lr: 0.012501005445498313
total time of one epoch: 230.37030816078186 s
train_loss:  0.0010592468041781397  acc:  0.8870239872253272
->>lr:0.012501
test_loss:  0.0010373174870542267  test_acc:  0.8919220746990941
best acc:  89.42796873061174

------Epoch: 100------
[batch_idx--0] train_loss: 0.001115306164138019, acc: 0.87109375, lr: 0.012500000000000006
[batch_idx--50] train_loss: 0.0010422861828998315, acc: 0.8880974264705882, lr: 0.012449762140604802
[batch_idx--100] train_loss: 0.0010537670171441565, acc: 0.8862159653465347, lr: 0.012399591944936346
[batch_idx--150] train_loss: 0.0010484087671036061, acc: 0.8872361341059603, lr: 0.012349489683483728
[batch_idx--200] train_loss: 0.0010462847772281414, acc: 0.8873212064676617, lr: 0.012299455626369788
[batch_idx--250] train_loss: 0.0010491103758067041, acc: 0.8878392679282868, lr: 0.012249490043349598
[batch_idx--300] train_loss: 0.0010476025346236495, acc: 0.8885485880398671, lr: 0.01219959320380913
[batch_idx--350] train_loss: 0.001049284861048954, acc: 0.8883101851851852, lr: 0.012149765376763677
[batch_idx--400] train_loss: 0.0010510681642967269, acc: 0.8877123597256857, lr: 0.012100006830856476
[batch_idx--450] train_loss: 0.0010577476071544592, acc: 0.8873016975040788, lr: 0.01205031783435723
total time of one epoch: 243.74633479118347 s
train_loss:  0.0010577476071544592  acc:  0.8873016975040788
->>lr:0.012050
test_loss:  0.0010311074489280387  test_acc:  0.8903089713363941
best acc:  89.42796873061174

------Epoch: 101------
[batch_idx--0] train_loss: 0.0011533709475770593, acc: 0.86328125, lr: 0.012049324765671741
[batch_idx--50] train_loss: 0.0010588783439814899, acc: 0.8886335784313726, lr: 0.01199970698555119
[batch_idx--100] train_loss: 0.0010497156826843794, acc: 0.8885365099009901, lr: 0.011950159295598187
[batch_idx--150] train_loss: 0.001049323682827468, acc: 0.8884002483443708, lr: 0.011900681962945607
[batch_idx--200] train_loss: 0.0010446587097321391, acc: 0.8880985696517413, lr: 0.011851275254347019
[batch_idx--250] train_loss: 0.0010494857212988682, acc: 0.8873723854581673, lr: 0.011801939436175232
[batch_idx--300] train_loss: 0.0010482530050409766, acc: 0.8874454941860465, lr: 0.01175267477442085
[batch_idx--350] train_loss: 0.0010433059765829935, acc: 0.8881877670940171, lr: 0.011703481534690844
[batch_idx--400] train_loss: 0.0010434967091776188, acc: 0.8885403678304239, lr: 0.011654359982207095
[batch_idx--450] train_loss: 0.0010442145417849532, acc: 0.8887857118061582, lr: 0.011605310381805019
total time of one epoch: 240.9783570766449 s
train_loss:  0.0010442145417849532  acc:  0.8887857118061582
->>lr:0.011605
test_loss:  0.0010312003875018378  test_acc:  0.8909293957066634
best acc:  89.42796873061174

------Epoch: 102------
[batch_idx--0] train_loss: 0.000915063195861876, acc: 0.90625, lr: 0.01160433012552509
[batch_idx--50] train_loss: 0.0010731183197897147, acc: 0.8864123774509803, lr: 0.011555354188677439
[batch_idx--100] train_loss: 0.0010558883094754401, acc: 0.8881110767326733, lr: 0.011506450737694249
[batch_idx--150] train_loss: 0.0010486989184159367, acc: 0.8876500413907285, lr: 0.011457620036235043
[batch_idx--200] train_loss: 0.0010576819316414532, acc: 0.8858636504975125, lr: 0.011408862347567132
[batch_idx--250] train_loss: 0.0010547814271561209, acc: 0.8860028635458167, lr: 0.011360177934564142
[batch_idx--300] train_loss: 0.0010526982196792341, acc: 0.8865759966777409, lr: 0.011311567059704701
[batch_idx--350] train_loss: 0.0010486069535690643, acc: 0.8867743945868946, lr: 0.01126302998507092
[batch_idx--400] train_loss: 0.0010519582057369413, acc: 0.8865044420199502, lr: 0.011214566972347026
[batch_idx--450] train_loss: 0.0010565304422935542, acc: 0.8861474641580172, lr: 0.01116617828281797
total time of one epoch: 234.21937036514282 s
train_loss:  0.0010565304422935542  acc:  0.8861474641580172
->>lr:0.011166
test_loss:  0.00104200309515739  test_acc:  0.8890681225958555
best acc:  89.42796873061174

------Epoch: 103------
[batch_idx--0] train_loss: 0.0009133884450420737, acc: 0.890625, lr: 0.011165211268916392
[batch_idx--50] train_loss: 0.0010128321568938154, acc: 0.8919270833333334, lr: 0.011116898657806221
[batch_idx--100] train_loss: 0.0010115478976196286, acc: 0.8921333539603961, lr: 0.01106866089646273
[batch_idx--150] train_loss: 0.0010239618409437355, acc: 0.890547392384106, lr: 0.011020498244956429
[batch_idx--200] train_loss: 0.0010305261279952096, acc: 0.8901197139303483, lr: 0.010972410962952879
[batch_idx--250] train_loss: 0.0010409356429764772, acc: 0.8884150896414342, lr: 0.010924399309711284
[batch_idx--300] train_loss: 0.001037437834063749, acc: 0.8889249377076412, lr: 0.010876463544083113
[batch_idx--350] train_loss: 0.0010420079653130107, acc: 0.8884103454415955, lr: 0.010828603924510663
[batch_idx--400] train_loss: 0.0010402946076251362, acc: 0.8885306265586035, lr: 0.010780820709025727
[batch_idx--450] train_loss: 0.0010423473438336169, acc: 0.8886208213281495, lr: 0.010733114155248157
total time of one epoch: 231.01525259017944 s
train_loss:  0.0010423473438336169  acc:  0.8886208213281495
->>lr:0.010733
test_loss:  0.0010017519006659307  test_acc:  0.8949001116763866
best acc:  89.42796873061174
Saving..

------Epoch: 104------
[batch_idx--0] train_loss: 0.001405872986651957, acc: 0.8359375, lr: 0.010732160807889211
[batch_idx--50] train_loss: 0.0010271468690559997, acc: 0.8908547794117647, lr: 0.010684532714024482
[batch_idx--100] train_loss: 0.0010314379434912732, acc: 0.8901995668316832, lr: 0.010636981800997085
[batch_idx--150] train_loss: 0.0010403482426907743, acc: 0.8890469784768212, lr: 0.01058950832517444
[batch_idx--200] train_loss: 0.0010421975198391807, acc: 0.8888370646766169, lr: 0.010542112542506449
[batch_idx--250] train_loss: 0.0010372567471985026, acc: 0.8890998505976095, lr: 0.01049479470852415
[batch_idx--300] train_loss: 0.0010330460639206378, acc: 0.8897684800664452, lr: 0.010447555078338317
[batch_idx--350] train_loss: 0.0010359393383981262, acc: 0.8895566239316239, lr: 0.010400393906638123
[batch_idx--400] train_loss: 0.0010328045660081759, acc: 0.8899236284289277, lr: 0.010353311447689712
[batch_idx--450] train_loss: 0.0010357864008900953, acc: 0.889896552921165, lr: 0.01030630795533484
total time of one epoch: 234.386372089386 s
train_loss:  0.0010357864008900953  acc:  0.889896552921165
->>lr:0.010306
test_loss:  0.0011075759646998755  test_acc:  0.8826157091450553
best acc:  89.49001116763867

------Epoch: 105------
[batch_idx--0] train_loss: 0.0011187272612005472, acc: 0.875, lr: 0.010305368692688175
[batch_idx--50] train_loss: 0.001046174574488153, acc: 0.8877910539215687, lr: 0.010258446007324987
[batch_idx--100] train_loss: 0.0010426261676659825, acc: 0.889426051980198, lr: 0.010211602800015714
[batch_idx--150] train_loss: 0.0010357595735772309, acc: 0.8898230546357616, lr: 0.010164839323312217
[batch_idx--200] train_loss: 0.0010347740133339308, acc: 0.8902363184079602, lr: 0.010118155829336504
[batch_idx--250] train_loss: 0.0010393273608992803, acc: 0.8894111055776892, lr: 0.010071552569779364
[batch_idx--300] train_loss: 0.0010389192025966176, acc: 0.8892104443521595, lr: 0.010025029795898983
[batch_idx--350] train_loss: 0.0010382025353371715, acc: 0.8890224358974359, lr: 0.00997858775851964
[batch_idx--400] train_loss: 0.0010387523300386036, acc: 0.8890663965087282, lr: 0.00993222670803032
[batch_idx--450] train_loss: 0.0010416832980030127, acc: 0.8889245669455341, lr: 0.009885946894383374
total time of one epoch: 236.36029529571533 s
train_loss:  0.0010416832980030127  acc:  0.8889245669455341
->>lr:0.009886
test_loss:  0.0010169050872939768  test_acc:  0.8957687057947636
best acc:  89.49001116763867
Saving..

------Epoch: 106------
[batch_idx--0] train_loss: 0.000899996142834425, acc: 0.91015625, lr: 0.00988502212844063
[batch_idx--50] train_loss: 0.0010215571942264396, acc: 0.8910079656862745, lr: 0.009838825433419594
[batch_idx--100] train_loss: 0.001034317473595095, acc: 0.8897354579207921, lr: 0.009792710478807351
[batch_idx--150] train_loss: 0.001041575785208222, acc: 0.8891245860927153, lr: 0.009746677513229449
[batch_idx--200] train_loss: 0.0010392319182842154, acc: 0.8890508395522388, lr: 0.00970072678486938
[batch_idx--250] train_loss: 0.0010358681496459086, acc: 0.8894577938247012, lr: 0.009654858541467274
[batch_idx--300] train_loss: 0.0010326430408448056, acc: 0.8900410091362126, lr: 0.009609073030318542
[batch_idx--350] train_loss: 0.0010347477242647752, acc: 0.8897458155270656, lr: 0.009563370498272567
[batch_idx--400] train_loss: 0.0010325482498071716, acc: 0.8899820760598504, lr: 0.009517751191731351
[batch_idx--450] train_loss: 0.0010346724100305672, acc: 0.889887874474954, lr: 0.00947221535664816
total time of one epoch: 235.17094779014587 s
train_loss:  0.0010346724100305672  acc:  0.889887874474954
->>lr:0.009472
test_loss:  0.0010362422126800077  test_acc:  0.8915498200769326
best acc:  89.57687057947636

------Epoch: 107------
[batch_idx--0] train_loss: 0.0010307257762178779, acc: 0.890625, lr: 0.009471305493042243
[batch_idx--50] train_loss: 0.0009781362856373045, acc: 0.8948376225490197, lr: 0.00942585505176061
[batch_idx--100] train_loss: 0.0010033782945005315, acc: 0.891823948019802, lr: 0.009380488577388602
[batch_idx--150] train_loss: 0.0010073582799056706, acc: 0.8914528145695364, lr: 0.009335206314516387
[batch_idx--200] train_loss: 0.0010089066869403184, acc: 0.8917133084577115, lr: 0.0092900085072801
[batch_idx--250] train_loss: 0.0010171708211662671, acc: 0.8909051294820717, lr: 0.009244895399360565
[batch_idx--300] train_loss: 0.0010148143123887925, acc: 0.8917021387043189, lr: 0.009199867233981912
[batch_idx--350] train_loss: 0.0010137184371473932, acc: 0.8919715990028491, lr: 0.009154924253910346
[batch_idx--400] train_loss: 0.0010157004035045475, acc: 0.8920374844139651, lr: 0.009110066701452797
[batch_idx--450] train_loss: 0.0010219618637228175, acc: 0.891684312840629, lr: 0.0090652948184556
total time of one epoch: 238.48690223693848 s
train_loss:  0.0010219618637228175  acc:  0.891684312840629
->>lr:0.009065
test_loss:  0.0010074297755952952  test_acc:  0.8951482814244943
best acc:  89.57687057947636

------Epoch: 108------
[batch_idx--0] train_loss: 0.001037843176163733, acc: 0.8984375, lr: 0.009064400256282757
[batch_idx--50] train_loss: 0.001037027492808799, acc: 0.8923100490196079, lr: 0.009019716004806225
[batch_idx--100] train_loss: 0.0010377423040163103, acc: 0.8907410272277227, lr: 0.0089751179099095
[batch_idx--150] train_loss: 0.001039025277386586, acc: 0.8903145695364238, lr: 0.008930606212040063
[batch_idx--200] train_loss: 0.0010307525161222847, acc: 0.8910331156716418, lr: 0.00888618115117962
[batch_idx--250] train_loss: 0.0010309763618214316, acc: 0.8903915587649402, lr: 0.00884184296684277
[batch_idx--300] train_loss: 0.0010326457222648263, acc: 0.8900669642857143, lr: 0.00879759189807571
[batch_idx--350] train_loss: 0.001030472709208281, acc: 0.8905470975783476, lr: 0.008753428183455004
[batch_idx--400] train_loss: 0.0010307253886506593, acc: 0.8907906016209476, lr: 0.008709352061086187
[batch_idx--450] train_loss: 0.0010321232121262302, acc: 0.890799111327108, lr: 0.008665363768602597
total time of one epoch: 222.05637168884277 s
train_loss:  0.0010321232121262302  acc:  0.890799111327108
->>lr:0.008665
test_loss:  0.0009941670080763128  test_acc:  0.899739421764487
best acc:  89.57687057947636
Saving..

------Epoch: 109------
[batch_idx--0] train_loss: 0.0010367155773565173, acc: 0.88671875, lr: 0.008664484900247363
[batch_idx--50] train_loss: 0.0009990903096930945, acc: 0.8942248774509803, lr: 0.00862058643856546
[batch_idx--100] train_loss: 0.0010174354953267197, acc: 0.8923654084158416, lr: 0.0085767762853424
[batch_idx--150] train_loss: 0.0010255866777306014, acc: 0.8910906456953642, lr: 0.008533054676777554
[batch_idx--200] train_loss: 0.0010187552838739175, acc: 0.8922768967661692, lr: 0.008489421848592919
[batch_idx--250] train_loss: 0.0010229939185787897, acc: 0.8915120766932271, lr: 0.008445878036031801
[batch_idx--300] train_loss: 0.0010245061571171438, acc: 0.8911700581395349, lr: 0.008402423473857626
[batch_idx--350] train_loss: 0.0010245369756899435, acc: 0.8914040242165242, lr: 0.008359058396352615
[batch_idx--400] train_loss: 0.0010273499642800717, acc: 0.890907496882793, lr: 0.008315783037316537
[batch_idx--450] train_loss: 0.0010274473126285438, acc: 0.8913545318846113, lr: 0.008272597630065468
total time of one epoch: 225.3411672115326 s
train_loss:  0.0010274473126285438  acc:  0.8913545318846113
->>lr:0.008273
test_loss:  0.0009915237151477397  test_acc:  0.899739421764487
best acc:  89.97394217644869

------Epoch: 110------
[batch_idx--0] train_loss: 0.001052416511811316, acc: 0.8828125, lr: 0.008271734841028545
[batch_idx--50] train_loss: 0.0010337758770522971, acc: 0.8896292892156863, lr: 0.008228641424457422
[batch_idx--100] train_loss: 0.001017426812011601, acc: 0.8908957301980198, lr: 0.00818563842948918
[batch_idx--150] train_loss: 0.0010276373124231172, acc: 0.8904956539735099, lr: 0.008142726087971458
[batch_idx--200] train_loss: 0.0010271275906003456, acc: 0.890605565920398, lr: 0.00809990463126313
[batch_idx--250] train_loss: 0.0010244777978980447, acc: 0.8904693725099602, lr: 0.008057174290233077
[batch_idx--300] train_loss: 0.001022058828197036, acc: 0.8911311254152824, lr: 0.008014535295258926
[batch_idx--350] train_loss: 0.0010229801912354226, acc: 0.8909588675213675, lr: 0.00797198787622585
[batch_idx--400] train_loss: 0.0010237168069833662, acc: 0.8909562032418953, lr: 0.007929532262525246
[batch_idx--450] train_loss: 0.001027462368455173, acc: 0.8911028569444926, lr: 0.007887168683053591
total time of one epoch: 243.22159671783447 s
train_loss:  0.001027462368455173  acc:  0.8911028569444926
->>lr:0.007887
test_loss:  0.0009998189839406765  test_acc:  0.8972577242834099
best acc:  89.97394217644869

------Epoch: 111------
[batch_idx--0] train_loss: 0.0009408167679794133, acc: 0.90234375, lr: 0.00788632235178279
[batch_idx--50] train_loss: 0.001033544936445633, acc: 0.8900122549019608, lr: 0.00784405288251919
[batch_idx--100] train_loss: 0.0010207121595878633, acc: 0.8902769183168316, lr: 0.007801875908340622
[batch_idx--150] train_loss: 0.0010168339701720963, acc: 0.8914528145695364, lr: 0.007759791656641275
[batch_idx--200] train_loss: 0.0010210142093849605, acc: 0.8909165111940298, lr: 0.007717800354315446
[batch_idx--250] train_loss: 0.0010188805735744239, acc: 0.8909518177290837, lr: 0.007675902227756282
[batch_idx--300] train_loss: 0.0010207283799459174, acc: 0.8902486503322259, lr: 0.007634097502854598
[batch_idx--350] train_loss: 0.0010188166350603867, acc: 0.8906138710826211, lr: 0.007592386404997634
[batch_idx--400] train_loss: 0.0010190028372102247, acc: 0.8907029301745636, lr: 0.007550769159067847
[batch_idx--450] train_loss: 0.0010211632716366885, acc: 0.890790432880897, lr: 0.00750924598944171
total time of one epoch: 251.90636563301086 s
train_loss:  0.0010211632716366885  acc:  0.890790432880897
->>lr:0.007509
test_loss:  0.0010233055844113465  test_acc:  0.895396451172602
best acc:  89.97394217644869

------Epoch: 112------
[batch_idx--0] train_loss: 0.0009614562150090933, acc: 0.88671875, lr: 0.007508416487165862
[batch_idx--50] train_loss: 0.0010302763320414314, acc: 0.8903186274509803, lr: 0.007466989505996053
[batch_idx--100] train_loss: 0.0010263929892755529, acc: 0.8900061881188119, lr: 0.007425657052821996
[batch_idx--150] train_loss: 0.0010056444609519218, acc: 0.8924358443708609, lr: 0.007384419350484717
[batch_idx--200] train_loss: 0.0010095395814437437, acc: 0.8924906716417911, lr: 0.0073432766213143985
[batch_idx--250] train_loss: 0.001018990127349354, acc: 0.8910451942231076, lr: 0.007302229087129178
[batch_idx--300] train_loss: 0.0010200057314489147, acc: 0.8910921926910299, lr: 0.007261276969233954
[batch_idx--350] train_loss: 0.0010137746926129098, acc: 0.8919159544159544, lr: 0.007220420488419194
[batch_idx--400] train_loss: 0.0010141724821626026, acc: 0.8917939526184538, lr: 0.007179659864959754
[batch_idx--450] train_loss: 0.0010204782347580318, acc: 0.8912069982990245, lr: 0.007138995318613667
total time of one epoch: 225.8263475894928 s
train_loss:  0.0010204782347580318  acc:  0.8912069982990245
->>lr:0.007139
test_loss:  0.001006902053717393  test_acc:  0.8972577242834099
best acc:  89.97394217644869

------Epoch: 113------
[batch_idx--0] train_loss: 0.0009638944175094366, acc: 0.8984375, lr: 0.007138183009179922
[batch_idx--50] train_loss: 0.0009828770416788757, acc: 0.8959865196078431, lr: 0.007097616687346986
[batch_idx--100] train_loss: 0.0009938154892885302, acc: 0.8965037128712872, lr: 0.00705714688495745
[batch_idx--150] train_loss: 0.001003562732575005, acc: 0.8948158112582781, lr: 0.007016773820201414
[batch_idx--200] train_loss: 0.0010082722115631571, acc: 0.8935984141791045, lr: 0.00697649771074741
[batch_idx--250] train_loss: 0.0010140579700770517, acc: 0.8930527888446215, lr: 0.006936318773741257
[batch_idx--300] train_loss: 0.0010184745388987328, acc: 0.8924937707641196, lr: 0.00689623722580488
[batch_idx--350] train_loss: 0.0010139205475786217, acc: 0.8928841702279202, lr: 0.006856253283035133
[batch_idx--400] train_loss: 0.0010132356494562955, acc: 0.8925050654613467, lr: 0.00681636716100264
[batch_idx--450] train_loss: 0.0010157519100608872, acc: 0.8925174436768841, lr: 0.006776579074750619
total time of one epoch: 241.78558135032654 s
train_loss:  0.0010157519100608872  acc:  0.8925174436768841
->>lr:0.006777
test_loss:  0.001017142991848657  test_acc:  0.8945278570542251
best acc:  89.97394217644869

------Epoch: 114------
[batch_idx--0] train_loss: 0.0008907803567126393, acc: 0.89453125, lr: 0.006775784314464717
[batch_idx--50] train_loss: 0.0009978795070292464, acc: 0.8939185049019608, lr: 0.006736096445698165
[batch_idx--100] train_loss: 0.0009929102339486747, acc: 0.8942605198019802, lr: 0.0066965070454860194
[batch_idx--150] train_loss: 0.0010010780660984482, acc: 0.8932895281456954, lr: 0.006657016327271753
[batch_idx--200] train_loss: 0.0010042611630610306, acc: 0.8931708644278606, lr: 0.006617624503966805
[batch_idx--250] train_loss: 0.0010083031954718717, acc: 0.8927259711155379, lr: 0.006578331787949427
[batch_idx--300] train_loss: 0.001011531820143279, acc: 0.8926105689368771, lr: 0.006539138391063526
[batch_idx--350] train_loss: 0.0010092567371873136, acc: 0.892516915954416, lr: 0.006500044524617568
[batch_idx--400] train_loss: 0.0010119968108737614, acc: 0.8921738622194514, lr: 0.0064610503993833834
[batch_idx--450] train_loss: 0.0010151715691380464, acc: 0.8922484118443433, lr: 0.006422156225595066
total time of one epoch: 241.53022646903992 s
train_loss:  0.0010151715691380464  acc:  0.8922484118443433
->>lr:0.006422
test_loss:  0.0010013927436670752  test_acc:  0.8945278570542251
best acc:  89.97394217644869

------Epoch: 115------
[batch_idx--0] train_loss: 0.0010261749848723412, acc: 0.87109375, lr: 0.00642137936306515
[batch_idx--50] train_loss: 0.000982495985797369, acc: 0.8960631127450981, lr: 0.006382587355775901
[batch_idx--100] train_loss: 0.0010082789219565467, acc: 0.891978650990099, lr: 0.006343895722960522
[batch_idx--150] train_loss: 0.0009999319915628888, acc: 0.8930049668874173, lr: 0.006305304673222229
[batch_idx--200] train_loss: 0.0010129664106577152, acc: 0.8914995335820896, lr: 0.0062668144146219495
[batch_idx--250] train_loss: 0.0010131712990397387, acc: 0.8918077689243028, lr: 0.006228425154677217
[batch_idx--300] train_loss: 0.001010702315337362, acc: 0.8922212416943521, lr: 0.0061901371003610295
[batch_idx--350] train_loss: 0.0010077483226356768, acc: 0.8924724002849003, lr: 0.00615195045810075
[batch_idx--400] train_loss: 0.0010072387585955255, acc: 0.8923784289276808, lr: 0.006113865433776986
[batch_idx--450] train_loss: 0.001009474443255268, acc: 0.892691012601104, lr: 0.006075882232722457
total time of one epoch: 218.83931183815002 s
train_loss:  0.001009474443255268  acc:  0.892691012601104
->>lr:0.006076
test_loss:  0.0009976577349788335  test_acc:  0.8970095545353022
best acc:  89.97394217644869

------Epoch: 116------
[batch_idx--0] train_loss: 0.0009716858039610088, acc: 0.91015625, lr: 0.006075123608706093
[batch_idx--50] train_loss: 0.0010049873871692254, acc: 0.8925398284313726, lr: 0.006037244478350651
[batch_idx--100] train_loss: 0.0009951541801951457, acc: 0.8934096534653465, lr: 0.00599946758436096
[batch_idx--150] train_loss: 0.0009964020400067533, acc: 0.894505380794702, lr: 0.005961793130408489
[batch_idx--200] train_loss: 0.0010002617421907497, acc: 0.8936955845771144, lr: 0.005924221319612417
[batch_idx--250] train_loss: 0.001003526787290283, acc: 0.8926792828685259, lr: 0.005886752354538527
[batch_idx--300] train_loss: 0.0010104967436700613, acc: 0.891624273255814, lr: 0.0058493864371981065
[batch_idx--350] train_loss: 0.0010059101339907218, acc: 0.892516915954416, lr: 0.005812123769046874
[batch_idx--400] train_loss: 0.0010080585547112058, acc: 0.8923199812967582, lr: 0.005774964550983902
[batch_idx--450] train_loss: 0.0010091989432500777, acc: 0.892682334154893, lr: 0.005737908983350504
total time of one epoch: 210.7469494342804 s
train_loss:  0.0010091989432500777  acc:  0.892682334154893
->>lr:0.005738
test_loss:  0.000977508384442711  test_acc:  0.9008561856309716
best acc:  89.97394217644869
Saving..

------Epoch: 117------
[batch_idx--0] train_loss: 0.0010979661019518971, acc: 0.87109375, lr: 0.005737168930605272
[batch_idx--50] train_loss: 0.0010025738259120023, acc: 0.8939185049019608, lr: 0.005700219292222111
[batch_idx--100] train_loss: 0.0009979279919315389, acc: 0.8939511138613861, lr: 0.005663373707252357
[batch_idx--150] train_loss: 0.0010000673401792416, acc: 0.8932119205298014, lr: 0.005626632374346372
[batch_idx--200] train_loss: 0.0010006289378350684, acc: 0.8930542599502488, lr: 0.005589995491592479
[batch_idx--250] train_loss: 0.0010048945833728519, acc: 0.8928193476095617, lr: 0.005553463256515865
[batch_idx--300] train_loss: 0.001005546353444878, acc: 0.892389950166113, lr: 0.005517035866077508
[batch_idx--350] train_loss: 0.0010011906349537973, acc: 0.8930288461538461, lr: 0.0054807135166731365
[batch_idx--400] train_loss: 0.00099985452631298, acc: 0.8934207450124688, lr: 0.005444496404132135
[batch_idx--450] train_loss: 0.001001695682002309, acc: 0.8934373589752491, lr: 0.005408384723716528
total time of one epoch: 226.10757875442505 s
train_loss:  0.001001695682002309  acc:  0.8934373589752491
->>lr:0.005408
test_loss:  0.000990476031681491  test_acc:  0.8982504032758407
best acc:  90.08561856309716

------Epoch: 118------
[batch_idx--0] train_loss: 0.001624126685783267, acc: 0.84765625, lr: 0.005407663566854007
[batch_idx--50] train_loss: 0.00103181066886321, acc: 0.891390931372549, lr: 0.005371659627775735
[batch_idx--100] train_loss: 0.0010125324842381743, acc: 0.8926748143564357, lr: 0.005335761513517229
[batch_idx--150] train_loss: 0.00100852062174779, acc: 0.8919184602649006, lr: 0.0052999694176206515
[batch_idx--200] train_loss: 0.0010075355939038876, acc: 0.8927433146766169, lr: 0.005264283533056586
[batch_idx--250] train_loss: 0.001004197766477487, acc: 0.8927415338645418, lr: 0.0052287040522229575
[batch_idx--300] train_loss: 0.0010038101227653902, acc: 0.8928960755813954, lr: 0.005193231166944048
[batch_idx--350] train_loss: 0.0009990851860825088, acc: 0.8932291666666666, lr: 0.005157865068469426
[batch_idx--400] train_loss: 0.0009988541241637676, acc: 0.8933233322942643, lr: 0.005122605947472936
[batch_idx--450] train_loss: 0.001002623883335329, acc: 0.8933418960669282, lr: 0.0050874539940516635
total time of one epoch: 233.5624978542328 s
train_loss:  0.001002623883335329  acc:  0.8933418960669282
->>lr:0.005087
test_loss:  0.0009677286297619114  test_acc:  0.8989949125201638
best acc:  90.08561856309716

------Epoch: 119------
[batch_idx--0] train_loss: 0.0009840684942901134, acc: 0.90234375, lr: 0.005086752049395094
[batch_idx--50] train_loss: 0.0009983890717301298, acc: 0.8943014705882353, lr: 0.005051709602139323
[batch_idx--100] train_loss: 0.0009916897201541774, acc: 0.8941831683168316, lr: 0.005016774704691432
[batch_idx--150] train_loss: 0.000984756023135801, acc: 0.8956953642384106, lr: 0.004981947545400465
[batch_idx--200] train_loss: 0.0009942192324224062, acc: 0.8944340796019901, lr: 0.004947228312034608
[batch_idx--250] train_loss: 0.0009915324403863563, acc: 0.8946090637450199, lr: 0.004912617191780173
[batch_idx--300] train_loss: 0.000986328385839938, acc: 0.8953358596345515, lr: 0.004878114371240583
[batch_idx--350] train_loss: 0.0009884306447224909, acc: 0.8949875356125356, lr: 0.004843720036435387
[batch_idx--400] train_loss: 0.0009869076813828952, acc: 0.8946968516209476, lr: 0.004809434372799207
[batch_idx--450] train_loss: 0.0009947399837265086, acc: 0.8942965251501371, lr: 0.004775257565180805
total time of one epoch: 217.4007694721222 s
train_loss:  0.0009947399837265086  acc:  0.8942965251501371
->>lr:0.004775
test_loss:  0.0009761707671656918  test_acc:  0.8989949125201638
best acc:  90.08561856309716

------Epoch: 120------
[batch_idx--0] train_loss: 0.0009743338450789452, acc: 0.8984375, lr: 0.004774575140626317
[batch_idx--50] train_loss: 0.0009852401608619473, acc: 0.8961397058823529, lr: 0.004740509555968578
[batch_idx--100] train_loss: 0.0009906690453621789, acc: 0.8952274133663366, lr: 0.004706553198931926
[batch_idx--150] train_loss: 0.000996324885559472, acc: 0.8949192880794702, lr: 0.004672706252589681
[batch_idx--200] train_loss: 0.0009909675442683163, acc: 0.8949782338308457, lr: 0.004638968899425284
[batch_idx--250] train_loss: 0.0009890100236915318, acc: 0.8951381972111554, lr: 0.004605341321331294
[batch_idx--300] train_loss: 0.0009939630383987636, acc: 0.8946350705980066, lr: 0.004571823699608443
[batch_idx--350] train_loss: 0.0009921055170707405, acc: 0.8945757656695157, lr: 0.0045384162149646355
[batch_idx--400] train_loss: 0.0009948060420478817, acc: 0.8941708229426434, lr: 0.004505119047513989
[batch_idx--450] train_loss: 0.0009989755352114002, acc: 0.8937931752698997, lr: 0.0044719323767758445
total time of one epoch: 226.28534173965454 s
train_loss:  0.0009989755352114002  acc:  0.8937931752698997
->>lr:0.004472
test_loss:  0.0009902374355975534  test_acc:  0.8987467427720561
best acc:  90.08561856309716

------Epoch: 121------
[batch_idx--0] train_loss: 0.0009428526973351836, acc: 0.89453125, lr: 0.004471269771657399
[batch_idx--50] train_loss: 0.0009858291641827307, acc: 0.8921568627450981, lr: 0.004438195991889007
[batch_idx--100] train_loss: 0.0009779337848914733, acc: 0.8947633044554455, lr: 0.004405233069644058
[batch_idx--150] train_loss: 0.0009815373977596891, acc: 0.8949968956953642, lr: 0.004372381182639854
[batch_idx--200] train_loss: 0.0009808167267882667, acc: 0.8950948383084577, lr: 0.004339640507995033
[batch_idx--250] train_loss: 0.0009871252874595177, acc: 0.8945156872509961, lr: 0.00430701122222864
[batch_idx--300] train_loss: 0.0009849117736199073, acc: 0.8949854651162791, lr: 0.004274493501259191
[batch_idx--350] train_loss: 0.0009837715834793118, acc: 0.8952435007122507, lr: 0.004242087520403681
[batch_idx--400] train_loss: 0.0009851579084363012, acc: 0.8953105517456359, lr: 0.004209793454376692
[batch_idx--450] train_loss: 0.0009885689387670903, acc: 0.8952251188947131, lr: 0.0041776114772894115
total time of one epoch: 210.43062162399292 s
train_loss:  0.0009885689387670903  acc:  0.8952251188947131
->>lr:0.004178
test_loss:  0.0010073424210278001  test_acc:  0.8931629234396327
best acc:  90.08561856309716

------Epoch: 122------
[batch_idx--0] train_loss: 0.0008979254635050893, acc: 0.90234375, lr: 0.004176968982247515
[batch_idx--50] train_loss: 0.0009842039754742063, acc: 0.8943780637254902, lr: 0.004144901514621361
[batch_idx--100] train_loss: 0.00099053040912172, acc: 0.8941444925742574, lr: 0.0041129464857952575
[batch_idx--150] train_loss: 0.0009997978564413475, acc: 0.8926686672185431, lr: 0.004081104068052505
[batch_idx--200] train_loss: 0.0010058927258235677, acc: 0.8919853855721394, lr: 0.00404937443306925
[batch_idx--250] train_loss: 0.0010072872816284458, acc: 0.89261703187251, lr: 0.004017757751913604
[batch_idx--300] train_loss: 0.0009975444762952057, acc: 0.893687707641196, lr: 0.003986254195044678
[batch_idx--350] train_loss: 0.0009960190416579042, acc: 0.8937633547008547, lr: 0.003954863932311695
[batch_idx--400] train_loss: 0.0009930824223404141, acc: 0.8940441864089775, lr: 0.003923587132953052
[batch_idx--450] train_loss: 0.0009940228143277385, acc: 0.894357274273614, lr: 0.003892423965595415
total time of one epoch: 214.53370666503906 s
train_loss:  0.0009940228143277385  acc:  0.894357274273614
->>lr:0.003892
test_loss:  0.0009745735157836326  test_acc:  0.8988708276461099
best acc:  90.08561856309716

------Epoch: 123------
[batch_idx--0] train_loss: 0.0009189636912196875, acc: 0.89453125, lr: 0.003891801862449629
[batch_idx--50] train_loss: 0.0010011044796556234, acc: 0.8938419117647058, lr: 0.003860754772816863
[batch_idx--100] train_loss: 0.0009977588957950179, acc: 0.8953047648514851, lr: 0.0038298216539413596
[batch_idx--150] train_loss: 0.00099447209832092, acc: 0.8953073261589404, lr: 0.0037990026725968685
[batch_idx--200] train_loss: 0.000990463432621915, acc: 0.8954057835820896, lr: 0.003768297994941761
[batch_idx--250] train_loss: 0.0009901493412546398, acc: 0.8951070717131474, lr: 0.0037377077865181603
[batch_idx--300] train_loss: 0.0009838040483778226, acc: 0.8958679401993356, lr: 0.003707232212251013
[batch_idx--350] train_loss: 0.0009888864951168434, acc: 0.895065438034188, lr: 0.003676871436447249
[batch_idx--400] train_loss: 0.0009885528299056383, acc: 0.8950767612219451, lr: 0.0036466256227948553
[batch_idx--450] train_loss: 0.0009938110657080014, acc: 0.8951383344326032, lr: 0.003616494934362016
total time of one epoch: 227.87521290779114 s
train_loss:  0.0009938110657080014  acc:  0.8951383344326032
->>lr:0.003616
test_loss:  0.0009735252942558494  test_acc:  0.899739421764487
best acc:  90.08561856309716

------Epoch: 124------
[batch_idx--0] train_loss: 0.001019070390611887, acc: 0.90234375, lr: 0.003615893495987335
[batch_idx--50] train_loss: 0.0009684574495836654, acc: 0.9007352941176471, lr: 0.003585880402627581
[batch_idx--100] train_loss: 0.00098248546203082, acc: 0.8977413366336634, lr: 0.0035559827619909834
[batch_idx--150] train_loss: 0.0009953375294379002, acc: 0.8955918874172185, lr: 0.0035262007352685563
[batch_idx--200] train_loss: 0.0009900201566688791, acc: 0.8957555970149254, lr: 0.003496534483028016
[batch_idx--250] train_loss: 0.0009862459865324497, acc: 0.8960097111553785, lr: 0.0034669841652128805
[batch_idx--300] train_loss: 0.0009834841551240596, acc: 0.8963091777408638, lr: 0.00343754994114161
[batch_idx--350] train_loss: 0.0009864878809567742, acc: 0.8960447827635327, lr: 0.0034082319695067616
[batch_idx--400] train_loss: 0.000981137257370113, acc: 0.8965574345386533, lr: 0.003379030408374123
[batch_idx--450] train_loss: 0.0009832474291448761, acc: 0.8964661367028847, lr: 0.00334994541518186
total time of one epoch: 219.13748002052307 s
train_loss:  0.0009832474291448761  acc:  0.8964661367028847
->>lr:0.003350
test_loss:  0.000977608523056427  test_acc:  0.8993671671423253
best acc:  90.08561856309716

------Epoch: 125------
[batch_idx--0] train_loss: 0.001105034607462585, acc: 0.87109375, lr: 0.003349364905389038
[batch_idx--50] train_loss: 0.0009800764690975055, acc: 0.8948376225490197, lr: 0.003320398973036992
[batch_idx--100] train_loss: 0.0009809165125675868, acc: 0.8962716584158416, lr: 0.0032915499247325843
[batch_idx--150] train_loss: 0.0009671071234362706, acc: 0.8979977235099338, lr: 0.003262817916013447
[batch_idx--200] train_loss: 0.0009730185077419106, acc: 0.8972714552238806, lr: 0.0032342031017861847
[batch_idx--250] train_loss: 0.0009746671766988874, acc: 0.8971302290836654, lr: 0.003205705636325565
[batch_idx--300] train_loss: 0.0009734146010774216, acc: 0.896906146179402, lr: 0.0031773256732736594
[batch_idx--350] train_loss: 0.0009737538782073094, acc: 0.8969017094017094, lr: 0.0031490633656390573
[batch_idx--400] train_loss: 0.0009799834786150187, acc: 0.8962262312967582, lr: 0.0031209188657960046
[batch_idx--450] train_loss: 0.000983981992068499, acc: 0.8959193945915923, lr: 0.0030928923254835983
total time of one epoch: 216.87539649009705 s
train_loss:  0.000983981992068499  acc:  0.8959193945915923
->>lr:0.003093
test_loss:  0.0009821743838085047  test_acc:  0.8970095545353022
best acc:  90.08561856309716

------Epoch: 126------
[batch_idx--0] train_loss: 0.0011204899055883288, acc: 0.859375, lr: 0.0030923329989034107
[batch_idx--50] train_loss: 0.0009680995683404891, acc: 0.8967524509803921, lr: 0.003064426932974329
[batch_idx--100] train_loss: 0.0009699334980606442, acc: 0.8977413366336634, lr: 0.003036639131148192
[batch_idx--150] train_loss: 0.0009709854316527629, acc: 0.8974803394039735, lr: 0.003008969743240972
[batch_idx--200] train_loss: 0.0009712168381581852, acc: 0.8973686256218906, lr: 0.002981418918430234
[batch_idx--250] train_loss: 0.0009684249238329995, acc: 0.8978149900398407, lr: 0.002953986805254319
[batch_idx--300] train_loss: 0.000968602742184498, acc: 0.8977367109634552, lr: 0.002926673551611542
[batch_idx--350] train_loss: 0.0009671448788969138, acc: 0.8980034722222222, lr: 0.002899479304759398
[batch_idx--400] train_loss: 0.0009714886583875576, acc: 0.8976387157107232, lr: 0.0028724042113137424
[batch_idx--450] train_loss: 0.000977097260268985, acc: 0.8972124830770299, lr: 0.002845448417248059
total time of one epoch: 219.10653018951416 s
train_loss:  0.000977097260268985  acc:  0.8972124830770299
->>lr:0.002845
test_loss:  0.0009795636778094363  test_acc:  0.8994912520163793
best acc:  90.08561856309716

------Epoch: 127------
[batch_idx--0] train_loss: 0.000989553052932024, acc: 0.8828125, lr: 0.0028449105192196373
[batch_idx--50] train_loss: 0.0009563821858689919, acc: 0.9028799019607843, lr: 0.0028180765602363435
[batch_idx--100] train_loss: 0.0009648661356244125, acc: 0.9002552599009901, lr: 0.0027913621935367313
[batch_idx--150] train_loss: 0.0009663660265813699, acc: 0.898411630794702, lr: 0.002764767563149445
[batch_idx--200] train_loss: 0.0009646351881839558, acc: 0.8979516480099502, lr: 0.002738292812457563
[batch_idx--250] train_loss: 0.000969022681029417, acc: 0.897503735059761, lr: 0.00271193808419784
[batch_idx--300] train_loss: 0.0009701667199579634, acc: 0.8969969892026578, lr: 0.002685703520459948
[batch_idx--350] train_loss: 0.0009730785721621113, acc: 0.8967125178062678, lr: 0.0026595892626856965
[batch_idx--400] train_loss: 0.000973845284084959, acc: 0.8964015741895262, lr: 0.0026335954516682747
[batch_idx--450] train_loss: 0.000974615550937741, acc: 0.8969174159058562, lr: 0.0026077222275514957
total time of one epoch: 237.23686861991882 s
train_loss:  0.000974615550937741  acc:  0.8969174159058562
->>lr:0.002608
test_loss:  0.0009729950836122235  test_acc:  0.8993671671423253
best acc:  90.08561856309716

------Epoch: 128------
[batch_idx--0] train_loss: 0.0010720827849581838, acc: 0.87890625, lr: 0.0026072059940146775
[batch_idx--50] train_loss: 0.0009794988071399869, acc: 0.8969056372549019, lr: 0.002581455912238459
[batch_idx--100] train_loss: 0.001002905548591683, acc: 0.8931002475247525, lr: 0.0025558266984695406
[batch_idx--150] train_loss: 0.0009822781233961959, acc: 0.8955142798013245, lr: 0.002530318490886033
[batch_idx--200] train_loss: 0.0009746726310408827, acc: 0.8965135261194029, lr: 0.0025049314270136516
[batch_idx--250] train_loss: 0.0009734767335615458, acc: 0.8967878486055777, lr: 0.0024796656437249655
[batch_idx--300] train_loss: 0.0009772229720791956, acc: 0.8960755813953488, lr: 0.0024545212772386807
[batch_idx--350] train_loss: 0.000971422954581869, acc: 0.8966791310541311, lr: 0.0024294984631188735
[batch_idx--400] train_loss: 0.0009721712906905299, acc: 0.8966061408977556, lr: 0.0024045973362742893
[batch_idx--450] train_loss: 0.0009759571260367587, acc: 0.8963099246710869, lr: 0.0023798180309576172
total time of one epoch: 215.96940112113953 s
train_loss:  0.0009759571260367587  acc:  0.8963099246710869
->>lr:0.002380
test_loss:  0.0009790676553368583  test_acc:  0.8977540637796253
best acc:  90.08561856309716

------Epoch: 129------
[batch_idx--0] train_loss: 0.0011064052814617753, acc: 0.86328125, lr: 0.0023793236883495163
[batch_idx--50] train_loss: 0.0009581809155825598, acc: 0.8968290441176471, lr: 0.002354668778617275
[batch_idx--100] train_loss: 0.0009678542189816437, acc: 0.8970064975247525, lr: 0.0023301359595992556
[batch_idx--150] train_loss: 0.0009757739642869361, acc: 0.8965231788079471, lr: 0.0023057253635624278
[batch_idx--200] train_loss: 0.0009742826521651477, acc: 0.8967078669154229, lr: 0.0022814371221148186
[batch_idx--250] train_loss: 0.0009715905279919238, acc: 0.8970835408366534, lr: 0.0022572713662047635
[batch_idx--300] train_loss: 0.0009713661557208883, acc: 0.8973473837209303, lr: 0.0022332282261202457
[batch_idx--350] train_loss: 0.0009714525968746476, acc: 0.8973023504273504, lr: 0.0022093078314881667
[batch_idx--400] train_loss: 0.000971690889510635, acc: 0.8973367362842892, lr: 0.002185510311273653
[batch_idx--450] train_loss: 0.0009767942679653804, acc: 0.8970302357065991, lr: 0.0021618357937793764
total time of one epoch: 226.10379576683044 s
train_loss:  0.0009767942679653804  acc:  0.8970302357065991
->>lr:0.002162
test_loss:  0.0009705931380925484  test_acc:  0.8998635066385408
best acc:  90.08561856309716

------Epoch: 130------
[batch_idx--0] train_loss: 0.0010047367541119456, acc: 0.8828125, lr: 0.0021613635589349755
[batch_idx--50] train_loss: 0.0009578421606919637, acc: 0.8985906862745098, lr: 0.0021378146357049848
[batch_idx--100] train_loss: 0.0009551587056986397, acc: 0.8989789603960396, lr: 0.0021143889723431067
[batch_idx--150] train_loss: 0.0009628092686627184, acc: 0.8987220612582781, lr: 0.0020910866951471623
[batch_idx--200] train_loss: 0.0009679039462413917, acc: 0.8973103233830846, lr: 0.0020679079297497515
[batch_idx--250] train_loss: 0.0009735193921241954, acc: 0.8968345368525896, lr: 0.0020448528011175527
[batch_idx--300] train_loss: 0.000975435421000733, acc: 0.8962442898671097, lr: 0.0020219214335506857
[batch_idx--350] train_loss: 0.0009752880485709809, acc: 0.8962228454415955, lr: 0.0019991139506819965
[batch_idx--400] train_loss: 0.0009753119500651213, acc: 0.8960703709476309, lr: 0.001976430475476429
[batch_idx--450] train_loss: 0.0009770024660046878, acc: 0.8966483840733155, lr: 0.0019538711302303584
total time of one epoch: 216.8539695739746 s
train_loss:  0.0009770024660046878  acc:  0.8966483840733155
->>lr:0.001954
test_loss:  0.0009774560149690178  test_acc:  0.8992430822682715
best acc:  90.08561856309716

------Epoch: 131------
[batch_idx--0] train_loss: 0.0008314093574881554, acc: 0.90234375, lr: 0.00195342121028749
[batch_idx--50] train_loss: 0.000971874647874239, acc: 0.8969822303921569, lr: 0.001930988602895767
[batch_idx--100] train_loss: 0.0009628218226365303, acc: 0.8981667698019802, lr: 0.001908680370460203
[batch_idx--150] train_loss: 0.000951378456693118, acc: 0.8997050910596026, lr: 0.0018864966332540673
[batch_idx--200] train_loss: 0.0009609297223722757, acc: 0.898379197761194, lr: 0.0018644375108794243
[batch_idx--250] train_loss: 0.0009636269097097693, acc: 0.8981418077689243, lr: 0.0018425031222664813
[batch_idx--300] train_loss: 0.000964900797412443, acc: 0.8977886212624585, lr: 0.0018206935856729584
[batch_idx--350] train_loss: 0.0009664437651337042, acc: 0.8977029914529915, lr: 0.0017990090186834396
[batch_idx--400] train_loss: 0.0009640786100638812, acc: 0.8979017300498753, lr: 0.0017774495382087503
[batch_idx--450] train_loss: 0.0009669733287449551, acc: 0.8976811191724233, lr: 0.001756015260485311
total time of one epoch: 229.55445289611816 s
train_loss:  0.0009669733287449551  acc:  0.8976811191724233
->>lr:0.001756
test_loss:  0.0009752553229533734  test_acc:  0.8986226578980022
best acc:  90.08561856309716

------Epoch: 132------
[batch_idx--0] train_loss: 0.001017218455672264, acc: 0.8828125, lr: 0.0017555878527937164
[batch_idx--50] train_loss: 0.0009423774991220995, acc: 0.9026501225490197, lr: 0.0017342814009232738
[batch_idx--100] train_loss: 0.0009522808100198313, acc: 0.899636448019802, lr: 0.0017131003845420657
[batch_idx--150] train_loss: 0.0009532674186437434, acc: 0.9003259519867549, lr: 0.0016920449178460556
[batch_idx--200] train_loss: 0.0009545481694857613, acc: 0.8998561878109452, lr: 0.0016711151143543159
[batch_idx--250] train_loss: 0.0009551947417880494, acc: 0.8996202689243028, lr: 0.0016503110869084154
[batch_idx--300] train_loss: 0.0009548607515557932, acc: 0.8998520556478405, lr: 0.0016296329476718054
[batch_idx--350] train_loss: 0.0009597248127126796, acc: 0.8990495904558404, lr: 0.0016090808081292208
[batch_idx--400] train_loss: 0.0009640277053596466, acc: 0.8983887936408977, lr: 0.0015886547790860768
[batch_idx--450] train_loss: 0.0009641538597168775, acc: 0.8984708577776235, lr: 0.0015683549706678873
total time of one epoch: 227.56144762039185 s
train_loss:  0.0009641538597168775  acc:  0.8984708577776235
->>lr:0.001568
test_loss:  0.0009926810263404036  test_acc:  0.8981263184017868
best acc:  90.08561856309716

------Epoch: 133------
[batch_idx--0] train_loss: 0.0006265974370762706, acc: 0.9453125, lr: 0.0015679502627027138
[batch_idx--50] train_loss: 0.0009793143755957192, acc: 0.8960631127450981, lr: 0.0015477793120675237
[batch_idx--100] train_loss: 0.0009608726463243735, acc: 0.8975866336633663, lr: 0.0015277348024344995
[batch_idx--150] train_loss: 0.000952191792724543, acc: 0.8994205298013245, lr: 0.001507816841872195
[batch_idx--200] train_loss: 0.0009541667827557939, acc: 0.8990788246268657, lr: 0.0014880255377669072
[batch_idx--250] train_loss: 0.0009570582767492123, acc: 0.8990911354581673, lr: 0.0014683609968220602
[batch_idx--300] train_loss: 0.0009554794997648271, acc: 0.8992680647840532, lr: 0.0014488233250576467
[batch_idx--350] train_loss: 0.0009575517184135539, acc: 0.898704594017094, lr: 0.0014294126278096538
[batch_idx--400] train_loss: 0.0009585086152043444, acc: 0.8985641365336658, lr: 0.0014101290097294967
[batch_idx--450] train_loss: 0.0009605082263851603, acc: 0.8986183913632103, lr: 0.0013909725747834447
total time of one epoch: 241.9778516292572 s
train_loss:  0.0009605082263851603  acc:  0.8986183913632103
->>lr:0.001391
test_loss:  0.0009743137818321221  test_acc:  0.9007321007569178
best acc:  90.08561856309716

------Epoch: 134------
[batch_idx--0] train_loss: 0.0006823156145401299, acc: 0.94140625, lr: 0.001390590744062975
[batch_idx--50] train_loss: 0.000947752959487558, acc: 0.8994332107843137, lr: 0.0013715641423086456
[batch_idx--100] train_loss: 0.0009677524933139655, acc: 0.8971998762376238, lr: 0.0013526649316081968
[batch_idx--150] train_loss: 0.000967186439662111, acc: 0.8975838162251656, lr: 0.0013338932138554
[batch_idx--200] train_loss: 0.0009594125191296511, acc: 0.898398631840796, lr: 0.0013152490902566538
[batch_idx--250] train_loss: 0.0009541412070115279, acc: 0.8990911354581673, lr: 0.0012967326613304436
[batch_idx--300] train_loss: 0.0009525250305075112, acc: 0.899358907807309, lr: 0.0012783440269067943
[batch_idx--350] train_loss: 0.0009589071083413251, acc: 0.8985710470085471, lr: 0.0012600832861267342
[batch_idx--400] train_loss: 0.0009563922980205711, acc: 0.8988661159600998, lr: 0.0012419505374417718
[batch_idx--450] train_loss: 0.0009609930457540648, acc: 0.8987659249487971, lr: 0.0012239458786133446
total time of one epoch: 243.8055636882782 s
train_loss:  0.0009609930457540648  acc:  0.8987659249487971
->>lr:0.001224
test_loss:  0.0009763393856659911  test_acc:  0.8998635066385408
best acc:  90.08561856309716

------Epoch: 135------
[batch_idx--0] train_loss: 0.0009029255015775561, acc: 0.9140625, lr: 0.0012235870926211618
[batch_idx--50] train_loss: 0.0009413205678392129, acc: 0.8985140931372549, lr: 0.0012057131854440546
[batch_idx--100] train_loss: 0.0009558319591336173, acc: 0.8993657178217822, lr: 0.0011879675634946297
[batch_idx--150] train_loss: 0.0009495403678526497, acc: 0.8999896523178808, lr: 0.0011703503224471529
[batch_idx--200] train_loss: 0.0009496058624084872, acc: 0.8997978855721394, lr: 0.001152861557283752
[batch_idx--250] train_loss: 0.0009439089252016102, acc: 0.9009275398406374, lr: 0.0011355013622938726
[batch_idx--300] train_loss: 0.0009495094809155181, acc: 0.8998780107973422, lr: 0.0011182698310737928
[batch_idx--350] train_loss: 0.0009585345647181052, acc: 0.8985376602564102, lr: 0.0011011670565261005
[batch_idx--400] train_loss: 0.0009609020111601605, acc: 0.8983887936408977, lr: 0.0010841931308592041
[batch_idx--450] train_loss: 0.0009630277730116151, acc: 0.8984274655465685, lr: 0.00106734814558683
total time of one epoch: 248.32371973991394 s
train_loss:  0.0009630277730116151  acc:  0.8984274655465685
->>lr:0.001067
test_loss:  0.0009795462157711791  test_acc:  0.8989949125201638
best acc:  90.08561856309716

------Epoch: 136------
[batch_idx--0] train_loss: 0.0009362087002955377, acc: 0.90234375, lr: 0.001067012561698319
[batch_idx--50] train_loss: 0.000988430596942849, acc: 0.8948376225490197, lr: 0.0010502991891848613
[batch_idx--100] train_loss: 0.0009688350255601108, acc: 0.8960009282178217, lr: 0.0010337149398027378
[batch_idx--150] train_loss: 0.0009697551391124479, acc: 0.8963162251655629, lr: 0.001017259902964765
[batch_idx--200] train_loss: 0.0009721113178897556, acc: 0.896435789800995, lr: 0.0010009341673871241
[batch_idx--250] train_loss: 0.0009688522566510625, acc: 0.897379233067729, lr: 0.000984737821088863
[batch_idx--300] train_loss: 0.0009675715428056115, acc: 0.8971527200996677, lr: 0.000968670951391451
[batch_idx--350] train_loss: 0.0009674352077645199, acc: 0.8971688034188035, lr: 0.0009527336449182884
[batch_idx--400] train_loss: 0.0009644439119086171, acc: 0.8979114713216958, lr: 0.0009369259875942449
[batch_idx--450] train_loss: 0.0009637593681952075, acc: 0.8982018259450828, lr: 0.0009212480646451971
total time of one epoch: 245.60988759994507 s
train_loss:  0.0009637593681952075  acc:  0.8982018259450828
->>lr:0.000921
test_loss:  0.0009814984638824966  test_acc:  0.8982504032758407
best acc:  90.08561856309716

------Epoch: 137------
[batch_idx--0] train_loss: 0.0009906577179208398, acc: 0.8984375, lr: 0.0009209358300585474
[batch_idx--50] train_loss: 0.000974662614502378, acc: 0.8956801470588235, lr: 0.0009053903232463079
[batch_idx--100] train_loss: 0.0009682846415815598, acc: 0.8965810643564357, lr: 0.0008899747208313852
[batch_idx--150] train_loss: 0.0009704147992094374, acc: 0.8969888245033113, lr: 0.0008746891059259105
[batch_idx--200] train_loss: 0.0009690755083392471, acc: 0.8974269278606966, lr: 0.0008595335609412142
[batch_idx--250] train_loss: 0.0009685621948901608, acc: 0.8976749252988048, lr: 0.0008445081675873518
[batch_idx--300] train_loss: 0.0009669854485142073, acc: 0.8979443521594684, lr: 0.0008296130068726787
[batch_idx--350] train_loss: 0.0009636283932423532, acc: 0.8982928240740741, lr: 0.0008148481591034013
[batch_idx--400] train_loss: 0.0009596626186613318, acc: 0.8986518079800498, lr: 0.0008002137038831625
[batch_idx--450] train_loss: 0.0009620114688927998, acc: 0.8985749991321553, lr: 0.000785709720112604
total time of one epoch: 268.86891651153564 s
train_loss:  0.0009620114688927998  acc:  0.8985749991321553
->>lr:0.000786
test_loss:  0.000977281649749648  test_acc:  0.8983744881498945
best acc:  90.08561856309716

------Epoch: 138------
[batch_idx--0] train_loss: 0.0012333299964666367, acc: 0.8671875, lr: 0.0007854209717842232
[batch_idx--50] train_loss: 0.0009637128564017807, acc: 0.8998927696078431, lr: 0.0007710501494462701
[batch_idx--100] train_loss: 0.0009586701969533126, acc: 0.8993270420792079, lr: 0.0007568099557912517
[batch_idx--150] train_loss: 0.0009543215277734281, acc: 0.9009726821192053, lr: 0.000742700467594179
[batch_idx--200] train_loss: 0.0009584680149813567, acc: 0.9001088308457711, lr: 0.0007287217609253605
[batch_idx--250] train_loss: 0.0009539970268673482, acc: 0.90042953187251, lr: 0.0007148739111500131
[batch_idx--300] train_loss: 0.0009601479678560185, acc: 0.8996054817275747, lr: 0.0007011569929278511
[batch_idx--350] train_loss: 0.0009624594023207102, acc: 0.8989383012820513, lr: 0.0006875710802126706
[batch_idx--400] train_loss: 0.0009644965580525225, acc: 0.8985056889027432, lr: 0.0006741162462519713
[batch_idx--450] train_loss: 0.0009668081650698525, acc: 0.8984535008852015, lr: 0.0006607925635865458
total time of one epoch: 252.9615445137024 s
train_loss:  0.0009668081650698525  acc:  0.8984535008852015
->>lr:0.000661
test_loss:  0.000976716685138309  test_acc:  0.8993671671423253
best acc:  90.08561856309716

------Epoch: 139------
[batch_idx--0] train_loss: 0.0010039511835202575, acc: 0.8828125, lr: 0.0006605274281709927
[batch_idx--50] train_loss: 0.0009404685937196893, acc: 0.9020373774509803, lr: 0.0006473375938249676
[batch_idx--100] train_loss: 0.0009515202520092451, acc: 0.8994043935643564, lr: 0.0006342790551494393
[batch_idx--150] train_loss: 0.0009528098570873701, acc: 0.8996274834437086, lr: 0.0006213518825486042
[batch_idx--200] train_loss: 0.000954022127741123, acc: 0.8993509017412935, lr: 0.0006085561457184031
[batch_idx--250] train_loss: 0.0009505107940408397, acc: 0.8996513944223108, lr: 0.0005958919136461599
[batch_idx--300] train_loss: 0.0009511283897033635, acc: 0.899436773255814, lr: 0.000583359254610194
[batch_idx--350] train_loss: 0.0009488583463801341, acc: 0.8998286146723646, lr: 0.0005709582361794502
[batch_idx--400] train_loss: 0.0009516128653862474, acc: 0.8995869700748129, lr: 0.0005586889252131494
[batch_idx--450] train_loss: 0.0009575986499986169, acc: 0.8995730204464193, lr: 0.0005465513878604278
total time of one epoch: 248.10356330871582 s
train_loss:  0.0009575986499986169  acc:  0.8995730204464193
->>lr:0.000547
test_loss:  0.0009801235151196224  test_acc:  0.8991189973942176
best acc:  90.08561856309716

------Epoch: 140------
[batch_idx--0] train_loss: 0.0009449441567994654, acc: 0.890625, lr: 0.0005463099816548578
[batch_idx--50] train_loss: 0.0009607627015451298, acc: 0.8989736519607843, lr: 0.0005343069207980278
[batch_idx--100] train_loss: 0.0009621641907545895, acc: 0.8977413366336634, lr: 0.0005224357650086414
[batch_idx--150] train_loss: 0.0009545892433090666, acc: 0.8984375, lr: 0.0005106965782891965
[batch_idx--200] train_loss: 0.0009573708167901976, acc: 0.8989816542288557, lr: 0.0004990894239306987
[batch_idx--250] train_loss: 0.0009573994286031837, acc: 0.8992623256972112, lr: 0.0004876143645123038
[batch_idx--300] train_loss: 0.0009634535329608228, acc: 0.8981779485049833, lr: 0.00047627146190098725
[batch_idx--350] train_loss: 0.0009601954314353586, acc: 0.8984597578347578, lr: 0.00046506077725121944
[batch_idx--400] train_loss: 0.0009547804243934627, acc: 0.8992265430174564, lr: 0.00045398237100461594
[batch_idx--450] train_loss: 0.000960102150474108, acc: 0.8991651334745028, lr: 0.0004430363028896239
total time of one epoch: 248.9239890575409 s
train_loss:  0.000960102150474108  acc:  0.8991651334745028
->>lr:0.000443
test_loss:  0.0009804370219424368  test_acc:  0.8982504032758407
best acc:  90.08561856309716

------Epoch: 141------
[batch_idx--0] train_loss: 0.000881799147464335, acc: 0.9140625, lr: 0.00044281873178278475
[batch_idx--50] train_loss: 0.0009721302879316842, acc: 0.8962928921568627, lr: 0.0004320077093543484
[batch_idx--100] train_loss: 0.000958732917725044, acc: 0.8984375, lr: 0.0004213291435323757
[batch_idx--150] train_loss: 0.0009628155662690517, acc: 0.8982046771523179, lr: 0.0004107830918895994
[batch_idx--200] train_loss: 0.0009549314929960083, acc: 0.8993703358208955, lr: 0.00040036961128431806
[batch_idx--250] train_loss: 0.0009540262941894422, acc: 0.899371264940239, lr: 0.00039008875786008537
[batch_idx--300] train_loss: 0.000956446551594054, acc: 0.8995535714285714, lr: 0.00037994058704539927
[batch_idx--350] train_loss: 0.0009599808158095597, acc: 0.8990162037037037, lr: 0.0003699251535534104
[batch_idx--400] train_loss: 0.0009564406211206927, acc: 0.8993336970074813, lr: 0.0003600425113816253
[batch_idx--450] train_loss: 0.0009575364362151926, acc: 0.8995383066615753, lr: 0.0003502927138116147
total time of one epoch: 266.35875821113586 s
train_loss:  0.0009575364362151926  acc:  0.8995383066615753
->>lr:0.000350
test_loss:  0.0009777030018544815  test_acc:  0.9009802705050254
best acc:  90.08561856309716
Saving..

------Epoch: 142------
[batch_idx--0] train_loss: 0.0009198210900649428, acc: 0.9140625, lr: 0.00035009907323737546
[batch_idx--50] train_loss: 0.0009437788850810452, acc: 0.9021139705882353, lr: 0.00034048483130907914
[batch_idx--100] train_loss: 0.000953784494863657, acc: 0.8999071782178217, lr: 0.00033100353942642217
[batch_idx--150] train_loss: 0.0009516081375699021, acc: 0.9004294288079471, lr: 0.0003216552487071145
[batch_idx--200] train_loss: 0.000950912001776736, acc: 0.900400342039801, lr: 0.00031244000955181765
[batch_idx--250] train_loss: 0.0009541924793803804, acc: 0.8997136454183267, lr: 0.00030335787164384453
[batch_idx--300] train_loss: 0.0009483162967714038, acc: 0.9003062707641196, lr: 0.00029440888394890454
[batch_idx--350] train_loss: 0.0009464589766813097, acc: 0.9003516737891738, lr: 0.00028559309471483943
[batch_idx--400] train_loss: 0.0009488350886821356, acc: 0.8997233478802993, lr: 0.00027691055147135437
[batch_idx--450] train_loss: 0.0009571988200623668, acc: 0.8992692748290346, lr: 0.0002683613010297709
total time of one epoch: 241.4223916530609 s
train_loss:  0.0009571988200623668  acc:  0.8992692748290346
->>lr:0.000268
test_loss:  0.0009759980734501957  test_acc:  0.9004839310088101
best acc:  90.09802705050254

------Epoch: 143------
[batch_idx--0] train_loss: 0.0008403921383433044, acc: 0.91796875, lr: 0.0002681916759252945
[batch_idx--50] train_loss: 0.0009472537180865366, acc: 0.9000459558823529, lr: 0.00025977843162139916
[batch_idx--100] train_loss: 0.0009479534824950491, acc: 0.9011834777227723, lr: 0.0002514985724860308
[batch_idx--150] train_loss: 0.0009459835490279689, acc: 0.9009209437086093, lr: 0.00024335214315946986
[batch_idx--200] train_loss: 0.0009345133714748555, acc: 0.9021299751243781, lr: 0.00023533918756261376
[batch_idx--250] train_loss: 0.0009378446681161534, acc: 0.9012076693227091, lr: 0.00022745974889675503
[batch_idx--300] train_loss: 0.0009451971698376006, acc: 0.8998650332225914, lr: 0.0002197138696433315
[batch_idx--350] train_loss: 0.0009430230112926785, acc: 0.9002737713675214, lr: 0.0002121015915637098
[batch_idx--400] train_loss: 0.0009475401800097968, acc: 0.900044809850374, lr: 0.0002046229556989493
[batch_idx--450] train_loss: 0.0009540669968163627, acc: 0.899824695386538, lr: 0.00019727800236959416
total time of one epoch: 249.07351899147034 s
train_loss:  0.0009540669968163627  acc:  0.899824695386538
->>lr:0.000197
test_loss:  0.0009776662324672747  test_acc:  0.8998635066385408
best acc:  90.09802705050254

------Epoch: 144------
[batch_idx--0] train_loss: 0.0010964579414576292, acc: 0.87890625, lr: 0.0001971324671380531
[batch_idx--50] train_loss: 0.0009558817335203582, acc: 0.9006587009803921, lr: 0.00018992391078557493
[batch_idx--100] train_loss: 0.0009576472203652974, acc: 0.8989789603960396, lr: 0.00018284911621737067
[batch_idx--150] train_loss: 0.0009466243305687627, acc: 0.9008950745033113, lr: 0.00017590812157669555
[batch_idx--200] train_loss: 0.0009471972545942487, acc: 0.9000699626865671, lr: 0.00016910096428543743
[batch_idx--250] train_loss: 0.0009419020134083689, acc: 0.9008341633466136, lr: 0.00016242768104390848
[batch_idx--300] train_loss: 0.0009478888098472277, acc: 0.9001764950166113, lr: 0.00015588830783064834
[batch_idx--350] train_loss: 0.0009486663581118879, acc: 0.8998731303418803, lr: 0.0001494828799022241
[batch_idx--400] train_loss: 0.0009500845518320836, acc: 0.8995285224438903, lr: 0.00014321143179305552
[batch_idx--450] train_loss: 0.0009527242945735869, acc: 0.8993734161835665, lr: 0.00013707399731520964
total time of one epoch: 228.63240098953247 s
train_loss:  0.0009527242945735869  acc:  0.8993734161835665
->>lr:0.000137
test_loss:  0.0009758995286819879  test_acc:  0.9003598461347562
best acc:  90.09802705050254

------Epoch: 145------
[batch_idx--0] train_loss: 0.0007989237201400101, acc: 0.92578125, lr: 0.00013695261579316776
[batch_idx--50] train_loss: 0.0009574123735850056, acc: 0.8979779411764706, lr: 0.0001309519093031647
[batch_idx--100] train_loss: 0.0009482031069133468, acc: 0.8980894183168316, lr: 0.0001250852825408405
[batch_idx--150] train_loss: 0.000940645326758482, acc: 0.8994722682119205, lr: 0.0001193527671357053
[batch_idx--200] train_loss: 0.0009390917859753751, acc: 0.9003614738805971, lr: 0.00011375439399421428
[batch_idx--250] train_loss: 0.0009368321198814241, acc: 0.9006318476095617, lr: 0.00010829019329959833
[batch_idx--300] train_loss: 0.000941292609419191, acc: 0.9004879568106312, lr: 0.00010296019451171701
[batch_idx--350] train_loss: 0.0009420428365705127, acc: 0.9006521545584045, lr: 9.776442636688366e-05
[batch_idx--400] train_loss: 0.0009431390502859381, acc: 0.9005026496259352, lr: 9.270291687771548e-05
[batch_idx--450] train_loss: 0.0009472894910974496, acc: 0.9002065470198216, lr: 8.77756933329893e-05
total time of one epoch: 234.29571723937988 s
train_loss:  0.0009472894910974496  acc:  0.9002065470198216
->>lr:0.000088
test_loss:  0.0009785854153752046  test_acc:  0.9004839310088101
best acc:  90.09802705050254

------Epoch: 146------
[batch_idx--0] train_loss: 0.000816632469650358, acc: 0.91796875, lr: 8.767851876239075e-05
[batch_idx--50] train_loss: 0.000970848069033202, acc: 0.8959099264705882, lr: 8.288829424305533e-05
[batch_idx--100] train_loss: 0.0009744806724628157, acc: 0.8965810643564357, lr: 7.82324085830094e-05
[batch_idx--150] train_loss: 0.000970015490800759, acc: 0.8977649006622517, lr: 7.371088688413186e-05
[batch_idx--200] train_loss: 0.0009761300341652437, acc: 0.8967078669154229, lr: 6.93237535238922e-05
[batch_idx--250] train_loss: 0.0009739967445709345, acc: 0.8970057270916335, lr: 6.507103215520893e-05
[batch_idx--300] train_loss: 0.0009694986859107533, acc: 0.8974122715946844, lr: 6.09527457063358e-05
[batch_idx--350] train_loss: 0.0009627971555069196, acc: 0.8983484686609686, lr: 5.6968916380720215e-05
[batch_idx--400] train_loss: 0.0009599042888858502, acc: 0.8986907730673317, lr: 5.311956565690057e-05
[batch_idx--450] train_loss: 0.0009642090682940857, acc: 0.8984101086541466, lr: 4.9404714288381335e-05
total time of one epoch: 245.55852580070496 s
train_loss:  0.0009642090682940857  acc:  0.8984101086541466
->>lr:0.000049
test_loss:  0.000979198481948134  test_acc:  0.8999875915125947
best acc:  90.09802705050254

------Epoch: 147------
[batch_idx--0] train_loss: 0.00098847271874547, acc: 0.91015625, lr: 4.933178929321103e-05
[batch_idx--50] train_loss: 0.000934228401485027, acc: 0.9002757352941176, lr: 4.57541478953355e-05
[batch_idx--100] train_loss: 0.000928285407215947, acc: 0.9006033415841584, lr: 4.231104556289278e-05
[batch_idx--150] train_loss: 0.0009402379240156059, acc: 0.8986961920529801, lr: 3.9002500859128264e-05
[batch_idx--200] train_loss: 0.0009489409290763795, acc: 0.8985735385572139, lr: 3.582853162182598e-05
[batch_idx--250] train_loss: 0.0009482070236407458, acc: 0.8991378237051793, lr: 3.2789154963222546e-05
[batch_idx--300] train_loss: 0.0009493443568042198, acc: 0.8990214908637874, lr: 2.9884387269901725e-05
[batch_idx--350] train_loss: 0.0009478974745454973, acc: 0.8994836182336182, lr: 2.7114244202716688e-05
[batch_idx--400] train_loss: 0.0009510560504664804, acc: 0.8990512001246883, lr: 2.4478740696695647e-05
[batch_idx--450] train_loss: 0.0009520113392906551, acc: 0.8995816988926303, lr: 2.1977890960975244e-05
total time of one epoch: 253.64062190055847 s
train_loss:  0.0009520113392906551  acc:  0.8995816988926303
->>lr:0.000022
test_loss:  0.0009749618371968707  test_acc:  0.9011043553790793
best acc:  90.09802705050254
Saving..

------Epoch: 148------
[batch_idx--0] train_loss: 0.0007245308952406049, acc: 0.8984375, lr: 2.192924752854042e-05
[batch_idx--50] train_loss: 0.0009504182460516983, acc: 0.8982843137254902, lr: 1.9565758523884538e-05
[batch_idx--100] train_loss: 0.0009509533024761863, acc: 0.8985148514851485, lr: 1.7336949777524425e-05
[batch_idx--150] train_loss: 0.0009488186017233903, acc: 0.8990842301324503, lr: 1.524283330592846e-05
[batch_idx--200] train_loss: 0.0009471641674484891, acc: 0.8995258084577115, lr: 1.3283420399376467e-05
[batch_idx--250] train_loss: 0.0009465805545683015, acc: 0.8997292081673307, lr: 1.14587216219042e-05
[batch_idx--300] train_loss: 0.0009513055950950869, acc: 0.8996833471760798, lr: 9.768746811253394e-06
[batch_idx--350] train_loss: 0.0009483859840809683, acc: 0.9000066773504274, lr: 8.213505078799587e-06
[batch_idx--400] train_loss: 0.0009492861768614009, acc: 0.8999961034912718, lr: 6.793004809518832e-06
[batch_idx--450] train_loss: 0.0009513702612772046, acc: 0.8999375151872808, lr: 5.507253661940492e-06
total time of one epoch: 231.4713454246521 s
train_loss:  0.0009513702612772046  acc:  0.8999375151872808
->>lr:0.000006
test_loss:  0.0009758356010548485  test_acc:  0.9007321007569178
best acc:  90.11043553790793

------Epoch: 149------
[batch_idx--0] train_loss: 0.0011684916680678725, acc: 0.890625, lr: 5.482913128862511e-06
[batch_idx--50] train_loss: 0.0009893669025497693, acc: 0.8959865196078431, lr: 4.334613221818051e-06
[batch_idx--100] train_loss: 0.000973623280533322, acc: 0.8973545792079208, lr: 3.321075690718156e-06
[batch_idx--150] train_loss: 0.000965985210862208, acc: 0.8990324917218543, lr: 2.4423059999861833e-06
[batch_idx--200] train_loss: 0.0009633046253445322, acc: 0.8990982587064676, lr: 1.6983088874406029e-06
[batch_idx--250] train_loss: 0.0009566050517257764, acc: 0.8995735806772909, lr: 1.089088364294999e-06
[batch_idx--300] train_loss: 0.0009558911203635714, acc: 0.8998001453488372, lr: 6.146477151164343e-07
[batch_idx--350] train_loss: 0.0009558132056616502, acc: 0.8995392628205128, lr: 2.749894978198997e-07
[batch_idx--400] train_loss: 0.0009507057702626355, acc: 0.9003175654613467, lr: 7.011554364610984e-08
[batch_idx--450] train_loss: 0.0009558533307381, acc: 0.8999982643107578, lr: 2.6957161503027296e-11
total time of one epoch: 228.14600586891174 s
train_loss:  0.0009558533307381  acc:  0.8999982643107578
->>lr:0.000000
test_loss:  0.0009764817556386432  test_acc:  0.9003598461347562
best acc:  90.11043553790793