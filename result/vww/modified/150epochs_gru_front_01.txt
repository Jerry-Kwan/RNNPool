Model: mobilenet_gru_front
Batch size: 256
Number of dataloader workers: 32

loading annotations into memory...
Done (t=2.09s)
creating index...
index created!
Len of trainloader: 451

loading annotations into memory...
Done (t=0.16s)
creating index...
index created!
Len of testloader: 32

use 4 GPUs!
DataParallel device_ids: [0, 1, 2, 3]

------Epoch: 0------
[batch_idx--0] train_loss: 0.0026956999208778143, acc: 0.52734375, lr: 0.05
[batch_idx--50] train_loss: 0.0027780169895028368, acc: 0.5452665441176471, lr: 0.04999993260712715
[batch_idx--100] train_loss: 0.0027075393798548985, acc: 0.5673344678217822, lr: 0.04999973042887193
[batch_idx--150] train_loss: 0.002690333395036838, acc: 0.5791597682119205, lr: 0.049999393466324364
[batch_idx--200] train_loss: 0.002654684662346297, acc: 0.5908737562189055, lr: 0.04999892172130118
[batch_idx--250] train_loss: 0.002618005680128101, acc: 0.602496264940239, lr: 0.04999831519634575
[batch_idx--300] train_loss: 0.0025946191238220844, acc: 0.6110361295681063, lr: 0.0499975738947281
[batch_idx--350] train_loss: 0.002568067410334605, acc: 0.6191907051282052, lr: 0.04999669782044491
[batch_idx--400] train_loss: 0.002550797452197928, acc: 0.6254480985037406, lr: 0.049995686978219496
[batch_idx--450] train_loss: 0.0025339139094640575, acc: 0.6315565661124032, lr: 0.04999454137350172
total time of one epoch: 322.25352931022644 s
train_loss:  0.0025339139094640575  acc:  0.6315565661124032
->>lr:0.049995
test_loss:  0.003045802421702361  test_acc:  0.5284774785953592
best acc:  0
Saving..
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(

------Epoch: 1------
[batch_idx--0] train_loss: 0.0024158654268831015, acc: 0.640625, lr: 0.04999451708687114
[batch_idx--50] train_loss: 0.002330365540532797, acc: 0.6907169117647058, lr: 0.04999323403077913
[batch_idx--100] train_loss: 0.0023274975713563732, acc: 0.6888149752475248, lr: 0.04999181622541965
[batch_idx--150] train_loss: 0.0023169916952707316, acc: 0.6906560430463576, lr: 0.0499902636784367
[batch_idx--200] train_loss: 0.0023004139775864374, acc: 0.6943019278606966, lr: 0.04998857639820074
[batch_idx--250] train_loss: 0.002287326329127993, acc: 0.6969621513944223, lr: 0.04998675439380862
[batch_idx--300] train_loss: 0.0022791414943205014, acc: 0.6997378529900332, lr: 0.04998479767508354
[batch_idx--350] train_loss: 0.0022601805218731576, acc: 0.7035033831908832, lr: 0.04998270625257502
[batch_idx--400] train_loss: 0.0022468345359947877, acc: 0.7060863466334164, lr: 0.04998048013755882
[batch_idx--450] train_loss: 0.0022424478068977277, acc: 0.7078140729683757, lr: 0.049978119342036866
total time of one epoch: 316.3151099681854 s
train_loss:  0.0022424478068977277  acc:  0.7078140729683757
->>lr:0.049978
test_loss:  0.004364590185394742  test_acc:  0.5701699962774538
best acc:  52.84774785953592
Saving..

------Epoch: 2------
[batch_idx--0] train_loss: 0.002002279506996274, acc: 0.7578125, lr: 0.04997807075247146
[batch_idx--50] train_loss: 0.00217738870403492, acc: 0.7138480392156863, lr: 0.04997557259595109
[batch_idx--100] train_loss: 0.002160758690650363, acc: 0.7166228341584159, lr: 0.04997293978538365
[batch_idx--150] train_loss: 0.0021452309890644043, acc: 0.7195260761589404, lr: 0.04997017233496374
[batch_idx--200] train_loss: 0.0021347829884390775, acc: 0.7230837997512438, lr: 0.04996727025961189
[batch_idx--250] train_loss: 0.002120032658396044, acc: 0.7264068725099602, lr: 0.04996423357497442
[batch_idx--300] train_loss: 0.0021111829518851055, acc: 0.7286778446843853, lr: 0.04996106229742341
[batch_idx--350] train_loss: 0.002104952431912733, acc: 0.7300792378917379, lr: 0.04995775644405658
[batch_idx--400] train_loss: 0.0020996567922669865, acc: 0.730770729426434, lr: 0.049954316032697205
[batch_idx--450] train_loss: 0.002095674507450022, acc: 0.7321050439129378, lr: 0.049950741081894026
total time of one epoch: 314.22435331344604 s
train_loss:  0.002095674507450022  acc:  0.7321050439129378
->>lr:0.049951
test_loss:  0.002223447847194745  test_acc:  0.7332175207842164
best acc:  57.01699962774538
Saving..

------Epoch: 3------
[batch_idx--0] train_loss: 0.001965122763067484, acc: 0.7421875, lr: 0.04995066821070679
[batch_idx--50] train_loss: 0.002011071235471058, acc: 0.7511488970588235, lr: 0.04994695604953209
[batch_idx--100] train_loss: 0.002017448073031731, acc: 0.7464805074257426, lr: 0.0499431093885944
[batch_idx--150] train_loss: 0.0020269406203871332, acc: 0.7436879139072847, lr: 0.04993912824863275
[batch_idx--200] train_loss: 0.002018275054458955, acc: 0.7451220460199005, lr: 0.049935012651111166
[batch_idx--250] train_loss: 0.0020207570428845, acc: 0.7451755478087649, lr: 0.0499307626182186
[batch_idx--300] train_loss: 0.0020206918745793623, acc: 0.7448479028239202, lr: 0.0499263781728688
[batch_idx--350] train_loss: 0.002011972212861491, acc: 0.7463719729344729, lr: 0.04992185933870021
[batch_idx--400] train_loss: 0.0020070927649587763, acc: 0.7473114089775561, lr: 0.049917206140075804
[batch_idx--450] train_loss: 0.0020066492142339462, acc: 0.7478390668934634, lr: 0.04991241860208297
total time of one epoch: 313.98707938194275 s
train_loss:  0.0020066492142339462  acc:  0.7478390668934634
->>lr:0.049912
test_loss:  0.002319597572232464  test_acc:  0.6932621913388758
best acc:  73.32175207842164

------Epoch: 4------
[batch_idx--0] train_loss: 0.001901976764202118, acc: 0.7578125, lr: 0.049912321481237615
[batch_idx--50] train_loss: 0.0019960352196814676, acc: 0.7458639705882353, lr: 0.04990739694368515
[batch_idx--100] train_loss: 0.001962000197537317, acc: 0.7508895420792079, lr: 0.04990233811964985
[batch_idx--150] train_loss: 0.0019537043828665225, acc: 0.7528456125827815, lr: 0.049897145036406014
[batch_idx--200] train_loss: 0.0019536184306854186, acc: 0.753925684079602, lr: 0.04989181772195179
[batch_idx--250] train_loss: 0.0019443347114156857, acc: 0.7554158366533864, lr: 0.04988635620500901
[batch_idx--300] train_loss: 0.0019473268459411803, acc: 0.7552818729235881, lr: 0.049880760515023076
[batch_idx--350] train_loss: 0.0019472555039806074, acc: 0.7556312321937322, lr: 0.04987503068216274
[batch_idx--400] train_loss: 0.0019424293025343347, acc: 0.7566338061097256, lr: 0.04986916673732
[batch_idx--450] train_loss: 0.0019462523568043602, acc: 0.7565175131044538, lr: 0.049863168712109905
total time of one epoch: 313.3785297870636 s
train_loss:  0.0019462523568043602  acc:  0.7565175131044538
->>lr:0.049863
test_loss:  0.0019199641307954354  test_acc:  0.7633701451793027
best acc:  73.32175207842164
Saving..

------Epoch: 5------
[batch_idx--0] train_loss: 0.0019513331353664398, acc: 0.74609375, lr: 0.049863047384206834
[batch_idx--50] train_loss: 0.0019742125375926786, acc: 0.7486979166666666, lr: 0.04985691263034154
[batch_idx--100] train_loss: 0.0019498395705872243, acc: 0.7540996287128713, lr: 0.049850643862176046
[batch_idx--150] train_loss: 0.001933585416019851, acc: 0.7588731374172185, lr: 0.04984424111350797
[batch_idx--200] train_loss: 0.0019235038198530674, acc: 0.7609608208955224, lr: 0.0498377044188573
[batch_idx--250] train_loss: 0.0019160276283491477, acc: 0.762668077689243, lr: 0.04983103381346615
[batch_idx--300] train_loss: 0.0019129379524809131, acc: 0.7635356104651163, lr: 0.049824229333298636
[batch_idx--350] train_loss: 0.001904423752245082, acc: 0.7649795227920227, lr: 0.049817291015040614
[batch_idx--400] train_loss: 0.0018984846041498339, acc: 0.7658685317955112, lr: 0.04981021889609956
[batch_idx--450] train_loss: 0.001902329963156196, acc: 0.7664282986774048, lr: 0.0498030130146043
total time of one epoch: 310.39633440971375 s
train_loss:  0.001902329963156196  acc:  0.7664282986774048
->>lr:0.049803
test_loss:  0.001860611786956541  test_acc:  0.7755304628365802
best acc:  76.33701451793027
Saving..

------Epoch: 6------
[batch_idx--0] train_loss: 0.0015904322499409318, acc: 0.8203125, lr: 0.04980286753286195
[batch_idx--50] train_loss: 0.0018861528540797094, acc: 0.7679993872549019, lr: 0.04979552525358963
[batch_idx--100] train_loss: 0.0018714372746388216, acc: 0.7682549504950495, lr: 0.04978804929098283
[batch_idx--150] train_loss: 0.001861194673685098, acc: 0.7704366721854304, lr: 0.049780439685347705
[batch_idx--200] train_loss: 0.0018634810384631675, acc: 0.7708333333333334, lr: 0.0497726964777109
[batch_idx--250] train_loss: 0.001858593832026143, acc: 0.7723325448207171, lr: 0.049764819709819365
[batch_idx--300] train_loss: 0.0018541770964006945, acc: 0.7729703073089701, lr: 0.04975680942414015
[batch_idx--350] train_loss: 0.0018536444916588883, acc: 0.7727363782051282, lr: 0.04974866566386016
[batch_idx--400] train_loss: 0.0018499802491462737, acc: 0.7733400872817955, lr: 0.049740388472885894
[batch_idx--450] train_loss: 0.0018479505538129342, acc: 0.7742302218210851, lr: 0.04973197789584324
total time of one epoch: 309.85475158691406 s
train_loss:  0.0018479505538129342  acc:  0.7742302218210851
->>lr:0.049732
test_loss:  0.0021021345780288954  test_acc:  0.7566695619803946
best acc:  77.55304628365802

------Epoch: 7------
[batch_idx--0] train_loss: 0.0019113834714516997, acc: 0.77734375, lr: 0.049731808324074714
[batch_idx--50] train_loss: 0.0018170164651511347, acc: 0.7797947303921569, lr: 0.04972326173996171
[batch_idx--100] train_loss: 0.0018119698339649061, acc: 0.7803604579207921, lr: 0.049714581862117906
[batch_idx--150] train_loss: 0.0018132183483388546, acc: 0.7806291390728477, lr: 0.049705768737340256
[batch_idx--200] train_loss: 0.001811693724828647, acc: 0.779170553482587, lr: 0.04969682241314409
[batch_idx--250] train_loss: 0.0018192028164848745, acc: 0.7775771912350598, lr: 0.0496877429377629
[batch_idx--300] train_loss: 0.0018143754052555195, acc: 0.7782002699335548, lr: 0.04967853036014805
[batch_idx--350] train_loss: 0.0018121016525565262, acc: 0.7790576032763533, lr: 0.04966918472996849
[batch_idx--400] train_loss: 0.00181171852756208, acc: 0.778970542394015, lr: 0.04965970609761053
[batch_idx--450] train_loss: 0.0018135660022810646, acc: 0.7796282153643211, lr: 0.04965009451417756
total time of one epoch: 315.39790749549866 s
train_loss:  0.0018135660022810646  acc:  0.7796282153643211
->>lr:0.049650
test_loss:  0.0018602013033249048  test_acc:  0.7730487653555032
best acc:  77.55304628365802

------Epoch: 8------
[batch_idx--0] train_loss: 0.0017835951875895262, acc: 0.78515625, lr: 0.04964990092676263
[batch_idx--50] train_loss: 0.0018112757425828307, acc: 0.7787990196078431, lr: 0.0496401537866232
[batch_idx--100] train_loss: 0.0018168791522281153, acc: 0.7771116955445545, lr: 0.04963027380082368
[batch_idx--150] train_loss: 0.0018049304069803153, acc: 0.7790252483443708, lr: 0.04962026102263131
[batch_idx--200] train_loss: 0.001788671597009015, acc: 0.7821828358208955, lr: 0.04961011550602926
[batch_idx--250] train_loss: 0.0017826065937784385, acc: 0.7837244770916335, lr: 0.04959983730571641
[batch_idx--300] train_loss: 0.0017821827703820808, acc: 0.7835600083056479, lr: 0.04958942647710693
[batch_idx--350] train_loss: 0.0017788914825629305, acc: 0.7840433582621082, lr: 0.04957888307633007
[batch_idx--400] train_loss: 0.0017748690222475928, acc: 0.784786081670823, lr: 0.04956820716022985
[batch_idx--450] train_loss: 0.0017764475881343674, acc: 0.7847658555212275, lr: 0.049557398786364705
total time of one epoch: 311.95117378234863 s
train_loss:  0.0017764475881343674  acc:  0.7847658555212275
->>lr:0.049557
test_loss:  0.0021456996861159735  test_acc:  0.7661000124084874
best acc:  77.55304628365802

------Epoch: 9------
[batch_idx--0] train_loss: 0.0019101587822660804, acc: 0.76953125, lr: 0.049557181268217225
[batch_idx--50] train_loss: 0.0017623935218936966, acc: 0.7897518382352942, lr: 0.04954623784746919
[batch_idx--100] train_loss: 0.0017474678674675892, acc: 0.790416150990099, lr: 0.04953516208740226
[batch_idx--150] train_loss: 0.0017519766697660089, acc: 0.7903818294701986, lr: 0.049523954047730606
[batch_idx--200] train_loss: 0.001748908290278111, acc: 0.7913362873134329, lr: 0.04951261378888158
[batch_idx--250] train_loss: 0.001746554410018294, acc: 0.791007843625498, lr: 0.049501141371995405
[batch_idx--300] train_loss: 0.0017408366969467893, acc: 0.791359530730897, lr: 0.0494895368589248
[batch_idx--350] train_loss: 0.0017422733240047114, acc: 0.7913884437321937, lr: 0.0494778003122347
[batch_idx--400] train_loss: 0.0017384904514570858, acc: 0.7915270417705735, lr: 0.049465931795201847
[batch_idx--450] train_loss: 0.0017405316382610352, acc: 0.7917780400597078, lr: 0.049453931371814544
total time of one epoch: 316.52325797080994 s
train_loss:  0.0017405316382610352  acc:  0.7917780400597078
->>lr:0.049454
test_loss:  0.0017067572255187243  test_acc:  0.7958803821814121
best acc:  77.55304628365802
Saving..

------Epoch: 10------
[batch_idx--0] train_loss: 0.0015663579106330872, acc: 0.80859375, lr: 0.049453690018345146
[batch_idx--50] train_loss: 0.0016987795106080525, acc: 0.7963388480392157, lr: 0.04944155511713453
[batch_idx--100] train_loss: 0.001718772612143271, acc: 0.79296875, lr: 0.04942928844099462
[batch_idx--150] train_loss: 0.001725219954915394, acc: 0.7926583195364238, lr: 0.0494168900560603
[batch_idx--200] train_loss: 0.0017129265221382552, acc: 0.794795553482587, lr: 0.04940436002917662
[batch_idx--250] train_loss: 0.0017159273328474793, acc: 0.7940737051792829, lr: 0.04939169842789834
[batch_idx--300] train_loss: 0.0017128843826510977, acc: 0.7942145971760798, lr: 0.04937890532048959
[batch_idx--350] train_loss: 0.0017113320601101106, acc: 0.7944934116809117, lr: 0.04936598077592351
[batch_idx--400] train_loss: 0.0017067997122968447, acc: 0.7957547537406484, lr: 0.049352924863881875
[batch_idx--450] train_loss: 0.0017103970709821015, acc: 0.7962300829659458, lr: 0.04933973765475472
total time of one epoch: 309.5332570075989 s
train_loss:  0.0017103970709821015  acc:  0.7962300829659458
->>lr:0.049340
test_loss:  0.0018566078103672912  test_acc:  0.7775158208214419
best acc:  79.58803821814121

------Epoch: 11------
[batch_idx--0] train_loss: 0.0017567540053278208, acc: 0.80078125, lr: 0.04933947257182901
[batch_idx--50] train_loss: 0.001711083338687233, acc: 0.7947303921568627, lr: 0.04932615151292455
[batch_idx--100] train_loss: 0.001697635093685424, acc: 0.7967976485148515, lr: 0.04931269930128121
[batch_idx--150] train_loss: 0.0016992763216786136, acc: 0.796771523178808, lr: 0.04929911600942565
[batch_idx--200] train_loss: 0.0016936337684202401, acc: 0.7977884017412935, lr: 0.04928540171059123
[batch_idx--250] train_loss: 0.0016862484478054056, acc: 0.7990537848605578, lr: 0.04927155647871764
[batch_idx--300] train_loss: 0.0016860897266816508, acc: 0.7991071428571429, lr: 0.04925758038845046
[batch_idx--350] train_loss: 0.001683357991264905, acc: 0.7996015847578347, lr: 0.04924347351514081
[batch_idx--400] train_loss: 0.0016833675283232606, acc: 0.7995635910224439, lr: 0.049229235934844906
[batch_idx--450] train_loss: 0.0016918007363158074, acc: 0.7989898288610408, lr: 0.04921486772432365
total time of one epoch: 312.5505690574646 s
train_loss:  0.0016918007363158074  acc:  0.7989898288610408
->>lr:0.049215
test_loss:  0.0019725132615709146  test_acc:  0.766472267030649
best acc:  79.58803821814121

------Epoch: 12------
[batch_idx--0] train_loss: 0.0018764379201456904, acc: 0.78515625, lr: 0.04921457902821578
[batch_idx--50] train_loss: 0.001700339220263356, acc: 0.7961856617647058, lr: 0.04920007765467417
[batch_idx--100] train_loss: 0.0016818262088011103, acc: 0.7988474628712872, lr: 0.049185445808112044
[batch_idx--150] train_loss: 0.0016629636636164213, acc: 0.8018160182119205, lr: 0.049170683567415975
[batch_idx--200] train_loss: 0.0016676078409197466, acc: 0.8012476679104478, lr: 0.04915579101217554
[batch_idx--250] train_loss: 0.001669690793981234, acc: 0.8009524402390438, lr: 0.04914076822268292
[batch_idx--300] train_loss: 0.0016761212516885461, acc: 0.8003010797342193, lr: 0.04912561527993242
[batch_idx--350] train_loss: 0.0016746345842442876, acc: 0.8008368945868946, lr: 0.049110332265620074
[batch_idx--400] train_loss: 0.0016730251339405887, acc: 0.8011903834164589, lr: 0.049094919262143176
[batch_idx--450] train_loss: 0.0016763438076400565, acc: 0.8010986912903114, lr: 0.049079376352599846
total time of one epoch: 309.55422830581665 s
train_loss:  0.0016763438076400565  acc:  0.8010986912903114
->>lr:0.049079
test_loss:  0.0016701579840932624  test_acc:  0.8067998510981511
best acc:  79.58803821814121
Saving..

------Epoch: 13------
[batch_idx--0] train_loss: 0.0019179914379492402, acc: 0.76953125, lr: 0.049079064169941455
[batch_idx--50] train_loss: 0.0016703305848161964, acc: 0.7999387254901961, lr: 0.04906338884254441
[batch_idx--100] train_loss: 0.0016681225809019686, acc: 0.8014000618811881, lr: 0.04904758377907498
[batch_idx--150] train_loss: 0.001653907358004952, acc: 0.8039372930463576, lr: 0.04903164906474507
[batch_idx--200] train_loss: 0.0016570828973190553, acc: 0.8032882462686567, lr: 0.04901558478546556
[batch_idx--250] train_loss: 0.001652559018285715, acc: 0.8044540587649402, lr: 0.04899939102784589
[batch_idx--300] train_loss: 0.0016467409719716126, acc: 0.8053363787375415, lr: 0.04898306787919357
[batch_idx--350] train_loss: 0.0016428263688146897, acc: 0.8054331374643875, lr: 0.04896661542751371
[batch_idx--400] train_loss: 0.0016424993588414945, acc: 0.8058077462593516, lr: 0.04895003376150854
[batch_idx--450] train_loss: 0.0016492120969459787, acc: 0.8051775610094769, lr: 0.04893332297057697
total time of one epoch: 311.16753363609314 s
train_loss:  0.0016492120969459787  acc:  0.8051775610094769
->>lr:0.048933
test_loss:  0.0016268467042238751  test_acc:  0.8123836704305745
best acc:  80.6799851098151
Saving..

------Epoch: 14------
[batch_idx--0] train_loss: 0.0017059135716408491, acc: 0.8203125, lr: 0.048932987438301684
[batch_idx--50] train_loss: 0.0016373248506045225, acc: 0.8075980392156863, lr: 0.04891614503276587
[batch_idx--100] train_loss: 0.0016254193857219992, acc: 0.8090191831683168, lr: 0.04889917368501234
[batch_idx--150] train_loss: 0.001632827062727205, acc: 0.8068087748344371, lr: 0.04888207348654094
[batch_idx--200] train_loss: 0.0016270140869385418, acc: 0.8088463930348259, lr: 0.048864844529546175
[batch_idx--250] train_loss: 0.0016273713918343424, acc: 0.8087493774900398, lr: 0.04884748690691675
[batch_idx--300] train_loss: 0.0016259761319102788, acc: 0.8088922342192691, lr: 0.048830000712235096
[batch_idx--350] train_loss: 0.0016312842317684382, acc: 0.8079037571225072, lr: 0.048812386039776785
[batch_idx--400] train_loss: 0.001631793985840054, acc: 0.8078534133416458, lr: 0.0487946429845101
[batch_idx--450] train_loss: 0.0016330052398011482, acc: 0.8083191585378554, lr: 0.048776771642095464
total time of one epoch: 312.9128701686859 s
train_loss:  0.0016330052398011482  acc:  0.8083191585378554
->>lr:0.048777
test_loss:  0.0015975364400340837  test_acc:  0.8183397443851594
best acc:  81.23836704305745
Saving..

------Epoch: 15------
[batch_idx--0] train_loss: 0.0014224053593352437, acc: 0.83203125, lr: 0.048776412907378844
[batch_idx--50] train_loss: 0.001621581116399052, acc: 0.80859375, lr: 0.04875841081133997
[batch_idx--100] train_loss: 0.0016282737799136356, acc: 0.8093285891089109, lr: 0.04874028062349638
[batch_idx--150] train_loss: 0.0016295550821275012, acc: 0.8091887417218543, lr: 0.0487220224415957
[batch_idx--200] train_loss: 0.0016274136451735575, acc: 0.8089629975124378, lr: 0.04870363636407563
[batch_idx--250] train_loss: 0.0016125880123349834, acc: 0.811535109561753, lr: 0.04868512249006343
[batch_idx--300] train_loss: 0.0016096423107796532, acc: 0.8112411752491694, lr: 0.048666480919375345
[batch_idx--350] train_loss: 0.001609564445079689, acc: 0.8110421118233618, lr: 0.0486477117525161
[batch_idx--400] train_loss: 0.0016098425676001054, acc: 0.8108245012468828, lr: 0.04862881509067834
[batch_idx--450] train_loss: 0.0016158096970511884, acc: 0.8107751588155656, lr: 0.04860979103574209
total time of one epoch: 310.5995833873749 s
train_loss:  0.0016158096970511884  acc:  0.8107751588155656
->>lr:0.048610
test_loss:  0.001690133065558468  test_acc:  0.802705050254374
best acc:  81.83397443851595

------Epoch: 16------
[batch_idx--0] train_loss: 0.0016737659461796284, acc: 0.80078125, lr: 0.04860940925593703
[batch_idx--50] train_loss: 0.0016136993037755875, acc: 0.8076746323529411, lr: 0.048590255365709406
[batch_idx--100] train_loss: 0.001608618077508515, acc: 0.8099860767326733, lr: 0.04857097429027534
[batch_idx--150] train_loss: 0.0016092571533217236, acc: 0.8108443708609272, lr: 0.0485515661335874
[batch_idx--200] train_loss: 0.0016099583005430686, acc: 0.8103816853233831, lr: 0.048532031000283304
[batch_idx--250] train_loss: 0.0016040195594077922, acc: 0.8115973605577689, lr: 0.048512368995685354
[batch_idx--300] train_loss: 0.0016064823746675025, acc: 0.8113320182724253, lr: 0.04849258022579986
[batch_idx--350] train_loss: 0.0016059514779884082, acc: 0.8116764601139601, lr: 0.04847266479731658
[batch_idx--400] train_loss: 0.0016005001715419262, acc: 0.8127045667082294, lr: 0.048452622817608176
[batch_idx--450] train_loss: 0.0016029362444595068, acc: 0.8130141979380012, lr: 0.04843245439472954
total time of one epoch: 310.1248347759247 s
train_loss:  0.0016029362444595068  acc:  0.8130141979380012
->>lr:0.048432
test_loss:  0.0015614908324945859  test_acc:  0.8228067998510982
best acc:  81.83397443851595
Saving..

------Epoch: 17------
[batch_idx--0] train_loss: 0.0013986813137307763, acc: 0.8203125, lr: 0.04843204973729729
[batch_idx--50] train_loss: 0.0016558162831500464, acc: 0.8032322303921569, lr: 0.048411752454410206
[batch_idx--100] train_loss: 0.0016202557599171996, acc: 0.8077042079207921, lr: 0.0483913289487026
[batch_idx--150] train_loss: 0.0015974672594483918, acc: 0.8106632864238411, lr: 0.04837077933028638
[batch_idx--200] train_loss: 0.0015857017365057224, acc: 0.8121501865671642, lr: 0.04835010370995336
[batch_idx--250] train_loss: 0.0015852393144630342, acc: 0.8120953685258964, lr: 0.0483293021991747
[batch_idx--300] train_loss: 0.001587362449068539, acc: 0.8119160091362126, lr: 0.04830837491010029
[batch_idx--350] train_loss: 0.0015853609580631525, acc: 0.8119546830484331, lr: 0.04828732195555814
[batch_idx--400] train_loss: 0.0015886790502904694, acc: 0.8121200903990025, lr: 0.04826614344905377
[batch_idx--450] train_loss: 0.0015913314126000276, acc: 0.8124934911653418, lr: 0.04824483950476961
total time of one epoch: 307.04280376434326 s
train_loss:  0.0015913314126000276  acc:  0.8124934911653418
->>lr:0.048245
test_loss:  0.0015544925638043359  test_acc:  0.8214418662365057
best acc:  82.28067998510981

------Epoch: 18------
[batch_idx--0] train_loss: 0.0015674307942390442, acc: 0.828125, lr: 0.04824441214720629
[batch_idx--50] train_loss: 0.0015628708631494174, acc: 0.8174019607843137, lr: 0.04822298037471885
[batch_idx--100] train_loss: 0.0015835318193392883, acc: 0.8132735148514851, lr: 0.04820142339716232
[batch_idx--150] train_loss: 0.0015937322234142793, acc: 0.812525869205298, lr: 0.04817974133075961
[batch_idx--200] train_loss: 0.0015905599036851704, acc: 0.812558302238806, lr: 0.04815793429240808
[batch_idx--250] train_loss: 0.0015924290463558408, acc: 0.8117685507968128, lr: 0.04813600239967885
[batch_idx--300] train_loss: 0.0015891478930683527, acc: 0.8125, lr: 0.04811394577081616
[batch_idx--350] train_loss: 0.0015829874685517064, acc: 0.8135349893162394, lr: 0.04809176452473679
[batch_idx--400] train_loss: 0.0015770355320798043, acc: 0.814691786159601, lr: 0.048069458781029376
[batch_idx--450] train_loss: 0.0015787014548725648, acc: 0.8153053077377026, lr: 0.048047028659953764
total time of one epoch: 308.7516906261444 s
train_loss:  0.0015787014548725648  acc:  0.8153053077377026
->>lr:0.048047
test_loss:  0.0015258559933340658  test_acc:  0.8285147040575754
best acc:  82.28067998510981
Saving..

------Epoch: 19------
[batch_idx--0] train_loss: 0.0015599170001223683, acc: 0.81640625, lr: 0.04804657878971252
[batch_idx--50] train_loss: 0.0015897505286642734, acc: 0.8173253676470589, lr: 0.04802402192830846
[batch_idx--100] train_loss: 0.0015831710079150035, acc: 0.8161355198019802, lr: 0.04800134093450581
[batch_idx--150] train_loss: 0.0015708284016192847, acc: 0.8162769039735099, lr: 0.04797853593058756
[batch_idx--200] train_loss: 0.0015694191337641866, acc: 0.8159203980099502, lr: 0.04795560703950527
[batch_idx--250] train_loss: 0.0015705713317673876, acc: 0.8158771165338645, lr: 0.047932554384878465
[batch_idx--300] train_loss: 0.0015721104913808876, acc: 0.8154718646179402, lr: 0.0479093780909939
[batch_idx--350] train_loss: 0.0015708442304437275, acc: 0.8161280270655271, lr: 0.047886078282804945
[batch_idx--400] train_loss: 0.00156383959174695, acc: 0.8170686564837906, lr: 0.047862655085930884
[batch_idx--450] train_loss: 0.0015629231575445197, acc: 0.8177005588919359, lr: 0.04783910862665624
total time of one epoch: 306.73818349838257 s
train_loss:  0.0015629231575445197  acc:  0.8177005588919359
->>lr:0.047839
test_loss:  0.0015577809407406609  test_acc:  0.8224345452289366
best acc:  82.85147040575754

------Epoch: 20------
[batch_idx--0] train_loss: 0.0015651581343263388, acc: 0.83203125, lr: 0.04783863644106502
[batch_idx--50] train_loss: 0.0015825709994590166, acc: 0.8164828431372549, lr: 0.047814964384929284
[batch_idx--100] train_loss: 0.0015601247242458239, acc: 0.8173731435643564, lr: 0.047791169323514016
[batch_idx--150] train_loss: 0.001568822445354073, acc: 0.8177255794701986, lr: 0.047767251385108636
[batch_idx--200] train_loss: 0.0015621967017140925, acc: 0.8182719216417911, lr: 0.04774321069866503
[batch_idx--250] train_loss: 0.001554605392442341, acc: 0.8194254233067729, lr: 0.04771904739379687
[batch_idx--300] train_loss: 0.0015523434609663596, acc: 0.818859011627907, lr: 0.0476947616007789
[batch_idx--350] train_loss: 0.0015569264387600443, acc: 0.81815349002849, lr: 0.0476703534505463
[batch_idx--400] train_loss: 0.0015555690376533944, acc: 0.8186759663341646, lr: 0.047645823074693894
[batch_idx--450] train_loss: 0.0015577786592801234, acc: 0.8185684035130351, lr: 0.047621170605475466
total time of one epoch: 306.8134114742279 s
train_loss:  0.0015577786592801234  acc:  0.8185684035130351
->>lr:0.047621
test_loss:  0.001619366868611142  test_acc:  0.8152376225338132
best acc:  82.85147040575754

------Epoch: 21------
[batch_idx--0] train_loss: 0.0016202570404857397, acc: 0.8125, lr: 0.04762067631165049
[batch_idx--50] train_loss: 0.0015584768992209551, acc: 0.8200827205882353, lr: 0.047595899444129244
[batch_idx--100] train_loss: 0.0015600181903948288, acc: 0.8198483910891089, lr: 0.04757100075240174
[batch_idx--150] train_loss: 0.0015524032707665337, acc: 0.820209023178808, lr: 0.04754598037070751
[batch_idx--200] train_loss: 0.0015445926773422097, acc: 0.8207011815920398, lr: 0.047520838433942204
[batch_idx--250] train_loss: 0.001541901485107661, acc: 0.8209972609561753, lr: 0.04749557507765681
[batch_idx--300] train_loss: 0.0015417239883995036, acc: 0.8202735672757475, lr: 0.047470190438056926
[batch_idx--350] train_loss: 0.0015441280188691667, acc: 0.8199786324786325, lr: 0.047444684652002064
[batch_idx--400] train_loss: 0.0015417404198192265, acc: 0.8203612063591023, lr: 0.04741905785700488
[batch_idx--450] train_loss: 0.0015416729259144185, acc: 0.8210417606831673, lr: 0.04739331019123044
total time of one epoch: 306.54872965812683 s
train_loss:  0.0015416729259144185  acc:  0.8210417606831673
->>lr:0.047393
test_loss:  0.001560318753269355  test_acc:  0.8203251023700211
best acc:  82.85147040575754

------Epoch: 22------
[batch_idx--0] train_loss: 0.0013959561474621296, acc: 0.84375, lr: 0.047392794005985325
[batch_idx--50] train_loss: 0.001570003310346282, acc: 0.8154105392156863, lr: 0.04736692319503155
[batch_idx--100] train_loss: 0.001551486439956813, acc: 0.8203511757425742, lr: 0.047340931794380904
[batch_idx--150] train_loss: 0.0015432875386026028, acc: 0.8225631208609272, lr: 0.04731481994416418
[batch_idx--200] train_loss: 0.0015379515990837297, acc: 0.8225279850746269, lr: 0.04728858778516159
[batch_idx--250] train_loss: 0.0015366865271902773, acc: 0.8220555278884463, lr: 0.04726223545880198
[batch_idx--300] train_loss: 0.0015367293464285986, acc: 0.8219476744186046, lr: 0.04723576310716207
[batch_idx--350] train_loss: 0.0015361995908545804, acc: 0.8215366809116809, lr: 0.047209170872965694
[batch_idx--400] train_loss: 0.0015373450960555204, acc: 0.8212379208229427, lr: 0.047182458899583
[batch_idx--450] train_loss: 0.0015415615699046, acc: 0.8212153296073871, lr: 0.04715562733102973
total time of one epoch: 305.76783204078674 s
train_loss:  0.0015415615699046  acc:  0.8212153296073871
->>lr:0.047156
test_loss:  0.0014484819976578489  test_acc:  0.8394341729743144
best acc:  82.85147040575754
Saving..

------Epoch: 23------
[batch_idx--0] train_loss: 0.0016374413389712572, acc: 0.8046875, lr: 0.04715508948078037
[batch_idx--50] train_loss: 0.0015493586737041671, acc: 0.8200061274509803, lr: 0.047128136074186804
[batch_idx--100] train_loss: 0.001531377586877287, acc: 0.8224783415841584, lr: 0.04710106336530035
[batch_idx--150] train_loss: 0.0015346240660866464, acc: 0.8218129139072847, lr: 0.04707387150008163
[batch_idx--200] train_loss: 0.0015297135551325717, acc: 0.8230527052238806, lr: 0.04704656062513368
[batch_idx--250] train_loss: 0.0015205167089236448, acc: 0.8237207420318725, lr: 0.04701913088770116
[batch_idx--300] train_loss: 0.0015193915522140622, acc: 0.8235828488372093, lr: 0.04699158243566958
[batch_idx--350] train_loss: 0.0015216847951988295, acc: 0.8232060185185185, lr: 0.04696391541756448
[batch_idx--400] train_loss: 0.0015193533594778127, acc: 0.8237901340399002, lr: 0.046936129982550645
[batch_idx--450] train_loss: 0.001523325819596242, acc: 0.8238622557017392, lr: 0.0469082262804313
total time of one epoch: 303.8092095851898 s
train_loss:  0.001523325819596242  acc:  0.8238622557017392
->>lr:0.046908
test_loss:  0.0016025229983419116  test_acc:  0.8177193200148902
best acc:  83.94341729743144

------Epoch: 24------
[batch_idx--0] train_loss: 0.001620484865270555, acc: 0.796875, lr: 0.04690766700109659
[batch_idx--50] train_loss: 0.0015651515237621817, acc: 0.8190104166666666, lr: 0.04687964282151817
[batch_idx--100] train_loss: 0.0015436071340031554, acc: 0.8210860148514851, lr: 0.046851500679380806
[batch_idx--150] train_loss: 0.0015405555963454557, acc: 0.8221233443708609, lr: 0.046823240726410885
[batch_idx--200] train_loss: 0.0015302684687457941, acc: 0.8235968594527363, lr: 0.046794863114969956
[batch_idx--250] train_loss: 0.0015233308763291495, acc: 0.8247478834661355, lr: 0.04676636799805392
[batch_idx--300] train_loss: 0.001524007831625888, acc: 0.8242836378737541, lr: 0.046737755529292206
[batch_idx--350] train_loss: 0.0015216181512412608, acc: 0.8242410078347578, lr: 0.046709025862946923
[batch_idx--400] train_loss: 0.0015211244836040862, acc: 0.8240336658354115, lr: 0.046680179153912066
[batch_idx--450] train_loss: 0.0015224114520260017, acc: 0.8242788211198667, lr: 0.04665121555771262
total time of one epoch: 305.1037926673889 s
train_loss:  0.0015224114520260017  acc:  0.8242788211198667
->>lr:0.046651
test_loss:  0.0016214554718697776  test_acc:  0.8126318401786822
best acc:  83.94341729743144

------Epoch: 25------
[batch_idx--0] train_loss: 0.0012257718481123447, acc: 0.8671875, lr: 0.046650635094610975
[batch_idx--50] train_loss: 0.0014942054403945804, acc: 0.8275122549019608, lr: 0.04662155243437907
[batch_idx--100] train_loss: 0.0014862583300080336, acc: 0.8290145420792079, lr: 0.04659235320306443
[batch_idx--150] train_loss: 0.0014817957305318572, acc: 0.8289786837748344, lr: 0.046563037558092685
[batch_idx--200] train_loss: 0.001489600730800436, acc: 0.8286302860696517, lr: 0.04653360565751704
[batch_idx--250] train_loss: 0.001495719564971013, acc: 0.8279382470119522, lr: 0.04650405766001754
[batch_idx--300] train_loss: 0.0014968478063622681, acc: 0.827437188538206, lr: 0.04647439372490014
[batch_idx--350] train_loss: 0.0014987516444457689, acc: 0.8271456552706553, lr: 0.046444614012095875
[batch_idx--400] train_loss: 0.0015015311053189963, acc: 0.8266345854114713, lr: 0.046414718682159954
[batch_idx--450] train_loss: 0.0015056994143767023, acc: 0.8266480369354671, lr: 0.04638470789627097
total time of one epoch: 307.1465892791748 s
train_loss:  0.0015056994143767023  acc:  0.8266480369354671
->>lr:0.046385
test_loss:  0.0015034419547418371  test_acc:  0.8285147040575754
best acc:  83.94341729743144

------Epoch: 26------
[batch_idx--0] train_loss: 0.0014705555513501167, acc: 0.8515625, lr: 0.04638410650401267
[batch_idx--50] train_loss: 0.0014749550164731987, acc: 0.8310355392156863, lr: 0.04635397811974326
[batch_idx--100] train_loss: 0.0014841234343735002, acc: 0.8301361386138614, lr: 0.04632373460699926
[batch_idx--150] train_loss: 0.0014790223212912679, acc: 0.8307636589403974, lr: 0.04629337612883644
[batch_idx--200] train_loss: 0.001479549666482084, acc: 0.830146144278607, lr: 0.046262902848930414
[batch_idx--250] train_loss: 0.0014879653426035646, acc: 0.8291988296812749, lr: 0.04623231493157573
[batch_idx--300] train_loss: 0.0014887896514933965, acc: 0.8291112956810631, lr: 0.046201612541685
[batch_idx--350] train_loss: 0.0014893674690334758, acc: 0.8288261217948718, lr: 0.046170795844788
[batch_idx--400] train_loss: 0.001485569348867676, acc: 0.8294108478802993, lr: 0.04613986500703078
[batch_idx--450] train_loss: 0.001495735239574164, acc: 0.829416461276773, lr: 0.0461088201951748
total time of one epoch: 304.84551453590393 s
train_loss:  0.001495735239574164  acc:  0.829416461276773
->>lr:0.046109
test_loss:  0.0015639034782276658  test_acc:  0.8245439880878521
best acc:  83.94341729743144

------Epoch: 27------
[batch_idx--0] train_loss: 0.001435623737052083, acc: 0.82421875, lr: 0.04610819813755038
[batch_idx--50] train_loss: 0.0015317622056303948, acc: 0.8209252450980392, lr: 0.04607703724454855
[batch_idx--100] train_loss: 0.0015099821324082146, acc: 0.8247988861386139, lr: 0.046045762716179425
[batch_idx--150] train_loss: 0.001505522573187898, acc: 0.8265211092715232, lr: 0.04601437472105743
[batch_idx--200] train_loss: 0.0015051982230020325, acc: 0.8269200870646766, lr: 0.04598287342840873
[batch_idx--250] train_loss: 0.0015067563010045732, acc: 0.8263197211155379, lr: 0.04595125900807036
[batch_idx--300] train_loss: 0.0015031589574932408, acc: 0.8269310631229236, lr: 0.045919531630489216
[batch_idx--350] train_loss: 0.0014996615353244705, acc: 0.8272124287749287, lr: 0.045887691466721246
[batch_idx--400] train_loss: 0.0014956141772686953, acc: 0.8277645729426434, lr: 0.04585573868843045
[batch_idx--450] train_loss: 0.001498036576419387, acc: 0.8278977331898497, lr: 0.04582367346788801
total time of one epoch: 305.32887172698975 s
train_loss:  0.001498036576419387  acc:  0.8278977331898497
->>lr:0.045824
test_loss:  0.0014977132043378172  test_acc:  0.8291351284278446
best acc:  83.94341729743144

------Epoch: 28------
[batch_idx--0] train_loss: 0.0017557727405801415, acc: 0.7890625, lr: 0.04582303101775249
[batch_idx--50] train_loss: 0.0015460139587886777, acc: 0.8203125, lr: 0.04579085128421578
[batch_idx--100] train_loss: 0.001497150879436274, acc: 0.8268873762376238, lr: 0.04575855945826332
[batch_idx--150] train_loss: 0.00148021722434471, acc: 0.8293149834437086, lr: 0.04572615571399419
[batch_idx--200] train_loss: 0.001475553709981194, acc: 0.8293687810945274, lr: 0.045693640226110915
[batch_idx--250] train_loss: 0.0014701780099681471, acc: 0.8303349103585658, lr: 0.045661013169918455
[batch_idx--300] train_loss: 0.001476704401344655, acc: 0.8296693313953488, lr: 0.04562827472132332
[batch_idx--350] train_loss: 0.0014777061004759451, acc: 0.8294938568376068, lr: 0.045595425056832534
[batch_idx--400] train_loss: 0.0014798110275485198, acc: 0.8295082605985037, lr: 0.04556246435355277
[batch_idx--450] train_loss: 0.0014826560431577508, acc: 0.8298330266949006, lr: 0.04552939278918935
total time of one epoch: 304.2185642719269 s
train_loss:  0.0014826560431577508  acc:  0.8298330266949006
->>lr:0.045529
test_loss:  0.0014543044669173436  test_acc:  0.8324854200272986
best acc:  83.94341729743144

------Epoch: 29------
[batch_idx--0] train_loss: 0.0013756213011220098, acc: 0.8515625, lr: 0.045528730228342605
[batch_idx--50] train_loss: 0.0014554437103809095, acc: 0.8339460784313726, lr: 0.04549554576936571
[batch_idx--100] train_loss: 0.0014621849877224995, acc: 0.8319925742574258, lr: 0.04546225081009201
[batch_idx--150] train_loss: 0.0014675354140977197, acc: 0.8313845198675497, lr: 0.04542884553002893
[batch_idx--200] train_loss: 0.0014590242303055318, acc: 0.832206156716418, lr: 0.04539533010927871
[batch_idx--250] train_loss: 0.0014634142737405234, acc: 0.8316266185258964, lr: 0.04536170472853737
[batch_idx--300] train_loss: 0.0014632213489458807, acc: 0.8318625415282392, lr: 0.045327969569093796
[batch_idx--350] train_loss: 0.0014658452945620756, acc: 0.8317752849002849, lr: 0.04529412481282874
[batch_idx--400] train_loss: 0.0014673529124291534, acc: 0.8318656483790524, lr: 0.04526017064221382
[batch_idx--450] train_loss: 0.0014735422279712504, acc: 0.8316555003992085, lr: 0.04522610724031057
total time of one epoch: 305.4169411659241 s
train_loss:  0.0014735422279712504  acc:  0.8316555003992085
->>lr:0.045226
test_loss:  0.0014791421528444766  test_acc:  0.832981759523514
best acc:  83.94341729743144

------Epoch: 30------
[batch_idx--0] train_loss: 0.001444977824576199, acc: 0.80859375, lr: 0.04522542485937369
[batch_idx--50] train_loss: 0.0014639622120953659, acc: 0.8284313725490197, lr: 0.04519125023075707
[batch_idx--100] train_loss: 0.0014513203088138806, acc: 0.8326887376237624, lr: 0.045156966742431685
[batch_idx--150] train_loss: 0.001438211362087322, acc: 0.8352390314569537, lr: 0.04512257457923455
[batch_idx--200] train_loss: 0.0014516879376997032, acc: 0.8329057835820896, lr: 0.04508807392658861
[batch_idx--250] train_loss: 0.0014582127629523258, acc: 0.8326070717131474, lr: 0.0450534649705017
[batch_idx--300] train_loss: 0.0014614535343254673, acc: 0.8318755191029901, lr: 0.04501874789756559
[batch_idx--350] train_loss: 0.0014574986526296816, acc: 0.83244301994302, lr: 0.04498392289495493
[batch_idx--400] train_loss: 0.00145821276229999, acc: 0.8322455579800498, lr: 0.04494899015042629
[batch_idx--450] train_loss: 0.0014643601135113109, acc: 0.8321848856180789, lr: 0.04491394985231711
total time of one epoch: 304.94845628738403 s
train_loss:  0.0014643601135113109  acc:  0.8321848856180789
->>lr:0.044914
test_loss:  0.0014291973582330599  test_acc:  0.8395582578483682
best acc:  83.94341729743144
Saving..

------Epoch: 31------
[batch_idx--0] train_loss: 0.0013846628135070205, acc: 0.86328125, lr: 0.04491324795060491
[batch_idx--50] train_loss: 0.0014869404007114616, acc: 0.8262101715686274, lr: 0.04487809814247016
[batch_idx--100] train_loss: 0.0014661057001569926, acc: 0.8292079207920792, lr: 0.044842841162964144
[batch_idx--150] train_loss: 0.0014622759487208546, acc: 0.8305825745033113, lr: 0.04480747720217241
[batch_idx--200] train_loss: 0.0014625814134041912, acc: 0.8308457711442786, lr: 0.04477200645075726
[batch_idx--250] train_loss: 0.0014601875355363307, acc: 0.8313620517928287, lr: 0.04473642909995676
[batch_idx--300] train_loss: 0.0014600724216234991, acc: 0.8313564161129569, lr: 0.044700745341583706
[batch_idx--350] train_loss: 0.0014566696123578227, acc: 0.8320980235042735, lr: 0.044664955368024575
[batch_idx--400] train_loss: 0.001453451213352568, acc: 0.8324501246882793, lr: 0.044629059372238496
[batch_idx--450] train_loss: 0.0014576851849869314, acc: 0.8327923768528482, lr: 0.044593057547756214
total time of one epoch: 305.2921597957611 s
train_loss:  0.0014576851849869314  acc:  0.8327923768528482
->>lr:0.044593
test_loss:  0.001399622940960941  test_acc:  0.8474996897878149
best acc:  83.95582578483683
Saving..

------Epoch: 32------
[batch_idx--0] train_loss: 0.0013462880160659552, acc: 0.85546875, lr: 0.044592336433146
[batch_idx--50] train_loss: 0.0014308956725632444, acc: 0.8338694852941176, lr: 0.04455622686336067
[batch_idx--100] train_loss: 0.0014326580913073504, acc: 0.8367496905940595, lr: 0.0445200118575505
[batch_idx--150] train_loss: 0.00144503614402666, acc: 0.8354459850993378, lr: 0.04448369161096615
[batch_idx--200] train_loss: 0.001440486330330483, acc: 0.835820895522388, lr: 0.044447266319425686
[batch_idx--250] train_loss: 0.001442073423237321, acc: 0.8354706175298805, lr: 0.044410736179313494
[batch_idx--300] train_loss: 0.0014443010338535687, acc: 0.8348733388704319, lr: 0.04437410138757928
[batch_idx--350] train_loss: 0.001445121225699294, acc: 0.8344684829059829, lr: 0.04433736214173695
[batch_idx--400] train_loss: 0.00144632192220576, acc: 0.8342912250623441, lr: 0.04430051863986356
[batch_idx--450] train_loss: 0.0014523697995210913, acc: 0.8337643628284792, lr: 0.04426357108059828
total time of one epoch: 305.8412809371948 s
train_loss:  0.0014523697995210913  acc:  0.8337643628284792
->>lr:0.044264
test_loss:  0.0014319969275287932  test_acc:  0.839806427596476
best acc:  84.74996897878148

------Epoch: 33------
[batch_idx--0] train_loss: 0.0014415305340662599, acc: 0.81640625, lr: 0.044262831069394735
[batch_idx--50] train_loss: 0.001456935604687269, acc: 0.8313419117647058, lr: 0.04422577757680957
[batch_idx--100] train_loss: 0.0014498919815673392, acc: 0.8331528465346535, lr: 0.04418862042979371
[batch_idx--150] train_loss: 0.0014477184717697615, acc: 0.8332212334437086, lr: 0.044151359828677295
[batch_idx--200] train_loss: 0.0014452764750527802, acc: 0.8330223880597015, lr: 0.04411399597434825
[batch_idx--250] train_loss: 0.0014416931546757006, acc: 0.8338209661354582, lr: 0.04407652906825116
[batch_idx--300] train_loss: 0.001438213564127535, acc: 0.8352107558139535, lr: 0.04403895931238623
[batch_idx--350] train_loss: 0.0014348192285730415, acc: 0.8356815349002849, lr: 0.044001286909308164
[batch_idx--400] train_loss: 0.0014377841421117324, acc: 0.8354017300498753, lr: 0.04396351206212508
[batch_idx--450] train_loss: 0.0014398606140317177, acc: 0.8356822994411081, lr: 0.043925634974497405
total time of one epoch: 305.8922097682953 s
train_loss:  0.0014398606140317177  acc:  0.8356822994411081
->>lr:0.043926
test_loss:  0.0014193976601443142  test_acc:  0.8385655788559374
best acc:  84.74996897878148

------Epoch: 34------
[batch_idx--0] train_loss: 0.001135893864557147, acc: 0.87890625, lr: 0.043924876391293916
[batch_idx--50] train_loss: 0.0014234513007834845, acc: 0.8374693627450981, lr: 0.0438868952287954
[batch_idx--100] train_loss: 0.0014225908239270644, acc: 0.8370977722772277, lr: 0.04384881223892658
[batch_idx--150] train_loss: 0.0014378705543052676, acc: 0.8352131622516556, lr: 0.04381062762700922
[batch_idx--200] train_loss: 0.0014345267751666518, acc: 0.836054104477612, lr: 0.043772341598912995
[batch_idx--250] train_loss: 0.0014315273838147403, acc: 0.8360620019920318, lr: 0.04373395436105431
[batch_idx--300] train_loss: 0.001435985011311613, acc: 0.8361710963455149, lr: 0.04369546612039528
[batch_idx--350] train_loss: 0.0014352975177719255, acc: 0.8360599180911681, lr: 0.04365687708444255
[batch_idx--400] train_loss: 0.0014378951492015634, acc: 0.8353432824189526, lr: 0.04361818746124621
[batch_idx--450] train_loss: 0.0014379989584309078, acc: 0.835743048564585, lr: 0.04357939745939863
total time of one epoch: 305.50975799560547 s
train_loss:  0.0014379989584309078  acc:  0.835743048564585
->>lr:0.043579
test_loss:  0.0015198816132169753  test_acc:  0.8344707780121603
best acc:  84.74996897878148

------Epoch: 35------
[batch_idx--0] train_loss: 0.0014025067212060094, acc: 0.83203125, lr: 0.04357862063693486
[batch_idx--50] train_loss: 0.0014334639726097092, acc: 0.8376225490196079, lr: 0.04353972846431615
[batch_idx--100] train_loss: 0.0014123352806978296, acc: 0.8394183168316832, lr: 0.043500736336052385
[batch_idx--150] train_loss: 0.0014164236301728926, acc: 0.8383433360927153, lr: 0.04346164446236689
[batch_idx--200] train_loss: 0.0014197459329725868, acc: 0.837880907960199, lr: 0.04342245305402075
[batch_idx--250] train_loss: 0.001417220875331427, acc: 0.8386765438247012, lr: 0.04338316232231171
[batch_idx--300] train_loss: 0.0014175379859976643, acc: 0.8387147009966778, lr: 0.043343772479072985
[batch_idx--350] train_loss: 0.0014146632057856078, acc: 0.8387753739316239, lr: 0.043304283736672146
[batch_idx--400] train_loss: 0.0014135573596979242, acc: 0.8390254831670823, lr: 0.04326469630800999
[batch_idx--450] train_loss: 0.0014213091188925153, acc: 0.8383552608740931, lr: 0.04322501040651934
total time of one epoch: 305.6625306606293 s
train_loss:  0.0014213091188925153  acc:  0.8383552608740931
->>lr:0.043225
test_loss:  0.0013736753061992504  test_acc:  0.8514704057575382
best acc:  84.74996897878148
Saving..

------Epoch: 36------
[batch_idx--0] train_loss: 0.0012960145249962807, acc: 0.85546875, lr: 0.04322421568553529
[batch_idx--50] train_loss: 0.0014373343597695815, acc: 0.8344822303921569, lr: 0.04318442956218869
[batch_idx--100] train_loss: 0.0014142287159707434, acc: 0.838490099009901, lr: 0.04314454539876614
[batch_idx--150] train_loss: 0.0014143509108770565, acc: 0.8381881208609272, lr: 0.043104563410300306
[batch_idx--200] train_loss: 0.0014211180439191078, acc: 0.837764303482587, lr: 0.043064483812351256
[batch_idx--250] train_loss: 0.0014206394520718084, acc: 0.8379450946215139, lr: 0.04302430682100536
[batch_idx--300] train_loss: 0.0014234036709989523, acc: 0.8372352574750831, lr: 0.042984032652874024
[batch_idx--350] train_loss: 0.0014219132259997546, acc: 0.8375845797720798, lr: 0.04294366152509261
[batch_idx--400] train_loss: 0.0014199104985719235, acc: 0.837846789276808, lr: 0.04290319365531922
[batch_idx--450] train_loss: 0.001424556303414111, acc: 0.8376696636234249, lr: 0.04286262926173353
total time of one epoch: 302.956880569458 s
train_loss:  0.001424556303414111  acc:  0.8376696636234249
->>lr:0.042863
test_loss:  0.0014074487741775408  test_acc:  0.8425362948256607
best acc:  85.14704057575382

------Epoch: 37------
[batch_idx--0] train_loss: 0.0013051232090219855, acc: 0.85546875, lr: 0.04286181699082009
[batch_idx--50] train_loss: 0.0014251183567787794, acc: 0.8359375, lr: 0.04282115436825425
[batch_idx--100] train_loss: 0.0014154953976613608, acc: 0.8394183168316832, lr: 0.04278039566418517
[batch_idx--150] train_loss: 0.0014217989133757274, acc: 0.8387831125827815, lr: 0.04273954109836054
[batch_idx--200] train_loss: 0.0014237701141076226, acc: 0.8386777052238806, lr: 0.0426985908910449
[batch_idx--250] train_loss: 0.001414149835431184, acc: 0.8402328187250996, lr: 0.042657545263018404
[batch_idx--300] train_loss: 0.0014170537709700952, acc: 0.8393635797342193, lr: 0.042616404435575676
[batch_idx--350] train_loss: 0.0014140057772864983, acc: 0.8397992343304843, lr: 0.04257516863052461
[batch_idx--400] train_loss: 0.0014143231295239635, acc: 0.839278756234414, lr: 0.04253383807018514
[batch_idx--450] train_loss: 0.001417231150536609, acc: 0.8391189641406602, lr: 0.042492412977388094
total time of one epoch: 302.0727562904358 s
train_loss:  0.001417231150536609  acc:  0.8391189641406602
->>lr:0.042492
test_loss:  0.0013651139964860933  test_acc:  0.8493609628986226
best acc:  85.14704057575382

------Epoch: 38------
[batch_idx--0] train_loss: 0.001489509828388691, acc: 0.8203125, lr: 0.042491583512834136
[batch_idx--50] train_loss: 0.0013884252197492648, acc: 0.8442861519607843, lr: 0.04245006222701923
[batch_idx--100] train_loss: 0.0013905976055245293, acc: 0.8417775371287128, lr: 0.04240844686041831
[batch_idx--150] train_loss: 0.0013980634451923979, acc: 0.8403093956953642, lr: 0.042366737637397726
[batch_idx--200] train_loss: 0.0013909271700465265, acc: 0.8413790422885572, lr: 0.04232493478282982
[batch_idx--250] train_loss: 0.0013903683117327402, acc: 0.8416179033864541, lr: 0.042283038522091754
[batch_idx--300] train_loss: 0.001389781504318712, acc: 0.8416995431893688, lr: 0.04224104908106427
[batch_idx--350] train_loss: 0.0013947729220311355, acc: 0.8408898682336182, lr: 0.0421989666861305
[batch_idx--400] train_loss: 0.001393881841839066, acc: 0.841275716957606, lr: 0.04215679156417471
[batch_idx--450] train_loss: 0.0014002991853627848, acc: 0.8407852258131704, lr: 0.04211452394258114
total time of one epoch: 303.86635518074036 s
train_loss:  0.0014002991853627848  acc:  0.8407852258131704
->>lr:0.042115
test_loss:  0.001390143971923031  test_acc:  0.8437771435661993
best acc:  85.14704057575382

------Epoch: 39------
[batch_idx--0] train_loss: 0.0012403231812641025, acc: 0.85546875, lr: 0.04211367764821722
[batch_idx--50] train_loss: 0.0014264956892778475, acc: 0.8350949754901961, lr: 0.04207131591176148
[batch_idx--100] train_loss: 0.0014136649234828972, acc: 0.8378326113861386, lr: 0.042028862136503926
[batch_idx--150] train_loss: 0.0014144408058634165, acc: 0.8389900662251656, lr: 0.0419863165513311
[batch_idx--200] train_loss: 0.001406898680930744, acc: 0.8403684701492538, lr: 0.041943679385624544
[batch_idx--250] train_loss: 0.001405598227940203, acc: 0.8406685756972112, lr: 0.04190095086925955
[batch_idx--300] train_loss: 0.0014004332889057077, acc: 0.8414919019933554, lr: 0.041858131232603915
[batch_idx--350] train_loss: 0.0013984804518621659, acc: 0.8412348646723646, lr: 0.04181522070651669
[batch_idx--400] train_loss: 0.0013991952049278856, acc: 0.8411295978802993, lr: 0.04177221952234698
[batch_idx--450] train_loss: 0.0014051323612449642, acc: 0.8413493248168847, lr: 0.041729127911932645
total time of one epoch: 304.34609818458557 s
train_loss:  0.0014051323612449642  acc:  0.8413493248168847
->>lr:0.041729
test_loss:  0.0014404311918534865  test_acc:  0.8393100881002605
best acc:  85.14704057575382

------Epoch: 40------
[batch_idx--0] train_loss: 0.0015527583891525865, acc: 0.8046875, lr: 0.04172826515897146
[batch_idx--50] train_loss: 0.0014198424691772636, acc: 0.8358609068627451, lr: 0.04168508155313258
[batch_idx--100] train_loss: 0.0014152102550436365, acc: 0.838180693069307, lr: 0.04164180799084732
[batch_idx--150] train_loss: 0.001401616709880432, acc: 0.8400507036423841, lr: 0.04159844470542206
[batch_idx--200] train_loss: 0.0013986716304085593, acc: 0.8407182835820896, lr: 0.041554991930646906
[batch_idx--250] train_loss: 0.0014001168853295337, acc: 0.840824203187251, lr: 0.041511449900794445
[batch_idx--300] train_loss: 0.001400193308388808, acc: 0.840843023255814, lr: 0.04146781885061848
[batch_idx--350] train_loss: 0.001397695300664137, acc: 0.8413572827635327, lr: 0.04142409901535277
[batch_idx--400] train_loss: 0.0013950925410093457, acc: 0.8418212281795511, lr: 0.04138029063070971
[batch_idx--450] train_loss: 0.0013997787313879346, acc: 0.8415836428645815, lr: 0.041336393932879134
total time of one epoch: 304.5812773704529 s
train_loss:  0.0013997787313879346  acc:  0.8415836428645815
->>lr:0.041336
test_loss:  0.0013226736219072181  test_acc:  0.8545725276088845
best acc:  85.14704057575382
Saving..

------Epoch: 41------
[batch_idx--0] train_loss: 0.0012626241659745574, acc: 0.84765625, lr: 0.04133551509975264
[batch_idx--50] train_loss: 0.0013623333230212914, acc: 0.8464307598039216, lr: 0.041291528566287365
[batch_idx--100] train_loss: 0.0013787864665915765, acc: 0.8444461633663366, lr: 0.041247454198189024
[batch_idx--150] train_loss: 0.001378237476436705, acc: 0.8452245447019867, lr: 0.04120329223308148
[batch_idx--200] train_loss: 0.0013781735240319623, acc: 0.8446634017412935, lr: 0.041159042909060875
[batch_idx--250] train_loss: 0.0013790687669506408, acc: 0.8446682021912351, lr: 0.04111470646469433
[batch_idx--300] train_loss: 0.0013783886453192496, acc: 0.8444897217607974, lr: 0.04107028313901867
[batch_idx--350] train_loss: 0.001384206505245569, acc: 0.8432380698005698, lr: 0.04102577317153916
[batch_idx--400] train_loss: 0.0013832092320574378, acc: 0.8439350841645885, lr: 0.04098117680222813
[batch_idx--450] train_loss: 0.0013914536929810876, acc: 0.8430589787204499, lr: 0.04093649427152381
total time of one epoch: 306.86337900161743 s
train_loss:  0.0013914536929810876  acc:  0.8430589787204499
->>lr:0.040936
test_loss:  0.0013797672130079657  test_acc:  0.8509740662613228
best acc:  85.45725276088845

------Epoch: 42------
[batch_idx--0] train_loss: 0.0014935591025277972, acc: 0.83203125, lr: 0.040935599743717244
[batch_idx--50] train_loss: 0.0014180425559079239, acc: 0.8396139705882353, lr: 0.04089082957657292
[batch_idx--100] train_loss: 0.0013895130665548662, acc: 0.8428217821782178, lr: 0.04084597373513602
[batch_idx--150] train_loss: 0.001392202010063689, acc: 0.8418356788079471, lr: 0.04080103246124366
[batch_idx--200] train_loss: 0.0013894541229617166, acc: 0.8431086753731343, lr: 0.04075600599719357
[batch_idx--250] train_loss: 0.0013873414878559065, acc: 0.8428473605577689, lr: 0.04071089458574278
[batch_idx--300] train_loss: 0.0013886284012737315, acc: 0.8423873546511628, lr: 0.04066569847010627
[batch_idx--350] train_loss: 0.0013848077373159917, acc: 0.8424701745014245, lr: 0.040620417893955756
[batch_idx--400] train_loss: 0.0013863392066247669, acc: 0.8424641521197007, lr: 0.04057505310141827
[batch_idx--450] train_loss: 0.0013846239215957628, acc: 0.8432759398757247, lr: 0.04052960433707492
total time of one epoch: 305.49783158302307 s
train_loss:  0.0013846239215957628  acc:  0.8432759398757247
->>lr:0.040530
test_loss:  0.0013370298395560388  test_acc:  0.8533316788683459
best acc:  85.45725276088845

------Epoch: 43------
[batch_idx--0] train_loss: 0.0013695990201085806, acc: 0.8359375, lr: 0.040528694506957764
[batch_idx--50] train_loss: 0.0013621686683858141, acc: 0.8474264705882353, lr: 0.04048316034380937
[batch_idx--100] train_loss: 0.0013533457986881386, acc: 0.8467280321782178, lr: 0.040437542704288454
[batch_idx--150] train_loss: 0.0013640638231145626, acc: 0.8452762831125827, lr: 0.04039184183433934
[batch_idx--200] train_loss: 0.0013715572642458982, acc: 0.8447411380597015, lr: 0.04034605798035504
[batch_idx--250] train_loss: 0.0013717797265269337, acc: 0.8448549551792829, lr: 0.04030019138917598
[batch_idx--300] train_loss: 0.0013748237515484104, acc: 0.8448790490033222, lr: 0.040254242308088696
[batch_idx--350] train_loss: 0.001374929435411866, acc: 0.8446069266381766, lr: 0.040208210984824425
[batch_idx--400] train_loss: 0.0013770347403332201, acc: 0.8444416302992519, lr: 0.04016209766755781
[batch_idx--450] train_loss: 0.0013788857417388108, acc: 0.8448814524247579, lr: 0.040115902604905565
total time of one epoch: 304.18833208084106 s
train_loss:  0.0013788857417388108  acc:  0.8448814524247579
->>lr:0.040116
test_loss:  0.0013243002614337141  test_acc:  0.8522149150018613
best acc:  85.45725276088845

------Epoch: 44------
[batch_idx--0] train_loss: 0.001302253222092986, acc: 0.859375, lr: 0.040114977871559376
[batch_idx--50] train_loss: 0.001360890183908244, acc: 0.8439031862745098, lr: 0.04006869968519579
[batch_idx--100] train_loss: 0.0013675510740405556, acc: 0.8428604579207921, lr: 0.04002234025699524
[batch_idx--150] train_loss: 0.001368695737436315, acc: 0.843724130794702, lr: 0.039975899836901335
[batch_idx--200] train_loss: 0.0013713240067460644, acc: 0.8440803793532339, lr: 0.03992937867529435
[batch_idx--250] train_loss: 0.0013698336744376743, acc: 0.8442635707171314, lr: 0.03988277702298985
[batch_idx--300] train_loss: 0.0013700487889640306, acc: 0.8448011835548173, lr: 0.03983609513123738
[batch_idx--350] train_loss: 0.001371557456825958, acc: 0.8446403133903134, lr: 0.03978933325171908
[batch_idx--400] train_loss: 0.001369817996167687, acc: 0.844987141521197, lr: 0.03974249163654834
[batch_idx--450] train_loss: 0.0013700728135438017, acc: 0.8450463429027667, lr: 0.03969557053826845
total time of one epoch: 303.08975315093994 s
train_loss:  0.0013700728135438017  acc:  0.8450463429027667
->>lr:0.039696
test_loss:  0.0013125817582541888  test_acc:  0.8523389998759151
best acc:  85.45725276088845

------Epoch: 45------
[batch_idx--0] train_loss: 0.0012549436651170254, acc: 0.86328125, lr: 0.03969463130731183
[batch_idx--50] train_loss: 0.0013648748041733222, acc: 0.8459712009803921, lr: 0.0396476293968751
[batch_idx--100] train_loss: 0.0013473726898929712, acc: 0.8480043316831684, lr: 0.03960054851477232
[batch_idx--150] train_loss: 0.0013553260953554156, acc: 0.8468543046357616, lr: 0.039553388914836764
[batch_idx--200] train_loss: 0.0013616618744343222, acc: 0.8461015236318408, lr: 0.039506150851326104
[batch_idx--250] train_loss: 0.0013604784677495282, acc: 0.8460532868525896, lr: 0.039458834578921055
[batch_idx--300] train_loss: 0.0013674533836221775, acc: 0.8451905107973422, lr: 0.03941144035272397
[batch_idx--350] train_loss: 0.0013724725731274383, acc: 0.8446737001424501, lr: 0.03936396842825749
[batch_idx--400] train_loss: 0.001368876477526942, acc: 0.8453865336658354, lr: 0.03931641906146319
[batch_idx--450] train_loss: 0.0013717440167655922, acc: 0.8454108376436282, lr: 0.03926879250870011
total time of one epoch: 305.34685945510864 s
train_loss:  0.0013717440167655922  acc:  0.8454108376436282
->>lr:0.039269
test_loss:  0.0013472420256018624  test_acc:  0.8510981511353766
best acc:  85.45725276088845

------Epoch: 46------
[batch_idx--0] train_loss: 0.0012926807394251227, acc: 0.8671875, lr: 0.0392678391921108
[batch_idx--50] train_loss: 0.001357540216607352, acc: 0.8446691176470589, lr: 0.03922013417419226
[batch_idx--100] train_loss: 0.001377963235066964, acc: 0.8435566212871287, lr: 0.03917235248941817
[batch_idx--150] train_loss: 0.0013661039353268134, acc: 0.8460782284768212, lr: 0.03912449439540013
[batch_idx--200] train_loss: 0.001373851330677483, acc: 0.8448188743781094, lr: 0.0390765601501617
[batch_idx--250] train_loss: 0.001365416431409934, acc: 0.8456019671314741, lr: 0.03902855001213699
[batch_idx--300] train_loss: 0.0013623895224932569, acc: 0.8460600083056479, lr: 0.0389804642401693
[batch_idx--350] train_loss: 0.001365913706698967, acc: 0.8458422364672364, lr: 0.03893230309350968
[batch_idx--400] train_loss: 0.0013640306096296395, acc: 0.8459710099750624, lr: 0.03888406683181559
[batch_idx--450] train_loss: 0.0013645330563792294, acc: 0.8466778907904329, lr: 0.03883575571514944
total time of one epoch: 304.68804693222046 s
train_loss:  0.0013645330563792294  acc:  0.8466778907904329
->>lr:0.038836
test_loss:  0.0013946867459523559  test_acc:  0.8420399553294453
best acc:  85.45725276088845

------Epoch: 47------
[batch_idx--0] train_loss: 0.001518157427199185, acc: 0.80859375, lr: 0.038834788731083605
[batch_idx--50] train_loss: 0.0013671343433944618, acc: 0.8451286764705882, lr: 0.038786401530680796
[batch_idx--100] train_loss: 0.0013637156802054384, acc: 0.8446008663366337, lr: 0.03873794000186154
[batch_idx--150] train_loss: 0.0013542761378582346, acc: 0.8463369205298014, lr: 0.03868940440590278
[batch_idx--200] train_loss: 0.0013418339803323743, acc: 0.8478117226368159, lr: 0.03864079500448077
[batch_idx--250] train_loss: 0.0013448436442109574, acc: 0.8472983067729084, lr: 0.03859211205966969
[batch_idx--300] train_loss: 0.0013481523908142532, acc: 0.8470073712624585, lr: 0.038543355833940224
[batch_idx--350] train_loss: 0.0013512094817562108, acc: 0.8463652955840456, lr: 0.03849452659015813
[batch_idx--400] train_loss: 0.0013576975717044383, acc: 0.8457956670822943, lr: 0.03844562459158286
[batch_idx--450] train_loss: 0.0013620611988223986, acc: 0.845653834137536, lr: 0.0383966501018661
total time of one epoch: 305.4667570590973 s
train_loss:  0.0013620611988223986  acc:  0.845653834137536
->>lr:0.038397
test_loss:  0.0013078919806363846  test_acc:  0.8565578855937461
best acc:  85.45725276088845
Saving..

------Epoch: 48------
[batch_idx--0] train_loss: 0.0014862691750749946, acc: 0.82421875, lr: 0.03839566987447492
[batch_idx--50] train_loss: 0.0013799649667834827, acc: 0.8427542892156863, lr: 0.038346621715813135
[batch_idx--100] train_loss: 0.0013687459343933676, acc: 0.8451423267326733, lr: 0.038297501599776934
[batch_idx--150] train_loss: 0.0013646975148851608, acc: 0.8460782284768212, lr: 0.03824830979119395
[batch_idx--200] train_loss: 0.0013589348825880914, acc: 0.8461986940298507, lr: 0.038199046555278386
[batch_idx--250] train_loss: 0.0013493032197456852, acc: 0.8484032619521913, lr: 0.038149712157629516
[batch_idx--300] train_loss: 0.0013479829268480505, acc: 0.8478509136212624, lr: 0.038100306864230285
[batch_idx--350] train_loss: 0.0013524215297635507, acc: 0.8469551282051282, lr: 0.038050830941445866
[batch_idx--400] train_loss: 0.0013519198087362243, acc: 0.8467113466334164, lr: 0.03800128465602222
[batch_idx--450] train_loss: 0.0013563000975737871, acc: 0.8470857777623494, lr: 0.03795166827508467
total time of one epoch: 304.5182695388794 s
train_loss:  0.0013563000975737871  acc:  0.8470857777623494
->>lr:0.037952
test_loss:  0.0013328567230460335  test_acc:  0.8543243578607768
best acc:  85.65578855937461

------Epoch: 49------
[batch_idx--0] train_loss: 0.001393636572174728, acc: 0.83203125, lr: 0.03795067523432826
[batch_idx--50] train_loss: 0.001390070239008934, acc: 0.8428308823529411, lr: 0.037900987631550954
[batch_idx--100] train_loss: 0.0013731510083347853, acc: 0.8457224628712872, lr: 0.03785123047400412
[batch_idx--150] train_loss: 0.0013552905416535522, acc: 0.8480701572847682, lr: 0.03780140402994997
[batch_idx--200] train_loss: 0.001358714380384937, acc: 0.8474230410447762, lr: 0.03775150856802428
[batch_idx--250] train_loss: 0.0013491867858716157, acc: 0.84765625, lr: 0.03770154435723495
[batch_idx--300] train_loss: 0.0013479686383176532, acc: 0.8475264742524917, lr: 0.037651511666960506
[batch_idx--350] train_loss: 0.0013478024069357802, acc: 0.8478454415954416, lr: 0.03760141076694869
[batch_idx--400] train_loss: 0.0013479226840162962, acc: 0.84765625, lr: 0.037551241927314974
[batch_idx--450] train_loss: 0.0013517929036672648, acc: 0.8479796577220814, lr: 0.03750100541854115
total time of one epoch: 304.37893867492676 s
train_loss:  0.0013517929036672648  acc:  0.8479796577220814
->>lr:0.037501
test_loss:  0.0013224084703601876  test_acc:  0.8556892914753692
best acc:  85.65578855937461

------Epoch: 50------
[batch_idx--0] train_loss: 0.0013110496802255511, acc: 0.8359375, lr: 0.037500000000000006
[batch_idx--50] train_loss: 0.0013912911549685341, acc: 0.8404564950980392, lr: 0.037449694747731944
[batch_idx--100] train_loss: 0.0013639437781628406, acc: 0.8457611386138614, lr: 0.03739932237380827
[batch_idx--150] train_loss: 0.001363646295322537, acc: 0.8458712748344371, lr: 0.03734888314980809
[batch_idx--200] train_loss: 0.0013569181510455796, acc: 0.8463736007462687, lr: 0.037298377347670955
[batch_idx--250] train_loss: 0.0013556833085845192, acc: 0.8464890438247012, lr: 0.03724780523969534
[batch_idx--300] train_loss: 0.0013534479884375072, acc: 0.8467607973421927, lr: 0.03719716709853723
[batch_idx--350] train_loss: 0.0013506224948085016, acc: 0.8470552884615384, lr: 0.037146463197208594
[batch_idx--400] train_loss: 0.0013468991111536648, acc: 0.8482796913965087, lr: 0.03709569380907597
[batch_idx--450] train_loss: 0.0013486640724732495, acc: 0.848352830909154, lr: 0.03704485920785895
total time of one epoch: 302.4601686000824 s
train_loss:  0.0013486640724732495  acc:  0.848352830909154
->>lr:0.037045
test_loss:  0.0013161681140381818  test_acc:  0.8596600074450924
best acc:  85.65578855937461
Saving..

------Epoch: 51------
[batch_idx--0] train_loss: 0.0012241611257195473, acc: 0.87890625, lr: 0.037043841852542884
[batch_idx--50] train_loss: 0.0013207341338891316, acc: 0.8531709558823529, lr: 0.03699294101633032
[batch_idx--100] train_loss: 0.0013343281605935628, acc: 0.8500541460396039, lr: 0.036941975521017835
[batch_idx--150] train_loss: 0.0013261621672234541, acc: 0.8502949089403974, lr: 0.0368909456413823
[batch_idx--200] train_loss: 0.001324123554383474, acc: 0.8504741915422885, lr: 0.03683985165254776
[batch_idx--250] train_loss: 0.0013280895817375546, acc: 0.8501151643426295, lr: 0.03678869382998386
[batch_idx--300] train_loss: 0.0013295737730626921, acc: 0.850342607973422, lr: 0.03673747244950439
[batch_idx--350] train_loss: 0.0013330305475102169, acc: 0.8499376780626781, lr: 0.03668618778726586
[batch_idx--400] train_loss: 0.0013354083160553917, acc: 0.8496337281795511, lr: 0.0366348401197659
[batch_idx--450] train_loss: 0.001338419456130724, acc: 0.8496719547332245, lr: 0.036583429723841876
total time of one epoch: 303.58419847488403 s
train_loss:  0.001338419456130724  acc:  0.8496719547332245
->>lr:0.036583
test_loss:  0.0013337608106468552  test_acc:  0.8563097158456384
best acc:  85.96600074450924

------Epoch: 52------
[batch_idx--0] train_loss: 0.0011516365921124816, acc: 0.875, lr: 0.036582400877996545
[batch_idx--50] train_loss: 0.0013153404316992737, acc: 0.8511795343137255, lr: 0.03653092678462853
[batch_idx--100] train_loss: 0.00131784919026944, acc: 0.8530321782178217, lr: 0.036479390523077894
[batch_idx--150] train_loss: 0.0013253318102697269, acc: 0.8511744619205298, lr: 0.036427792371198774
[batch_idx--200] train_loss: 0.0013258334368569267, acc: 0.8512709888059702, lr: 0.036376132607179
[batch_idx--250] train_loss: 0.0013202499784714732, acc: 0.8520138197211156, lr: 0.03632441150953856
[batch_idx--300] train_loss: 0.001324150163256424, acc: 0.8518090739202658, lr: 0.036272629357128106
[batch_idx--350] train_loss: 0.0013279025784515884, acc: 0.8504496082621082, lr: 0.0362207864291275
[batch_idx--400] train_loss: 0.0013317643107957858, acc: 0.8501110504987531, lr: 0.03616888300504424
[batch_idx--450] train_loss: 0.0013338768853508752, acc: 0.8498802374422884, lr: 0.03611691936471199
total time of one epoch: 305.1779112815857 s
train_loss:  0.0013338768853508752  acc:  0.8498802374422884
->>lr:0.036117
test_loss:  0.0013413377635930724  test_acc:  0.8573023948380692
best acc:  85.96600074450924

------Epoch: 53------
[batch_idx--0] train_loss: 0.0011916211806237698, acc: 0.859375, lr: 0.036115879479623185
[batch_idx--50] train_loss: 0.0013257641546136024, acc: 0.8477328431372549, lr: 0.0360638547073383
[batch_idx--100] train_loss: 0.0013301701453228545, acc: 0.8484297648514851, lr: 0.036011770285057136
[batch_idx--150] train_loss: 0.0013264878506507008, acc: 0.8505794701986755, lr: 0.03595962649358918
[batch_idx--200] train_loss: 0.0013234389005275212, acc: 0.8509794776119403, lr: 0.03590742361406404
[batch_idx--250] train_loss: 0.001316327322923775, acc: 0.8527297061752988, lr: 0.03585516192792988
[batch_idx--300] train_loss: 0.0013169498748279043, acc: 0.8522113787375415, lr: 0.03580284171695191
[batch_idx--350] train_loss: 0.001315183051997143, acc: 0.8522524928774928, lr: 0.03575046326321087
[batch_idx--400] train_loss: 0.0013161479951837043, acc: 0.8520105985037406, lr: 0.035698026849101526
[batch_idx--450] train_loss: 0.0013212541485335969, acc: 0.8518589231783942, lr: 0.03564553275733112
total time of one epoch: 303.02396845817566 s
train_loss:  0.0013212541485335969  acc:  0.8518589231783942
->>lr:0.035646
test_loss:  0.0012890769006715162  test_acc:  0.8601563469413078
best acc:  85.96600074450924
Saving..

------Epoch: 54------
[batch_idx--0] train_loss: 0.0015712431631982327, acc: 0.8046875, lr: 0.03564448228912682
[batch_idx--50] train_loss: 0.0013569226241944468, acc: 0.8478860294117647, lr: 0.035591929657709624
[batch_idx--100] train_loss: 0.0013320814716712673, acc: 0.8506342821782178, lr: 0.03553931992064693
[batch_idx--150] train_loss: 0.0013359565440479, acc: 0.8495188327814569, lr: 0.035486653361580446
[batch_idx--200] train_loss: 0.0013308315167194279, acc: 0.849735696517413, lr: 0.03543393026445823
[batch_idx--250] train_loss: 0.0013246353285709968, acc: 0.8510022410358565, lr: 0.03538115091353316
[batch_idx--300] train_loss: 0.001325532354443857, acc: 0.8510823297342193, lr: 0.035328315593361394
[batch_idx--350] train_loss: 0.0013246077825607163, acc: 0.8517405626780626, lr: 0.03527542458880086
[batch_idx--400] train_loss: 0.001321737460723551, acc: 0.851952150872818, lr: 0.035222478185009704
[batch_idx--450] train_loss: 0.0013240138163521317, acc: 0.8517981740549172, lr: 0.035169476667444736
total time of one epoch: 304.20114970207214 s
train_loss:  0.0013240138163521317  acc:  0.8517981740549172
->>lr:0.035169
test_loss:  0.001413629744037799  test_acc:  0.8439012284402532
best acc:  86.01563469413078

------Epoch: 55------
[batch_idx--0] train_loss: 0.001074866158887744, acc: 0.90625, lr: 0.035168416076895005
[batch_idx--50] train_loss: 0.001314709531417226, acc: 0.8536305147058824, lr: 0.03511535863766653
[batch_idx--100] train_loss: 0.0013268666000723248, acc: 0.852606745049505, lr: 0.03506224666219176
[batch_idx--150] train_loss: 0.001320783937787822, acc: 0.8528042218543046, lr: 0.03500908043682018
[batch_idx--200] train_loss: 0.0013197866533141566, acc: 0.8520483519900498, lr: 0.034955860248193804
[batch_idx--250] train_loss: 0.001318355798916112, acc: 0.851624750996016, lr: 0.034902586383245504
[batch_idx--300] train_loss: 0.0013191010963490412, acc: 0.851484634551495, lr: 0.03484925912919761
[batch_idx--350] train_loss: 0.0013192041461658466, acc: 0.8510505698005698, lr: 0.03479587877356025
[batch_idx--400] train_loss: 0.0013166828537673372, acc: 0.8512702618453866, lr: 0.034742445604129875
[batch_idx--450] train_loss: 0.001317236191530488, acc: 0.851893636963238, lr: 0.034688959908987675
total time of one epoch: 304.23919916152954 s
train_loss:  0.001317236191530488  acc:  0.851893636963238
->>lr:0.034689
test_loss:  0.0012624816265720369  test_acc:  0.8632584687926542
best acc:  86.01563469413078
Saving..

------Epoch: 56------
[batch_idx--0] train_loss: 0.0012443473096936941, acc: 0.8671875, lr: 0.034687889661302575
[batch_idx--50] train_loss: 0.0013095418529986752, acc: 0.8544730392156863, lr: 0.034634350687009215
[batch_idx--100] train_loss: 0.001298104726368248, acc: 0.8543858292079208, lr: 0.034580759769790186
[batch_idx--150] train_loss: 0.0012993213542527365, acc: 0.8545115894039735, lr: 0.034527117198577144
[batch_idx--200] train_loss: 0.001302683758676812, acc: 0.8533115671641791, lr: 0.034473423262580266
[batch_idx--250] train_loss: 0.0013037198638280044, acc: 0.85355453187251, lr: 0.03441967825128663
[batch_idx--300] train_loss: 0.0013038078858671814, acc: 0.8541061046511628, lr: 0.0343658824544587
[batch_idx--350] train_loss: 0.0013085641336701597, acc: 0.8532763532763533, lr: 0.034312036162132735
[batch_idx--400] train_loss: 0.0013092920366161388, acc: 0.8531016209476309, lr: 0.034258139664617236
[batch_idx--450] train_loss: 0.0013093646206707875, acc: 0.8535772555281702, lr: 0.0342041932524914
total time of one epoch: 305.64541125297546 s
train_loss:  0.0013093646206707875  acc:  0.8535772555281702
->>lr:0.034204
test_loss:  0.001221224963332187  test_acc:  0.8678496091326467
best acc:  86.32584687926541
Saving..

------Epoch: 57------
[batch_idx--0] train_loss: 0.0012021877337247133, acc: 0.84765625, lr: 0.03420311381711696
[batch_idx--50] train_loss: 0.0012986561244664092, acc: 0.8568474264705882, lr: 0.03414911679172232
[batch_idx--100] train_loss: 0.0012979635163118122, acc: 0.855159344059406, lr: 0.034095070439506506
[batch_idx--150] train_loss: 0.0013118687418092116, acc: 0.8536579056291391, lr: 0.03404097505185664
[batch_idx--200] train_loss: 0.0013073112358644938, acc: 0.8541666666666666, lr: 0.0339868309204242
[batch_idx--250] train_loss: 0.0013056161752679344, acc: 0.8545661105577689, lr: 0.03393263833712346
[batch_idx--300] train_loss: 0.001307444395752704, acc: 0.8537167774086378, lr: 0.03387839759412996
[batch_idx--350] train_loss: 0.001305227894256385, acc: 0.8536769943019943, lr: 0.03382410898387883
[batch_idx--400] train_loss: 0.0013031233229820716, acc: 0.8536471321695761, lr: 0.033769772799063326
[batch_idx--450] train_loss: 0.0013037316835300698, acc: 0.8540719269621967, lr: 0.03371538933263315
total time of one epoch: 304.8385179042816 s
train_loss:  0.0013037316835300698  acc:  0.8540719269621967
->>lr:0.033715
test_loss:  0.0012758329098359839  test_acc:  0.8610249410596849
best acc:  86.78496091326467

------Epoch: 58------
[batch_idx--0] train_loss: 0.001262326491996646, acc: 0.8671875, lr: 0.03371430118304538
[batch_idx--50] train_loss: 0.0013334267594687203, acc: 0.8494178921568627, lr: 0.03365986979142943
[batch_idx--100] train_loss: 0.0012997212107431623, acc: 0.8536123143564357, lr: 0.03360539171073317
[batch_idx--150] train_loss: 0.0013065458489705296, acc: 0.8529335678807947, lr: 0.03355086723467137
[batch_idx--200] train_loss: 0.0013050307990028639, acc: 0.8532921330845771, lr: 0.03349629665720888
[batch_idx--250] train_loss: 0.00130141619361002, acc: 0.8540369770916335, lr: 0.03344168027255918
[batch_idx--300] train_loss: 0.0013021301382230563, acc: 0.854326723421927, lr: 0.033387018375182646
[batch_idx--350] train_loss: 0.0013027064839876827, acc: 0.8536769943019943, lr: 0.03333231125978507
[batch_idx--400] train_loss: 0.0013010065787485766, acc: 0.8539198877805486, lr: 0.03327755922131603
[batch_idx--450] train_loss: 0.0013059556593367585, acc: 0.8534297219425834, lr: 0.033222762554967304
total time of one epoch: 311.5604236125946 s
train_loss:  0.0013059556593367585  acc:  0.8534297219425834
->>lr:0.033223
test_loss:  0.0012564452029676825  test_acc:  0.8647474872813005
best acc:  86.78496091326467

------Epoch: 59------
[batch_idx--0] train_loss: 0.0012823323486372828, acc: 0.84375, lr: 0.03322166616846458
[batch_idx--50] train_loss: 0.0012873679082201538, acc: 0.8587622549019608, lr: 0.033166824286034645
[batch_idx--100] train_loss: 0.001290707113013815, acc: 0.8563196163366337, lr: 0.03311193837274467
[batch_idx--150] train_loss: 0.001275108636446322, acc: 0.8579004552980133, lr: 0.03305700872450816
[batch_idx--200] train_loss: 0.0012914692100939058, acc: 0.8559934701492538, lr: 0.03300203563747449
[batch_idx--250] train_loss: 0.001293144925113441, acc: 0.8559200697211156, lr: 0.0329470194080272
[batch_idx--300] train_loss: 0.0012888176062305233, acc: 0.8561046511627907, lr: 0.032891960332782424
[batch_idx--350] train_loss: 0.0012916066938217867, acc: 0.8554798789173789, lr: 0.03283685870858731
[batch_idx--400] train_loss: 0.0012944502486879855, acc: 0.85481608478803, lr: 0.03278171483251839
[batch_idx--450] train_loss: 0.0012967862094671893, acc: 0.8551740896309925, lr: 0.03272652900188
total time of one epoch: 309.4994447231293 s
train_loss:  0.0012967862094671893  acc:  0.8551740896309925
->>lr:0.032727
test_loss:  0.001249133612355489  test_acc:  0.8635066385407619
best acc:  86.78496091326467

------Epoch: 60------
[batch_idx--0] train_loss: 0.0011339376214891672, acc: 0.87109375, lr: 0.032725424859373686
[batch_idx--50] train_loss: 0.001295377000454156, acc: 0.854702818627451, lr: 0.032670196541591943
[batch_idx--100] train_loss: 0.0012912045424287714, acc: 0.8548499381188119, lr: 0.03261492687048379
[batch_idx--150] train_loss: 0.0012892672525324075, acc: 0.8549254966887417, lr: 0.03255961614403176
[batch_idx--200] train_loss: 0.0012928668753619291, acc: 0.8545942164179104, lr: 0.03250426466043975
[batch_idx--250] train_loss: 0.001295363034707943, acc: 0.854410483067729, lr: 0.03244887271813142
[batch_idx--300] train_loss: 0.0012999603267994236, acc: 0.8538465531561462, lr: 0.032393440615748524
[batch_idx--350] train_loss: 0.0012969973117665009, acc: 0.8543002136752137, lr: 0.03233796865214936
[batch_idx--400] train_loss: 0.0012942780755074727, acc: 0.8546699657107232, lr: 0.03228245712640712
[batch_idx--450] train_loss: 0.0013083780125742028, acc: 0.8540024993925087, lr: 0.0322269063378083
total time of one epoch: 308.23425936698914 s
train_loss:  0.0013083780125742028  acc:  0.8540024993925087
->>lr:0.032227
test_loss:  0.0012545538408641765  test_acc:  0.8644993175331928
best acc:  86.78496091326467

------Epoch: 61------
[batch_idx--0] train_loss: 0.0010831672698259354, acc: 0.88671875, lr: 0.03222579492361179
[batch_idx--50] train_loss: 0.0013426748565489462, acc: 0.8474264705882353, lr: 0.032170204395443734
[batch_idx--100] train_loss: 0.0013142831745732687, acc: 0.8523360148514851, lr: 0.03211457520962184
[batch_idx--150] train_loss: 0.0013145740423043141, acc: 0.8519246688741722, lr: 0.032058907666066935
[batch_idx--200] train_loss: 0.0013061355583981347, acc: 0.8526508084577115, lr: 0.03200320206490668
[batch_idx--250] train_loss: 0.0013054929512731019, acc: 0.8537568476095617, lr: 0.03194745870647391
[batch_idx--300] train_loss: 0.0013053475949136644, acc: 0.8534702034883721, lr: 0.03189167789130505
[batch_idx--350] train_loss: 0.0013019418129312707, acc: 0.8538661858974359, lr: 0.031835859920138446
[batch_idx--400] train_loss: 0.001294446986591318, acc: 0.8551083229426434, lr: 0.03178000509391275
[batch_idx--450] train_loss: 0.0013006758563613371, acc: 0.8545058492727462, lr: 0.03172411371376536
total time of one epoch: 307.2090983390808 s
train_loss:  0.0013006758563613371  acc:  0.8545058492727462
->>lr:0.031724
test_loss:  0.0014051778993382912  test_acc:  0.8507258965132151
best acc:  86.78496091326467

------Epoch: 62------
[batch_idx--0] train_loss: 0.0013657708186656237, acc: 0.83203125, lr: 0.031722995515381644
[batch_idx--50] train_loss: 0.0013519469854038429, acc: 0.8457414215686274, lr: 0.03166706716067022
[batch_idx--100] train_loss: 0.0013095536816745332, acc: 0.8524907178217822, lr: 0.03161110286093404
[batch_idx--150] train_loss: 0.0012985261327537728, acc: 0.8537872516556292, lr: 0.031555102917900694
[batch_idx--200] train_loss: 0.0012917131030890368, acc: 0.8552355410447762, lr: 0.03149906763348994
[batch_idx--250] train_loss: 0.0012930806360274287, acc: 0.8547217380478087, lr: 0.0314429973098121
[batch_idx--300] train_loss: 0.0012961047578934097, acc: 0.8538205980066446, lr: 0.031386892249166375
[batch_idx--350] train_loss: 0.0012932539948373714, acc: 0.8542223112535613, lr: 0.03133075275403927
[batch_idx--400] train_loss: 0.0012953071320833559, acc: 0.8539198877805486, lr: 0.03127457912710293
[batch_idx--450] train_loss: 0.001299032779230017, acc: 0.8540719269621967, lr: 0.031218371671213524
total time of one epoch: 306.71987318992615 s
train_loss:  0.001299032779230017  acc:  0.8540719269621967
->>lr:0.031218
test_loss:  0.0013297657980518315  test_acc:  0.852463084749969
best acc:  86.78496091326467

------Epoch: 63------
[batch_idx--0] train_loss: 0.0011776740429922938, acc: 0.875, lr: 0.031217247179121367
[batch_idx--50] train_loss: 0.0013124881239206182, acc: 0.8534007352941176, lr: 0.0311610055298914
[batch_idx--100] train_loss: 0.0013016620708518837, acc: 0.8536509900990099, lr: 0.031104730664032437
[batch_idx--150] train_loss: 0.0012943377473163388, acc: 0.8548220198675497, lr: 0.031048422884946483
[batch_idx--200] train_loss: 0.0012966893220653951, acc: 0.8548857276119403, lr: 0.030992082496212964
[batch_idx--250] train_loss: 0.0012890751811256446, acc: 0.8561379482071713, lr: 0.030935709801587143
[batch_idx--300] train_loss: 0.0012825820693650291, acc: 0.8569871262458472, lr: 0.03087930510499845
[batch_idx--350] train_loss: 0.0012809549912046164, acc: 0.8567597044159544, lr: 0.030822868710548842
[batch_idx--400] train_loss: 0.0012846392108489784, acc: 0.8563746882793017, lr: 0.030766400922511174
[batch_idx--450] train_loss: 0.001285472807376831, acc: 0.8565799979171729, lr: 0.030709902045327583
total time of one epoch: 312.7852439880371 s
train_loss:  0.001285472807376831  acc:  0.8565799979171729
->>lr:0.030710
test_loss:  0.001268665841442581  test_acc:  0.8635066385407619
best acc:  86.78496091326467

------Epoch: 64------
[batch_idx--0] train_loss: 0.0010950859868898988, acc: 0.8984375, lr: 0.030708771752766397
[batch_idx--50] train_loss: 0.0013018444034398771, acc: 0.8543198529411765, lr: 0.030652241478464032
[batch_idx--100] train_loss: 0.001296954158011197, acc: 0.8562035891089109, lr: 0.03059568073049836
[batch_idx--150] train_loss: 0.0012867987396454575, acc: 0.8577452400662252, lr: 0.030539089813812693
[batch_idx--200] train_loss: 0.001289522200614325, acc: 0.8569068718905473, lr: 0.03048246903351297
[batch_idx--250] train_loss: 0.0012897633454870003, acc: 0.856418077689243, lr: 0.030425818694866172
[batch_idx--300] train_loss: 0.0012899396393410984, acc: 0.856156561461794, lr: 0.030369139103298623
[batch_idx--350] train_loss: 0.0012887518806847349, acc: 0.8559027777777778, lr: 0.030312430564394355
[batch_idx--400] train_loss: 0.0012854845589665496, acc: 0.8562090866583542, lr: 0.03025569338389348
[batch_idx--450] train_loss: 0.0012863966744567302, acc: 0.856493213455063, lr: 0.03019892786769053
total time of one epoch: 313.89247012138367 s
train_loss:  0.0012863966744567302  acc:  0.856493213455063
->>lr:0.030199
test_loss:  0.00128619923294589  test_acc:  0.8618935351780618
best acc:  86.78496091326467

------Epoch: 65------
[batch_idx--0] train_loss: 0.0014118041144683957, acc: 0.84765625, lr: 0.03019779227044398
[batch_idx--50] train_loss: 0.0012863393777104862, acc: 0.85546875, lr: 0.03014099816711588
[batch_idx--100] train_loss: 0.0012762949705160786, acc: 0.8574412128712872, lr: 0.030084176346456905
[batch_idx--150] train_loss: 0.0012796638851109523, acc: 0.8574348096026491, lr: 0.030027327114817932
[batch_idx--200] train_loss: 0.0012743930090265117, acc: 0.8575676305970149, lr: 0.029970450778697578
[batch_idx--250] train_loss: 0.0012802044472349178, acc: 0.8561690737051793, lr: 0.02991354764474065
[batch_idx--300] train_loss: 0.001287293873349842, acc: 0.8558191445182725, lr: 0.02985661801973638
[batch_idx--350] train_loss: 0.0012843925525776597, acc: 0.855735844017094, lr: 0.02979966221061685
[batch_idx--400] train_loss: 0.0012767455976646848, acc: 0.8570273534912718, lr: 0.029742680524455323
[batch_idx--450] train_loss: 0.0012730945479889706, acc: 0.8580206199881973, lr: 0.02968567326846454
total time of one epoch: 310.40168142318726 s
train_loss:  0.0012730945479889706  acc:  0.8580206199881973
->>lr:0.029686
test_loss:  0.0012636391559477287  test_acc:  0.8602804318153617
best acc:  86.78496091326467

------Epoch: 66------
[batch_idx--0] train_loss: 0.0010878050234168768, acc: 0.88671875, lr: 0.02968453286464312
[batch_idx--50] train_loss: 0.0012573123048972704, acc: 0.8629748774509803, lr: 0.029627499844060053
[batch_idx--100] train_loss: 0.0012684256849248, acc: 0.859375, lr: 0.029570441874636297
[batch_idx--150] train_loss: 0.0012671571261163134, acc: 0.8590904387417219, lr: 0.029513359263995894
[batch_idx--200] train_loss: 0.001263906929609528, acc: 0.8598802860696517, lr: 0.029456252319895716
[batch_idx--250] train_loss: 0.001261200810099889, acc: 0.8605266434262948, lr: 0.029399121350223874
[batch_idx--300] train_loss: 0.001260778071719262, acc: 0.8608025332225914, lr: 0.029341966662997956
[batch_idx--350] train_loss: 0.0012609338955993517, acc: 0.8603432158119658, lr: 0.02928478856636346
[batch_idx--400] train_loss: 0.0012618229714886488, acc: 0.86024197319202, lr: 0.02922758736859208
[batch_idx--450] train_loss: 0.0012674477667399596, acc: 0.8595219911826987, lr: 0.02917036337808005
total time of one epoch: 315.84651732444763 s
train_loss:  0.0012674477667399596  acc:  0.8595219911826987
->>lr:0.029170
test_loss:  0.0012619753809303012  test_acc:  0.8601563469413078
best acc:  86.78496091326467

------Epoch: 67------
[batch_idx--0] train_loss: 0.001109176897443831, acc: 0.8984375, lr: 0.02916921866790256
[batch_idx--50] train_loss: 0.0012803610583182936, acc: 0.8559283088235294, lr: 0.029111971746632322
[batch_idx--100] train_loss: 0.0012835722063935483, acc: 0.8548886138613861, lr: 0.02905470265595496
[batch_idx--150] train_loss: 0.0012804207681918775, acc: 0.8550807119205298, lr: 0.028997411704632756
[batch_idx--200] train_loss: 0.0012741117820430972, acc: 0.8563627176616916, lr: 0.02894009920154584
[batch_idx--250] train_loss: 0.0012699375532018355, acc: 0.8571806523904383, lr: 0.02888276545569057
[batch_idx--300] train_loss: 0.0012688406575254577, acc: 0.8567924626245847, lr: 0.0288254107761778
[batch_idx--350] train_loss: 0.0012694218300781782, acc: 0.8571714743589743, lr: 0.028768035472231265
[batch_idx--400] train_loss: 0.0012668029096284115, acc: 0.8577189837905237, lr: 0.0287106398531859
[batch_idx--450] train_loss: 0.0012742576213295492, acc: 0.8572569167216302, lr: 0.02865322422848614
total time of one epoch: 307.6233289241791 s
train_loss:  0.0012742576213295492  acc:  0.8572569167216302
->>lr:0.028653
test_loss:  0.0012356029918877507  test_acc:  0.865119741903462
best acc:  86.78496091326467

------Epoch: 68------
[batch_idx--0] train_loss: 0.0012144611682742834, acc: 0.87109375, lr: 0.028652075714060296
[batch_idx--50] train_loss: 0.0012554865782423055, acc: 0.8609834558823529, lr: 0.028594640002494582
[batch_idx--100] train_loss: 0.0012749230090325864, acc: 0.857131806930693, lr: 0.028537184910679542
[batch_idx--150] train_loss: 0.0012628798610499956, acc: 0.8574348096026491, lr: 0.028479710748380266
[batch_idx--200] train_loss: 0.001254973526515845, acc: 0.8588891480099502, lr: 0.028422217825464665
[batch_idx--250] train_loss: 0.001256334635733341, acc: 0.8592971862549801, lr: 0.028364706451901797
[batch_idx--300] train_loss: 0.0012572454454909479, acc: 0.8594658430232558, lr: 0.028307176937760206
[batch_idx--350] train_loss: 0.001259572064687108, acc: 0.8591746794871795, lr: 0.028249629593206222
[batch_idx--400] train_loss: 0.0012583064038464405, acc: 0.859180174563591, lr: 0.02819206472850232
[batch_idx--450] train_loss: 0.0012624828451329147, acc: 0.8595306696289097, lr: 0.02813448265400542
total time of one epoch: 310.11075496673584 s
train_loss:  0.0012624828451329147  acc:  0.8595306696289097
->>lr:0.028134
test_loss:  0.0012148750828282534  test_acc:  0.8719444099764239
best acc:  86.78496091326467
Saving..

------Epoch: 69------
[batch_idx--0] train_loss: 0.001039105816744268, acc: 0.89453125, lr: 0.028133330839107608
[batch_idx--50] train_loss: 0.0012674484865319933, acc: 0.8608302696078431, lr: 0.028075731530447786
[batch_idx--100] train_loss: 0.0012656920341691832, acc: 0.8615021658415841, lr: 0.028018115639197247
[batch_idx--150] train_loss: 0.0012627972470325053, acc: 0.8619619205298014, lr: 0.027960483475988025
[batch_idx--200] train_loss: 0.0012701699395538933, acc: 0.8610268967661692, lr: 0.02790283535153988
[batch_idx--250] train_loss: 0.0012645770223306647, acc: 0.8605888944223108, lr: 0.027845171576658636
[batch_idx--300] train_loss: 0.0012610760611014755, acc: 0.8607765780730897, lr: 0.027787492462234484
[batch_idx--350] train_loss: 0.0012589606278684744, acc: 0.8606436965811965, lr: 0.02772979831924033
[batch_idx--400] train_loss: 0.001256653073881323, acc: 0.8607582605985037, lr: 0.02767208945873009
[batch_idx--450] train_loss: 0.0012545497524753624, acc: 0.8613444648870067, lr: 0.027614366191837037
total time of one epoch: 305.89749789237976 s
train_loss:  0.0012545497524753624  acc:  0.8613444648870067
->>lr:0.027614
test_loss:  0.001246732334327958  test_acc:  0.8620176200521157
best acc:  87.19444099764239

------Epoch: 70------
[batch_idx--0] train_loss: 0.0012833147775381804, acc: 0.859375, lr: 0.02761321158169134
[batch_idx--50] train_loss: 0.0012416660091748425, acc: 0.8642769607843137, lr: 0.027555473940897853
[batch_idx--100] train_loss: 0.0012356072063742223, acc: 0.8642868193069307, lr: 0.027497722522445946
[batch_idx--150] train_loss: 0.0012358788532723013, acc: 0.8636951572847682, lr: 0.027439957637698322
[batch_idx--200] train_loss: 0.0012419593572009595, acc: 0.8619402985074627, lr: 0.027382179598090313
[batch_idx--250] train_loss: 0.0012420046294434554, acc: 0.8618806025896414, lr: 0.027324388715128153
[batch_idx--300] train_loss: 0.0012400140133036605, acc: 0.8617758513289037, lr: 0.027266585300387343
[batch_idx--350] train_loss: 0.0012449929243593114, acc: 0.8604211182336182, lr: 0.027208769665510946
[batch_idx--400] train_loss: 0.001247533345496296, acc: 0.8601543017456359, lr: 0.027150942122207884
[batch_idx--450] train_loss: 0.0012507199635617657, acc: 0.860068733293991, lr: 0.027093102982251305
total time of one epoch: 309.32397747039795 s
train_loss:  0.0012507199635617657  acc:  0.860068733293991
->>lr:0.027093
test_loss:  0.0012632184066197346  test_acc:  0.8599081771932001
best acc:  87.19444099764239

------Epoch: 71------
[batch_idx--0] train_loss: 0.001364035764709115, acc: 0.84375, lr: 0.02709194608330789
[batch_idx--50] train_loss: 0.0012610647918692992, acc: 0.8602175245098039, lr: 0.027034095436018247
[batch_idx--100] train_loss: 0.0012520311762219166, acc: 0.8592202970297029, lr: 0.026976233822045795
[batch_idx--150] train_loss: 0.0012527276208278853, acc: 0.8608236754966887, lr: 0.026918361553347366
[batch_idx--200] train_loss: 0.0012430978935462102, acc: 0.8621152052238806, lr: 0.026860478941937244
[batch_idx--250] train_loss: 0.001242768335289719, acc: 0.8621762948207171, lr: 0.026802586299885446
[batch_idx--300] train_loss: 0.001251216764728913, acc: 0.860906353820598, lr: 0.026744683939316106
[batch_idx--350] train_loss: 0.0012516141345092968, acc: 0.8609107905982906, lr: 0.026686772172405743
[batch_idx--400] train_loss: 0.0012474904795458303, acc: 0.8609920511221946, lr: 0.02662885131138157
[batch_idx--450] train_loss: 0.0012485791629725197, acc: 0.8615093553650155, lr: 0.026570921668519862
total time of one epoch: 311.4623637199402 s
train_loss:  0.0012485791629725197  acc:  0.8615093553650155
->>lr:0.026571
test_loss:  0.0012468725335643847  test_acc:  0.8631343839186003
best acc:  87.19444099764239

------Epoch: 72------
[batch_idx--0] train_loss: 0.0010713932570070028, acc: 0.87109375, lr: 0.026569762988232833
[batch_idx--50] train_loss: 0.001280664822415394, acc: 0.8572303921568627, lr: 0.026511824709652916
[batch_idx--100] train_loss: 0.0012506205141359923, acc: 0.8609993811881188, lr: 0.02645387828017616
[batch_idx--150] train_loss: 0.0012449906492877185, acc: 0.8622723509933775, lr: 0.026395924012216673
[batch_idx--200] train_loss: 0.001242843515063585, acc: 0.8630286069651741, lr: 0.02633796221823084
[batch_idx--250] train_loss: 0.0012451016772686843, acc: 0.8626743027888446, lr: 0.026279993210715575
[batch_idx--300] train_loss: 0.0012426843800569616, acc: 0.8628789451827242, lr: 0.026222017302206753
[batch_idx--350] train_loss: 0.0012407646347978218, acc: 0.8627804487179487, lr: 0.02616403480527739
[batch_idx--400] train_loss: 0.0012416997574620468, acc: 0.8625019482543641, lr: 0.02610604603253605
[batch_idx--450] train_loss: 0.001242148469792529, acc: 0.862828479189086, lr: 0.026048051296625147
total time of one epoch: 308.8454658985138 s
train_loss:  0.001242148469792529  acc:  0.862828479189086
->>lr:0.026048
test_loss:  0.001295276604688024  test_acc:  0.857426479712123
best acc:  87.19444099764239

------Epoch: 73------
[batch_idx--0] train_loss: 0.0011059683747589588, acc: 0.875, lr: 0.02604689134322999
[batch_idx--50] train_loss: 0.0012268541556527362, acc: 0.8623621323529411, lr: 0.025988890847003655
[batch_idx--100] train_loss: 0.0012161278812500584, acc: 0.8650216584158416, lr: 0.025930885019241706
[batch_idx--150] train_loss: 0.0012188820582382776, acc: 0.8651179635761589, lr: 0.025872874172678507
[batch_idx--200] train_loss: 0.0012273321948153204, acc: 0.8640780472636815, lr: 0.02581485862007545
[batch_idx--250] train_loss: 0.001234752460442246, acc: 0.8625964890438247, lr: 0.02575683867421932
[batch_idx--300] train_loss: 0.0012384473372860332, acc: 0.8624117524916943, lr: 0.02569881464792059
[batch_idx--350] train_loss: 0.0012384975601672234, acc: 0.8622240028490028, lr: 0.02564078685401172
[batch_idx--400] train_loss: 0.0012395547521753501, acc: 0.8621025561097256, lr: 0.025582755605345495
[batch_idx--450] train_loss: 0.001241763037966851, acc: 0.8621428819384177, lr: 0.02552472121479332
total time of one epoch: 308.3006248474121 s
train_loss:  0.001241763037966851  acc:  0.8621428819384177
->>lr:0.025525
test_loss:  0.001198497225620238  test_acc:  0.8718203251023701
best acc:  87.19444099764239

------Epoch: 74------
[batch_idx--0] train_loss: 0.0011158623965457082, acc: 0.87890625, lr: 0.025523560497083927
[batch_idx--50] train_loss: 0.0012296496698742405, acc: 0.8616727941176471, lr: 0.025465523224145754
[batch_idx--100] train_loss: 0.0012491321799778703, acc: 0.8604965965346535, lr: 0.02540748344137178
[batch_idx--150] train_loss: 0.0012392131762042494, acc: 0.8620395281456954, lr: 0.02534944146167944
[batch_idx--200] train_loss: 0.001240255433917787, acc: 0.8620957711442786, lr: 0.025291397597997967
[batch_idx--250] train_loss: 0.0012391101169136475, acc: 0.8623786105577689, lr: 0.025233352163266793
[batch_idx--300] train_loss: 0.0012389396532342778, acc: 0.8623857973421927, lr: 0.025175305470433812
[batch_idx--350] train_loss: 0.0012403097601695002, acc: 0.8622796474358975, lr: 0.025117257832453683
[batch_idx--400] train_loss: 0.00124064013736434, acc: 0.8622778990024937, lr: 0.025059209562286185
[batch_idx--450] train_loss: 0.0012467650779851974, acc: 0.8624032353247475, lr: 0.02500116097289448
total time of one epoch: 305.7167453765869 s
train_loss:  0.0012467650779851974  acc:  0.8624032353247475
->>lr:0.025001
test_loss:  0.001188552258313183  test_acc:  0.8749224469537163
best acc:  87.19444099764239
Saving..

------Epoch: 75------
[batch_idx--0] train_loss: 0.0011694206623360515, acc: 0.85546875, lr: 0.025
[batch_idx--50] train_loss: 0.0012455723424186454, acc: 0.8609834558823529, lr: 0.024941951407416053
[batch_idx--100] train_loss: 0.0012492758336034374, acc: 0.8588722153465347, lr: 0.024883903127797022
[batch_idx--150] train_loss: 0.0012403118060994277, acc: 0.8605391142384106, lr: 0.02482585547410613
[batch_idx--200] train_loss: 0.0012270893237845443, acc: 0.8627759639303483, lr: 0.024767808759303227
[batch_idx--250] train_loss: 0.0012325120679811533, acc: 0.8630789342629482, lr: 0.024709763296343102
[batch_idx--300] train_loss: 0.0012301228392445343, acc: 0.8637484426910299, lr: 0.024651719398173802
[batch_idx--350] train_loss: 0.0012306555433323518, acc: 0.8636818910256411, lr: 0.024593677377734924
[batch_idx--400] train_loss: 0.0012330755217179674, acc: 0.8633104738154613, lr: 0.02453563754795596
[batch_idx--450] train_loss: 0.001236625634009411, acc: 0.8631148679140487, lr: 0.024477600221754565
total time of one epoch: 311.66377449035645 s
train_loss:  0.001236625634009411  acc:  0.8631148679140487
->>lr:0.024478
test_loss:  0.0012040475263446477  test_acc:  0.8707035612358853
best acc:  87.49224469537164

------Epoch: 76------
[batch_idx--0] train_loss: 0.0011736570158973336, acc: 0.87890625, lr: 0.02447643950291608
[batch_idx--50] train_loss: 0.0012225377368832043, acc: 0.8656556372549019, lr: 0.024418405052717584
[batch_idx--100] train_loss: 0.0012261568093764605, acc: 0.8650603341584159, lr: 0.024360373738147447
[batch_idx--150] train_loss: 0.0012274693897370225, acc: 0.8642901490066225, lr: 0.024302345872077406
[batch_idx--200] train_loss: 0.0012311924324806464, acc: 0.8644861629353234, lr: 0.024244321767360646
[batch_idx--250] train_loss: 0.0012245574844092042, acc: 0.8649153386454184, lr: 0.024186301736830045
[batch_idx--300] train_loss: 0.0012300070477695981, acc: 0.8639041735880398, lr: 0.024128286093296536
[batch_idx--350] train_loss: 0.0012322817224295454, acc: 0.8635372150997151, lr: 0.02407027514954738
[batch_idx--400] train_loss: 0.0012330171522078222, acc: 0.8638072786783042, lr: 0.024012269218344526
[batch_idx--450] train_loss: 0.0012361795011731037, acc: 0.8635748255632312, lr: 0.023954268612422863
total time of one epoch: 315.6641800403595 s
train_loss:  0.0012361795011731037  acc:  0.8635748255632312
->>lr:0.023954
test_loss:  0.0012363754485585077  test_acc:  0.8677255242585928
best acc:  87.49224469537164

------Epoch: 77------
[batch_idx--0] train_loss: 0.001251721172593534, acc: 0.84375, lr: 0.02395310865677001
[batch_idx--50] train_loss: 0.0012303518688342736, acc: 0.8638939950980392, lr: 0.023895113804784887
[batch_idx--100] train_loss: 0.0012235881381502172, acc: 0.8640160891089109, lr: 0.02383712490971616
[batch_idx--150] train_loss: 0.001214575537847392, acc: 0.8657646937086093, lr: 0.023779142284206876
[batch_idx--200] train_loss: 0.0012232836362539759, acc: 0.8649137126865671, lr: 0.023721166240866298
[batch_idx--250] train_loss: 0.001225243657187325, acc: 0.8646974601593626, lr: 0.0236631970922682
[batch_idx--300] train_loss: 0.0012267743362240691, acc: 0.864280523255814, lr: 0.023605235150949158
[batch_idx--350] train_loss: 0.00122469143167223, acc: 0.8646055911680912, lr: 0.02354728072940694
[batch_idx--400] train_loss: 0.0012241653846042635, acc: 0.8648983011221946, lr: 0.02348933414009873
[batch_idx--450] train_loss: 0.001228240354967311, acc: 0.8648939493873017, lr: 0.02343139569543949
total time of one epoch: 311.60961079597473 s
train_loss:  0.001228240354967311  acc:  0.8648939493873017
->>lr:0.023431
test_loss:  0.0012385032175196388  test_acc:  0.8688422881250776
best acc:  87.49224469537164

------Epoch: 78------
[batch_idx--0] train_loss: 0.0011907384032383561, acc: 0.8671875, lr: 0.023430237011767167
[batch_idx--50] train_loss: 0.0012577770234487367, acc: 0.8602941176470589, lr: 0.02337230719645424
[batch_idx--100] train_loss: 0.0012393174168543134, acc: 0.8621596534653465, lr: 0.023314386156732855
[batch_idx--150] train_loss: 0.0012353299650523985, acc: 0.8618584437086093, lr: 0.023256474204880216
[batch_idx--200] train_loss: 0.0012307418741990084, acc: 0.8630286069651741, lr: 0.023198571653124563
[batch_idx--250] train_loss: 0.001224351322614176, acc: 0.864277265936255, lr: 0.02314067881364343
[batch_idx--300] train_loss: 0.0012283402271151072, acc: 0.8636705772425249, lr: 0.02308279599856199
[batch_idx--350] train_loss: 0.0012301047487805288, acc: 0.8634481837606838, lr: 0.023024923519951404
[batch_idx--400] train_loss: 0.0012279575922296492, acc: 0.8640021041147132, lr: 0.02296706168982706
[batch_idx--450] train_loss: 0.0012321185449805376, acc: 0.8641389245669455, lr: 0.022909210820146964
total time of one epoch: 311.72348713874817 s
train_loss:  0.0012321185449805376  acc:  0.8641389245669455
->>lr:0.022909
test_loss:  0.0012054391235819465  test_acc:  0.8754187864499318
best acc:  87.49224469537164
Saving..

------Epoch: 79------
[batch_idx--0] train_loss: 0.0012283849064260721, acc: 0.859375, lr: 0.022908053916692112
[batch_idx--50] train_loss: 0.001179889084168655, acc: 0.8697916666666666, lr: 0.022850214547982983
[batch_idx--100] train_loss: 0.0012088481971929495, acc: 0.8677289603960396, lr: 0.022792386769691267
[batch_idx--150] train_loss: 0.0012141753042838382, acc: 0.8674203228476821, lr: 0.022734570893591363
[batch_idx--200] train_loss: 0.0012276258770798087, acc: 0.8655939054726368, lr: 0.022676767231393526
[batch_idx--250] train_loss: 0.0012251500996197035, acc: 0.8652888446215139, lr: 0.02261897609474213
[batch_idx--300] train_loss: 0.0012236471454987296, acc: 0.865422549833887, lr: 0.022561197795214035
[batch_idx--350] train_loss: 0.0012199502667820776, acc: 0.8660300925925926, lr: 0.022503432644316902
[batch_idx--400] train_loss: 0.0012187884268153486, acc: 0.8657068266832918, lr: 0.022445680953487472
[batch_idx--450] train_loss: 0.0012217962869774089, acc: 0.865475405283438, lr: 0.022387943034089947
total time of one epoch: 308.51732110977173 s
train_loss:  0.0012217962869774089  acc:  0.865475405283438
->>lr:0.022388
test_loss:  0.0012203466731008873  test_acc:  0.8678496091326467
best acc:  87.54187864499318

------Epoch: 80------
[batch_idx--0] train_loss: 0.0012462000595405698, acc: 0.86328125, lr: 0.022386788418308663
[batch_idx--50] train_loss: 0.001245899487734206, acc: 0.8630514705882353, lr: 0.022329064866462054
[batch_idx--100] train_loss: 0.0012308059353611921, acc: 0.8632425742574258, lr: 0.022271355714774788
[batch_idx--150] train_loss: 0.0012317325519737078, acc: 0.8630225579470199, lr: 0.022213661274381714
[batch_idx--200] train_loss: 0.001231917344318675, acc: 0.8636699315920398, lr: 0.022155981856338363
[batch_idx--250] train_loss: 0.0012197620919497454, acc: 0.8654133466135459, lr: 0.022098317771619257
[batch_idx--300] train_loss: 0.001223291039344641, acc: 0.8644102990033222, lr: 0.022040669331116272
[batch_idx--350] train_loss: 0.0012184260069774704, acc: 0.8653623575498576, lr: 0.021983036845636923
[batch_idx--400] train_loss: 0.0012213996444025224, acc: 0.8651807980049875, lr: 0.02192542062590272
[batch_idx--450] train_loss: 0.0012246829448173092, acc: 0.8650761967577325, lr: 0.02186782098254747
total time of one epoch: 309.2931430339813 s
train_loss:  0.0012246829448173092  acc:  0.8650761967577325
->>lr:0.021868
test_loss:  0.0012255775557216365  test_acc:  0.8647474872813005
best acc:  87.54187864499318

------Epoch: 81------
[batch_idx--0] train_loss: 0.0012170671252533793, acc: 0.87890625, lr: 0.02186666916089239
[batch_idx--50] train_loss: 0.0012336956455792282, acc: 0.8625919117647058, lr: 0.021809086745365924
[batch_idx--100] train_loss: 0.0012166993865411323, acc: 0.865833849009901, lr: 0.021751521533424346
[batch_idx--150] train_loss: 0.0012172445028847613, acc: 0.8655836092715232, lr: 0.021693973835426473
[batch_idx--200] train_loss: 0.0012206712993098172, acc: 0.8654967350746269, lr: 0.021636443961636685
[batch_idx--250] train_loss: 0.0012212322321738973, acc: 0.8653510956175299, lr: 0.021578932222223245
[batch_idx--300] train_loss: 0.0012154063026952957, acc: 0.8660844061461794, lr: 0.021521438927256664
[batch_idx--350] train_loss: 0.001215637341623282, acc: 0.8659521901709402, lr: 0.021463964386708015
[batch_idx--400] train_loss: 0.0012137388122184412, acc: 0.8660477711970075, lr: 0.021406508910447243
[batch_idx--450] train_loss: 0.0012167960036273517, acc: 0.8660828965182074, lr: 0.021349072808241526
total time of one epoch: 309.23897790908813 s
train_loss:  0.0012167960036273517  acc:  0.8660828965182074
->>lr:0.021349
test_loss:  0.0012000068321404349  test_acc:  0.8730611738429086
best acc:  87.54187864499318

------Epoch: 82------
[batch_idx--0] train_loss: 0.0010096647311002016, acc: 0.87890625, lr: 0.021347924285939714
[batch_idx--50] train_loss: 0.0012069206351560413, acc: 0.8678002450980392, lr: 0.02129050826428394
[batch_idx--100] train_loss: 0.001211212325546116, acc: 0.8686958539603961, lr: 0.021233112242092567
[batch_idx--150] train_loss: 0.0012037000527901464, acc: 0.8684292218543046, lr: 0.02117573652881221
[batch_idx--200] train_loss: 0.0012170573385474064, acc: 0.8659437189054726, lr: 0.02111838143378
[batch_idx--250] train_loss: 0.0012177175436859052, acc: 0.8654911603585658, lr: 0.021061047266221912
[batch_idx--300] train_loss: 0.0012122298709961565, acc: 0.8658248546511628, lr: 0.021003734335251087
[batch_idx--350] train_loss: 0.001210181268251785, acc: 0.8657296118233618, lr: 0.020946442949866164
[batch_idx--400] train_loss: 0.0012106596594711214, acc: 0.8657263092269327, lr: 0.020889173418949643
[batch_idx--450] train_loss: 0.0012146142510965647, acc: 0.8658399000242997, lr: 0.020831926051266162
total time of one epoch: 308.91467022895813 s
train_loss:  0.0012146142510965647  acc:  0.8658399000242997
->>lr:0.020832
test_loss:  0.001194312504731569  test_acc:  0.8705794763618315
best acc:  87.54187864499318

------Epoch: 83------
[batch_idx--0] train_loss: 0.0012147711822763085, acc: 0.875, lr: 0.020830781332097453
[batch_idx--50] train_loss: 0.0012017112458124757, acc: 0.8689491421568627, lr: 0.020773556888877096
[batch_idx--100] train_loss: 0.0012085588780314763, acc: 0.8672261757425742, lr: 0.020716355232228204
[batch_idx--150] train_loss: 0.001211170169188709, acc: 0.8673427152317881, lr: 0.020659176670549492
[batch_idx--200] train_loss: 0.0012041644314280827, acc: 0.8675373134328358, lr: 0.020602021512115154
[batch_idx--250] train_loss: 0.0011952725184368957, acc: 0.8686348356573705, lr: 0.02054489006507322
[batch_idx--300] train_loss: 0.001192930840811324, acc: 0.8690562707641196, lr: 0.02048778263744388
[batch_idx--350] train_loss: 0.0012020171516139771, acc: 0.8679331374643875, lr: 0.02043069953711782
[batch_idx--400] train_loss: 0.0012051058714533517, acc: 0.8676745635910225, lr: 0.020373641071854572
[batch_idx--450] train_loss: 0.0012059067800285692, acc: 0.8680615822543132, lr: 0.020316607549280843
total time of one epoch: 310.67638087272644 s
train_loss:  0.0012059067800285692  acc:  0.8680615822543132
->>lr:0.020317
test_loss:  0.0011603493506477376  test_acc:  0.8776523141829011
best acc:  87.54187864499318
Saving..

------Epoch: 84------
[batch_idx--0] train_loss: 0.0011099213734269142, acc: 0.87890625, lr: 0.020315467135356893
[batch_idx--50] train_loss: 0.0012456061884614767, acc: 0.8607536764705882, lr: 0.02025845937110404
[batch_idx--100] train_loss: 0.0012166854668417854, acc: 0.8641707920792079, lr: 0.020201477170534773
[batch_idx--150] train_loss: 0.0012008457873263303, acc: 0.8668770695364238, lr: 0.020144520840864624
[batch_idx--200] train_loss: 0.0012032326408754571, acc: 0.8662157960199005, lr: 0.02008759068916964
[batch_idx--250] train_loss: 0.0012020021707164607, acc: 0.866253735059761, lr: 0.020030687022384752
[batch_idx--300] train_loss: 0.0011999868276139159, acc: 0.8667722176079734, lr: 0.019973810147302068
[batch_idx--350] train_loss: 0.0012021158669977064, acc: 0.8667312143874644, lr: 0.01991696037056928
[batch_idx--400] train_loss: 0.0011999155400539202, acc: 0.8666712125935162, lr: 0.01986013799868798
[batch_idx--450] train_loss: 0.001204253390100865, acc: 0.8666383170757108, lr: 0.01980334333801198
total time of one epoch: 310.19017148017883 s
train_loss:  0.001204253390100865  acc:  0.8666383170757108
->>lr:0.019803
test_loss:  0.0011842397986577837  test_acc:  0.8738056830872317
best acc:  87.76523141829011

------Epoch: 85------
[batch_idx--0] train_loss: 0.0012274625478312373, acc: 0.86328125, lr: 0.019802207729556022
[batch_idx--50] train_loss: 0.0011876024894745035, acc: 0.8696384803921569, lr: 0.0197454416497602
[batch_idx--100] train_loss: 0.001174933943865212, acc: 0.8712871287128713, lr: 0.019688703899547008
[batch_idx--150] train_loss: 0.0011903705790065327, acc: 0.8693346440397351, lr: 0.01963199478481404
[batch_idx--200] train_loss: 0.001193422946930673, acc: 0.8683924129353234, lr: 0.019575314611304503
[batch_idx--250] train_loss: 0.0011902105972723686, acc: 0.8685725846613546, lr: 0.019518663684605593
[batch_idx--300] train_loss: 0.0011928118784692249, acc: 0.8683814368770764, lr: 0.01946204231014678
[batch_idx--350] train_loss: 0.0011873123565346447, acc: 0.8693019943019943, lr: 0.019405450793198248
[batch_idx--400] train_loss: 0.0011892267813478734, acc: 0.869184460723192, lr: 0.01934888943886919
[batch_idx--450] train_loss: 0.0011961903638645556, acc: 0.8684868261186517, lr: 0.019292358552106172
total time of one epoch: 309.0817301273346 s
train_loss:  0.0011961903638645556  acc:  0.8684868261186517
->>lr:0.019292
test_loss:  0.0012417322375783554  test_acc:  0.867601439384539
best acc:  87.76523141829011

------Epoch: 86------
[batch_idx--0] train_loss: 0.0015174600994214416, acc: 0.828125, lr: 0.019291228247233613
[batch_idx--50] train_loss: 0.0012162334865470435, acc: 0.8633578431372549, lr: 0.019234728751373553
[batch_idx--100] train_loss: 0.0011953297682051169, acc: 0.8679610148514851, lr: 0.01917826033856888
[batch_idx--150] train_loss: 0.0011900284424707886, acc: 0.8689207367549668, lr: 0.019121823313265066
[batch_idx--200] train_loss: 0.001190186993957993, acc: 0.8690531716417911, lr: 0.01906541797973838
[batch_idx--250] train_loss: 0.00118682920061742, acc: 0.8694285358565738, lr: 0.01900904464209422
[batch_idx--300] train_loss: 0.001192217660824957, acc: 0.8684982350498339, lr: 0.018952703604265476
[batch_idx--350] train_loss: 0.001192273239258868, acc: 0.8683671652421653, lr: 0.018896395170010898
[batch_idx--400] train_loss: 0.00119106443958854, acc: 0.868619466957606, lr: 0.01884011964291346
[batch_idx--450] train_loss: 0.001194773300135732, acc: 0.8686864303815045, lr: 0.018783877326378724
total time of one epoch: 312.783328294754 s
train_loss:  0.001194773300135732  acc:  0.8686864303815045
->>lr:0.018784
test_loss:  0.0011646491612345516  test_acc:  0.8729370889688547
best acc:  87.76523141829011

------Epoch: 87------
[batch_idx--0] train_loss: 0.0011187135241925716, acc: 0.859375, lr: 0.018782752820878636
[batch_idx--50] train_loss: 0.0011746860657106427, acc: 0.8702512254901961, lr: 0.018726544691500546
[batch_idx--100] train_loss: 0.0011822917351111918, acc: 0.8695467202970297, lr: 0.01867037038501655
[batch_idx--150] train_loss: 0.0011883139577910107, acc: 0.8694381208609272, lr: 0.018614230204286455
[batch_idx--200] train_loss: 0.0011883028339830907, acc: 0.869014303482587, lr: 0.018558124451986114
[batch_idx--250] train_loss: 0.0011873128520143014, acc: 0.8694440986055777, lr: 0.018502053430605753
[batch_idx--300] train_loss: 0.0011875612200609102, acc: 0.8691341362126246, lr: 0.01844601744244835
[batch_idx--350] train_loss: 0.0011822169975303327, acc: 0.8702368233618234, lr: 0.018390016789628004
[batch_idx--400] train_loss: 0.0011772651408515648, acc: 0.8708599594763092, lr: 0.018334051774068303
[batch_idx--450] train_loss: 0.0011842355299441657, acc: 0.8703787273926477, lr: 0.0182781226975007
total time of one epoch: 306.9912588596344 s
train_loss:  0.0011842355299441657  acc:  0.8703787273926477
->>lr:0.018278
test_loss:  0.00117758378702678  test_acc:  0.8713239856061546
best acc:  87.76523141829011

------Epoch: 88------
[batch_idx--0] train_loss: 0.0011864170664921403, acc: 0.875, lr: 0.01827700448461836
[batch_idx--50] train_loss: 0.001209696292575887, acc: 0.8669577205882353, lr: 0.018221112376465492
[batch_idx--100] train_loss: 0.0011999095769340891, acc: 0.867496905940594, lr: 0.018165256816209563
[batch_idx--150] train_loss: 0.0011896288314593698, acc: 0.8688172599337748, lr: 0.018109438104991903
[batch_idx--200] train_loss: 0.0011936799881965923, acc: 0.8687810945273632, lr: 0.01805365654375518
[batch_idx--250] train_loss: 0.0011903858795554276, acc: 0.8690083416334662, lr: 0.017997912433241763
[batch_idx--300] train_loss: 0.0011894168514770724, acc: 0.8684463247508306, lr: 0.017942206073992117
[batch_idx--350] train_loss: 0.0011908886348895008, acc: 0.8684228098290598, lr: 0.017886537766343167
[batch_idx--400] train_loss: 0.0011943782558676292, acc: 0.8681908509975063, lr: 0.017830907810426684
[batch_idx--450] train_loss: 0.0011965114370231045, acc: 0.8686430381504495, lr: 0.017775316506167683
total time of one epoch: 310.9821436405182 s
train_loss:  0.0011965114370231045  acc:  0.8686430381504495
->>lr:0.017775
test_loss:  0.0011601131379360271  test_acc:  0.8749224469537163
best acc:  87.76523141829011

------Epoch: 89------
[batch_idx--0] train_loss: 0.0011952248169109225, acc: 0.8671875, lr: 0.017774205076388213
[batch_idx--50] train_loss: 0.0012036716056458069, acc: 0.8670343137254902, lr: 0.017718653505586445
[batch_idx--100] train_loss: 0.0011961621440956278, acc: 0.8694693688118812, lr: 0.01766314119165336
[batch_idx--150] train_loss: 0.0011880131140012073, acc: 0.8689983443708609, lr: 0.017607668433879703
[batch_idx--200] train_loss: 0.0011828095873410059, acc: 0.8698111007462687, lr: 0.017552235531342955
[batch_idx--250] train_loss: 0.0011880335263978407, acc: 0.8692884711155379, lr: 0.017496842782905715
[batch_idx--300] train_loss: 0.0011862960115749624, acc: 0.8694196428571429, lr: 0.017441490487214106
[batch_idx--350] train_loss: 0.0011863095197956637, acc: 0.8692463497150997, lr: 0.017386178942696135
[batch_idx--400] train_loss: 0.0011892362397298811, acc: 0.868794809850374, lr: 0.01733090844756013
[batch_idx--450] train_loss: 0.0011940998960117358, acc: 0.8686777519352935, lr: 0.017275679299793074
total time of one epoch: 309.263959646225 s
train_loss:  0.0011940998960117358  acc:  0.8686777519352935
->>lr:0.017276
test_loss:  0.0011570931446139578  test_acc:  0.8764114654423626
best acc:  87.76523141829011

------Epoch: 90------
[batch_idx--0] train_loss: 0.0009493209072388709, acc: 0.890625, lr: 0.017274575140626316
[batch_idx--50] train_loss: 0.0011869870906914858, acc: 0.8701746323529411, lr: 0.017219388473930602
[batch_idx--100] train_loss: 0.0011890945710601414, acc: 0.8691599628712872, lr: 0.017164243755855953
[batch_idx--150] train_loss: 0.0011735693000361866, acc: 0.8704728890728477, lr: 0.017109141283711254
[batch_idx--200] train_loss: 0.0011776436391907434, acc: 0.8700831778606966, lr: 0.0170540813545776
[batch_idx--250] train_loss: 0.0011767263946761619, acc: 0.8702066733067729, lr: 0.016999064265306747
[batch_idx--300] train_loss: 0.0011732739545683379, acc: 0.8706135797342193, lr: 0.016944090312519478
[batch_idx--350] train_loss: 0.001174353751980108, acc: 0.870414886039886, lr: 0.01688915979260398
[batch_idx--400] train_loss: 0.0011747158833598239, acc: 0.8706261689526185, lr: 0.016834273001714316
[batch_idx--450] train_loss: 0.0011860329819312384, acc: 0.8697885930503003, lr: 0.016779430235768767
total time of one epoch: 310.0131525993347 s
train_loss:  0.0011860329819312384  acc:  0.8697885930503003
->>lr:0.016779
test_loss:  0.0011518244996883242  test_acc:  0.8780245688050626
best acc:  87.76523141829011
Saving..

------Epoch: 91------
[batch_idx--0] train_loss: 0.0011663883924484253, acc: 0.8828125, lr: 0.01677833383153542
[batch_idx--50] train_loss: 0.0011794062504800512, acc: 0.8694852941176471, lr: 0.016723536275641708
[batch_idx--100] train_loss: 0.00117908133479702, acc: 0.8701268564356436, lr: 0.01666878334172139
[batch_idx--150] train_loss: 0.0011792453507035478, acc: 0.8696192052980133, lr: 0.01661407532497108
[batch_idx--200] train_loss: 0.0011830703704038736, acc: 0.8689560012437811, lr: 0.016559412520345193
[batch_idx--250] train_loss: 0.001175463197064545, acc: 0.8702066733067729, lr: 0.016504795222554415
[batch_idx--300] train_loss: 0.0011745116741480027, acc: 0.8706784676079734, lr: 0.01645022372606408
[batch_idx--350] train_loss: 0.0011744776042841608, acc: 0.8707710113960114, lr: 0.01639569832509256
[batch_idx--400] train_loss: 0.0011730520385654266, acc: 0.8708599594763092, lr: 0.016341219313609757
[batch_idx--450] train_loss: 0.001177870171659876, acc: 0.8707605790259312, lr: 0.01628678698533542
total time of one epoch: 307.69465494155884 s
train_loss:  0.001177870171659876  acc:  0.8707605790259312
->>lr:0.016287
test_loss:  0.0011562158417533091  test_acc:  0.8782727385531703
best acc:  87.80245688050627
Saving..

------Epoch: 92------
[batch_idx--0] train_loss: 0.0010261452989652753, acc: 0.8984375, lr: 0.016285698816954627
[batch_idx--50] train_loss: 0.0011527724689621404, acc: 0.875, lr: 0.016231314407882003
[batch_idx--100] train_loss: 0.0011724440863881591, acc: 0.8715578589108911, lr: 0.016176977274562434
[batch_idx--150] train_loss: 0.0011627671859282631, acc: 0.8725424254966887, lr: 0.016122687709950775
[batch_idx--200] train_loss: 0.0011673774428327397, acc: 0.8720460199004975, lr: 0.01606844600674539
[batch_idx--250] train_loss: 0.0011653417857749708, acc: 0.8721364541832669, lr: 0.016014252457386614
[batch_idx--300] train_loss: 0.0011674439388735722, acc: 0.8717945390365448, lr: 0.015960107354055172
[batch_idx--350] train_loss: 0.0011684789268918165, acc: 0.8718282585470085, lr: 0.01590601098867059
[batch_idx--400] train_loss: 0.0011706841213075894, acc: 0.8714054706982544, lr: 0.015851963652889624
[batch_idx--450] train_loss: 0.001170380138445038, acc: 0.8720276321727358, lr: 0.015797965638104688
total time of one epoch: 309.2418637275696 s
train_loss:  0.001170380138445038  acc:  0.8720276321727358
->>lr:0.015798
test_loss:  0.001176255520186807  test_acc:  0.8721925797245316
best acc:  87.82727385531703

------Epoch: 93------
[batch_idx--0] train_loss: 0.0010274831438437104, acc: 0.89453125, lr: 0.01579688618288306
[batch_idx--50] train_loss: 0.0012007607911786466, acc: 0.8670343137254902, lr: 0.01574293877543077
[batch_idx--100] train_loss: 0.0011752000721724758, acc: 0.8709777227722773, lr: 0.015689041276774486
[batch_idx--150] train_loss: 0.0011796992197355242, acc: 0.8701624586092715, lr: 0.015635193977498796
[batch_idx--200] train_loss: 0.001173356258650936, acc: 0.8702192164179104, lr: 0.015581397167917649
[batch_idx--250] train_loss: 0.0011752397928153169, acc: 0.8703467380478087, lr: 0.01552765113807274
[batch_idx--300] train_loss: 0.0011733410681947522, acc: 0.870328073089701, lr: 0.015473956177732033
[batch_idx--350] train_loss: 0.001173751043325603, acc: 0.8705818198005698, lr: 0.01542031257638813
[batch_idx--400] train_loss: 0.001170109312962787, acc: 0.871181421446384, lr: 0.015366720623256752
[batch_idx--450] train_loss: 0.0011730346620883597, acc: 0.8711077168743708, lr: 0.015313180607275165
total time of one epoch: 312.2092604637146 s
train_loss:  0.0011730346620883597  acc:  0.8711077168743708
->>lr:0.015313
test_loss:  0.0011619461712107674  test_acc:  0.8752947015758779
best acc:  87.82727385531703

------Epoch: 94------
[batch_idx--0] train_loss: 0.0013721006689593196, acc: 0.83203125, lr: 0.015312110338697428
[batch_idx--50] train_loss: 0.001158750398020607, acc: 0.8723192401960784, lr: 0.015258623595981367
[batch_idx--100] train_loss: 0.0011749815323740466, acc: 0.8705136138613861, lr: 0.015205189373212608
[batch_idx--150] train_loss: 0.0011709456745263756, acc: 0.8703435430463576, lr: 0.015151807958478031
[batch_idx--200] train_loss: 0.0011649185528663632, acc: 0.8708411069651741, lr: 0.015098479639579785
[batch_idx--250] train_loss: 0.0011654105563870672, acc: 0.8721675796812749, lr: 0.015045204704033754
[batch_idx--300] train_loss: 0.0011644704440265175, acc: 0.872326619601329, lr: 0.01499198343906803
[batch_idx--350] train_loss: 0.0011644904611849802, acc: 0.8720619658119658, lr: 0.014938816131621303
[batch_idx--400] train_loss: 0.0011660722905927874, acc: 0.8718048628428927, lr: 0.014885703068341395
[batch_idx--450] train_loss: 0.0011698848313112429, acc: 0.8719495261568369, lr: 0.014832644535583656
total time of one epoch: 310.5096106529236 s
train_loss:  0.0011698848313112429  acc:  0.8719495261568369
->>lr:0.014833
test_loss:  0.001191429805853243  test_acc:  0.8729370889688547
best acc:  87.82727385531703

------Epoch: 95------
[batch_idx--0] train_loss: 0.0010865663643926382, acc: 0.8828125, lr: 0.014831583923105
[batch_idx--50] train_loss: 0.0011808453230461216, acc: 0.8720128676470589, lr: 0.014778581306178257
[batch_idx--100] train_loss: 0.0011757777474756066, acc: 0.872756806930693, lr: 0.014725633797313148
[batch_idx--150] train_loss: 0.001173723115900297, acc: 0.8730080711920529, lr: 0.014672741681972468
[batch_idx--200] train_loss: 0.0011639209827338693, acc: 0.8740282960199005, lr: 0.01461990524532032
[batch_idx--250] train_loss: 0.001156150163717167, acc: 0.8751245019920318, lr: 0.014567124772220653
[batch_idx--300] train_loss: 0.0011563583981459248, acc: 0.8750908430232558, lr: 0.014514400547235684
[batch_idx--350] train_loss: 0.001156055983726434, acc: 0.8745548433048433, lr: 0.014461732854624376
[batch_idx--400] train_loss: 0.0011547436481028181, acc: 0.8744544887780549, lr: 0.014409121978340905
[batch_idx--450] train_loss: 0.0011628634514357012, acc: 0.8735637171520811, lr: 0.014356568202033099
total time of one epoch: 306.3777494430542 s
train_loss:  0.0011628634514357012  acc:  0.8735637171520811
->>lr:0.014357
test_loss:  0.0011449737800441231  test_acc:  0.876039210820201
best acc:  87.82727385531703

------Epoch: 96------
[batch_idx--0] train_loss: 0.0012713357573375106, acc: 0.8359375, lr: 0.014355517710873192
[batch_idx--50] train_loss: 0.0011582787105284048, acc: 0.8750765931372549, lr: 0.014303022468435317
[batch_idx--100] train_loss: 0.0011600016438780298, acc: 0.874690594059406, lr: 0.014250584898001182
[batch_idx--150] train_loss: 0.0011526374235002954, acc: 0.8754139072847682, lr: 0.014198205282284266
[batch_idx--200] train_loss: 0.0011643379908147736, acc: 0.873056592039801, lr: 0.014145883903685591
[batch_idx--250] train_loss: 0.0011615326544140055, acc: 0.8735371015936255, lr: 0.014093621044292189
[batch_idx--300] train_loss: 0.001158262615748047, acc: 0.8740266818936877, lr: 0.014041416985875627
[batch_idx--350] train_loss: 0.0011565412888555465, acc: 0.8740651709401709, lr: 0.013989272009890398
[batch_idx--400] train_loss: 0.0011569165499553437, acc: 0.8742986284289277, lr: 0.013937186397472484
[batch_idx--450] train_loss: 0.001160030043896514, acc: 0.8738848196618877, lr: 0.01388516042943782
total time of one epoch: 308.39871287345886 s
train_loss:  0.001160030043896514  acc:  0.8738848196618877
->>lr:0.013885
test_loss:  0.001142108977721101  test_acc:  0.8803821814120859
best acc:  87.82727385531703
Saving..

------Epoch: 97------
[batch_idx--0] train_loss: 0.0013377720024436712, acc: 0.81640625, lr: 0.01388412052037681
[batch_idx--50] train_loss: 0.0011532246066695627, acc: 0.8732383578431373, lr: 0.01383215567857612
[batch_idx--100] train_loss: 0.0011493750464051297, acc: 0.873801051980198, lr: 0.013780251047424422
[batch_idx--150] train_loss: 0.0011487119400947793, acc: 0.8748706539735099, lr: 0.013728406906761904
[batch_idx--200] train_loss: 0.0011492953838465449, acc: 0.8743003731343284, lr: 0.013676623536102595
[batch_idx--250] train_loss: 0.0011474168323726203, acc: 0.8748910607569721, lr: 0.013624901214632912
[batch_idx--300] train_loss: 0.0011539274830126708, acc: 0.8740396594684385, lr: 0.01357324022121012
[batch_idx--350] train_loss: 0.001146515368840835, acc: 0.8747551638176638, lr: 0.013521640834360844
[batch_idx--400] train_loss: 0.0011498028276885333, acc: 0.8742206982543641, lr: 0.013470103332279566
[batch_idx--450] train_loss: 0.0011578064133713577, acc: 0.8737633214149338, lr: 0.013418627992827087
total time of one epoch: 311.65133929252625 s
train_loss:  0.0011578064133713577  acc:  0.8737633214149338
->>lr:0.013419
test_loss:  0.0011379989087100893  test_acc:  0.8807544360342474
best acc:  88.03821814120859
Saving..

------Epoch: 98------
[batch_idx--0] train_loss: 0.0013479760382324457, acc: 0.84765625, lr: 0.013417599122003463
[batch_idx--50] train_loss: 0.0011586927964041631, acc: 0.8733149509803921, lr: 0.013366187474337023
[batch_idx--100] train_loss: 0.0011557603714812436, acc: 0.8751160272277227, lr: 0.013314838549554453
[batch_idx--150] train_loss: 0.001157682040931398, acc: 0.8745343543046358, lr: 0.013263552624499875
[batch_idx--200] train_loss: 0.0011516152351135527, acc: 0.8748445273631841, lr: 0.01321232997567776
[batch_idx--250] train_loss: 0.0011508798475314184, acc: 0.875, lr: 0.01316117087925142
[batch_idx--300] train_loss: 0.0011528254654088314, acc: 0.8745328073089701, lr: 0.013110075611041534
[batch_idx--350] train_loss: 0.0011488444943304713, acc: 0.8751335470085471, lr: 0.01305904444652466
[batch_idx--400] train_loss: 0.0011476280965767986, acc: 0.8752435317955112, lr: 0.013008077660831736
[batch_idx--450] train_loss: 0.0011559893822402655, acc: 0.874587773804978, lr: 0.01295717552874661
total time of one epoch: 309.5046617984772 s
train_loss:  0.0011559893822402655  acc:  0.874587773804978
->>lr:0.012957
test_loss:  0.0011458694472592794  test_acc:  0.8777763990569549
best acc:  88.07544360342474

------Epoch: 99------
[batch_idx--0] train_loss: 0.0010648820316419005, acc: 0.87890625, lr: 0.012956158147457115
[batch_idx--50] train_loss: 0.0011687099525029315, acc: 0.8719362745098039, lr: 0.012905322244772761
[batch_idx--100] train_loss: 0.0011507948321096673, acc: 0.8755801361386139, lr: 0.012854551549694835
[batch_idx--150] train_loss: 0.0011459545275529488, acc: 0.8762675910596026, lr: 0.012803846335949954
[batch_idx--200] train_loss: 0.0011487693394955933, acc: 0.8750971703980099, lr: 0.012753206876911727
[batch_idx--250] train_loss: 0.0011460834810792272, acc: 0.875031125498008, lr: 0.012702633445599246
[batch_idx--300] train_loss: 0.001145579494795827, acc: 0.8748961794019934, lr: 0.012652126314675622
[batch_idx--350] train_loss: 0.0011490541332841789, acc: 0.8745325854700855, lr: 0.012601685756446507
[batch_idx--400] train_loss: 0.0011498370079237718, acc: 0.8740940617206983, lr: 0.012551312042858621
[batch_idx--450] train_loss: 0.0011580880774924702, acc: 0.8733814697816503, lr: 0.012501005445498313
total time of one epoch: 310.1775441169739 s
train_loss:  0.0011580880774924702  acc:  0.8733814697816503
->>lr:0.012501
test_loss:  0.0011337200030157504  test_acc:  0.8781486536791165
best acc:  88.07544360342474

------Epoch: 100------
[batch_idx--0] train_loss: 0.0012706711422652006, acc: 0.8515625, lr: 0.012500000000000006
[batch_idx--50] train_loss: 0.0011659784667084321, acc: 0.8745404411764706, lr: 0.012449762140604802
[batch_idx--100] train_loss: 0.0011525975913731473, acc: 0.8755414603960396, lr: 0.012399591944936346
[batch_idx--150] train_loss: 0.001142759167123586, acc: 0.8764745447019867, lr: 0.012349489683483728
[batch_idx--200] train_loss: 0.0011410575909702229, acc: 0.8763603855721394, lr: 0.012299455626369788
[batch_idx--250] train_loss: 0.0011414140683183246, acc: 0.8764473356573705, lr: 0.012249490043349598
[batch_idx--300] train_loss: 0.0011403282533439985, acc: 0.876232869601329, lr: 0.01219959320380913
[batch_idx--350] train_loss: 0.0011428261047727998, acc: 0.8761351495726496, lr: 0.012149765376763677
[batch_idx--400] train_loss: 0.001139345456337431, acc: 0.8765975685785536, lr: 0.012100006830856476
[batch_idx--450] train_loss: 0.0011458743973874863, acc: 0.8764709966327628, lr: 0.01205031783435723
total time of one epoch: 309.8522996902466 s
train_loss:  0.0011458743973874863  acc:  0.8764709966327628
->>lr:0.012050
test_loss:  0.0011325547965558946  test_acc:  0.881995284774786
best acc:  88.07544360342474
Saving..

------Epoch: 101------
[batch_idx--0] train_loss: 0.001141090178862214, acc: 0.88671875, lr: 0.012049324765671741
[batch_idx--50] train_loss: 0.0011577296787507686, acc: 0.8744638480392157, lr: 0.01199970698555119
[batch_idx--100] train_loss: 0.0011414470315892435, acc: 0.8748839727722773, lr: 0.011950159295598187
[batch_idx--150] train_loss: 0.0011425238628470838, acc: 0.874948261589404, lr: 0.011900681962945607
[batch_idx--200] train_loss: 0.0011409697524244105, acc: 0.8745530161691543, lr: 0.011851275254347019
[batch_idx--250] train_loss: 0.0011425337388246985, acc: 0.8746576195219123, lr: 0.011801939436175232
[batch_idx--300] train_loss: 0.0011430213427437203, acc: 0.8742083679401993, lr: 0.01175267477442085
[batch_idx--350] train_loss: 0.001141437552398352, acc: 0.8747106481481481, lr: 0.011703481534690844
[batch_idx--400] train_loss: 0.0011389974147334528, acc: 0.8748733634663342, lr: 0.011654359982207095
[batch_idx--450] train_loss: 0.001143912156620877, acc: 0.8746745582670878, lr: 0.011605310381805019
total time of one epoch: 309.5458574295044 s
train_loss:  0.001143912156620877  acc:  0.8746745582670878
->>lr:0.011605
test_loss:  0.0011328766719921305  test_acc:  0.8782727385531703
best acc:  88.1995284774786

------Epoch: 102------
[batch_idx--0] train_loss: 0.001149987569078803, acc: 0.84375, lr: 0.01160433012552509
[batch_idx--50] train_loss: 0.001158598056017403, acc: 0.8741574754901961, lr: 0.011555354188677439
[batch_idx--100] train_loss: 0.0011357744783393596, acc: 0.8767404084158416, lr: 0.011506450737694249
[batch_idx--150] train_loss: 0.0011412708323128176, acc: 0.8755173841059603, lr: 0.011457620036235043
[batch_idx--200] train_loss: 0.0011398475423144798, acc: 0.8757190609452736, lr: 0.011408862347567132
[batch_idx--250] train_loss: 0.001139842837156572, acc: 0.8757470119521913, lr: 0.011360177934564142
[batch_idx--300] train_loss: 0.0011406153749111434, acc: 0.8758305647840532, lr: 0.011311567059704701
[batch_idx--350] train_loss: 0.0011395410579188789, acc: 0.8761128917378918, lr: 0.01126302998507092
[batch_idx--400] train_loss: 0.0011403858995511014, acc: 0.8759059382793017, lr: 0.011214566972347026
[batch_idx--450] train_loss: 0.0011404850758948643, acc: 0.8762366785850662, lr: 0.01116617828281797
total time of one epoch: 312.6313192844391 s
train_loss:  0.0011404850758948643  acc:  0.8762366785850662
->>lr:0.011166
test_loss:  0.001130535571802075  test_acc:  0.8805062662861397
best acc:  88.1995284774786

------Epoch: 103------
[batch_idx--0] train_loss: 0.001217320212163031, acc: 0.85546875, lr: 0.011165211268916392
[batch_idx--50] train_loss: 0.0011345668177704746, acc: 0.8776807598039216, lr: 0.011116898657806221
[batch_idx--100] train_loss: 0.001127184602076944, acc: 0.8782874381188119, lr: 0.01106866089646273
[batch_idx--150] train_loss: 0.0011328196200073406, acc: 0.8772506208609272, lr: 0.011020498244956429
[batch_idx--200] train_loss: 0.0011400155142755873, acc: 0.8754469838308457, lr: 0.010972410962952879
[batch_idx--250] train_loss: 0.001136133595475504, acc: 0.8756847609561753, lr: 0.010924399309711284
[batch_idx--300] train_loss: 0.0011361879534459367, acc: 0.8756229235880398, lr: 0.010876463544083113
[batch_idx--350] train_loss: 0.0011356996096726349, acc: 0.8753338675213675, lr: 0.010828603924510663
[batch_idx--400] train_loss: 0.0011360466133621973, acc: 0.875194825436409, lr: 0.010780820709025727
[batch_idx--450] train_loss: 0.0011368279437828938, acc: 0.8757159718124067, lr: 0.010733114155248157
total time of one epoch: 312.07425355911255 s
train_loss:  0.0011368279437828938  acc:  0.8757159718124067
->>lr:0.010733
test_loss:  0.0011279138272210082  test_acc:  0.8800099267899243
best acc:  88.1995284774786

------Epoch: 104------
[batch_idx--0] train_loss: 0.0012064051115885377, acc: 0.86328125, lr: 0.010732160807889211
[batch_idx--50] train_loss: 0.0011601398753769258, acc: 0.8726256127450981, lr: 0.010684532714024482
[batch_idx--100] train_loss: 0.0011375569669290048, acc: 0.8762762995049505, lr: 0.010636981800997085
[batch_idx--150] train_loss: 0.0011308262427645853, acc: 0.8763193294701986, lr: 0.01058950832517444
[batch_idx--200] train_loss: 0.0011234416571950809, acc: 0.877079446517413, lr: 0.010542112542506449
[batch_idx--250] train_loss: 0.0011266849701296524, acc: 0.8761049551792829, lr: 0.01049479470852415
[batch_idx--300] train_loss: 0.001122752644092253, acc: 0.8768038828903655, lr: 0.010447555078338317
[batch_idx--350] train_loss: 0.001122185697233798, acc: 0.8768696581196581, lr: 0.010400393906638123
[batch_idx--400] train_loss: 0.0011246875982308885, acc: 0.8768898067331671, lr: 0.010353311447689712
[batch_idx--450] train_loss: 0.0011294810676535808, acc: 0.8769049189433124, lr: 0.01030630795533484
total time of one epoch: 310.5830433368683 s
train_loss:  0.0011294810676535808  acc:  0.8769049189433124
->>lr:0.010306
test_loss:  0.001141210082136737  test_acc:  0.8787690780493858
best acc:  88.1995284774786

------Epoch: 105------
[batch_idx--0] train_loss: 0.0008140068966895342, acc: 0.90234375, lr: 0.010305368692688175
[batch_idx--50] train_loss: 0.0011446271719429276, acc: 0.8728553921568627, lr: 0.010258446007324987
[batch_idx--100] train_loss: 0.0011288128703334692, acc: 0.8750773514851485, lr: 0.010211602800015714
[batch_idx--150] train_loss: 0.0011341591610030475, acc: 0.8748447847682119, lr: 0.010164839323312217
[batch_idx--200] train_loss: 0.0011320787621546184, acc: 0.8758939676616916, lr: 0.010118155829336504
[batch_idx--250] train_loss: 0.0011303370848179338, acc: 0.8765562749003984, lr: 0.010071552569779364
[batch_idx--300] train_loss: 0.001127533112038422, acc: 0.877141299833887, lr: 0.010025029795898983
[batch_idx--350] train_loss: 0.001123084989674867, acc: 0.8775596509971509, lr: 0.00997858775851964
[batch_idx--400] train_loss: 0.0011223976448366414, acc: 0.8776788497506235, lr: 0.00993222670803032
[batch_idx--450] train_loss: 0.0011249706516367006, acc: 0.8777293713333565, lr: 0.009885946894383374
total time of one epoch: 315.98628401756287 s
train_loss:  0.0011249706516367006  acc:  0.8777293713333565
->>lr:0.009886
test_loss:  0.0011324599128249326  test_acc:  0.8817471150266782
best acc:  88.1995284774786

------Epoch: 106------
[batch_idx--0] train_loss: 0.0010352774988859892, acc: 0.87109375, lr: 0.00988502212844063
[batch_idx--50] train_loss: 0.0011361497066294153, acc: 0.8765318627450981, lr: 0.009838825433419594
[batch_idx--100] train_loss: 0.0011172692687942249, acc: 0.8774752475247525, lr: 0.009792710478807351
[batch_idx--150] train_loss: 0.001117363755995198, acc: 0.8778456125827815, lr: 0.009746677513229449
[batch_idx--200] train_loss: 0.0011181220133089234, acc: 0.8778956778606966, lr: 0.00970072678486938
[batch_idx--250] train_loss: 0.0011177390729878618, acc: 0.877910234063745, lr: 0.009654858541467274
[batch_idx--300] train_loss: 0.0011158741572005458, acc: 0.8777123131229236, lr: 0.009609073030318542
[batch_idx--350] train_loss: 0.001118993097080443, acc: 0.877693198005698, lr: 0.009563370498272567
[batch_idx--400] train_loss: 0.0011217205601156762, acc: 0.8771528210723192, lr: 0.009517751191731351
[batch_idx--450] train_loss: 0.0011230729545926039, acc: 0.8770871663137432, lr: 0.00947221535664816
total time of one epoch: 311.7143540382385 s
train_loss:  0.0011230729545926039  acc:  0.8770871663137432
->>lr:0.009472
test_loss:  0.0011335546572608679  test_acc:  0.8774041444347934
best acc:  88.1995284774786

------Epoch: 107------
[batch_idx--0] train_loss: 0.0011469023302197456, acc: 0.859375, lr: 0.009471305493042243
[batch_idx--50] train_loss: 0.0011187092407935245, acc: 0.8780637254901961, lr: 0.00942585505176061
[batch_idx--100] train_loss: 0.0011075636911399588, acc: 0.8797184405940595, lr: 0.009380488577388602
[batch_idx--150] train_loss: 0.001099872935581829, acc: 0.8806912251655629, lr: 0.009335206314516387
[batch_idx--200] train_loss: 0.0011139242059611414, acc: 0.8779539800995025, lr: 0.0092900085072801
[batch_idx--250] train_loss: 0.0011074675510978824, acc: 0.8787506225099602, lr: 0.009244895399360565
[batch_idx--300] train_loss: 0.0011133797545267573, acc: 0.8778939991694352, lr: 0.009199867233981912
[batch_idx--350] train_loss: 0.0011120465291568483, acc: 0.8780493233618234, lr: 0.009154924253910346
[batch_idx--400] train_loss: 0.0011157123441633738, acc: 0.8779223815461347, lr: 0.009110066701452797
[batch_idx--450] train_loss: 0.0011183023711396642, acc: 0.8783108272294928, lr: 0.0090652948184556
total time of one epoch: 312.9142482280731 s
train_loss:  0.0011183023711396642  acc:  0.8783108272294928
->>lr:0.009065
test_loss:  0.0011168613314317967  test_acc:  0.8806303511601936
best acc:  88.1995284774786

------Epoch: 108------
[batch_idx--0] train_loss: 0.0011446088319644332, acc: 0.88671875, lr: 0.009064400256282757
[batch_idx--50] train_loss: 0.0011106392816074338, acc: 0.8785232843137255, lr: 0.009019716004806225
[batch_idx--100] train_loss: 0.0011166298351628651, acc: 0.8772045173267327, lr: 0.0089751179099095
[batch_idx--150] train_loss: 0.0011137460523426828, acc: 0.8787510347682119, lr: 0.008930606212040063
[batch_idx--200] train_loss: 0.0011176066765612668, acc: 0.8779928482587065, lr: 0.00888618115117962
[batch_idx--250] train_loss: 0.0011191554801200936, acc: 0.8780347360557769, lr: 0.00884184296684277
[batch_idx--300] train_loss: 0.001120867781214218, acc: 0.8779718646179402, lr: 0.00879759189807571
[batch_idx--350] train_loss: 0.0011231513575191724, acc: 0.8778378739316239, lr: 0.008753428183455004
[batch_idx--400] train_loss: 0.0011185713408763366, acc: 0.8784484102244389, lr: 0.008709352061086187
[batch_idx--450] train_loss: 0.0011253737761019072, acc: 0.8777814420106225, lr: 0.008665363768602597
total time of one epoch: 311.5133709907532 s
train_loss:  0.0011253737761019072  acc:  0.8777814420106225
->>lr:0.008665
test_loss:  0.0011280060003052014  test_acc:  0.8798858419158705
best acc:  88.1995284774786

------Epoch: 109------
[batch_idx--0] train_loss: 0.0011376870097592473, acc: 0.87109375, lr: 0.008664484900247363
[batch_idx--50] train_loss: 0.0011046496790596376, acc: 0.8823529411764706, lr: 0.00862058643856546
[batch_idx--100] train_loss: 0.0011111934695826236, acc: 0.8810334158415841, lr: 0.0085767762853424
[batch_idx--150] train_loss: 0.0011115847012823732, acc: 0.8797599337748344, lr: 0.008533054676777554
[batch_idx--200] train_loss: 0.0011089953413784541, acc: 0.8800917288557214, lr: 0.008489421848592919
[batch_idx--250] train_loss: 0.0011146707169014025, acc: 0.8786728087649402, lr: 0.008445878036031801
[batch_idx--300] train_loss: 0.0011160257904777966, acc: 0.8785169227574751, lr: 0.008402423473857626
[batch_idx--350] train_loss: 0.0011166436557904778, acc: 0.8784054487179487, lr: 0.008359058396352615
[batch_idx--400] train_loss: 0.001114930488265577, acc: 0.8784971165835411, lr: 0.008315783037316537
[batch_idx--450] train_loss: 0.0011216142456434773, acc: 0.8783976116916027, lr: 0.008272597630065468
total time of one epoch: 313.230348110199 s
train_loss:  0.0011216142456434773  acc:  0.8783976116916027
->>lr:0.008273
test_loss:  0.0011385136302077515  test_acc:  0.8793895024196551
best acc:  88.1995284774786

------Epoch: 110------
[batch_idx--0] train_loss: 0.0011271084658801556, acc: 0.89453125, lr: 0.008271734841028545
[batch_idx--50] train_loss: 0.0011218464693657176, acc: 0.8782169117647058, lr: 0.008228641424457422
[batch_idx--100] train_loss: 0.0011148352122930165, acc: 0.8789836014851485, lr: 0.00818563842948918
[batch_idx--150] train_loss: 0.0011154527954035593, acc: 0.8787769039735099, lr: 0.008142726087971458
[batch_idx--200] train_loss: 0.0011096175523145839, acc: 0.8793532338308457, lr: 0.00809990463126313
[batch_idx--250] train_loss: 0.0011159617447320269, acc: 0.8789996264940239, lr: 0.008057174290233077
[batch_idx--300] train_loss: 0.0011127584130794083, acc: 0.8794123754152824, lr: 0.008014535295258926
[batch_idx--350] train_loss: 0.001111679183427998, acc: 0.8795739850427351, lr: 0.00797198787622585
[batch_idx--400] train_loss: 0.0011085462477754921, acc: 0.8800459788029925, lr: 0.007929532262525246
[batch_idx--450] train_loss: 0.0011181992508056415, acc: 0.8795865588225085, lr: 0.007887168683053591
total time of one epoch: 316.8189651966095 s
train_loss:  0.0011181992508056415  acc:  0.8795865588225085
->>lr:0.007887
test_loss:  0.0011264178146128472  test_acc:  0.8808785209083013
best acc:  88.1995284774786

------Epoch: 111------
[batch_idx--0] train_loss: 0.0012747454456984997, acc: 0.8671875, lr: 0.00788632235178279
[batch_idx--50] train_loss: 0.0011077768068906723, acc: 0.8819699754901961, lr: 0.00784405288251919
[batch_idx--100] train_loss: 0.0011029194522934902, acc: 0.8808787128712872, lr: 0.007801875908340622
[batch_idx--150] train_loss: 0.0011014865637318978, acc: 0.8813379552980133, lr: 0.007759791656641275
[batch_idx--200] train_loss: 0.0011027287132922207, acc: 0.8810439987562189, lr: 0.007717800354315446
[batch_idx--250] train_loss: 0.0011032641001706164, acc: 0.8805247758964143, lr: 0.007675902227756282
[batch_idx--300] train_loss: 0.0011067830967528133, acc: 0.879594061461794, lr: 0.007634097502854598
[batch_idx--350] train_loss: 0.0011097999874030125, acc: 0.8792067307692307, lr: 0.007592386404997634
[batch_idx--400] train_loss: 0.001111673047049598, acc: 0.8787796134663342, lr: 0.007550769159067847
[batch_idx--450] train_loss: 0.0011201559703007092, acc: 0.8779897247196862, lr: 0.00750924598944171
total time of one epoch: 312.1691598892212 s
train_loss:  0.0011201559703007092  acc:  0.8779897247196862
->>lr:0.007509
test_loss:  0.0011465798308586332  test_acc:  0.8782727385531703
best acc:  88.1995284774786

------Epoch: 112------
[batch_idx--0] train_loss: 0.0011547101894393563, acc: 0.87890625, lr: 0.007508416487165862
[batch_idx--50] train_loss: 0.0011284110255028103, acc: 0.8759957107843137, lr: 0.007466989505996053
[batch_idx--100] train_loss: 0.001112193630496501, acc: 0.8794090346534653, lr: 0.007425657052821996
[batch_idx--150] train_loss: 0.0011048709957502685, acc: 0.8809757864238411, lr: 0.007384419350484717
[batch_idx--200] train_loss: 0.0010901490806727045, acc: 0.8821906094527363, lr: 0.0073432766213143985
[batch_idx--250] train_loss: 0.001082828265857842, acc: 0.8824701195219123, lr: 0.007302229087129178
[batch_idx--300] train_loss: 0.0010870862249408746, acc: 0.8819430024916943, lr: 0.007261276969233954
[batch_idx--350] train_loss: 0.0010904971244174487, acc: 0.8814881588319088, lr: 0.007220420488419194
[batch_idx--400] train_loss: 0.0010972956592911515, acc: 0.8806986440149626, lr: 0.007179659864959754
[batch_idx--450] train_loss: 0.0011029569349051986, acc: 0.8804457249973965, lr: 0.007138995318613667
total time of one epoch: 311.3193693161011 s
train_loss:  0.0011029569349051986  acc:  0.8804457249973965
->>lr:0.007139
test_loss:  0.0011112697201547885  test_acc:  0.8859660007445093
best acc:  88.1995284774786
Saving..

------Epoch: 113------
[batch_idx--0] train_loss: 0.0012493554968386889, acc: 0.84375, lr: 0.007138183009179922
[batch_idx--50] train_loss: 0.001067740099696333, acc: 0.8886335784313726, lr: 0.007097616687346986
[batch_idx--100] train_loss: 0.001088117094281692, acc: 0.8847076113861386, lr: 0.00705714688495745
[batch_idx--150] train_loss: 0.0010929481108635911, acc: 0.8835368377483444, lr: 0.007016773820201414
[batch_idx--200] train_loss: 0.0010909396255578828, acc: 0.8832789179104478, lr: 0.00697649771074741
[batch_idx--250] train_loss: 0.0010943325297662104, acc: 0.8829836902390438, lr: 0.006936318773741257
[batch_idx--300] train_loss: 0.0010966155308676246, acc: 0.8824621054817275, lr: 0.00689623722580488
[batch_idx--350] train_loss: 0.0011014673443301515, acc: 0.8818442841880342, lr: 0.006856253283035133
[batch_idx--400] train_loss: 0.0011029709412128737, acc: 0.8813123441396509, lr: 0.00681636716100264
[batch_idx--450] train_loss: 0.0011050029862331335, acc: 0.8811052869094317, lr: 0.006776579074750619
total time of one epoch: 309.2130126953125 s
train_loss:  0.0011050029862331335  acc:  0.8811052869094317
->>lr:0.006777
test_loss:  0.0011231680782605436  test_acc:  0.8832361335153245
best acc:  88.59660007445092

------Epoch: 114------
[batch_idx--0] train_loss: 0.0011194410035386682, acc: 0.88671875, lr: 0.006775784314464717
[batch_idx--50] train_loss: 0.0010960256868023791, acc: 0.8785998774509803, lr: 0.006736096445698165
[batch_idx--100] train_loss: 0.0011030775823372204, acc: 0.8792930074257426, lr: 0.0066965070454860194
[batch_idx--150] train_loss: 0.001104393708735507, acc: 0.8798634105960265, lr: 0.006657016327271753
[batch_idx--200] train_loss: 0.0010975599723325959, acc: 0.8801888992537313, lr: 0.006617624503966805
[batch_idx--250] train_loss: 0.0011026676724742786, acc: 0.8790930029880478, lr: 0.006578331787949427
[batch_idx--300] train_loss: 0.001104867222148034, acc: 0.8793734426910299, lr: 0.006539138391063526
[batch_idx--350] train_loss: 0.0010994522778603893, acc: 0.8801860754985755, lr: 0.006500044524617568
[batch_idx--400] train_loss: 0.0010973994047938384, acc: 0.8808447630922693, lr: 0.0064610503993833834
[batch_idx--450] train_loss: 0.0011004593017586947, acc: 0.880853611969313, lr: 0.006422156225595066
total time of one epoch: 311.08235812187195 s
train_loss:  0.0011004593017586947  acc:  0.880853611969313
->>lr:0.006422
test_loss:  0.0011133628109575634  test_acc:  0.8805062662861397
best acc:  88.59660007445092

------Epoch: 115------
[batch_idx--0] train_loss: 0.0011019200319424272, acc: 0.87890625, lr: 0.00642137936306515
[batch_idx--50] train_loss: 0.0010833983268479213, acc: 0.883578431372549, lr: 0.006382587355775901
[batch_idx--100] train_loss: 0.0010778822118905143, acc: 0.8838954207920792, lr: 0.006343895722960522
[batch_idx--150] train_loss: 0.0010816005354636158, acc: 0.8832264072847682, lr: 0.006305304673222229
[batch_idx--200] train_loss: 0.0010825379659532945, acc: 0.8834149564676617, lr: 0.0062668144146219495
[batch_idx--250] train_loss: 0.0010859329177834746, acc: 0.8823923057768924, lr: 0.006228425154677217
[batch_idx--300] train_loss: 0.001087577254712532, acc: 0.8822544642857143, lr: 0.0061901371003610295
[batch_idx--350] train_loss: 0.0010831255355963957, acc: 0.8826566951566952, lr: 0.00615195045810075
[batch_idx--400] train_loss: 0.0010828451069705932, acc: 0.882617674563591, lr: 0.006113865433776986
[batch_idx--450] train_loss: 0.001088296704569226, acc: 0.8822508418092825, lr: 0.006075882232722457
total time of one epoch: 315.6591103076935 s
train_loss:  0.001088296704569226  acc:  0.8822508418092825
->>lr:0.006076
test_loss:  0.0011136247489274562  test_acc:  0.8848492368780245
best acc:  88.59660007445092

------Epoch: 116------
[batch_idx--0] train_loss: 0.0008262322517111897, acc: 0.90234375, lr: 0.006075123608706093
[batch_idx--50] train_loss: 0.0010894597017242775, acc: 0.8806678921568627, lr: 0.006037244478350651
[batch_idx--100] train_loss: 0.0010934561683501273, acc: 0.8797957920792079, lr: 0.00599946758436096
[batch_idx--150] train_loss: 0.0010960018659312747, acc: 0.8798634105960265, lr: 0.005961793130408489
[batch_idx--200] train_loss: 0.0010905962191818661, acc: 0.8813160758706468, lr: 0.005924221319612417
[batch_idx--250] train_loss: 0.0010882126062132596, acc: 0.8815519173306773, lr: 0.005886752354538527
[batch_idx--300] train_loss: 0.0010914531910785805, acc: 0.8808399086378738, lr: 0.0058493864371981065
[batch_idx--350] train_loss: 0.0010908792716413842, acc: 0.8808092948717948, lr: 0.005812123769046874
[batch_idx--400] train_loss: 0.0010883586019326346, acc: 0.8813610504987531, lr: 0.005774964550983902
[batch_idx--450] train_loss: 0.0010897685524505433, acc: 0.8812007498177526, lr: 0.005737908983350504
total time of one epoch: 311.95626401901245 s
train_loss:  0.0010897685524505433  acc:  0.8812007498177526
->>lr:0.005738
test_loss:  0.0011124815493692667  test_acc:  0.8826157091450553
best acc:  88.59660007445092

------Epoch: 117------
[batch_idx--0] train_loss: 0.0010395091958343983, acc: 0.90234375, lr: 0.005737168930605272
[batch_idx--50] train_loss: 0.0010855678736013087, acc: 0.8805912990196079, lr: 0.005700219292222111
[batch_idx--100] train_loss: 0.0010850638615677484, acc: 0.8816909034653465, lr: 0.005663373707252357
[batch_idx--150] train_loss: 0.0010873264816608156, acc: 0.8802255794701986, lr: 0.005626632374346372
[batch_idx--200] train_loss: 0.0010878600794659806, acc: 0.8797419154228856, lr: 0.005589995491592479
[batch_idx--250] train_loss: 0.001091325323958232, acc: 0.8797466384462151, lr: 0.005553463256515865
[batch_idx--300] train_loss: 0.001092282750417921, acc: 0.880048276578073, lr: 0.005517035866077508
[batch_idx--350] train_loss: 0.0010932366814108783, acc: 0.8804086538461539, lr: 0.0054807135166731365
[batch_idx--400] train_loss: 0.0010919385847166423, acc: 0.8805427836658354, lr: 0.005444496404132135
[batch_idx--450] train_loss: 0.0010947898185722415, acc: 0.8804804387822405, lr: 0.005408384723716528
total time of one epoch: 317.3938715457916 s
train_loss:  0.0010947898185722415  acc:  0.8804804387822405
->>lr:0.005408
test_loss:  0.0011037615466345657  test_acc:  0.8853455763742399
best acc:  88.59660007445092

------Epoch: 118------
[batch_idx--0] train_loss: 0.001172559568658471, acc: 0.875, lr: 0.005407663566854007
[batch_idx--50] train_loss: 0.0011023881311035331, acc: 0.8824295343137255, lr: 0.005371659627775735
[batch_idx--100] train_loss: 0.0010932136677426867, acc: 0.8831992574257426, lr: 0.005335761513517229
[batch_idx--150] train_loss: 0.0010833908924802102, acc: 0.8835885761589404, lr: 0.0052999694176206515
[batch_idx--200] train_loss: 0.0010866274670883087, acc: 0.8831428793532339, lr: 0.005264283533056586
[batch_idx--250] train_loss: 0.0010864713706495426, acc: 0.8825323705179283, lr: 0.0052287040522229575
[batch_idx--300] train_loss: 0.0010832092042879335, acc: 0.8825789036544851, lr: 0.005193231166944048
[batch_idx--350] train_loss: 0.001086863083167909, acc: 0.8818331552706553, lr: 0.005157865068469426
[batch_idx--400] train_loss: 0.0010888524123576662, acc: 0.8817896664588528, lr: 0.005122605947472936
[batch_idx--450] train_loss: 0.0010892965892579979, acc: 0.8815999583434582, lr: 0.0050874539940516635
total time of one epoch: 312.46583676338196 s
train_loss:  0.0010892965892579979  acc:  0.8815999583434582
->>lr:0.005087
test_loss:  0.001098975803615704  test_acc:  0.8818711999007322
best acc:  88.59660007445092

------Epoch: 119------
[batch_idx--0] train_loss: 0.000986080733127892, acc: 0.890625, lr: 0.005086752049395094
[batch_idx--50] train_loss: 0.0010864490611186507, acc: 0.8809742647058824, lr: 0.005051709602139323
[batch_idx--100] train_loss: 0.0010839413591005867, acc: 0.8822323638613861, lr: 0.005016774704691432
[batch_idx--150] train_loss: 0.001075105238181619, acc: 0.8833557533112583, lr: 0.004981947545400465
[batch_idx--200] train_loss: 0.0010869266703928734, acc: 0.8812966417910447, lr: 0.004947228312034608
[batch_idx--250] train_loss: 0.00108508157067973, acc: 0.8819254233067729, lr: 0.004912617191780173
[batch_idx--300] train_loss: 0.001084806984855153, acc: 0.8819949127906976, lr: 0.004878114371240583
[batch_idx--350] train_loss: 0.0010852692244133974, acc: 0.881866542022792, lr: 0.004843720036435387
[batch_idx--400] train_loss: 0.0010880631890538104, acc: 0.8812636377805486, lr: 0.004809434372799207
[batch_idx--450] train_loss: 0.0010890909494703422, acc: 0.8813569618495505, lr: 0.004775257565180805
total time of one epoch: 314.5948660373688 s
train_loss:  0.0010890909494703422  acc:  0.8813569618495505
->>lr:0.004775
test_loss:  0.0011157864157652674  test_acc:  0.8798858419158705
best acc:  88.59660007445092

------Epoch: 120------
[batch_idx--0] train_loss: 0.0011163282906636596, acc: 0.875, lr: 0.004774575140626317
[batch_idx--50] train_loss: 0.0010604322933610163, acc: 0.8855698529411765, lr: 0.004740509555968578
[batch_idx--100] train_loss: 0.0010723778845438052, acc: 0.8836246905940595, lr: 0.004706553198931926
[batch_idx--150] train_loss: 0.001069980008151407, acc: 0.8842094370860927, lr: 0.004672706252589681
[batch_idx--200] train_loss: 0.0010764365926018884, acc: 0.8834149564676617, lr: 0.004638968899425284
[batch_idx--250] train_loss: 0.0010836478934968374, acc: 0.882874750996016, lr: 0.004605341321331294
[batch_idx--300] train_loss: 0.001076534873901857, acc: 0.8836041320598007, lr: 0.004571823699608443
[batch_idx--350] train_loss: 0.0010747067405420363, acc: 0.8840811965811965, lr: 0.0045384162149646355
[batch_idx--400] train_loss: 0.00107774581003033, acc: 0.883484647755611, lr: 0.004505119047513989
[batch_idx--450] train_loss: 0.0010768432963782913, acc: 0.883639393203041, lr: 0.0044719323767758445
total time of one epoch: 311.85028529167175 s
train_loss:  0.0010768432963782913  acc:  0.883639393203041
->>lr:0.004472
test_loss:  0.0011364262713319773  test_acc:  0.8797617570418166
best acc:  88.59660007445092

------Epoch: 121------
[batch_idx--0] train_loss: 0.0011919799726456404, acc: 0.87109375, lr: 0.004471269771657399
[batch_idx--50] train_loss: 0.00109166443215537, acc: 0.8824295343137255, lr: 0.004438195991889007
[batch_idx--100] train_loss: 0.0011010693189097882, acc: 0.8818456064356436, lr: 0.004405233069644058
[batch_idx--150] train_loss: 0.0010928258716918233, acc: 0.8819329470198676, lr: 0.004372381182639854
[batch_idx--200] train_loss: 0.0010834919475250651, acc: 0.882637593283582, lr: 0.004339640507995033
[batch_idx--250] train_loss: 0.0010836658873168597, acc: 0.8826413097609562, lr: 0.00430701122222864
[batch_idx--300] train_loss: 0.0010753167761053482, acc: 0.8837728405315615, lr: 0.004274493501259191
[batch_idx--350] train_loss: 0.0010745310170862537, acc: 0.8836249109686609, lr: 0.004242087520403681
[batch_idx--400] train_loss: 0.0010758245198643694, acc: 0.8834262001246883, lr: 0.004209793454376692
[batch_idx--450] train_loss: 0.0010798180806693503, acc: 0.8831707571076475, lr: 0.0041776114772894115
total time of one epoch: 309.9177715778351 s
train_loss:  0.0010798180806693503  acc:  0.8831707571076475
->>lr:0.004178
test_loss:  0.0011049808809753979  test_acc:  0.883608388137486
best acc:  88.59660007445092

------Epoch: 122------
[batch_idx--0] train_loss: 0.0009978971211239696, acc: 0.875, lr: 0.004176968982247515
[batch_idx--50] train_loss: 0.0010706405726024042, acc: 0.8861060049019608, lr: 0.004144901514621361
[batch_idx--100] train_loss: 0.0010564598793136233, acc: 0.8858292079207921, lr: 0.0041129464857952575
[batch_idx--150] train_loss: 0.001068117298626816, acc: 0.8830711920529801, lr: 0.004081104068052505
[batch_idx--200] train_loss: 0.0010692368157842749, acc: 0.8833955223880597, lr: 0.00404937443306925
[batch_idx--250] train_loss: 0.0010649478396927692, acc: 0.8841197709163346, lr: 0.004017757751913604
[batch_idx--300] train_loss: 0.0010667287329199455, acc: 0.8839934593023255, lr: 0.003986254195044678
[batch_idx--350] train_loss: 0.0010678030774687176, acc: 0.8839365206552706, lr: 0.003954863932311695
[batch_idx--400] train_loss: 0.0010730010482594091, acc: 0.8836307668329177, lr: 0.003923587132953052
[batch_idx--450] train_loss: 0.0010790522128667397, acc: 0.8831620786614365, lr: 0.003892423965595415
total time of one epoch: 312.90485644340515 s
train_loss:  0.0010790522128667397  acc:  0.8831620786614365
->>lr:0.003892
test_loss:  0.0010949648950928006  test_acc:  0.883608388137486
best acc:  88.59660007445092

------Epoch: 123------
[batch_idx--0] train_loss: 0.0009429371566511691, acc: 0.8984375, lr: 0.003891801862449629
[batch_idx--50] train_loss: 0.0010755468929168203, acc: 0.8856464460784313, lr: 0.003860754772816863
[batch_idx--100] train_loss: 0.001077170681443508, acc: 0.8833926361386139, lr: 0.0038298216539413596
[batch_idx--150] train_loss: 0.0010733454937688909, acc: 0.8839766142384106, lr: 0.0037990026725968685
[batch_idx--200] train_loss: 0.0010727460806568463, acc: 0.8840951492537313, lr: 0.003768297994941761
[batch_idx--250] train_loss: 0.0010708376978138142, acc: 0.8839174551792829, lr: 0.0037377077865181603
[batch_idx--300] train_loss: 0.0010686860036142048, acc: 0.8837079526578073, lr: 0.003707232212251013
[batch_idx--350] train_loss: 0.0010717933107979405, acc: 0.883346688034188, lr: 0.003676871436447249
[batch_idx--400] train_loss: 0.0010742437893680374, acc: 0.8828904301745636, lr: 0.0036466256227948553
[batch_idx--450] train_loss: 0.001074479770061602, acc: 0.883622036310619, lr: 0.003616494934362016
total time of one epoch: 313.67332100868225 s
train_loss:  0.001074479770061602  acc:  0.883622036310619
->>lr:0.003616
test_loss:  0.0010988328512053082  test_acc:  0.8843528973818091
best acc:  88.59660007445092

------Epoch: 124------
[batch_idx--0] train_loss: 0.0008557903929613531, acc: 0.91015625, lr: 0.003615893495987335
[batch_idx--50] train_loss: 0.0010870296072087013, acc: 0.8832720588235294, lr: 0.003585880402627581
[batch_idx--100] train_loss: 0.0010882647965094166, acc: 0.8814201732673267, lr: 0.0035559827619909834
[batch_idx--150] train_loss: 0.001077988170340213, acc: 0.882915976821192, lr: 0.0035262007352685563
[batch_idx--200] train_loss: 0.0010787734506415454, acc: 0.8836870335820896, lr: 0.003496534483028016
[batch_idx--250] train_loss: 0.0010787294525931408, acc: 0.8832482569721115, lr: 0.0034669841652128805
[batch_idx--300] train_loss: 0.001078065565402041, acc: 0.8831758720930233, lr: 0.00343754994114161
[batch_idx--350] train_loss: 0.001077863651439229, acc: 0.8833912037037037, lr: 0.0034082319695067616
[batch_idx--400] train_loss: 0.0010780043719438581, acc: 0.8832605985037406, lr: 0.003379030408374123
[batch_idx--450] train_loss: 0.0010855406228938256, acc: 0.8832575415697573, lr: 0.00334994541518186
total time of one epoch: 314.5307879447937 s
train_loss:  0.0010855406228938256  acc:  0.8832575415697573
->>lr:0.003350
test_loss:  0.0010982144613363026  test_acc:  0.8850974066261322
best acc:  88.59660007445092

------Epoch: 125------
[batch_idx--0] train_loss: 0.0009494195110164583, acc: 0.90234375, lr: 0.003349364905389038
[batch_idx--50] train_loss: 0.0010839917048738868, acc: 0.8798253676470589, lr: 0.003320398973036992
[batch_idx--100] train_loss: 0.0010803521565844, acc: 0.8803372524752475, lr: 0.0032915499247325843
[batch_idx--150] train_loss: 0.0010732803551560355, acc: 0.8812086092715232, lr: 0.003262817916013447
[batch_idx--200] train_loss: 0.001068652127938929, acc: 0.8823460820895522, lr: 0.0032342031017861847
[batch_idx--250] train_loss: 0.0010752048483953266, acc: 0.8815052290836654, lr: 0.003205705636325565
[batch_idx--300] train_loss: 0.0010765535601080579, acc: 0.8814758098006644, lr: 0.0031773256732736594
[batch_idx--350] train_loss: 0.001075717839783859, acc: 0.8824229878917379, lr: 0.0031490633656390573
[batch_idx--400] train_loss: 0.0010751745831383917, acc: 0.8827150872817955, lr: 0.0031209188657960046
[batch_idx--450] train_loss: 0.0010736892803234564, acc: 0.883535251848509, lr: 0.0030928923254835983
total time of one epoch: 313.51638984680176 s
train_loss:  0.0010736892803234564  acc:  0.883535251848509
->>lr:0.003093
test_loss:  0.0011037817655448095  test_acc:  0.8817471150266782
best acc:  88.59660007445092

------Epoch: 126------
[batch_idx--0] train_loss: 0.0008280957699753344, acc: 0.921875, lr: 0.0030923329989034107
[batch_idx--50] train_loss: 0.0010881481199141812, acc: 0.8807444852941176, lr: 0.003064426932974329
[batch_idx--100] train_loss: 0.0010821068432357273, acc: 0.882503094059406, lr: 0.003036639131148192
[batch_idx--150] train_loss: 0.0010723017236304205, acc: 0.8835368377483444, lr: 0.003008969743240972
[batch_idx--200] train_loss: 0.0010669581622200373, acc: 0.8845810012437811, lr: 0.002981418918430234
[batch_idx--250] train_loss: 0.0010704617020655498, acc: 0.8847111553784861, lr: 0.002953986805254319
[batch_idx--300] train_loss: 0.0010739833778280925, acc: 0.8840972799003323, lr: 0.002926673551611542
[batch_idx--350] train_loss: 0.0010662386714589604, acc: 0.8851607015669516, lr: 0.002899479304759398
[batch_idx--400] train_loss: 0.0010643025334434412, acc: 0.885676433915212, lr: 0.0028724042113137424
[batch_idx--450] train_loss: 0.0010692972422047524, acc: 0.8857222202936786, lr: 0.002845448417248059
total time of one epoch: 311.273494720459 s
train_loss:  0.0010692972422047524  acc:  0.8857222202936786
->>lr:0.002845
test_loss:  0.0011051789837685866  test_acc:  0.8838565578855937
best acc:  88.59660007445092

------Epoch: 127------
[batch_idx--0] train_loss: 0.0010230905609205365, acc: 0.8828125, lr: 0.0028449105192196373
[batch_idx--50] train_loss: 0.0010800279686044828, acc: 0.8828125, lr: 0.0028180765602363435
[batch_idx--100] train_loss: 0.0010786711262529807, acc: 0.8816522277227723, lr: 0.0027913621935367313
[batch_idx--150] train_loss: 0.001074000841102236, acc: 0.8821657698675497, lr: 0.002764767563149445
[batch_idx--200] train_loss: 0.0010624524823908894, acc: 0.8844643967661692, lr: 0.002738292812457563
[batch_idx--250] train_loss: 0.0010617308323716827, acc: 0.8846800298804781, lr: 0.00271193808419784
[batch_idx--300] train_loss: 0.001056838631738237, acc: 0.8856935215946844, lr: 0.002685703520459948
[batch_idx--350] train_loss: 0.0010555707008784844, acc: 0.8860955306267806, lr: 0.0026595892626856965
[batch_idx--400] train_loss: 0.0010563776643419558, acc: 0.8859297069825436, lr: 0.0026335954516682747
[batch_idx--450] train_loss: 0.00105908873519795, acc: 0.8858090047557885, lr: 0.0026077222275514957
total time of one epoch: 312.1478250026703 s
train_loss:  0.00105908873519795  acc:  0.8858090047557885
->>lr:0.002608
test_loss:  0.0011104598691318805  test_acc:  0.8853455763742399
best acc:  88.59660007445092

------Epoch: 128------
[batch_idx--0] train_loss: 0.0012053343234583735, acc: 0.8671875, lr: 0.0026072059940146775
[batch_idx--50] train_loss: 0.0010534312824864744, acc: 0.8881740196078431, lr: 0.002581455912238459
[batch_idx--100] train_loss: 0.0010530288587093796, acc: 0.887762995049505, lr: 0.0025558266984695406
[batch_idx--150] train_loss: 0.0010583935508239298, acc: 0.8872361341059603, lr: 0.002530318490886033
[batch_idx--200] train_loss: 0.001062422833840979, acc: 0.8862328980099502, lr: 0.0025049314270136516
[batch_idx--250] train_loss: 0.0010668975514437691, acc: 0.885738296812749, lr: 0.0024796656437249655
[batch_idx--300] train_loss: 0.001068241012621473, acc: 0.8855377906976745, lr: 0.0024545212772386807
[batch_idx--350] train_loss: 0.0010630511322212632, acc: 0.8860732727920227, lr: 0.0024294984631188735
[batch_idx--400] train_loss: 0.001064513075343122, acc: 0.8855595386533666, lr: 0.0024045973362742893
[batch_idx--450] train_loss: 0.0010674098604140992, acc: 0.8853056548755511, lr: 0.0023798180309576172
total time of one epoch: 313.3335120677948 s
train_loss:  0.0010674098604140992  acc:  0.8853056548755511
->>lr:0.002380
test_loss:  0.0010963766613171079  test_acc:  0.8843528973818091
best acc:  88.59660007445092

------Epoch: 129------
[batch_idx--0] train_loss: 0.0010917030740529299, acc: 0.8828125, lr: 0.0023793236883495163
[batch_idx--50] train_loss: 0.0010614730874259099, acc: 0.8857996323529411, lr: 0.002354668778617275
[batch_idx--100] train_loss: 0.001056654838093621, acc: 0.8868347772277227, lr: 0.0023301359595992556
[batch_idx--150] train_loss: 0.0010592297821256352, acc: 0.8863307119205298, lr: 0.0023057253635624278
[batch_idx--200] train_loss: 0.0010563119294918813, acc: 0.8873795087064676, lr: 0.0022814371221148186
[batch_idx--250] train_loss: 0.0010557861655924572, acc: 0.8875591384462151, lr: 0.0022572713662047635
[batch_idx--300] train_loss: 0.0010544810205484522, acc: 0.8873806063122923, lr: 0.0022332282261202457
[batch_idx--350] train_loss: 0.0010534416931612348, acc: 0.8874866452991453, lr: 0.0022093078314881667
[batch_idx--400] train_loss: 0.0010558517870116989, acc: 0.8872350374064838, lr: 0.002185510311273653
[batch_idx--450] train_loss: 0.0010570415631922033, acc: 0.8874318741972437, lr: 0.0021618357937793764
total time of one epoch: 314.413268327713 s
train_loss:  0.0010570415631922033  acc:  0.8874318741972437
->>lr:0.002162
test_loss:  0.0010967784028355634  test_acc:  0.8842288125077553
best acc:  88.59660007445092

------Epoch: 130------
[batch_idx--0] train_loss: 0.0012531280517578125, acc: 0.85546875, lr: 0.0021613635589349755
[batch_idx--50] train_loss: 0.0010493685658016772, acc: 0.8877910539215687, lr: 0.0021378146357049848
[batch_idx--100] train_loss: 0.001046475871364669, acc: 0.8872602103960396, lr: 0.0021143889723431067
[batch_idx--150] train_loss: 0.0010424900714412874, acc: 0.8876500413907285, lr: 0.0020910866951471623
[batch_idx--200] train_loss: 0.001049656138305937, acc: 0.8870879975124378, lr: 0.0020679079297497515
[batch_idx--250] train_loss: 0.00105010692365987, acc: 0.8871700697211156, lr: 0.0020448528011175527
[batch_idx--300] train_loss: 0.0010520901368154317, acc: 0.8870431893687708, lr: 0.0020219214335506857
[batch_idx--350] train_loss: 0.0010521414258883486, acc: 0.8868077813390314, lr: 0.0019991139506819965
[batch_idx--400] train_loss: 0.0010545256974679555, acc: 0.886348581670823, lr: 0.001976430475476429
[batch_idx--450] train_loss: 0.001057884322864285, acc: 0.8864078175443468, lr: 0.0019538711302303584
total time of one epoch: 316.2640588283539 s
train_loss:  0.001057884322864285  acc:  0.8864078175443468
->>lr:0.001954
test_loss:  0.0010984272304665793  test_acc:  0.8834843032634322
best acc:  88.59660007445092

------Epoch: 131------
[batch_idx--0] train_loss: 0.0011014558840543032, acc: 0.875, lr: 0.00195342121028749
[batch_idx--50] train_loss: 0.0010544254065619088, acc: 0.8841911764705882, lr: 0.001930988602895767
[batch_idx--100] train_loss: 0.0010542238931088607, acc: 0.8854037747524752, lr: 0.001908680370460203
[batch_idx--150] train_loss: 0.0010617668150665102, acc: 0.8847268211920529, lr: 0.0018864966332540673
[batch_idx--200] train_loss: 0.0010608530548906223, acc: 0.8843477922885572, lr: 0.0018644375108794243
[batch_idx--250] train_loss: 0.001058035392399536, acc: 0.8848823456175299, lr: 0.0018425031222664813
[batch_idx--300] train_loss: 0.0010556392642387816, acc: 0.8848889119601329, lr: 0.0018206935856729584
[batch_idx--350] train_loss: 0.0010599890351361805, acc: 0.8846042556980057, lr: 0.0017990090186834396
[batch_idx--400] train_loss: 0.0010592218308751367, acc: 0.8845659289276808, lr: 0.0017774495382087503
[batch_idx--450] train_loss: 0.0010665654362781221, acc: 0.8841687784219113, lr: 0.001756015260485311
total time of one epoch: 314.6327404975891 s
train_loss:  0.0010665654362781221  acc:  0.8841687784219113
->>lr:0.001756
test_loss:  0.0010989872434325927  test_acc:  0.8818711999007322
best acc:  88.59660007445092

------Epoch: 132------
[batch_idx--0] train_loss: 0.0009708459256216884, acc: 0.90625, lr: 0.0017555878527937164
[batch_idx--50] train_loss: 0.0010676164346674055, acc: 0.8833486519607843, lr: 0.0017342814009232738
[batch_idx--100] train_loss: 0.0010629056930993822, acc: 0.8837020420792079, lr: 0.0017131003845420657
[batch_idx--150] train_loss: 0.0010682946885935962, acc: 0.882915976821192, lr: 0.0016920449178460556
[batch_idx--200] train_loss: 0.0010615821504404777, acc: 0.8840562810945274, lr: 0.0016711151143543159
[batch_idx--250] train_loss: 0.001065402879821233, acc: 0.8836062001992032, lr: 0.0016503110869084154
[batch_idx--300] train_loss: 0.0010618187896706214, acc: 0.8844087416943521, lr: 0.0016296329476718054
[batch_idx--350] train_loss: 0.0010561412606624478, acc: 0.8852719907407407, lr: 0.0016090808081292208
[batch_idx--400] train_loss: 0.0010572391050633163, acc: 0.8849653210723192, lr: 0.0015886547790860768
[batch_idx--450] train_loss: 0.0010626207354722014, acc: 0.8852101919672302, lr: 0.0015683549706678873
total time of one epoch: 315.76834416389465 s
train_loss:  0.0010626207354722014  acc:  0.8852101919672302
->>lr:0.001568
test_loss:  0.0010985896621837348  test_acc:  0.8839806427596476
best acc:  88.59660007445092

------Epoch: 133------
[batch_idx--0] train_loss: 0.0010566124692559242, acc: 0.8671875, lr: 0.0015679502627027138
[batch_idx--50] train_loss: 0.0010779975176167984, acc: 0.8829656862745098, lr: 0.0015477793120675237
[batch_idx--100] train_loss: 0.0010577458444530937, acc: 0.8861386138613861, lr: 0.0015277348024344995
[batch_idx--150] train_loss: 0.0010627391208456645, acc: 0.8851924668874173, lr: 0.001507816841872195
[batch_idx--200] train_loss: 0.0010589289470849122, acc: 0.8853194962686567, lr: 0.0014880255377669072
[batch_idx--250] train_loss: 0.0010507678816213729, acc: 0.8861584910358565, lr: 0.0014683609968220602
[batch_idx--300] train_loss: 0.0010523092905925804, acc: 0.8862775124584718, lr: 0.0014488233250576467
[batch_idx--350] train_loss: 0.001054354769209575, acc: 0.8858506944444444, lr: 0.0014294126278096538
[batch_idx--400] train_loss: 0.001051168673105092, acc: 0.8862901340399002, lr: 0.0014101290097294967
[batch_idx--450] train_loss: 0.0010537054354411127, acc: 0.8857916478633665, lr: 0.0013909725747834447
total time of one epoch: 316.88752818107605 s
train_loss:  0.0010537054354411127  acc:  0.8857916478633665
->>lr:0.001391
test_loss:  0.00109524442453156  test_acc:  0.8850974066261322
best acc:  88.59660007445092

------Epoch: 134------
[batch_idx--0] train_loss: 0.0008447531145066023, acc: 0.90625, lr: 0.001390590744062975
[batch_idx--50] train_loss: 0.001058001154531524, acc: 0.8838082107843137, lr: 0.0013715641423086456
[batch_idx--100] train_loss: 0.0010545523543288877, acc: 0.8838180693069307, lr: 0.0013526649316081968
[batch_idx--150] train_loss: 0.0010529538394500877, acc: 0.8851407284768212, lr: 0.0013338932138554
[batch_idx--200] train_loss: 0.0010515478192318916, acc: 0.8859219527363185, lr: 0.0013152490902566538
[batch_idx--250] train_loss: 0.0010493191200738913, acc: 0.8862674302788844, lr: 0.0012967326613304436
[batch_idx--300] train_loss: 0.0010432016924008158, acc: 0.887328696013289, lr: 0.0012783440269067943
[batch_idx--350] train_loss: 0.0010452263400176185, acc: 0.8868745548433048, lr: 0.0012600832861267342
[batch_idx--400] train_loss: 0.0010472166526451837, acc: 0.8869525405236908, lr: 0.0012419505374417718
[batch_idx--450] train_loss: 0.0010524336489816043, acc: 0.8869545596556393, lr: 0.0012239458786133446
total time of one epoch: 318.4772250652313 s
train_loss:  0.0010524336489816043  acc:  0.8869545596556393
->>lr:0.001224
test_loss:  0.00109754504067591  test_acc:  0.8843528973818091
best acc:  88.59660007445092

------Epoch: 135------
[batch_idx--0] train_loss: 0.001350186299532652, acc: 0.83984375, lr: 0.0012235870926211618
[batch_idx--50] train_loss: 0.0010505273205447284, acc: 0.8875612745098039, lr: 0.0012057131854440546
[batch_idx--100] train_loss: 0.0010513334239989813, acc: 0.8865253712871287, lr: 0.0011879675634946297
[batch_idx--150] train_loss: 0.0010497407006278684, acc: 0.8858909354304636, lr: 0.0011703503224471529
[batch_idx--200] train_loss: 0.0010483354444161465, acc: 0.8870491293532339, lr: 0.001152861557283752
[batch_idx--250] train_loss: 0.0010466883703416949, acc: 0.8873412599601593, lr: 0.0011355013622938726
[batch_idx--300] train_loss: 0.0010458789607262443, acc: 0.8876012250830565, lr: 0.0011182698310737928
[batch_idx--350] train_loss: 0.0010460038459461788, acc: 0.8878538995726496, lr: 0.0011011670565261005
[batch_idx--400] train_loss: 0.0010444542790526185, acc: 0.8878195137157108, lr: 0.0010841931308592041
[batch_idx--450] train_loss: 0.0010514662660831388, acc: 0.887162842364703, lr: 0.00106734814558683
total time of one epoch: 316.70727491378784 s
train_loss:  0.0010514662660831388  acc:  0.887162842364703
->>lr:0.001067
test_loss:  0.0010949676501157783  test_acc:  0.8832361335153245
best acc:  88.59660007445092

------Epoch: 136------
[batch_idx--0] train_loss: 0.0008620864246040583, acc: 0.90234375, lr: 0.001067012561698319
[batch_idx--50] train_loss: 0.0010356366641216857, acc: 0.8871017156862745, lr: 0.0010502991891848613
[batch_idx--100] train_loss: 0.0010372191208811237, acc: 0.8878016707920792, lr: 0.0010337149398027378
[batch_idx--150] train_loss: 0.0010319363976526537, acc: 0.8893832781456954, lr: 0.001017259902964765
[batch_idx--200] train_loss: 0.0010338426565876537, acc: 0.8893229166666666, lr: 0.0010009341673871241
[batch_idx--250] train_loss: 0.001035157904637406, acc: 0.8891465388446215, lr: 0.000984737821088863
[batch_idx--300] train_loss: 0.001035640468902923, acc: 0.8889119601328903, lr: 0.000968670951391451
[batch_idx--350] train_loss: 0.0010327517087810123, acc: 0.8888443732193733, lr: 0.0009527336449182884
[batch_idx--400] train_loss: 0.0010333231505426925, acc: 0.8884916614713217, lr: 0.0009369259875942449
[batch_idx--450] train_loss: 0.001041809801526579, acc: 0.8879612594161141, lr: 0.0009212480646451971
total time of one epoch: 316.66174387931824 s
train_loss:  0.001041809801526579  acc:  0.8879612594161141
->>lr:0.000921
test_loss:  0.001096721667852306  test_acc:  0.8841047276337014
best acc:  88.59660007445092

------Epoch: 137------
[batch_idx--0] train_loss: 0.0009990767575800419, acc: 0.890625, lr: 0.0009209358300585474
[batch_idx--50] train_loss: 0.001037816572980042, acc: 0.8889399509803921, lr: 0.0009053903232463079
[batch_idx--100] train_loss: 0.0010354480882507223, acc: 0.8891939975247525, lr: 0.0008899747208313852
[batch_idx--150] train_loss: 0.0010316171640968135, acc: 0.8890469784768212, lr: 0.0008746891059259105
[batch_idx--200] train_loss: 0.0010400063199551767, acc: 0.8884678171641791, lr: 0.0008595335609412142
[batch_idx--250] train_loss: 0.0010390419585340884, acc: 0.8889597858565738, lr: 0.0008445081675873518
[batch_idx--300] train_loss: 0.001038168383718923, acc: 0.888561565614618, lr: 0.0008296130068726787
[batch_idx--350] train_loss: 0.0010389793232054134, acc: 0.8883880876068376, lr: 0.0008148481591034013
[batch_idx--400] train_loss: 0.0010395550566488537, acc: 0.8882091645885287, lr: 0.0008002137038831625
[batch_idx--450] train_loss: 0.0010412924599996372, acc: 0.8884212170652966, lr: 0.000785709720112604
total time of one epoch: 311.1779074668884 s
train_loss:  0.0010412924599996372  acc:  0.8884212170652966
->>lr:0.000786
test_loss:  0.0010968771935219296  test_acc:  0.8834843032634322
best acc:  88.59660007445092

------Epoch: 138------
[batch_idx--0] train_loss: 0.0009292950853705406, acc: 0.890625, lr: 0.0007854209717842232
[batch_idx--50] train_loss: 0.0010212918072391081, acc: 0.8907015931372549, lr: 0.0007710501494462701
[batch_idx--100] train_loss: 0.0010437583418258715, acc: 0.8899675123762376, lr: 0.0007568099557912517
[batch_idx--150] train_loss: 0.0010487166096900423, acc: 0.8887624172185431, lr: 0.000742700467594179
[batch_idx--200] train_loss: 0.0010403403664814002, acc: 0.8897115982587065, lr: 0.0007287217609253605
[batch_idx--250] train_loss: 0.0010415923030790966, acc: 0.8892087898406374, lr: 0.0007148739111500131
[batch_idx--300] train_loss: 0.0010440390123103891, acc: 0.8885745431893688, lr: 0.0007011569929278511
[batch_idx--350] train_loss: 0.001047354843600141, acc: 0.8878984152421653, lr: 0.0006875710802126706
[batch_idx--400] train_loss: 0.0010481861667031714, acc: 0.8873616739401496, lr: 0.0006741162462519713
[batch_idx--450] train_loss: 0.0010534449112141364, acc: 0.8873450897351338, lr: 0.0006607925635865458
total time of one epoch: 311.082909822464 s
train_loss:  0.0010534449112141364  acc:  0.8873450897351338
->>lr:0.000661
test_loss:  0.0010943846169913255  test_acc:  0.8837324730115399
best acc:  88.59660007445092

------Epoch: 139------
[batch_idx--0] train_loss: 0.000984388985671103, acc: 0.86328125, lr: 0.0006605274281709927
[batch_idx--50] train_loss: 0.001028576494861102, acc: 0.8863357843137255, lr: 0.0006473375938249676
[batch_idx--100] train_loss: 0.0010371938391616291, acc: 0.8874535891089109, lr: 0.0006342790551494393
[batch_idx--150] train_loss: 0.0010388044494709975, acc: 0.8872361341059603, lr: 0.0006213518825486042
[batch_idx--200] train_loss: 0.0010421873022227626, acc: 0.8868547885572139, lr: 0.0006085561457184031
[batch_idx--250] train_loss: 0.0010366553150347444, acc: 0.8869210657370518, lr: 0.0005958919136461599
[batch_idx--300] train_loss: 0.001033337105125919, acc: 0.8878218438538206, lr: 0.000583359254610194
[batch_idx--350] train_loss: 0.0010364255078529616, acc: 0.8875089031339032, lr: 0.0005709582361794502
[batch_idx--400] train_loss: 0.001041237443268643, acc: 0.8869525405236908, lr: 0.0005586889252131494
[batch_idx--450] train_loss: 0.0010451043224650877, acc: 0.8873103759502898, lr: 0.0005465513878604278
total time of one epoch: 312.5430760383606 s
train_loss:  0.0010451043224650877  acc:  0.8873103759502898
->>lr:0.000547
test_loss:  0.0010924387442620403  test_acc:  0.8846010671299168
best acc:  88.59660007445092

------Epoch: 140------
[batch_idx--0] train_loss: 0.0013204450951889157, acc: 0.8515625, lr: 0.0005463099816548578
[batch_idx--50] train_loss: 0.0009918680012810464, acc: 0.8935355392156863, lr: 0.0005343069207980278
[batch_idx--100] train_loss: 0.0010153950470969965, acc: 0.8900061881188119, lr: 0.0005224357650086414
[batch_idx--150] train_loss: 0.0010230471950567123, acc: 0.8897195778145696, lr: 0.0005106965782891965
[batch_idx--200] train_loss: 0.0010245179314981793, acc: 0.8897115982587065, lr: 0.0004990894239306987
[batch_idx--250] train_loss: 0.0010272930322893974, acc: 0.889660109561753, lr: 0.0004876143645123038
[batch_idx--300] train_loss: 0.001030245712692184, acc: 0.8889379152823921, lr: 0.00047627146190098725
[batch_idx--350] train_loss: 0.0010320514105883907, acc: 0.8890558226495726, lr: 0.00046506077725121944
[batch_idx--400] train_loss: 0.0010333767073969834, acc: 0.8885598503740648, lr: 0.00045398237100461594
[batch_idx--450] train_loss: 0.0010371432654950415, acc: 0.8888464609296352, lr: 0.0004430363028896239
total time of one epoch: 312.75357818603516 s
train_loss:  0.0010371432654950415  acc:  0.8888464609296352
->>lr:0.000443
test_loss:  0.0010907600625363928  test_acc:  0.8858419158704554
best acc:  88.59660007445092

------Epoch: 141------
[batch_idx--0] train_loss: 0.0011955901281908154, acc: 0.875, lr: 0.00044281873178278475
[batch_idx--50] train_loss: 0.0010226304807207163, acc: 0.8880208333333334, lr: 0.0004320077093543484
[batch_idx--100] train_loss: 0.0010252731464950756, acc: 0.8881884282178217, lr: 0.0004213291435323757
[batch_idx--150] train_loss: 0.0010325656972504807, acc: 0.8880380794701986, lr: 0.0004107830918895994
[batch_idx--200] train_loss: 0.0010426708668544518, acc: 0.8873212064676617, lr: 0.00040036961128431806
[batch_idx--250] train_loss: 0.0010404503165439988, acc: 0.887652514940239, lr: 0.00039008875786008537
[batch_idx--300] train_loss: 0.0010395995474674203, acc: 0.8876920681063123, lr: 0.00037994058704539927
[batch_idx--350] train_loss: 0.0010381234699310975, acc: 0.8872863247863247, lr: 0.0003699251535534104
[batch_idx--400] train_loss: 0.0010410503828619372, acc: 0.887088918329177, lr: 0.0003600425113816253
[batch_idx--450] train_loss: 0.0010459430276008855, acc: 0.8875446939979866, lr: 0.0003502927138116147
total time of one epoch: 309.56457138061523 s
train_loss:  0.0010459430276008855  acc:  0.8875446939979866
->>lr:0.000350
test_loss:  0.0010904501390924582  test_acc:  0.8852214915001861
best acc:  88.59660007445092

------Epoch: 142------
[batch_idx--0] train_loss: 0.0012353966012597084, acc: 0.859375, lr: 0.00035009907323737546
[batch_idx--50] train_loss: 0.0010217393590959117, acc: 0.8888633578431373, lr: 0.00034048483130907914
[batch_idx--100] train_loss: 0.0010207233175930411, acc: 0.8885365099009901, lr: 0.00033100353942642217
[batch_idx--150] train_loss: 0.0010283657932493662, acc: 0.8888141556291391, lr: 0.0003216552487071145
[batch_idx--200] train_loss: 0.0010304483865962286, acc: 0.8888759328358209, lr: 0.00031244000955181765
[batch_idx--250] train_loss: 0.0010318966100986795, acc: 0.8891465388446215, lr: 0.00030335787164384453
[batch_idx--300] train_loss: 0.0010382515953411271, acc: 0.888483700166113, lr: 0.00029440888394890454
[batch_idx--350] train_loss: 0.0010378347718729996, acc: 0.8884882478632479, lr: 0.00028559309471483943
[batch_idx--400] train_loss: 0.0010387369951505, acc: 0.8885598503740648, lr: 0.00027691055147135437
[batch_idx--450] train_loss: 0.0010401699251679937, acc: 0.8886208213281495, lr: 0.0002683613010297709
total time of one epoch: 310.79263639450073 s
train_loss:  0.0010401699251679937  acc:  0.8886208213281495
->>lr:0.000268
test_loss:  0.0010898616070161018  test_acc:  0.8859660007445093
best acc:  88.59660007445092

------Epoch: 143------
[batch_idx--0] train_loss: 0.0009775318903848529, acc: 0.90625, lr: 0.0002681916759252945
[batch_idx--50] train_loss: 0.001022544982797448, acc: 0.8900122549019608, lr: 0.00025977843162139916
[batch_idx--100] train_loss: 0.0010238918055097876, acc: 0.889426051980198, lr: 0.0002514985724860308
[batch_idx--150] train_loss: 0.0010290024605493326, acc: 0.8888658940397351, lr: 0.00024335214315946986
[batch_idx--200] train_loss: 0.0010366886726751998, acc: 0.8877293221393034, lr: 0.00023533918756261376
[batch_idx--250] train_loss: 0.001038458701074717, acc: 0.8877925796812749, lr: 0.00022745974889675503
[batch_idx--300] train_loss: 0.0010412040894055906, acc: 0.887250830564784, lr: 0.0002197138696433315
[batch_idx--350] train_loss: 0.0010398748387818748, acc: 0.8872306801994302, lr: 0.0002121015915637098
[batch_idx--400] train_loss: 0.0010367802659542, acc: 0.8874590866583542, lr: 0.0002046229556989493
[batch_idx--450] train_loss: 0.001038938558631965, acc: 0.8876054431214635, lr: 0.00019727800236959416
total time of one epoch: 309.4424641132355 s
train_loss:  0.001038938558631965  acc:  0.8876054431214635
->>lr:0.000197
test_loss:  0.0010901945006952405  test_acc:  0.8858419158704554
best acc:  88.59660007445092

------Epoch: 144------
[batch_idx--0] train_loss: 0.0010954177705571055, acc: 0.88671875, lr: 0.0001971324671380531
[batch_idx--50] train_loss: 0.0010587455506217392, acc: 0.8871017156862745, lr: 0.00018992391078557493
[batch_idx--100] train_loss: 0.0010419172640557927, acc: 0.8884204826732673, lr: 0.00018284911621737067
[batch_idx--150] train_loss: 0.0010334047922920067, acc: 0.8893315397350994, lr: 0.00017590812157669555
[batch_idx--200] train_loss: 0.0010412184525030986, acc: 0.8890508395522388, lr: 0.00016910096428543743
[batch_idx--250] train_loss: 0.0010356289036367904, acc: 0.8892399153386454, lr: 0.00016242768104390848
[batch_idx--300] train_loss: 0.0010362163037556747, acc: 0.8889768480066446, lr: 0.00015588830783064834
[batch_idx--350] train_loss: 0.0010361918992829904, acc: 0.8893785612535613, lr: 0.0001494828799022241
[batch_idx--400] train_loss: 0.0010413605041344398, acc: 0.8887449345386533, lr: 0.00014321143179305552
[batch_idx--450] train_loss: 0.0010405687673662879, acc: 0.8887162842364703, lr: 0.00013707399731520964
total time of one epoch: 309.87003922462463 s
train_loss:  0.0010405687673662879  acc:  0.8887162842364703
->>lr:0.000137
test_loss:  0.0010897431188399479  test_acc:  0.8852214915001861
best acc:  88.59660007445092

------Epoch: 145------
[batch_idx--0] train_loss: 0.000969451735727489, acc: 0.89453125, lr: 0.00013695261579316776
[batch_idx--50] train_loss: 0.0010284715487311284, acc: 0.887484681372549, lr: 0.0001309519093031647
[batch_idx--100] train_loss: 0.0010360375019066994, acc: 0.8878016707920792, lr: 0.0001250852825408405
[batch_idx--150] train_loss: 0.0010411475876821144, acc: 0.8874172185430463, lr: 0.0001193527671357053
[batch_idx--200] train_loss: 0.0010323831539332349, acc: 0.8889731032338308, lr: 0.00011375439399421428
[batch_idx--250] train_loss: 0.0010389393050338612, acc: 0.8877614541832669, lr: 0.00010829019329959833
[batch_idx--300] train_loss: 0.001037301432435707, acc: 0.8878997093023255, lr: 0.00010296019451171701
[batch_idx--350] train_loss: 0.0010370660679046054, acc: 0.8881209935897436, lr: 9.776442636688366e-05
[batch_idx--400] train_loss: 0.0010407333193460662, acc: 0.8876149470074813, lr: 9.270291687771548e-05
[batch_idx--450] train_loss: 0.0010429070413176783, acc: 0.8877356198146283, lr: 8.77756933329893e-05
total time of one epoch: 314.2531111240387 s
train_loss:  0.0010429070413176783  acc:  0.8877356198146283
->>lr:0.000088
test_loss:  0.0010901929475279242  test_acc:  0.8859660007445093
best acc:  88.59660007445092

------Epoch: 146------
[batch_idx--0] train_loss: 0.0009644122328609228, acc: 0.8984375, lr: 8.767851876239075e-05
[batch_idx--50] train_loss: 0.0010176338232578892, acc: 0.8897824754901961, lr: 8.288829424305533e-05
[batch_idx--100] train_loss: 0.0010149039917090668, acc: 0.8915918935643564, lr: 7.82324085830094e-05
[batch_idx--150] train_loss: 0.0010173490913954891, acc: 0.890676738410596, lr: 7.371088688413186e-05
[batch_idx--200] train_loss: 0.0010132706528344186, acc: 0.890741604477612, lr: 6.93237535238922e-05
[batch_idx--250] train_loss: 0.0010220011864581044, acc: 0.8897067978087649, lr: 6.507103215520893e-05
[batch_idx--300] train_loss: 0.0010215274595494607, acc: 0.8896646594684385, lr: 6.09527457063358e-05
[batch_idx--350] train_loss: 0.0010244940428137566, acc: 0.8895788817663818, lr: 5.6968916380720215e-05
[batch_idx--400] train_loss: 0.001026751942836222, acc: 0.8890956203241895, lr: 5.311956565690057e-05
[batch_idx--450] train_loss: 0.0010303580940088386, acc: 0.8893845245947165, lr: 4.9404714288381335e-05
total time of one epoch: 317.85455203056335 s
train_loss:  0.0010303580940088386  acc:  0.8893845245947165
->>lr:0.000049
test_loss:  0.0010904376176054742  test_acc:  0.8855937461223476
best acc:  88.59660007445092

------Epoch: 147------
[batch_idx--0] train_loss: 0.0007841835613362491, acc: 0.92578125, lr: 4.933178929321103e-05
[batch_idx--50] train_loss: 0.001036585615628271, acc: 0.8884037990196079, lr: 4.57541478953355e-05
[batch_idx--100] train_loss: 0.0010434160035536948, acc: 0.8865640470297029, lr: 4.231104556289278e-05
[batch_idx--150] train_loss: 0.0010501843039100582, acc: 0.8852442052980133, lr: 3.9002500859128264e-05
[batch_idx--200] train_loss: 0.0010451231379437246, acc: 0.8860385572139303, lr: 3.582853162182598e-05
[batch_idx--250] train_loss: 0.0010459110663973716, acc: 0.8862363047808764, lr: 3.2789154963222546e-05
[batch_idx--300] train_loss: 0.001044117932229541, acc: 0.8867836378737541, lr: 2.9884387269901725e-05
[batch_idx--350] train_loss: 0.001044578096554734, acc: 0.8866853632478633, lr: 2.7114244202716688e-05
[batch_idx--400] train_loss: 0.001041823048191029, acc: 0.8871765897755611, lr: 2.4478740696695647e-05
[batch_idx--450] train_loss: 0.0010516814604056566, acc: 0.8868677751935293, lr: 2.1977890960975244e-05
total time of one epoch: 312.5750615596771 s
train_loss:  0.0010516814604056566  acc:  0.8868677751935293
->>lr:0.000022
test_loss:  0.0010906456495754357  test_acc:  0.8848492368780245
best acc:  88.59660007445092

------Epoch: 148------
[batch_idx--0] train_loss: 0.0009857815457507968, acc: 0.87109375, lr: 2.192924752854042e-05
[batch_idx--50] train_loss: 0.0010385192901023901, acc: 0.8903952205882353, lr: 1.9565758523884538e-05
[batch_idx--100] train_loss: 0.0010397709383961218, acc: 0.8888845915841584, lr: 1.7336949777524425e-05
[batch_idx--150] train_loss: 0.0010342194566916403, acc: 0.8885037251655629, lr: 1.524283330592846e-05
[batch_idx--200] train_loss: 0.0010300607363165203, acc: 0.8895366915422885, lr: 1.3283420399376467e-05
[batch_idx--250] train_loss: 0.0010284096706636339, acc: 0.889597858565737, lr: 1.14587216219042e-05
[batch_idx--300] train_loss: 0.00103474828024763, acc: 0.8886783637873754, lr: 9.768746811253394e-06
[batch_idx--350] train_loss: 0.0010334150245455637, acc: 0.8888109864672364, lr: 8.213505078799587e-06
[batch_idx--400] train_loss: 0.001034309062032619, acc: 0.8887838996259352, lr: 6.793004809518832e-06
[batch_idx--450] train_loss: 0.0010371010131223813, acc: 0.8888724962682681, lr: 5.507253661940492e-06
total time of one epoch: 318.76740741729736 s
train_loss:  0.0010371010131223813  acc:  0.8888724962682681
->>lr:0.000006
test_loss:  0.0010913967446485662  test_acc:  0.8857178309964016
best acc:  88.59660007445092

------Epoch: 149------
[batch_idx--0] train_loss: 0.0011856365017592907, acc: 0.87109375, lr: 5.482913128862511e-06
[batch_idx--50] train_loss: 0.0010811946909491193, acc: 0.8856464460784313, lr: 4.334613221818051e-06
[batch_idx--100] train_loss: 0.0010450817102861435, acc: 0.8899675123762376, lr: 3.321075690718156e-06
[batch_idx--150] train_loss: 0.001039623095120445, acc: 0.8897971854304636, lr: 2.4423059999861833e-06
[batch_idx--200] train_loss: 0.0010408299832618726, acc: 0.8894395211442786, lr: 1.6983088874406029e-06
[batch_idx--250] train_loss: 0.0010328420910490788, acc: 0.8898157370517928, lr: 1.089088364294999e-06
[batch_idx--300] train_loss: 0.0010343004366927518, acc: 0.8896387043189369, lr: 6.146477151164343e-07
[batch_idx--350] train_loss: 0.0010353179419336262, acc: 0.8891671118233618, lr: 2.749894978198997e-07
[batch_idx--400] train_loss: 0.0010351382043245166, acc: 0.8889495012468828, lr: 7.011554364610984e-08
[batch_idx--450] train_loss: 0.0010419610891516133, acc: 0.8884906446349845, lr: 2.6957161503027296e-11
total time of one epoch: 320.1267111301422 s
train_loss:  0.0010419610891516133  acc:  0.8884906446349845
->>lr:0.000000
test_loss:  0.0010900589665077893  test_acc:  0.8855937461223476
best acc:  88.59660007445092