Model: mobilenet_lstm_front
Batch size: 256
Number of dataloader workers: 32

loading annotations into memory...
Done (t=2.00s)
creating index...
index created!
Len of trainloader: 451

loading annotations into memory...
Done (t=0.14s)
creating index...
index created!
Len of testloader: 32

use 4 GPUs!
DataParallel device_ids: [0, 1, 2, 3]

------Epoch: 0------
[batch_idx--0] train_loss: 0.002704719314351678, acc: 0.5, lr: 0.05
[batch_idx--50] train_loss: 0.002725569873719531, acc: 0.5534620098039216, lr: 0.04999993260712715
[batch_idx--100] train_loss: 0.0027467907328011082, acc: 0.5626933787128713, lr: 0.04999973042887193
[batch_idx--150] train_loss: 0.002713329644429664, acc: 0.5784612996688742, lr: 0.049999393466324364
[batch_idx--200] train_loss: 0.002658252290389802, acc: 0.5956156716417911, lr: 0.04999892172130118
[batch_idx--250] train_loss: 0.002619913807027487, acc: 0.6071650896414342, lr: 0.04999831519634575
[batch_idx--300] train_loss: 0.0025799018431430145, acc: 0.6185112126245847, lr: 0.0499975738947281
[batch_idx--350] train_loss: 0.002542689583924973, acc: 0.6291844729344729, lr: 0.04999669782044491
[batch_idx--400] train_loss: 0.002511852268742727, acc: 0.6376246882793017, lr: 0.049995686978219496
[batch_idx--450] train_loss: 0.002494792453007121, acc: 0.6438973166244316, lr: 0.04999454137350172
total time of one epoch: 414.2596023082733 s
train_loss:  0.002494792453007121  acc:  0.6438973166244316
->>lr:0.049995
test_loss:  0.003282747059812734  test_acc:  0.5284774785953592
best acc:  0
Saving..
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(

------Epoch: 1------
[batch_idx--0] train_loss: 0.0022312155924737453, acc: 0.71484375, lr: 0.04999451708687114
[batch_idx--50] train_loss: 0.0022871031051538153, acc: 0.6970741421568627, lr: 0.04999323403077913
[batch_idx--100] train_loss: 0.002264194861331051, acc: 0.7012685643564357, lr: 0.04999181622541965
[batch_idx--150] train_loss: 0.0022589132515096802, acc: 0.703202607615894, lr: 0.0499902636784367
[batch_idx--200] train_loss: 0.002241920699499807, acc: 0.7060595460199005, lr: 0.04998857639820074
[batch_idx--250] train_loss: 0.002227893696571014, acc: 0.7076693227091634, lr: 0.04998675439380862
[batch_idx--300] train_loss: 0.0022205685878766584, acc: 0.7090297965116279, lr: 0.04998479767508354
[batch_idx--350] train_loss: 0.0022144896154719118, acc: 0.7109597578347578, lr: 0.04998270625257502
[batch_idx--400] train_loss: 0.002201030056394098, acc: 0.7128175654613467, lr: 0.04998048013755882
[batch_idx--450] train_loss: 0.0021960511330319744, acc: 0.7143836567500954, lr: 0.049978119342036866
total time of one epoch: 411.2517786026001 s
train_loss:  0.0021960511330319744  acc:  0.7143836567500954
->>lr:0.049978
test_loss:  0.003979609738598539  test_acc:  0.5284774785953592
best acc:  52.84774785953592

------Epoch: 2------
[batch_idx--0] train_loss: 0.0020765583030879498, acc: 0.74609375, lr: 0.04997807075247146
[batch_idx--50] train_loss: 0.002122640769526947, acc: 0.7267922794117647, lr: 0.04997557259595109
[batch_idx--100] train_loss: 0.0021007725459495836, acc: 0.7322091584158416, lr: 0.04997293978538365
[batch_idx--150] train_loss: 0.002101207198266754, acc: 0.7316587334437086, lr: 0.04997017233496374
[batch_idx--200] train_loss: 0.0020974576258939222, acc: 0.7313044154228856, lr: 0.04996727025961189
[batch_idx--250] train_loss: 0.0020946636100288526, acc: 0.7322429033864541, lr: 0.04996423357497442
[batch_idx--300] train_loss: 0.0020875103985952626, acc: 0.732921511627907, lr: 0.04996106229742341
[batch_idx--350] train_loss: 0.002073776070758212, acc: 0.7348646723646723, lr: 0.04995775644405658
[batch_idx--400] train_loss: 0.0020685293853975033, acc: 0.7354367986284289, lr: 0.049954316032697205
[batch_idx--450] train_loss: 0.0020664646641181906, acc: 0.7369389384524595, lr: 0.049950741081894026
total time of one epoch: 419.4862115383148 s
train_loss:  0.0020664646641181906  acc:  0.7369389384524595
->>lr:0.049951
test_loss:  0.002958508228039768  test_acc:  0.5287256483434669
best acc:  52.84774785953592
Saving..

------Epoch: 3------
[batch_idx--0] train_loss: 0.0020540945697575808, acc: 0.74609375, lr: 0.04995066821070679
[batch_idx--50] train_loss: 0.002036243873447472, acc: 0.7368259803921569, lr: 0.04994695604953209
[batch_idx--100] train_loss: 0.0020294221104261013, acc: 0.7419554455445545, lr: 0.0499431093885944
[batch_idx--150] train_loss: 0.0020109700348956007, acc: 0.7440500827814569, lr: 0.04993912824863275
[batch_idx--200] train_loss: 0.0019947989173094505, acc: 0.7476873445273632, lr: 0.049935012651111166
[batch_idx--250] train_loss: 0.001984325479215152, acc: 0.7502956922310757, lr: 0.0499307626182186
[batch_idx--300] train_loss: 0.001984003195276119, acc: 0.7505839908637874, lr: 0.0499263781728688
[batch_idx--350] train_loss: 0.001983529578647616, acc: 0.7504340277777778, lr: 0.04992185933870021
[batch_idx--400] train_loss: 0.0019777928208444557, acc: 0.7511007637157108, lr: 0.049917206140075804
[batch_idx--450] train_loss: 0.001975844763797412, acc: 0.7525514631860312, lr: 0.04991241860208297
total time of one epoch: 416.6071639060974 s
train_loss:  0.001975844763797412  acc:  0.7525514631860312
->>lr:0.049912
test_loss:  0.003424471639672703  test_acc:  0.5894031517558009
best acc:  52.87256483434669
Saving..

------Epoch: 4------
[batch_idx--0] train_loss: 0.0021049424540251493, acc: 0.71875, lr: 0.049912321481237615
[batch_idx--50] train_loss: 0.0019637107159759777, acc: 0.7545189950980392, lr: 0.04990739694368515
[batch_idx--100] train_loss: 0.0019332601015668103, acc: 0.7613319925742574, lr: 0.04990233811964985
[batch_idx--150] train_loss: 0.0019336213744769724, acc: 0.7619515728476821, lr: 0.049897145036406014
[batch_idx--200] train_loss: 0.0019278482966060143, acc: 0.7623989427860697, lr: 0.04989181772195179
[batch_idx--250] train_loss: 0.0019210318782444732, acc: 0.7632438994023905, lr: 0.04988635620500901
[batch_idx--300] train_loss: 0.0019281287638909892, acc: 0.7614462209302325, lr: 0.049880760515023076
[batch_idx--350] train_loss: 0.001926310663244175, acc: 0.7620081018518519, lr: 0.04987503068216274
[batch_idx--400] train_loss: 0.0019214054502249508, acc: 0.7632481296758105, lr: 0.04986916673732
[batch_idx--450] train_loss: 0.001925270661096652, acc: 0.7629395633005867, lr: 0.049863168712109905
total time of one epoch: 407.1774663925171 s
train_loss:  0.001925270661096652  acc:  0.7629395633005867
->>lr:0.049863
test_loss:  0.003953683019823377  test_acc:  0.5588782727385532
best acc:  58.940315175580096

------Epoch: 5------
[batch_idx--0] train_loss: 0.001908503589220345, acc: 0.75390625, lr: 0.049863047384206834
[batch_idx--50] train_loss: 0.0018923525703048298, acc: 0.7659313725490197, lr: 0.04985691263034154
[batch_idx--100] train_loss: 0.0018890517081438314, acc: 0.7675974628712872, lr: 0.049850643862176046
[batch_idx--150] train_loss: 0.0018781490488261577, acc: 0.7689103890728477, lr: 0.04984424111350797
[batch_idx--200] train_loss: 0.0018825563602149487, acc: 0.7685206778606966, lr: 0.0498377044188573
[batch_idx--250] train_loss: 0.0018794331296098483, acc: 0.768597485059761, lr: 0.04983103381346615
[batch_idx--300] train_loss: 0.0018789166224148879, acc: 0.7686747300664452, lr: 0.049824229333298636
[batch_idx--350] train_loss: 0.0018768207365089757, acc: 0.7685519052706553, lr: 0.049817291015040614
[batch_idx--400] train_loss: 0.001878002169019452, acc: 0.7686155704488778, lr: 0.04981021889609956
[batch_idx--450] train_loss: 0.0018834560640373784, acc: 0.7683028430589787, lr: 0.0498030130146043
total time of one epoch: 407.6797847747803 s
train_loss:  0.0018834560640373784  acc:  0.7683028430589787
->>lr:0.049803
test_loss:  0.002074169049799657  test_acc:  0.7517061670182404
best acc:  58.940315175580096
Saving..

------Epoch: 6------
[batch_idx--0] train_loss: 0.0019061325583606958, acc: 0.796875, lr: 0.04980286753286195
[batch_idx--50] train_loss: 0.0018404686627179092, acc: 0.7771905637254902, lr: 0.04979552525358963
[batch_idx--100] train_loss: 0.0018293282782456072, acc: 0.7777691831683168, lr: 0.04978804929098283
[batch_idx--150] train_loss: 0.0018280079512739715, acc: 0.7786889486754967, lr: 0.049780439685347705
[batch_idx--200] train_loss: 0.0018277373031680634, acc: 0.7781599813432836, lr: 0.0497726964777109
[batch_idx--250] train_loss: 0.0018217432756993579, acc: 0.7786354581673307, lr: 0.049764819709819365
[batch_idx--300] train_loss: 0.0018211259248285892, acc: 0.7782911129568106, lr: 0.04975680942414015
[batch_idx--350] train_loss: 0.0018269058746123884, acc: 0.7775440705128205, lr: 0.04974866566386016
[batch_idx--400] train_loss: 0.0018269326471075638, acc: 0.7775288341645885, lr: 0.049740388472885894
[batch_idx--450] train_loss: 0.0018290615771419077, acc: 0.7774238900267296, lr: 0.04973197789584324
total time of one epoch: 405.58811116218567 s
train_loss:  0.0018290615771419077  acc:  0.7774238900267296
->>lr:0.049732
test_loss:  0.002323503680790694  test_acc:  0.703188981263184
best acc:  75.17061670182404

------Epoch: 7------
[batch_idx--0] train_loss: 0.001571347820572555, acc: 0.796875, lr: 0.049731808324074714
[batch_idx--50] train_loss: 0.0018213547437506564, acc: 0.7768841911764706, lr: 0.04972326173996171
[batch_idx--100] train_loss: 0.0018277037416188286, acc: 0.7776144801980198, lr: 0.049714581862117906
[batch_idx--150] train_loss: 0.001829591822588434, acc: 0.7762572433774835, lr: 0.049705768737340256
[batch_idx--200] train_loss: 0.0018183054861181708, acc: 0.7777907338308457, lr: 0.04969682241314409
[batch_idx--250] train_loss: 0.0018147790110651478, acc: 0.7792424053784861, lr: 0.0496877429377629
[batch_idx--300] train_loss: 0.0018074733461949516, acc: 0.7801339285714286, lr: 0.04967853036014805
[batch_idx--350] train_loss: 0.0018076691932397818, acc: 0.7804042022792023, lr: 0.04966918472996849
[batch_idx--400] train_loss: 0.0018035593057083815, acc: 0.780772677680798, lr: 0.04965970609761053
[batch_idx--450] train_loss: 0.0018123447448641116, acc: 0.7801576005831916, lr: 0.04965009451417756
total time of one epoch: 405.68569779396057 s
train_loss:  0.0018123447448641116  acc:  0.7801576005831916
->>lr:0.049650
test_loss:  0.0023041985839335377  test_acc:  0.6901600694875295
best acc:  75.17061670182404

------Epoch: 8------
[batch_idx--0] train_loss: 0.0015368303284049034, acc: 0.8359375, lr: 0.04964990092676263
[batch_idx--50] train_loss: 0.0018112285898121841, acc: 0.7776501225490197, lr: 0.0496401537866232
[batch_idx--100] train_loss: 0.0018096859025132687, acc: 0.7783493193069307, lr: 0.04963027380082368
[batch_idx--150] train_loss: 0.001801252406744274, acc: 0.7810689155629139, lr: 0.04962026102263131
[batch_idx--200] train_loss: 0.0017976384362048325, acc: 0.78125, lr: 0.04961011550602926
[batch_idx--250] train_loss: 0.00178852935685253, acc: 0.7822615786852589, lr: 0.04959983730571641
[batch_idx--300] train_loss: 0.0017867642779682959, acc: 0.7825996677740864, lr: 0.04958942647710693
[batch_idx--350] train_loss: 0.001779228909885739, acc: 0.7838875534188035, lr: 0.04957888307633007
[batch_idx--400] train_loss: 0.0017763773203499967, acc: 0.7847763403990025, lr: 0.04956820716022985
[batch_idx--450] train_loss: 0.0017768303819832758, acc: 0.7852865622938869, lr: 0.049557398786364705
total time of one epoch: 406.98315691947937 s
train_loss:  0.0017768303819832758  acc:  0.7852865622938869
->>lr:0.049557
test_loss:  0.002691349145688347  test_acc:  0.6824668072961906
best acc:  75.17061670182404

------Epoch: 9------
[batch_idx--0] train_loss: 0.0019051933195441961, acc: 0.78515625, lr: 0.049557181268217225
[batch_idx--50] train_loss: 0.0017546512478706883, acc: 0.7872242647058824, lr: 0.04954623784746919
[batch_idx--100] train_loss: 0.0017560399252700039, acc: 0.7866646039603961, lr: 0.04953516208740226
[batch_idx--150] train_loss: 0.0017543759687328772, acc: 0.7871223096026491, lr: 0.049523954047730606
[batch_idx--200] train_loss: 0.0017545941066858706, acc: 0.787099657960199, lr: 0.04951261378888158
[batch_idx--250] train_loss: 0.0017494988637935533, acc: 0.788113172310757, lr: 0.049501141371995405
[batch_idx--300] train_loss: 0.0017456907629688268, acc: 0.788984634551495, lr: 0.0494895368589248
[batch_idx--350] train_loss: 0.001742863601426517, acc: 0.7895187856125356, lr: 0.0494778003122347
[batch_idx--400] train_loss: 0.0017419228765142715, acc: 0.7892183603491272, lr: 0.049465931795201847
[batch_idx--450] train_loss: 0.0017459342728784407, acc: 0.7886885132085951, lr: 0.049453931371814544
total time of one epoch: 409.1701407432556 s
train_loss:  0.0017459342728784407  acc:  0.7886885132085951
->>lr:0.049454
test_loss:  0.0019288377602678152  test_acc:  0.7694503040079415
best acc:  75.17061670182404
Saving..

------Epoch: 10------
[batch_idx--0] train_loss: 0.0018101767636835575, acc: 0.7734375, lr: 0.049453690018345146
[batch_idx--50] train_loss: 0.0017253166913767071, acc: 0.7951133578431373, lr: 0.04944155511713453
[batch_idx--100] train_loss: 0.0017146256309703435, acc: 0.7954826732673267, lr: 0.04942928844099462
[batch_idx--150] train_loss: 0.0017220558843803622, acc: 0.7946502483443708, lr: 0.0494168900560603
[batch_idx--200] train_loss: 0.0017241433214173832, acc: 0.7946012126865671, lr: 0.04940436002917662
[batch_idx--250] train_loss: 0.0017173723025484923, acc: 0.7953965388446215, lr: 0.04939169842789834
[batch_idx--300] train_loss: 0.0017239276804741582, acc: 0.7939290905315615, lr: 0.04937890532048959
[batch_idx--350] train_loss: 0.0017188713196638514, acc: 0.793770032051282, lr: 0.04936598077592351
[batch_idx--400] train_loss: 0.0017201956047994686, acc: 0.7936798628428927, lr: 0.049352924863881875
[batch_idx--450] train_loss: 0.001718415859800238, acc: 0.794242718783629, lr: 0.04933973765475472
total time of one epoch: 401.6700482368469 s
train_loss:  0.001718415859800238  acc:  0.794242718783629
->>lr:0.049340
test_loss:  0.001966916626537241  test_acc:  0.7728005956073954
best acc:  76.94503040079414
Saving..

------Epoch: 11------
[batch_idx--0] train_loss: 0.0017538231331855059, acc: 0.8046875, lr: 0.04933947257182901
[batch_idx--50] train_loss: 0.0017290134918784687, acc: 0.7927389705882353, lr: 0.04932615151292455
[batch_idx--100] train_loss: 0.001715447784788759, acc: 0.7929300742574258, lr: 0.04931269930128121
[batch_idx--150] train_loss: 0.001716835456684429, acc: 0.7932533112582781, lr: 0.04929911600942565
[batch_idx--200] train_loss: 0.0017142734781083703, acc: 0.7935323383084577, lr: 0.04928540171059123
[batch_idx--250] train_loss: 0.0017131899902782593, acc: 0.7943538346613546, lr: 0.04927155647871764
[batch_idx--300] train_loss: 0.0017138863445733028, acc: 0.7945520141196013, lr: 0.04925758038845046
[batch_idx--350] train_loss: 0.0017097925892009525, acc: 0.7956285612535613, lr: 0.04924347351514081
[batch_idx--400] train_loss: 0.0017061472581258216, acc: 0.7956865648379052, lr: 0.049229235934844906
[batch_idx--450] train_loss: 0.0017116030705762628, acc: 0.7953709167910578, lr: 0.04921486772432365
total time of one epoch: 404.5773606300354 s
train_loss:  0.0017116030705762628  acc:  0.7953709167910578
->>lr:0.049215
test_loss:  0.002107763008616346  test_acc:  0.7358233031393473
best acc:  77.28005956073955

------Epoch: 12------
[batch_idx--0] train_loss: 0.0017827339470386505, acc: 0.78515625, lr: 0.04921457902821578
[batch_idx--50] train_loss: 0.001727004788870759, acc: 0.7945006127450981, lr: 0.04920007765467417
[batch_idx--100] train_loss: 0.0017141676542469033, acc: 0.7976485148514851, lr: 0.049185445808112044
[batch_idx--150] train_loss: 0.00170449917636417, acc: 0.7976769453642384, lr: 0.049170683567415975
[batch_idx--200] train_loss: 0.0017002157192788463, acc: 0.7980799129353234, lr: 0.04915579101217554
[batch_idx--250] train_loss: 0.001697732261344939, acc: 0.7982445219123506, lr: 0.04914076822268292
[batch_idx--300] train_loss: 0.001699802138536327, acc: 0.7972902823920266, lr: 0.04912561527993242
[batch_idx--350] train_loss: 0.001695369746392736, acc: 0.7980657941595442, lr: 0.049110332265620074
[batch_idx--400] train_loss: 0.001690169282494452, acc: 0.7986284289276808, lr: 0.049094919262143176
[batch_idx--450] train_loss: 0.0016931255282753024, acc: 0.7990332210920956, lr: 0.049079376352599846
total time of one epoch: 406.37540793418884 s
train_loss:  0.0016931255282753024  acc:  0.7990332210920956
->>lr:0.049079
test_loss:  0.0018964381353451902  test_acc:  0.7728005956073954
best acc:  77.28005956073955

------Epoch: 13------
[batch_idx--0] train_loss: 0.0014525143196806312, acc: 0.82421875, lr: 0.049079064169941455
[batch_idx--50] train_loss: 0.0016753927293215313, acc: 0.7970281862745098, lr: 0.04906338884254441
[batch_idx--100] train_loss: 0.0016495192372747282, acc: 0.8022122524752475, lr: 0.04904758377907498
[batch_idx--150] train_loss: 0.0016687679156932413, acc: 0.7998758278145696, lr: 0.04903164906474507
[batch_idx--200] train_loss: 0.0016629759793341235, acc: 0.8010727611940298, lr: 0.04901558478546556
[batch_idx--250] train_loss: 0.001666826805919854, acc: 0.8001276145418327, lr: 0.04899939102784589
[batch_idx--300] train_loss: 0.0016687934173184426, acc: 0.7995354028239202, lr: 0.04898306787919357
[batch_idx--350] train_loss: 0.0016678761249073804, acc: 0.7997796474358975, lr: 0.04896661542751371
[batch_idx--400] train_loss: 0.0016698383960171493, acc: 0.7995635910224439, lr: 0.04895003376150854
[batch_idx--450] train_loss: 0.0016749911929722914, acc: 0.7995278925261221, lr: 0.04893332297057697
total time of one epoch: 405.7738211154938 s
train_loss:  0.0016749911929722914  acc:  0.7995278925261221
->>lr:0.048933
test_loss:  0.0019769483530309865  test_acc:  0.7536915250031021
best acc:  77.28005956073955

------Epoch: 14------
[batch_idx--0] train_loss: 0.0020918233785778284, acc: 0.75, lr: 0.048932987438301684
[batch_idx--50] train_loss: 0.001693538832934756, acc: 0.7988664215686274, lr: 0.04891614503276587
[batch_idx--100] train_loss: 0.0017018322337252817, acc: 0.7975324876237624, lr: 0.04889917368501234
[batch_idx--150] train_loss: 0.0016716983445321783, acc: 0.8019971026490066, lr: 0.04888207348654094
[batch_idx--200] train_loss: 0.0016691981859977788, acc: 0.8016557835820896, lr: 0.048864844529546175
[batch_idx--250] train_loss: 0.0016670242245067875, acc: 0.8019017679282868, lr: 0.04884748690691675
[batch_idx--300] train_loss: 0.0016682829454145163, acc: 0.8012484426910299, lr: 0.048830000712235096
[batch_idx--350] train_loss: 0.0016592963664338756, acc: 0.8031517094017094, lr: 0.048812386039776785
[batch_idx--400] train_loss: 0.0016609269340622456, acc: 0.803060707605985, lr: 0.0487946429845101
[batch_idx--450] train_loss: 0.0016648040550127617, acc: 0.8033030166279029, lr: 0.048776771642095464
total time of one epoch: 406.7405481338501 s
train_loss:  0.0016648040550127617  acc:  0.8033030166279029
->>lr:0.048777
test_loss:  0.0021615008301113067  test_acc:  0.7291227199404393
best acc:  77.28005956073955

------Epoch: 15------
[batch_idx--0] train_loss: 0.00161687470972538, acc: 0.79296875, lr: 0.048776412907378844
[batch_idx--50] train_loss: 0.0016442555386353942, acc: 0.8029258578431373, lr: 0.04875841081133997
[batch_idx--100] train_loss: 0.001647828371577555, acc: 0.8016321163366337, lr: 0.04874028062349638
[batch_idx--150] train_loss: 0.0016554487176819255, acc: 0.8009623344370861, lr: 0.0487220224415957
[batch_idx--200] train_loss: 0.0016452341412300643, acc: 0.8035214552238806, lr: 0.04870363636407563
[batch_idx--250] train_loss: 0.001642025179281623, acc: 0.8038471115537849, lr: 0.04868512249006343
[batch_idx--300] train_loss: 0.001641225719521212, acc: 0.8044798588039868, lr: 0.048666480919375345
[batch_idx--350] train_loss: 0.0016410550645863016, acc: 0.8048210470085471, lr: 0.0486477117525161
[batch_idx--400] train_loss: 0.0016392437120472218, acc: 0.8053012001246883, lr: 0.04862881509067834
[batch_idx--450] train_loss: 0.0016452009101765976, acc: 0.8049953136390461, lr: 0.04860979103574209
total time of one epoch: 406.04610991477966 s
train_loss:  0.0016452009101765976  acc:  0.8049953136390461
->>lr:0.048610
test_loss:  0.0019914134033324777  test_acc:  0.7591512594614717
best acc:  77.28005956073955

------Epoch: 16------
[batch_idx--0] train_loss: 0.0016817802097648382, acc: 0.78125, lr: 0.04860940925593703
[batch_idx--50] train_loss: 0.001676888960669292, acc: 0.7983302696078431, lr: 0.048590255365709406
[batch_idx--100] train_loss: 0.0016656782752419315, acc: 0.8005491955445545, lr: 0.04857097429027534
[batch_idx--150] train_loss: 0.0016482843121587737, acc: 0.8044546771523179, lr: 0.0485515661335874
[batch_idx--200] train_loss: 0.001643698335861537, acc: 0.8047846703980099, lr: 0.048532031000283304
[batch_idx--250] train_loss: 0.0016456997254863381, acc: 0.8039560507968128, lr: 0.048512368995685354
[batch_idx--300] train_loss: 0.001640584652831908, acc: 0.8050119393687708, lr: 0.04849258022579986
[batch_idx--350] train_loss: 0.0016398492880812991, acc: 0.804954594017094, lr: 0.04847266479731658
[batch_idx--400] train_loss: 0.0016362423427342587, acc: 0.8053206826683291, lr: 0.048452622817608176
[batch_idx--450] train_loss: 0.0016407497098131637, acc: 0.8054205575033846, lr: 0.04843245439472954
total time of one epoch: 404.6974482536316 s
train_loss:  0.0016407497098131637  acc:  0.8054205575033846
->>lr:0.048432
test_loss:  0.0017027512039258412  test_acc:  0.7999751830251892
best acc:  77.28005956073955
Saving..

------Epoch: 17------
[batch_idx--0] train_loss: 0.0015385710867121816, acc: 0.81640625, lr: 0.04843204973729729
[batch_idx--50] train_loss: 0.0016598465496345477, acc: 0.8021599264705882, lr: 0.048411752454410206
[batch_idx--100] train_loss: 0.0016518091785232766, acc: 0.8036819306930693, lr: 0.0483913289487026
[batch_idx--150] train_loss: 0.0016464347756831655, acc: 0.804584023178808, lr: 0.04837077933028638
[batch_idx--200] train_loss: 0.0016314508729331678, acc: 0.806572605721393, lr: 0.04835010370995336
[batch_idx--250] train_loss: 0.0016254412466697246, acc: 0.8080179282868526, lr: 0.0483293021991747
[batch_idx--300] train_loss: 0.0016230237627698982, acc: 0.8089441445182725, lr: 0.04830837491010029
[batch_idx--350] train_loss: 0.0016278634693585017, acc: 0.8080261752136753, lr: 0.04828732195555814
[batch_idx--400] train_loss: 0.0016293470095146327, acc: 0.8079508260598504, lr: 0.04826614344905377
[batch_idx--450] train_loss: 0.001633364922806171, acc: 0.8079893775818378, lr: 0.04824483950476961
total time of one epoch: 401.2756826877594 s
train_loss:  0.001633364922806171  acc:  0.8079893775818378
->>lr:0.048245
test_loss:  0.0018724916753142921  test_acc:  0.7728005956073954
best acc:  79.99751830251893

------Epoch: 18------
[batch_idx--0] train_loss: 0.001850042724981904, acc: 0.765625, lr: 0.04824441214720629
[batch_idx--50] train_loss: 0.0016317633939359117, acc: 0.8071384803921569, lr: 0.04822298037471885
[batch_idx--100] train_loss: 0.001628261278521749, acc: 0.80859375, lr: 0.04820142339716232
[batch_idx--150] train_loss: 0.0016094267689037006, acc: 0.8109478476821192, lr: 0.04817974133075961
[batch_idx--200] train_loss: 0.0016076883668339444, acc: 0.8114894278606966, lr: 0.04815793429240808
[batch_idx--250] train_loss: 0.0016064374249398826, acc: 0.8109125996015937, lr: 0.04813600239967885
[batch_idx--300] train_loss: 0.0016064112982790038, acc: 0.811046511627907, lr: 0.04811394577081616
[batch_idx--350] train_loss: 0.0016093645012669499, acc: 0.811019853988604, lr: 0.04809176452473679
[batch_idx--400] train_loss: 0.001612881832277667, acc: 0.8106199345386533, lr: 0.048069458781029376
[batch_idx--450] train_loss: 0.00162162162658635, acc: 0.8101155969035304, lr: 0.048047028659953764
total time of one epoch: 405.66446685791016 s
train_loss:  0.00162162162658635  acc:  0.8101155969035304
->>lr:0.048047
test_loss:  0.0024508851931517883  test_acc:  0.7170864871572156
best acc:  79.99751830251893

------Epoch: 19------
[batch_idx--0] train_loss: 0.001499825855717063, acc: 0.8125, lr: 0.04804657878971252
[batch_idx--50] train_loss: 0.0016457415459787145, acc: 0.8039981617647058, lr: 0.04802402192830846
[batch_idx--100] train_loss: 0.0016157333969627277, acc: 0.8098700495049505, lr: 0.04800134093450581
[batch_idx--150] train_loss: 0.001620156184726993, acc: 0.8090076572847682, lr: 0.04797853593058756
[batch_idx--200] train_loss: 0.0016105293055338349, acc: 0.8099735696517413, lr: 0.04795560703950527
[batch_idx--250] train_loss: 0.0016037656260520755, acc: 0.8107102838645418, lr: 0.047932554384878465
[batch_idx--300] train_loss: 0.0016037008455920456, acc: 0.8109167358803987, lr: 0.0479093780909939
[batch_idx--350] train_loss: 0.0016083474668337197, acc: 0.8105301816239316, lr: 0.047886078282804945
[batch_idx--400] train_loss: 0.001606414176725743, acc: 0.8106978647132169, lr: 0.047862655085930884
[batch_idx--450] train_loss: 0.0016048534828864965, acc: 0.8115475405283438, lr: 0.04783910862665624
total time of one epoch: 404.16703271865845 s
train_loss:  0.0016048534828864965  acc:  0.8115475405283438
->>lr:0.047839
test_loss:  0.0025270773912129943  test_acc:  0.7014517930264301
best acc:  79.99751830251893

------Epoch: 20------
[batch_idx--0] train_loss: 0.0015501281013712287, acc: 0.82421875, lr: 0.04783863644106502
[batch_idx--50] train_loss: 0.0015993135542992283, acc: 0.8092830882352942, lr: 0.047814964384929284
[batch_idx--100] train_loss: 0.00158926412361757, acc: 0.8139310024752475, lr: 0.047791169323514016
[batch_idx--150] train_loss: 0.0015850975101085886, acc: 0.8143884519867549, lr: 0.047767251385108636
[batch_idx--200] train_loss: 0.0015899024733495135, acc: 0.8132384950248757, lr: 0.04774321069866503
[batch_idx--250] train_loss: 0.0015858273018166363, acc: 0.8139162101593626, lr: 0.04771904739379687
[batch_idx--300] train_loss: 0.0015844121375012882, acc: 0.8142779277408638, lr: 0.0476947616007789
[batch_idx--350] train_loss: 0.0015878616158911518, acc: 0.8137353098290598, lr: 0.0476703534505463
[batch_idx--400] train_loss: 0.0015855395012161233, acc: 0.8144872194513716, lr: 0.047645823074693894
[batch_idx--450] train_loss: 0.0015873998343027937, acc: 0.8150102405665289, lr: 0.047621170605475466
total time of one epoch: 401.78646540641785 s
train_loss:  0.0015873998343027937  acc:  0.8150102405665289
->>lr:0.047621
test_loss:  0.0020498887623402215  test_acc:  0.7559250527360715
best acc:  79.99751830251893

------Epoch: 21------
[batch_idx--0] train_loss: 0.0014571506762877107, acc: 0.83984375, lr: 0.04762067631165049
[batch_idx--50] train_loss: 0.0015763158626927465, acc: 0.8167126225490197, lr: 0.047595899444129244
[batch_idx--100] train_loss: 0.001593504779935252, acc: 0.8117651608910891, lr: 0.04757100075240174
[batch_idx--150] train_loss: 0.0015997481902456836, acc: 0.8110513245033113, lr: 0.04754598037070751
[batch_idx--200] train_loss: 0.0015939640319113857, acc: 0.8122279228855721, lr: 0.047520838433942204
[batch_idx--250] train_loss: 0.0015935130056505837, acc: 0.8120175547808764, lr: 0.04749557507765681
[batch_idx--300] train_loss: 0.0015886387168166794, acc: 0.8131229235880398, lr: 0.047470190438056926
[batch_idx--350] train_loss: 0.0015847808824045494, acc: 0.8135349893162394, lr: 0.047444684652002064
[batch_idx--400] train_loss: 0.0015851942444350246, acc: 0.8129968048628429, lr: 0.04741905785700488
[batch_idx--450] train_loss: 0.0015913743596739575, acc: 0.8128753427986254, lr: 0.04739331019123044
total time of one epoch: 410.09164118766785 s
train_loss:  0.0015913743596739575  acc:  0.8128753427986254
->>lr:0.047393
test_loss:  0.00172022892547491  test_acc:  0.8071721057203127
best acc:  79.99751830251893
Saving..

------Epoch: 22------
[batch_idx--0] train_loss: 0.0017240868182852864, acc: 0.78515625, lr: 0.047392794005985325
[batch_idx--50] train_loss: 0.0015759072631743609, acc: 0.813265931372549, lr: 0.04736692319503155
[batch_idx--100] train_loss: 0.001570586755982425, acc: 0.8147818688118812, lr: 0.047340931794380904
[batch_idx--150] train_loss: 0.0015759378400267354, acc: 0.8146212748344371, lr: 0.04731481994416418
[batch_idx--200] train_loss: 0.001582549933566531, acc: 0.8132190609452736, lr: 0.04728858778516159
[batch_idx--250] train_loss: 0.001582156696572039, acc: 0.8140407121513944, lr: 0.04726223545880198
[batch_idx--300] train_loss: 0.0015879287396053292, acc: 0.8131229235880398, lr: 0.04723576310716207
[batch_idx--350] train_loss: 0.0015836154771411521, acc: 0.813980146011396, lr: 0.047209170872965694
[batch_idx--400] train_loss: 0.0015799462562426925, acc: 0.8145651496259352, lr: 0.047182458899583
[batch_idx--450] train_loss: 0.001586629504221326, acc: 0.8144548200090256, lr: 0.04715562733102973
total time of one epoch: 408.69096994400024 s
train_loss:  0.001586629504221326  acc:  0.8144548200090256
->>lr:0.047156
test_loss:  0.002585161307680798  test_acc:  0.7260205980890929
best acc:  80.71721057203126

------Epoch: 23------
[batch_idx--0] train_loss: 0.0015931067755445838, acc: 0.80859375, lr: 0.04715508948078037
[batch_idx--50] train_loss: 0.0015512261763397678, acc: 0.8227634803921569, lr: 0.047128136074186804
[batch_idx--100] train_loss: 0.0015461433881727776, acc: 0.8220915841584159, lr: 0.04710106336530035
[batch_idx--150] train_loss: 0.0015575721742745663, acc: 0.8185792632450332, lr: 0.04707387150008163
[batch_idx--200] train_loss: 0.0015599490322904725, acc: 0.8177083333333334, lr: 0.04704656062513368
[batch_idx--250] train_loss: 0.0015608588070330392, acc: 0.8175423306772909, lr: 0.04701913088770116
[batch_idx--300] train_loss: 0.0015600303987016364, acc: 0.8178467607973422, lr: 0.04699158243566958
[batch_idx--350] train_loss: 0.0015526985788739092, acc: 0.8187321937321937, lr: 0.04696391541756448
[batch_idx--400] train_loss: 0.0015585518408998697, acc: 0.817662874064838, lr: 0.046936129982550645
[batch_idx--450] train_loss: 0.0015668362504772093, acc: 0.8168327142708369, lr: 0.0469082262804313
total time of one epoch: 404.3177721500397 s
train_loss:  0.0015668362504772093  acc:  0.8168327142708369
->>lr:0.046908
test_loss:  0.0016312712563343003  test_acc:  0.8063035116019357
best acc:  80.71721057203126

------Epoch: 24------
[batch_idx--0] train_loss: 0.0013103889068588614, acc: 0.84765625, lr: 0.04690766700109659
[batch_idx--50] train_loss: 0.0015641202757536781, acc: 0.8140318627450981, lr: 0.04687964282151817
[batch_idx--100] train_loss: 0.0015706656486865612, acc: 0.8156327351485149, lr: 0.046851500679380806
[batch_idx--150] train_loss: 0.0015597605448684946, acc: 0.8167942880794702, lr: 0.046823240726410885
[batch_idx--200] train_loss: 0.0015613399179587465, acc: 0.8168532338308457, lr: 0.046794863114969956
[batch_idx--250] train_loss: 0.0015617830741898235, acc: 0.8169353834661355, lr: 0.04676636799805392
[batch_idx--300] train_loss: 0.0015621016222049182, acc: 0.8175352990033222, lr: 0.046737755529292206
[batch_idx--350] train_loss: 0.0015587740281909875, acc: 0.8176972044159544, lr: 0.046709025862946923
[batch_idx--400] train_loss: 0.001558011339366566, acc: 0.8171563279301746, lr: 0.046680179153912066
[batch_idx--450] train_loss: 0.0015641739984762375, acc: 0.8165723608845072, lr: 0.04665121555771262
total time of one epoch: 401.84854102134705 s
train_loss:  0.0015641739984762375  acc:  0.8165723608845072
->>lr:0.046651
test_loss:  0.002007932846533452  test_acc:  0.7633701451793027
best acc:  80.71721057203126

------Epoch: 25------
[batch_idx--0] train_loss: 0.0015998611925169826, acc: 0.8203125, lr: 0.046650635094610975
[batch_idx--50] train_loss: 0.0015619177047126725, acc: 0.8192401960784313, lr: 0.04662155243437907
[batch_idx--100] train_loss: 0.001543608447997877, acc: 0.8203511757425742, lr: 0.04659235320306443
[batch_idx--150] train_loss: 0.0015431421296979418, acc: 0.8212179221854304, lr: 0.046563037558092685
[batch_idx--200] train_loss: 0.0015484271339367872, acc: 0.8197877798507462, lr: 0.04653360565751704
[batch_idx--250] train_loss: 0.0015456211870068693, acc: 0.8200634960159362, lr: 0.04650405766001754
[batch_idx--300] train_loss: 0.0015473233998453003, acc: 0.8197155315614618, lr: 0.04647439372490014
[batch_idx--350] train_loss: 0.001549267148376148, acc: 0.8198784722222222, lr: 0.046444614012095875
[batch_idx--400] train_loss: 0.0015496992174549925, acc: 0.819640352244389, lr: 0.046414718682159954
[batch_idx--450] train_loss: 0.0015548276063051566, acc: 0.8194015343492901, lr: 0.04638470789627097
total time of one epoch: 401.8787705898285 s
train_loss:  0.0015548276063051566  acc:  0.8194015343492901
->>lr:0.046385
test_loss:  0.001760198266323661  test_acc:  0.7916614964635811
best acc:  80.71721057203126

------Epoch: 26------
[batch_idx--0] train_loss: 0.001622229814529419, acc: 0.8359375, lr: 0.04638410650401267
[batch_idx--50] train_loss: 0.0015413188809236767, acc: 0.8160232843137255, lr: 0.04635397811974326
[batch_idx--100] train_loss: 0.0015514630093561984, acc: 0.8158647896039604, lr: 0.04632373460699926
[batch_idx--150] train_loss: 0.0015489099777013754, acc: 0.816432119205298, lr: 0.04629337612883644
[batch_idx--200] train_loss: 0.0015472226268820354, acc: 0.8177472014925373, lr: 0.046262902848930414
[batch_idx--250] train_loss: 0.0015510066507005715, acc: 0.8176045816733067, lr: 0.04623231493157573
[batch_idx--300] train_loss: 0.0015455645039535292, acc: 0.8187941237541528, lr: 0.046201612541685
[batch_idx--350] train_loss: 0.0015444491457252464, acc: 0.8189325142450142, lr: 0.046170795844788
[batch_idx--400] train_loss: 0.001542834933740354, acc: 0.8193675966334164, lr: 0.04613986500703078
[batch_idx--450] train_loss: 0.0015491559019368323, acc: 0.8195837817197209, lr: 0.0461088201951748
total time of one epoch: 404.0020887851715 s
train_loss:  0.0015491559019368323  acc:  0.8195837817197209
->>lr:0.046109
test_loss:  0.0018932572819633686  test_acc:  0.7715597468668569
best acc:  80.71721057203126

------Epoch: 27------
[batch_idx--0] train_loss: 0.0015680532669648528, acc: 0.8125, lr: 0.04610819813755038
[batch_idx--50] train_loss: 0.0015341020965327818, acc: 0.8226868872549019, lr: 0.04607703724454855
[batch_idx--100] train_loss: 0.0015391572735890156, acc: 0.8222462871287128, lr: 0.046045762716179425
[batch_idx--150] train_loss: 0.001532256519977028, acc: 0.8223044288079471, lr: 0.04601437472105743
[batch_idx--200] train_loss: 0.001532514098294969, acc: 0.8215174129353234, lr: 0.04598287342840873
[batch_idx--250] train_loss: 0.0015401643709246203, acc: 0.8200012450199203, lr: 0.04595125900807036
[batch_idx--300] train_loss: 0.0015370946109103058, acc: 0.8198842400332226, lr: 0.045919531630489216
[batch_idx--350] train_loss: 0.0015392870027996451, acc: 0.8196892806267806, lr: 0.045887691466721246
[batch_idx--400] train_loss: 0.0015367428737894592, acc: 0.8204099127182045, lr: 0.04585573868843045
[batch_idx--450] train_loss: 0.0015374745256878358, acc: 0.8210157253445343, lr: 0.04582367346788801
total time of one epoch: 399.2987492084503 s
train_loss:  0.0015374745256878358  acc:  0.8210157253445343
->>lr:0.045824
test_loss:  0.0015750201771463142  test_acc:  0.821193696488398
best acc:  80.71721057203126
Saving..

------Epoch: 28------
[batch_idx--0] train_loss: 0.0013244521105661988, acc: 0.84375, lr: 0.04582303101775249
[batch_idx--50] train_loss: 0.0015326000193097427, acc: 0.8179381127450981, lr: 0.04579085128421578
[batch_idx--100] train_loss: 0.0015384935056975129, acc: 0.8186107673267327, lr: 0.04575855945826332
[batch_idx--150] train_loss: 0.0015517694440775162, acc: 0.8172081953642384, lr: 0.04572615571399419
[batch_idx--200] train_loss: 0.0015406584945178374, acc: 0.8188743781094527, lr: 0.045693640226110915
[batch_idx--250] train_loss: 0.0015387882652926255, acc: 0.8191919820717132, lr: 0.045661013169918455
[batch_idx--300] train_loss: 0.0015431661328975347, acc: 0.8184956395348837, lr: 0.04562827472132332
[batch_idx--350] train_loss: 0.0015413229833980571, acc: 0.8190215455840456, lr: 0.045595425056832534
[batch_idx--400] train_loss: 0.0015417065087036971, acc: 0.8193286315461347, lr: 0.04556246435355277
[batch_idx--450] train_loss: 0.0015425276241804206, acc: 0.8198007428749957, lr: 0.04552939278918935
total time of one epoch: 398.7746720314026 s
train_loss:  0.0015425276241804206  acc:  0.8198007428749957
->>lr:0.045529
test_loss:  0.001696538993214419  test_acc:  0.8075443603424742
best acc:  82.11936964883981

------Epoch: 29------
[batch_idx--0] train_loss: 0.0015054778195917606, acc: 0.8125, lr: 0.045528730228342605
[batch_idx--50] train_loss: 0.001503260815333502, acc: 0.8271292892156863, lr: 0.04549554576936571
[batch_idx--100] train_loss: 0.0015101356830650775, acc: 0.8260751856435643, lr: 0.04546225081009201
[batch_idx--150] train_loss: 0.0015107261676908723, acc: 0.8252793874172185, lr: 0.04542884553002893
[batch_idx--200] train_loss: 0.001507494732997014, acc: 0.8259872512437811, lr: 0.04539533010927871
[batch_idx--250] train_loss: 0.0015161020330624632, acc: 0.8243121264940239, lr: 0.04536170472853737
[batch_idx--300] train_loss: 0.001512740125672341, acc: 0.8244653239202658, lr: 0.045327969569093796
[batch_idx--350] train_loss: 0.0015137251353745701, acc: 0.82463051994302, lr: 0.04529412481282874
[batch_idx--400] train_loss: 0.0015158168591229138, acc: 0.8242284912718204, lr: 0.04526017064221382
[batch_idx--450] train_loss: 0.001520153371068304, acc: 0.8235671885305655, lr: 0.04522610724031057
total time of one epoch: 397.8040962219238 s
train_loss:  0.001520153371068304  acc:  0.8235671885305655
->>lr:0.045226
test_loss:  0.0014962311535944254  test_acc:  0.8239235637175828
best acc:  82.11936964883981
Saving..

------Epoch: 30------
[batch_idx--0] train_loss: 0.0015188566176220775, acc: 0.8046875, lr: 0.04522542485937369
[batch_idx--50] train_loss: 0.0014771419878610794, acc: 0.8295802696078431, lr: 0.04519125023075707
[batch_idx--100] train_loss: 0.0014888881463649693, acc: 0.8289371905940595, lr: 0.045156966742431685
[batch_idx--150] train_loss: 0.0014903826742365166, acc: 0.8277369619205298, lr: 0.04512257457923455
[batch_idx--200] train_loss: 0.0014995834002484434, acc: 0.8266868781094527, lr: 0.04508807392658861
[batch_idx--250] train_loss: 0.0015037726477322825, acc: 0.8263197211155379, lr: 0.0450534649705017
[batch_idx--300] train_loss: 0.0015067097713917098, acc: 0.8255035299003323, lr: 0.04501874789756559
[batch_idx--350] train_loss: 0.001510802055762131, acc: 0.8254206730769231, lr: 0.04498392289495493
[batch_idx--400] train_loss: 0.001508753145510735, acc: 0.8260403678304239, lr: 0.04494899015042629
[batch_idx--450] train_loss: 0.0015141081320861653, acc: 0.8254417329121394, lr: 0.04491394985231711
total time of one epoch: 400.9456009864807 s
train_loss:  0.0015141081320861653  acc:  0.8254417329121394
->>lr:0.044914
test_loss:  0.0018918609068875633  test_acc:  0.7771435661992803
best acc:  82.39235637175828

------Epoch: 31------
[batch_idx--0] train_loss: 0.0014608666533604264, acc: 0.82421875, lr: 0.04491324795060491
[batch_idx--50] train_loss: 0.0014869207447832998, acc: 0.8302696078431373, lr: 0.04487809814247016
[batch_idx--100] train_loss: 0.0014748409261355305, acc: 0.8323019801980198, lr: 0.044842841162964144
[batch_idx--150] train_loss: 0.0014875156616804418, acc: 0.8297806291390728, lr: 0.04480747720217241
[batch_idx--200] train_loss: 0.0014914628025607683, acc: 0.8276585820895522, lr: 0.04477200645075726
[batch_idx--250] train_loss: 0.001501681976042599, acc: 0.826179656374502, lr: 0.04473642909995676
[batch_idx--300] train_loss: 0.0014995932478482441, acc: 0.826360049833887, lr: 0.044700745341583706
[batch_idx--350] train_loss: 0.0015040626510595663, acc: 0.8261774394586895, lr: 0.044664955368024575
[batch_idx--400] train_loss: 0.0015059633254819083, acc: 0.8259429551122195, lr: 0.044629059372238496
[batch_idx--450] train_loss: 0.0015109198846650494, acc: 0.8251640226333877, lr: 0.044593057547756214
total time of one epoch: 398.3898286819458 s
train_loss:  0.0015109198846650494  acc:  0.8251640226333877
->>lr:0.044593
test_loss:  0.0016488514018718503  test_acc:  0.810274227571659
best acc:  82.39235637175828

------Epoch: 32------
[batch_idx--0] train_loss: 0.001475161174312234, acc: 0.81640625, lr: 0.044592336433146
[batch_idx--50] train_loss: 0.0015263255895571965, acc: 0.821078431372549, lr: 0.04455622686336067
[batch_idx--100] train_loss: 0.0015138441542311028, acc: 0.8246441831683168, lr: 0.0445200118575505
[batch_idx--150] train_loss: 0.0015162172455908051, acc: 0.8243998344370861, lr: 0.04448369161096615
[batch_idx--200] train_loss: 0.0015074910297155826, acc: 0.8268034825870647, lr: 0.044447266319425686
[batch_idx--250] train_loss: 0.0015063422965813443, acc: 0.8268955428286853, lr: 0.044410736179313494
[batch_idx--300] train_loss: 0.0015020242434279666, acc: 0.8270478612956811, lr: 0.04437410138757928
[batch_idx--350] train_loss: 0.0015013966489811441, acc: 0.8268117877492878, lr: 0.04433736214173695
[batch_idx--400] train_loss: 0.0015004352817980762, acc: 0.8269657886533666, lr: 0.04430051863986356
[batch_idx--450] train_loss: 0.0015032940965800051, acc: 0.8265959662582011, lr: 0.04426357108059828
total time of one epoch: 397.137323141098 s
train_loss:  0.0015032940965800051  acc:  0.8265959662582011
->>lr:0.044264
test_loss:  0.0015757456135255762  test_acc:  0.8273979401910907
best acc:  82.39235637175828
Saving..

------Epoch: 33------
[batch_idx--0] train_loss: 0.0013361963210627437, acc: 0.85546875, lr: 0.044262831069394735
[batch_idx--50] train_loss: 0.0015263510571208363, acc: 0.8210018382352942, lr: 0.04422577757680957
[batch_idx--100] train_loss: 0.0015124599725966996, acc: 0.8226330445544554, lr: 0.04418862042979371
[batch_idx--150] train_loss: 0.0014928670280878217, acc: 0.8257709023178808, lr: 0.044151359828677295
[batch_idx--200] train_loss: 0.0014962596808379487, acc: 0.8252876243781094, lr: 0.04411399597434825
[batch_idx--250] train_loss: 0.0014999680192324804, acc: 0.8255260209163346, lr: 0.04407652906825116
[batch_idx--300] train_loss: 0.001495172240635213, acc: 0.8258539244186046, lr: 0.04403895931238623
[batch_idx--350] train_loss: 0.0014953641569178202, acc: 0.8257322827635327, lr: 0.044001286909308164
[batch_idx--400] train_loss: 0.0014958784740158075, acc: 0.8260403678304239, lr: 0.04396351206212508
[batch_idx--450] train_loss: 0.0015001000848970862, acc: 0.8260231888082757, lr: 0.043925634974497405
total time of one epoch: 398.2166419029236 s
train_loss:  0.0015001000848970862  acc:  0.8260231888082757
->>lr:0.043926
test_loss:  0.0020223437023896527  test_acc:  0.7757786325846879
best acc:  82.73979401910907

------Epoch: 34------
[batch_idx--0] train_loss: 0.0014913779450580478, acc: 0.828125, lr: 0.043924876391293916
[batch_idx--50] train_loss: 0.001465420202151233, acc: 0.8318780637254902, lr: 0.0438868952287954
[batch_idx--100] train_loss: 0.0014594492034544007, acc: 0.8309096534653465, lr: 0.04384881223892658
[batch_idx--150] train_loss: 0.001475416962674122, acc: 0.8285647764900662, lr: 0.04381062762700922
[batch_idx--200] train_loss: 0.001473223822381329, acc: 0.8293299129353234, lr: 0.043772341598912995
[batch_idx--250] train_loss: 0.0014734270266327724, acc: 0.8287319472111554, lr: 0.04373395436105431
[batch_idx--300] train_loss: 0.001479192905319836, acc: 0.827592919435216, lr: 0.04369546612039528
[batch_idx--350] train_loss: 0.0014817581039075966, acc: 0.8276575854700855, lr: 0.04365687708444255
[batch_idx--400] train_loss: 0.001486701794152155, acc: 0.8273359569825436, lr: 0.04361818746124621
[batch_idx--450] train_loss: 0.0014875524311654623, acc: 0.8278196271739507, lr: 0.04357939745939863
total time of one epoch: 397.85911536216736 s
train_loss:  0.0014875524311654623  acc:  0.8278196271739507
->>lr:0.043579
test_loss:  0.0016727931876087294  test_acc:  0.8074202754684204
best acc:  82.73979401910907

------Epoch: 35------
[batch_idx--0] train_loss: 0.001596124959178269, acc: 0.7890625, lr: 0.04357862063693486
[batch_idx--50] train_loss: 0.0014611782515238896, acc: 0.8301164215686274, lr: 0.04353972846431615
[batch_idx--100] train_loss: 0.001481603541743416, acc: 0.830368193069307, lr: 0.043500736336052385
[batch_idx--150] train_loss: 0.0014734199780983147, acc: 0.8304790976821192, lr: 0.04346164446236689
[batch_idx--200] train_loss: 0.0014752509397922538, acc: 0.8306319962686567, lr: 0.04342245305402075
[batch_idx--250] train_loss: 0.0014729957036911491, acc: 0.8305839143426295, lr: 0.04338316232231171
[batch_idx--300] train_loss: 0.0014736652401340909, acc: 0.8305388289036545, lr: 0.043343772479072985
[batch_idx--350] train_loss: 0.0014734531071519963, acc: 0.8309072293447294, lr: 0.043304283736672146
[batch_idx--400] train_loss: 0.0014713684368664933, acc: 0.8306187655860349, lr: 0.04326469630800999
[batch_idx--450] train_loss: 0.00147436787939603, acc: 0.8308050126705314, lr: 0.04322501040651934
total time of one epoch: 403.38749408721924 s
train_loss:  0.00147436787939603  acc:  0.8308050126705314
->>lr:0.043225
test_loss:  0.0017043779285067378  test_acc:  0.8032013897505894
best acc:  82.73979401910907

------Epoch: 36------
[batch_idx--0] train_loss: 0.0014544796431437135, acc: 0.83984375, lr: 0.04322421568553529
[batch_idx--50] train_loss: 0.0014664157882661505, acc: 0.8302696078431373, lr: 0.04318442956218869
[batch_idx--100] train_loss: 0.001479633195132091, acc: 0.829169245049505, lr: 0.04314454539876614
[batch_idx--150] train_loss: 0.0014696866936907665, acc: 0.8306084437086093, lr: 0.043104563410300306
[batch_idx--200] train_loss: 0.0014687499398625089, acc: 0.8308846393034826, lr: 0.043064483812351256
[batch_idx--250] train_loss: 0.0014705779870408048, acc: 0.831004108565737, lr: 0.04302430682100536
[batch_idx--300] train_loss: 0.001470915068550487, acc: 0.831187707641196, lr: 0.042984032652874024
[batch_idx--350] train_loss: 0.0014703355370052264, acc: 0.8308849715099715, lr: 0.04294366152509261
[batch_idx--400] train_loss: 0.0014682619006807297, acc: 0.8314272911471322, lr: 0.04290319365531922
[batch_idx--450] train_loss: 0.0014702522212978074, acc: 0.8317162495226854, lr: 0.04286262926173353
total time of one epoch: 398.1377651691437 s
train_loss:  0.0014702522212978074  acc:  0.8317162495226854
->>lr:0.042863
test_loss:  0.0015447546484926259  test_acc:  0.8252884973321752
best acc:  82.73979401910907

------Epoch: 37------
[batch_idx--0] train_loss: 0.0015285887056961656, acc: 0.8359375, lr: 0.04286181699082009
[batch_idx--50] train_loss: 0.0015058623804875156, acc: 0.8227634803921569, lr: 0.04282115436825425
[batch_idx--100] train_loss: 0.0014887354313626443, acc: 0.825417698019802, lr: 0.04278039566418517
[batch_idx--150] train_loss: 0.0014895036745668445, acc: 0.8257709023178808, lr: 0.04273954109836054
[batch_idx--200] train_loss: 0.001493459434216073, acc: 0.8251321517412935, lr: 0.0426985908910449
[batch_idx--250] train_loss: 0.0014875046389392647, acc: 0.8264909113545816, lr: 0.042657545263018404
[batch_idx--300] train_loss: 0.0014822928535062015, acc: 0.8275539867109635, lr: 0.042616404435575676
[batch_idx--350] train_loss: 0.0014807307171340808, acc: 0.8280693554131054, lr: 0.04257516863052461
[batch_idx--400] train_loss: 0.0014763611680630622, acc: 0.8287192175810474, lr: 0.04253383807018514
[batch_idx--450] train_loss: 0.001479802360609404, acc: 0.8289738605200125, lr: 0.042492412977388094
total time of one epoch: 399.5370078086853 s
train_loss:  0.001479802360609404  acc:  0.8289738605200125
->>lr:0.042492
test_loss:  0.0016780921581262156  test_acc:  0.8072961905943665
best acc:  82.73979401910907

------Epoch: 38------
[batch_idx--0] train_loss: 0.0013949894346296787, acc: 0.84375, lr: 0.042491583512834136
[batch_idx--50] train_loss: 0.0014582434555004333, acc: 0.8295036764705882, lr: 0.04245006222701923
[batch_idx--100] train_loss: 0.001458028172336445, acc: 0.8321086014851485, lr: 0.04240844686041831
[batch_idx--150] train_loss: 0.001453946922005259, acc: 0.8329625413907285, lr: 0.042366737637397726
[batch_idx--200] train_loss: 0.0014476933440110131, acc: 0.8336054104477612, lr: 0.04232493478282982
[batch_idx--250] train_loss: 0.0014499573410855999, acc: 0.8336186503984063, lr: 0.042283038522091754
[batch_idx--300] train_loss: 0.0014529052349828504, acc: 0.8330045681063123, lr: 0.04224104908106427
[batch_idx--350] train_loss: 0.0014514322578376344, acc: 0.8335225249287749, lr: 0.0421989666861305
[batch_idx--400] train_loss: 0.0014535118819927412, acc: 0.8328495168329177, lr: 0.04215679156417471
[batch_idx--450] train_loss: 0.0014609385235375728, acc: 0.8326882354983164, lr: 0.04211452394258114
total time of one epoch: 401.19112730026245 s
train_loss:  0.0014609385235375728  acc:  0.8326882354983164
->>lr:0.042115
test_loss:  0.0017146718888117697  test_acc:  0.7974934855441121
best acc:  82.73979401910907

------Epoch: 39------
[batch_idx--0] train_loss: 0.0015843583969399333, acc: 0.8046875, lr: 0.04211367764821722
[batch_idx--50] train_loss: 0.0014611623368646, acc: 0.8311121323529411, lr: 0.04207131591176148
[batch_idx--100] train_loss: 0.0014440223556196335, acc: 0.8340423886138614, lr: 0.042028862136503926
[batch_idx--150] train_loss: 0.0014467292098291466, acc: 0.8331694950331126, lr: 0.0419863165513311
[batch_idx--200] train_loss: 0.0014474220129091348, acc: 0.8342661691542289, lr: 0.041943679385624544
[batch_idx--250] train_loss: 0.0014487581162442606, acc: 0.8337275896414342, lr: 0.04190095086925955
[batch_idx--300] train_loss: 0.0014456707819448505, acc: 0.8347305855481728, lr: 0.041858131232603915
[batch_idx--350] train_loss: 0.0014477166807560244, acc: 0.8348468660968661, lr: 0.04181522070651669
[batch_idx--400] train_loss: 0.0014485196271990229, acc: 0.8344373441396509, lr: 0.04177221952234698
[batch_idx--450] train_loss: 0.0014581850530699242, acc: 0.833955288645121, lr: 0.041729127911932645
total time of one epoch: 401.9732904434204 s
train_loss:  0.0014581850530699242  acc:  0.833955288645121
->>lr:0.041729
test_loss:  0.001801363716114838  test_acc:  0.7916614964635811
best acc:  82.73979401910907

------Epoch: 40------
[batch_idx--0] train_loss: 0.0014710891991853714, acc: 0.86328125, lr: 0.04172826515897146
[batch_idx--50] train_loss: 0.0014609490617123596, acc: 0.8355545343137255, lr: 0.04168508155313258
[batch_idx--100] train_loss: 0.0014657424002111252, acc: 0.8329594678217822, lr: 0.04164180799084732
[batch_idx--150] train_loss: 0.001458224609173489, acc: 0.8325227649006622, lr: 0.04159844470542206
[batch_idx--200] train_loss: 0.0014581491733989239, acc: 0.8324004975124378, lr: 0.041554991930646906
[batch_idx--250] train_loss: 0.001457567818358956, acc: 0.8322958167330677, lr: 0.041511449900794445
[batch_idx--300] train_loss: 0.001455558031144555, acc: 0.8330824335548173, lr: 0.04146781885061848
[batch_idx--350] train_loss: 0.0014526015545567896, acc: 0.8334223646723646, lr: 0.04142409901535277
[batch_idx--400] train_loss: 0.0014522941574045547, acc: 0.8332391677057357, lr: 0.04138029063070971
[batch_idx--450] train_loss: 0.0014543462300654827, acc: 0.8337903981671122, lr: 0.041336393932879134
total time of one epoch: 397.12491488456726 s
train_loss:  0.0014543462300654827  acc:  0.8337903981671122
->>lr:0.041336
test_loss:  0.0016122557992955299  test_acc:  0.8198287628738057
best acc:  82.73979401910907

------Epoch: 41------
[batch_idx--0] train_loss: 0.001537524745799601, acc: 0.80859375, lr: 0.04133551509975264
[batch_idx--50] train_loss: 0.001472309487415295, acc: 0.8291973039215687, lr: 0.041291528566287365
[batch_idx--100] train_loss: 0.0014557861861321005, acc: 0.8315284653465347, lr: 0.041247454198189024
[batch_idx--150] train_loss: 0.0014498869114438232, acc: 0.8324451572847682, lr: 0.04120329223308148
[batch_idx--200] train_loss: 0.0014543024735034105, acc: 0.8324004975124378, lr: 0.041159042909060875
[batch_idx--250] train_loss: 0.0014548338110191355, acc: 0.8326226344621513, lr: 0.04111470646469433
[batch_idx--300] train_loss: 0.0014441198788496645, acc: 0.8344580564784053, lr: 0.04107028313901867
[batch_idx--350] train_loss: 0.0014384581804928235, acc: 0.835136217948718, lr: 0.04102577317153916
[batch_idx--400] train_loss: 0.0014376240039820274, acc: 0.8350997506234414, lr: 0.04098117680222813
[batch_idx--450] train_loss: 0.0014408407604495318, acc: 0.8354306245009894, lr: 0.04093649427152381
total time of one epoch: 398.9900333881378 s
train_loss:  0.0014408407604495318  acc:  0.8354306245009894
->>lr:0.040936
test_loss:  0.0015772609131435912  test_acc:  0.8223104603548828
best acc:  82.73979401910907

------Epoch: 42------
[batch_idx--0] train_loss: 0.0013440728653222322, acc: 0.84765625, lr: 0.040935599743717244
[batch_idx--50] train_loss: 0.001454288603317942, acc: 0.8353247549019608, lr: 0.04089082957657292
[batch_idx--100] train_loss: 0.0014708873131174115, acc: 0.830677599009901, lr: 0.04084597373513602
[batch_idx--150] train_loss: 0.001457644213262378, acc: 0.8326003725165563, lr: 0.04080103246124366
[batch_idx--200] train_loss: 0.0014487939894857322, acc: 0.8343439054726368, lr: 0.04075600599719357
[batch_idx--250] train_loss: 0.0014508264895298508, acc: 0.8338520916334662, lr: 0.04071089458574278
[batch_idx--300] train_loss: 0.001443815206415778, acc: 0.8347305855481728, lr: 0.04066569847010627
[batch_idx--350] train_loss: 0.0014396174333225458, acc: 0.8355146011396012, lr: 0.040620417893955756
[batch_idx--400] train_loss: 0.001440992413676272, acc: 0.8352166458852868, lr: 0.04057505310141827
[batch_idx--450] train_loss: 0.0014434141193967519, acc: 0.8350227375290727, lr: 0.04052960433707492
total time of one epoch: 399.52659845352173 s
train_loss:  0.0014434141193967519  acc:  0.8350227375290727
->>lr:0.040530
test_loss:  0.0015499126210019227  test_acc:  0.8245439880878521
best acc:  82.73979401910907

------Epoch: 43------
[batch_idx--0] train_loss: 0.001443582703359425, acc: 0.83203125, lr: 0.040528694506957764
[batch_idx--50] train_loss: 0.0014451293722160306, acc: 0.8300398284313726, lr: 0.04048316034380937
[batch_idx--100] train_loss: 0.0014482592497629546, acc: 0.8311803836633663, lr: 0.040437542704288454
[batch_idx--150] train_loss: 0.00144891596371493, acc: 0.8323158112582781, lr: 0.04039184183433934
[batch_idx--200] train_loss: 0.0014492063649897626, acc: 0.8324199315920398, lr: 0.04034605798035504
[batch_idx--250] train_loss: 0.0014435182190110603, acc: 0.8335563994023905, lr: 0.04030019138917598
[batch_idx--300] train_loss: 0.0014370711241072148, acc: 0.834484011627907, lr: 0.040254242308088696
[batch_idx--350] train_loss: 0.0014357731204633828, acc: 0.8343794515669516, lr: 0.040208210984824425
[batch_idx--400] train_loss: 0.001433466740842082, acc: 0.8345737219451371, lr: 0.04016209766755781
[batch_idx--450] train_loss: 0.0014432071819583342, acc: 0.833920574860277, lr: 0.040115902604905565
total time of one epoch: 401.55728554725647 s
train_loss:  0.0014432071819583342  acc:  0.833920574860277
->>lr:0.040116
test_loss:  0.0018536291349938556  test_acc:  0.7834718947760269
best acc:  82.73979401910907

------Epoch: 44------
[batch_idx--0] train_loss: 0.0012959024170413613, acc: 0.85546875, lr: 0.040114977871559376
[batch_idx--50] train_loss: 0.001457383490952791, acc: 0.8316482843137255, lr: 0.04006869968519579
[batch_idx--100] train_loss: 0.001432747438337912, acc: 0.8348545792079208, lr: 0.04002234025699524
[batch_idx--150] train_loss: 0.001426214988294076, acc: 0.8363514072847682, lr: 0.039975899836901335
[batch_idx--200] train_loss: 0.0014228828347505845, acc: 0.8372784514925373, lr: 0.03992937867529435
[batch_idx--250] train_loss: 0.001424090370472773, acc: 0.8370735806772909, lr: 0.03988277702298985
[batch_idx--300] train_loss: 0.0014247662817867492, acc: 0.837157392026578, lr: 0.03983609513123738
[batch_idx--350] train_loss: 0.0014235572335562347, acc: 0.8376179665242165, lr: 0.03978933325171908
[batch_idx--400] train_loss: 0.0014211573031849398, acc: 0.8377006701995012, lr: 0.03974249163654834
[batch_idx--450] train_loss: 0.0014273832259971207, acc: 0.8371836706356094, lr: 0.03969557053826845
total time of one epoch: 398.46038341522217 s
train_loss:  0.0014273832259971207  acc:  0.8371836706356094
->>lr:0.039696
test_loss:  0.0015694808946648076  test_acc:  0.8250403275840675
best acc:  82.73979401910907

------Epoch: 45------
[batch_idx--0] train_loss: 0.0012592057464644313, acc: 0.86328125, lr: 0.03969463130731183
[batch_idx--50] train_loss: 0.0014029619165276195, acc: 0.8384650735294118, lr: 0.0396476293968751
[batch_idx--100] train_loss: 0.0014069527422197828, acc: 0.8391475866336634, lr: 0.03960054851477232
[batch_idx--150] train_loss: 0.0014032841573734553, acc: 0.8394815811258278, lr: 0.039553388914836764
[batch_idx--200] train_loss: 0.0014035303443345932, acc: 0.8400769589552238, lr: 0.039506150851326104
[batch_idx--250] train_loss: 0.0014057466430975444, acc: 0.8392212400398407, lr: 0.039458834578921055
[batch_idx--300] train_loss: 0.001413705146506404, acc: 0.837702450166113, lr: 0.03941144035272397
[batch_idx--350] train_loss: 0.001414410171611102, acc: 0.8379184472934473, lr: 0.03936396842825749
[batch_idx--400] train_loss: 0.0014136627239832408, acc: 0.8383046290523691, lr: 0.03931641906146319
[batch_idx--450] train_loss: 0.0014192050151348727, acc: 0.8378345541014337, lr: 0.03926879250870011
total time of one epoch: 400.3736934661865 s
train_loss:  0.0014192050151348727  acc:  0.8378345541014337
->>lr:0.039269
test_loss:  0.0017209138537713532  test_acc:  0.7952599578111428
best acc:  82.73979401910907

------Epoch: 46------
[batch_idx--0] train_loss: 0.0016272466164082289, acc: 0.81640625, lr: 0.0392678391921108
[batch_idx--50] train_loss: 0.0014385296894675668, acc: 0.8333333333333334, lr: 0.03922013417419226
[batch_idx--100] train_loss: 0.0014429364300397511, acc: 0.8331915222772277, lr: 0.03917235248941817
[batch_idx--150] train_loss: 0.001428642427388406, acc: 0.835963369205298, lr: 0.03912449439540013
[batch_idx--200] train_loss: 0.0014278366553611053, acc: 0.8358597636815921, lr: 0.0390765601501617
[batch_idx--250] train_loss: 0.0014238733992136391, acc: 0.8365444472111554, lr: 0.03902855001213699
[batch_idx--300] train_loss: 0.0014212183446230436, acc: 0.8367680647840532, lr: 0.0389804642401693
[batch_idx--350] train_loss: 0.0014197729866914557, acc: 0.8367053952991453, lr: 0.03893230309350968
[batch_idx--400] train_loss: 0.0014195567957285857, acc: 0.83680447319202, lr: 0.03888406683181559
[batch_idx--450] train_loss: 0.0014226526126964365, acc: 0.8371836706356094, lr: 0.03883575571514944
total time of one epoch: 402.8086624145508 s
train_loss:  0.0014226526126964365  acc:  0.8371836706356094
->>lr:0.038836
test_loss:  0.0018001341770949354  test_acc:  0.7956322124333044
best acc:  82.73979401910907

------Epoch: 47------
[batch_idx--0] train_loss: 0.0013681715354323387, acc: 0.828125, lr: 0.038834788731083605
[batch_idx--50] train_loss: 0.0014336144679463377, acc: 0.8363970588235294, lr: 0.038786401530680796
[batch_idx--100] train_loss: 0.0014294709590733936, acc: 0.8364402846534653, lr: 0.03873794000186154
[batch_idx--150] train_loss: 0.0014248440082228143, acc: 0.8367911837748344, lr: 0.03868940440590278
[batch_idx--200] train_loss: 0.0014150091632273956, acc: 0.8380363805970149, lr: 0.03864079500448077
[batch_idx--250] train_loss: 0.0014199973946711813, acc: 0.8367000747011952, lr: 0.03859211205966969
[batch_idx--300] train_loss: 0.0014176276343042323, acc: 0.8379620016611296, lr: 0.038543355833940224
[batch_idx--350] train_loss: 0.0014187252305532963, acc: 0.83768474002849, lr: 0.03849452659015813
[batch_idx--400] train_loss: 0.0014171925996966715, acc: 0.8380513559850374, lr: 0.03844562459158286
[batch_idx--450] train_loss: 0.0014208662799385697, acc: 0.8381903703960842, lr: 0.0383966501018661
total time of one epoch: 401.15845799446106 s
train_loss:  0.0014208662799385697  acc:  0.8381903703960842
->>lr:0.038397
test_loss:  0.0014998471120078653  test_acc:  0.8285147040575754
best acc:  82.73979401910907
Saving..

------Epoch: 48------
[batch_idx--0] train_loss: 0.0013363100588321686, acc: 0.85546875, lr: 0.03839566987447492
[batch_idx--50] train_loss: 0.001439705201169001, acc: 0.8325674019607843, lr: 0.038346621715813135
[batch_idx--100] train_loss: 0.0014375760473569136, acc: 0.833694306930693, lr: 0.038297501599776934
[batch_idx--150] train_loss: 0.0014314054479107063, acc: 0.8346699089403974, lr: 0.03824830979119395
[batch_idx--200] train_loss: 0.001420944210359669, acc: 0.8365010883084577, lr: 0.038199046555278386
[batch_idx--250] train_loss: 0.0014193894339732797, acc: 0.8375249003984063, lr: 0.038149712157629516
[batch_idx--300] train_loss: 0.001419871766661662, acc: 0.8376245847176079, lr: 0.038100306864230285
[batch_idx--350] train_loss: 0.001415128419985013, acc: 0.8381855413105413, lr: 0.038050830941445866
[batch_idx--400] train_loss: 0.001410740198035657, acc: 0.8389475529925187, lr: 0.03800128465602222
[batch_idx--450] train_loss: 0.00141405406075242, acc: 0.8389280383240185, lr: 0.03795166827508467
total time of one epoch: 397.7055847644806 s
train_loss:  0.00141405406075242  acc:  0.8389280383240185
->>lr:0.037952
test_loss:  0.0014826546703146444  test_acc:  0.8285147040575754
best acc:  82.85147040575754

------Epoch: 49------
[batch_idx--0] train_loss: 0.0014016502536833286, acc: 0.8359375, lr: 0.03795067523432826
[batch_idx--50] train_loss: 0.0014377059209543992, acc: 0.8354779411764706, lr: 0.037900987631550954
[batch_idx--100] train_loss: 0.0014307738355554566, acc: 0.8359375, lr: 0.03785123047400412
[batch_idx--150] train_loss: 0.0014300494368453295, acc: 0.8353942466887417, lr: 0.03780140402994997
[batch_idx--200] train_loss: 0.0014149603238143953, acc: 0.8372201492537313, lr: 0.03775150856802428
[batch_idx--250] train_loss: 0.0014098262793729565, acc: 0.838863296812749, lr: 0.03770154435723495
[batch_idx--300] train_loss: 0.0014052134219161004, acc: 0.8387795888704319, lr: 0.037651511666960506
[batch_idx--350] train_loss: 0.001410108317018744, acc: 0.8382077991452992, lr: 0.03760141076694869
[batch_idx--400] train_loss: 0.0014074456557501432, acc: 0.8386553148379052, lr: 0.037551241927314974
[batch_idx--450] train_loss: 0.0014101397090293055, acc: 0.838389974658937, lr: 0.03750100541854115
total time of one epoch: 398.7848026752472 s
train_loss:  0.0014101397090293055  acc:  0.838389974658937
->>lr:0.037501
test_loss:  0.0020707992868959526  test_acc:  0.7556768829879638
best acc:  82.85147040575754

------Epoch: 50------
[batch_idx--0] train_loss: 0.0010972535237669945, acc: 0.91015625, lr: 0.037500000000000006
[batch_idx--50] train_loss: 0.001423804897486287, acc: 0.8400735294117647, lr: 0.037449694747731944
[batch_idx--100] train_loss: 0.0014090009533920058, acc: 0.8407719678217822, lr: 0.03739932237380827
[batch_idx--150] train_loss: 0.0014093929018196187, acc: 0.8393263658940397, lr: 0.03734888314980809
[batch_idx--200] train_loss: 0.0014053252450334122, acc: 0.8399409203980099, lr: 0.037298377347670955
[batch_idx--250] train_loss: 0.0014059809347302969, acc: 0.8399215637450199, lr: 0.03724780523969534
[batch_idx--300] train_loss: 0.0014089487289601435, acc: 0.8395063330564784, lr: 0.03719716709853723
[batch_idx--350] train_loss: 0.0014080117842012704, acc: 0.8395432692307693, lr: 0.037146463197208594
[batch_idx--400] train_loss: 0.0014114322194811004, acc: 0.838801433915212, lr: 0.03709569380907597
[batch_idx--450] train_loss: 0.0014156648922095665, acc: 0.8388672892005415, lr: 0.03704485920785895
total time of one epoch: 399.168484210968 s
train_loss:  0.0014156648922095665  acc:  0.8388672892005415
->>lr:0.037045
test_loss:  0.001471379648176194  test_acc:  0.8339744385159449
best acc:  82.85147040575754
Saving..

------Epoch: 51------
[batch_idx--0] train_loss: 0.0012797678355127573, acc: 0.8515625, lr: 0.037043841852542884
[batch_idx--50] train_loss: 0.0013994738532632006, acc: 0.8434436274509803, lr: 0.03699294101633032
[batch_idx--100] train_loss: 0.0014009392350026876, acc: 0.8415454826732673, lr: 0.036941975521017835
[batch_idx--150] train_loss: 0.001403709574423681, acc: 0.8414993791390728, lr: 0.0368909456413823
[batch_idx--200] train_loss: 0.0013941406516766, acc: 0.8424867848258707, lr: 0.03683985165254776
[batch_idx--250] train_loss: 0.0013993045563746496, acc: 0.8411354581673307, lr: 0.03678869382998386
[batch_idx--300] train_loss: 0.0014015096974593164, acc: 0.8408040905315615, lr: 0.03673747244950439
[batch_idx--350] train_loss: 0.001399876056318609, acc: 0.8405893874643875, lr: 0.03668618778726586
[batch_idx--400] train_loss: 0.0013994528924200934, acc: 0.8409250311720698, lr: 0.0366348401197659
[batch_idx--450] train_loss: 0.001397330273444151, acc: 0.8414100739403617, lr: 0.036583429723841876
total time of one epoch: 398.7164080142975 s
train_loss:  0.001397330273444151  acc:  0.8414100739403617
->>lr:0.036583
test_loss:  0.001655875774867068  test_acc:  0.8094056334532821
best acc:  83.39744385159449

------Epoch: 52------
[batch_idx--0] train_loss: 0.0012792752822861075, acc: 0.87109375, lr: 0.036582400877996545
[batch_idx--50] train_loss: 0.001396431268064999, acc: 0.8404564950980392, lr: 0.03653092678462853
[batch_idx--100] train_loss: 0.0014062885985718949, acc: 0.8385674504950495, lr: 0.036479390523077894
[batch_idx--150] train_loss: 0.001390863264701175, acc: 0.8399989652317881, lr: 0.036427792371198774
[batch_idx--200] train_loss: 0.0013927309959200188, acc: 0.839804881840796, lr: 0.036376132607179
[batch_idx--250] train_loss: 0.0013925464317365828, acc: 0.8404040089641435, lr: 0.03632441150953856
[batch_idx--300] train_loss: 0.0013876947360824904, acc: 0.8412193729235881, lr: 0.036272629357128106
[batch_idx--350] train_loss: 0.0013889853213714738, acc: 0.8413461538461539, lr: 0.0362207864291275
[batch_idx--400] train_loss: 0.0013867633776075004, acc: 0.8415484725685786, lr: 0.03616888300504424
[batch_idx--450] train_loss: 0.0013905559863439845, acc: 0.8417919255736453, lr: 0.03611691936471199
total time of one epoch: 399.6758975982666 s
train_loss:  0.0013905559863439845  acc:  0.8417919255736453
->>lr:0.036117
test_loss:  0.0015816692198634902  test_acc:  0.8158580469040824
best acc:  83.39744385159449

------Epoch: 53------
[batch_idx--0] train_loss: 0.0017227263888344169, acc: 0.78125, lr: 0.036115879479623185
[batch_idx--50] train_loss: 0.0013844654438834563, acc: 0.8409160539215687, lr: 0.0360638547073383
[batch_idx--100] train_loss: 0.0013807983077730578, acc: 0.8419709158415841, lr: 0.036011770285057136
[batch_idx--150] train_loss: 0.0013790341951446423, acc: 0.8425341473509934, lr: 0.03595962649358918
[batch_idx--200] train_loss: 0.0013694732081589859, acc: 0.8441775497512438, lr: 0.03590742361406404
[batch_idx--250] train_loss: 0.0013738961828189838, acc: 0.8432208665338645, lr: 0.03585516192792988
[batch_idx--300] train_loss: 0.001372593301472152, acc: 0.8432698297342193, lr: 0.03580284171695191
[batch_idx--350] train_loss: 0.0013806096336504503, acc: 0.8423477564102564, lr: 0.03575046326321087
[batch_idx--400] train_loss: 0.0013761211989651854, acc: 0.8430096633416458, lr: 0.035698026849101526
[batch_idx--450] train_loss: 0.001380929881474383, acc: 0.8425643072864234, lr: 0.03564553275733112
total time of one epoch: 400.2487041950226 s
train_loss:  0.001380929881474383  acc:  0.8425643072864234
->>lr:0.035646
test_loss:  0.0014811785548892117  test_acc:  0.8321131654051371
best acc:  83.39744385159449

------Epoch: 54------
[batch_idx--0] train_loss: 0.0013627074658870697, acc: 0.8515625, lr: 0.03564448228912682
[batch_idx--50] train_loss: 0.001392161672222702, acc: 0.8435968137254902, lr: 0.035591929657709624
[batch_idx--100] train_loss: 0.001373343132805116, acc: 0.8456837871287128, lr: 0.03553931992064693
[batch_idx--150] train_loss: 0.001378749463312476, acc: 0.8450434602649006, lr: 0.035486653361580446
[batch_idx--200] train_loss: 0.0013737948918344444, acc: 0.8454796330845771, lr: 0.03543393026445823
[batch_idx--250] train_loss: 0.0013774651681551658, acc: 0.844777141434263, lr: 0.03538115091353316
[batch_idx--300] train_loss: 0.0013811294189762585, acc: 0.8441782599667774, lr: 0.035328315593361394
[batch_idx--350] train_loss: 0.0013803681507945443, acc: 0.844017094017094, lr: 0.03527542458880086
[batch_idx--400] train_loss: 0.0013785174193715402, acc: 0.8438084476309227, lr: 0.035222478185009704
[batch_idx--450] train_loss: 0.00138308934718148, acc: 0.8436143992779532, lr: 0.035169476667444736
total time of one epoch: 395.14925813674927 s
train_loss:  0.00138308934718148  acc:  0.8436143992779532
->>lr:0.035169
test_loss:  0.002029986254466883  test_acc:  0.7690780493857798
best acc:  83.39744385159449

------Epoch: 55------
[batch_idx--0] train_loss: 0.0013824731577187777, acc: 0.859375, lr: 0.035168416076895005
[batch_idx--50] train_loss: 0.0013902508562394216, acc: 0.8415287990196079, lr: 0.03511535863766653
[batch_idx--100] train_loss: 0.0013779399277974325, acc: 0.8454904084158416, lr: 0.03506224666219176
[batch_idx--150] train_loss: 0.00137774251163968, acc: 0.8450434602649006, lr: 0.03500908043682018
[batch_idx--200] train_loss: 0.001381771585125643, acc: 0.8434584888059702, lr: 0.034955860248193804
[batch_idx--250] train_loss: 0.0013819664449568289, acc: 0.8432519920318725, lr: 0.034902586383245504
[batch_idx--300] train_loss: 0.0013819246632557523, acc: 0.8426858388704319, lr: 0.03484925912919761
[batch_idx--350] train_loss: 0.0013814056308759626, acc: 0.8428374287749287, lr: 0.03479587877356025
[batch_idx--400] train_loss: 0.0013799613389300365, acc: 0.8427758728179551, lr: 0.034742445604129875
[batch_idx--450] train_loss: 0.0013766577355784776, acc: 0.8434668656923664, lr: 0.034688959908987675
total time of one epoch: 395.2364559173584 s
train_loss:  0.0013766577355784776  acc:  0.8434668656923664
->>lr:0.034689
test_loss:  0.001667866411450513  test_acc:  0.8063035116019357
best acc:  83.39744385159449

------Epoch: 56------
[batch_idx--0] train_loss: 0.0013205441646277905, acc: 0.8671875, lr: 0.034687889661302575
[batch_idx--50] train_loss: 0.0013469869417010569, acc: 0.8500306372549019, lr: 0.034634350687009215
[batch_idx--100] train_loss: 0.001353527464221536, acc: 0.8487391707920792, lr: 0.034580759769790186
[batch_idx--150] train_loss: 0.0013580492794797417, acc: 0.8471129966887417, lr: 0.034527117198577144
[batch_idx--200] train_loss: 0.0013620129349729538, acc: 0.8465485074626866, lr: 0.034473423262580266
[batch_idx--250] train_loss: 0.0013695138156881548, acc: 0.8454152141434262, lr: 0.03441967825128663
[batch_idx--300] train_loss: 0.0013673168822095738, acc: 0.8454630398671097, lr: 0.0343658824544587
[batch_idx--350] train_loss: 0.0013657879871064188, acc: 0.8453859508547008, lr: 0.034312036162132735
[batch_idx--400] train_loss: 0.0013631558605467441, acc: 0.8457177369077307, lr: 0.034258139664617236
[batch_idx--450] train_loss: 0.0013623082674151347, acc: 0.8460009719859757, lr: 0.0342041932524914
total time of one epoch: 398.4460246562958 s
train_loss:  0.0013623082674151347  acc:  0.8460009719859757
->>lr:0.034204
test_loss:  0.0018716908326618191  test_acc:  0.779997518302519
best acc:  83.39744385159449

------Epoch: 57------
[batch_idx--0] train_loss: 0.0013239601394161582, acc: 0.8828125, lr: 0.03420311381711696
[batch_idx--50] train_loss: 0.0013529736452790745, acc: 0.8467371323529411, lr: 0.03414911679172232
[batch_idx--100] train_loss: 0.0013620173616224144, acc: 0.8457611386138614, lr: 0.034095070439506506
[batch_idx--150] train_loss: 0.0013640826345970298, acc: 0.8454573675496688, lr: 0.03404097505185664
[batch_idx--200] train_loss: 0.0013674877089360237, acc: 0.8451881218905473, lr: 0.0339868309204242
[batch_idx--250] train_loss: 0.00136495106417567, acc: 0.8451195219123506, lr: 0.03393263833712346
[batch_idx--300] train_loss: 0.0013658642460223894, acc: 0.8451645556478405, lr: 0.03387839759412996
[batch_idx--350] train_loss: 0.0013656580540088888, acc: 0.8448851495726496, lr: 0.03382410898387883
[batch_idx--400] train_loss: 0.0013656477914760796, acc: 0.8450455891521197, lr: 0.033769772799063326
[batch_idx--450] train_loss: 0.001369927380186543, acc: 0.8450550213489777, lr: 0.03371538933263315
total time of one epoch: 396.6109254360199 s
train_loss:  0.001369927380186543  acc:  0.8450550213489777
->>lr:0.033715
test_loss:  0.0016822452498718916  test_acc:  0.8028291351284278
best acc:  83.39744385159449

------Epoch: 58------
[batch_idx--0] train_loss: 0.0014234273694455624, acc: 0.82421875, lr: 0.03371430118304538
[batch_idx--50] train_loss: 0.0013488223776221275, acc: 0.8441329656862745, lr: 0.03365986979142943
[batch_idx--100] train_loss: 0.0013467224480787127, acc: 0.8442141089108911, lr: 0.03360539171073317
[batch_idx--150] train_loss: 0.0013556052469617583, acc: 0.8446812913907285, lr: 0.03355086723467137
[batch_idx--200] train_loss: 0.0013549780671192862, acc: 0.8454407649253731, lr: 0.03349629665720888
[batch_idx--250] train_loss: 0.0013520330458738474, acc: 0.8459132221115537, lr: 0.03344168027255918
[batch_idx--300] train_loss: 0.0013570367765498418, acc: 0.8455279277408638, lr: 0.033387018375182646
[batch_idx--350] train_loss: 0.001356416020377876, acc: 0.8455194978632479, lr: 0.03333231125978507
[batch_idx--400] train_loss: 0.0013595057118386774, acc: 0.8452404145885287, lr: 0.03327755922131603
[batch_idx--450] train_loss: 0.0013634530343685626, acc: 0.8450203075641337, lr: 0.033222762554967304
total time of one epoch: 398.61636328697205 s
train_loss:  0.0013634530343685626  acc:  0.8450203075641337
->>lr:0.033223
test_loss:  0.0013896456123034435  test_acc:  0.8468792654175455
best acc:  83.39744385159449
Saving..

------Epoch: 59------
[batch_idx--0] train_loss: 0.0014769657282158732, acc: 0.8515625, lr: 0.03322166616846458
[batch_idx--50] train_loss: 0.0014082077301709967, acc: 0.83984375, lr: 0.033166824286034645
[batch_idx--100] train_loss: 0.0013779538814992745, acc: 0.84375, lr: 0.03311193837274467
[batch_idx--150] train_loss: 0.0013746391790641459, acc: 0.8443191225165563, lr: 0.03305700872450816
[batch_idx--200] train_loss: 0.0013686917399042355, acc: 0.8461986940298507, lr: 0.03300203563747449
[batch_idx--250] train_loss: 0.0013653006290078192, acc: 0.8461777888446215, lr: 0.0329470194080272
[batch_idx--300] train_loss: 0.0013613691404570155, acc: 0.8465661337209303, lr: 0.032891960332782424
[batch_idx--350] train_loss: 0.0013578736000731482, acc: 0.8463430377492878, lr: 0.03283685870858731
[batch_idx--400] train_loss: 0.0013581774500314788, acc: 0.8465360037406484, lr: 0.03278171483251839
[batch_idx--450] train_loss: 0.0013598685660437808, acc: 0.8466692123442219, lr: 0.03272652900188
total time of one epoch: 400.5536940097809 s
train_loss:  0.0013598685660437808  acc:  0.8466692123442219
->>lr:0.032727
test_loss:  0.00164976840664752  test_acc:  0.8142449435413823
best acc:  84.68792654175456

------Epoch: 60------
[batch_idx--0] train_loss: 0.0012107965303584933, acc: 0.8828125, lr: 0.032725424859373686
[batch_idx--50] train_loss: 0.001419050032364241, acc: 0.8383884803921569, lr: 0.032670196541591943
[batch_idx--100] train_loss: 0.001381376228009415, acc: 0.8425897277227723, lr: 0.03261492687048379
[batch_idx--150] train_loss: 0.0013743520695839496, acc: 0.843827607615894, lr: 0.03255961614403176
[batch_idx--200] train_loss: 0.0013670354996997845, acc: 0.8447800062189055, lr: 0.03250426466043975
[batch_idx--250] train_loss: 0.0013603458261725852, acc: 0.845633092629482, lr: 0.03244887271813142
[batch_idx--300] train_loss: 0.0013594734505672887, acc: 0.845891299833887, lr: 0.032393440615748524
[batch_idx--350] train_loss: 0.00136043854950638, acc: 0.8451188568376068, lr: 0.03233796865214936
[batch_idx--400] train_loss: 0.0013607481910854096, acc: 0.844792316084788, lr: 0.03228245712640712
[batch_idx--450] train_loss: 0.0013614796552335467, acc: 0.8451244489186656, lr: 0.0322269063378083
total time of one epoch: 396.46055340766907 s
train_loss:  0.0013614796552335467  acc:  0.8451244489186656
->>lr:0.032227
test_loss:  0.0018317421119582017  test_acc:  0.783347809901973
best acc:  84.68792654175456

------Epoch: 61------
[batch_idx--0] train_loss: 0.0010835392167791724, acc: 0.89453125, lr: 0.03222579492361179
[batch_idx--50] train_loss: 0.0014091277490461281, acc: 0.8412990196078431, lr: 0.032170204395443734
[batch_idx--100] train_loss: 0.0013759827366937873, acc: 0.8461865717821783, lr: 0.03211457520962184
[batch_idx--150] train_loss: 0.0013595286819201875, acc: 0.8484323261589404, lr: 0.032058907666066935
[batch_idx--200] train_loss: 0.0013557205006216112, acc: 0.8485113495024875, lr: 0.03200320206490668
[batch_idx--250] train_loss: 0.0013577903078709436, acc: 0.8472516185258964, lr: 0.03194745870647391
[batch_idx--300] train_loss: 0.0013559532100009884, acc: 0.8474356312292359, lr: 0.03189167789130505
[batch_idx--350] train_loss: 0.0013571748763065456, acc: 0.8473335113960114, lr: 0.031835859920138446
[batch_idx--400] train_loss: 0.0013541336413159352, acc: 0.847373753117207, lr: 0.03178000509391275
[batch_idx--450] train_loss: 0.001361003749300929, acc: 0.8471985975630923, lr: 0.03172411371376536
total time of one epoch: 398.46351075172424 s
train_loss:  0.001361003749300929  acc:  0.8471985975630923
->>lr:0.031724
test_loss:  0.0014706115181858182  test_acc:  0.827149770442983
best acc:  84.68792654175456

------Epoch: 62------
[batch_idx--0] train_loss: 0.0012063790345564485, acc: 0.8671875, lr: 0.031722995515381644
[batch_idx--50] train_loss: 0.0013967495795120211, acc: 0.8394607843137255, lr: 0.03166706716067022
[batch_idx--100] train_loss: 0.001370885596140334, acc: 0.8422803217821783, lr: 0.03161110286093404
[batch_idx--150] train_loss: 0.001364785322490833, acc: 0.8432067466887417, lr: 0.031555102917900694
[batch_idx--200] train_loss: 0.0013644557347201479, acc: 0.8433224502487562, lr: 0.03149906763348994
[batch_idx--250] train_loss: 0.0013606468954427814, acc: 0.8449172061752988, lr: 0.0314429973098121
[batch_idx--300] train_loss: 0.001350654787855823, acc: 0.8463584925249169, lr: 0.031386892249166375
[batch_idx--350] train_loss: 0.0013485919553826316, acc: 0.8465767450142451, lr: 0.03133075275403927
[batch_idx--400] train_loss: 0.0013442630518141884, acc: 0.8473153054862843, lr: 0.03127457912710293
[batch_idx--450] train_loss: 0.0013517288130782687, acc: 0.8468688166070747, lr: 0.031218371671213524
total time of one epoch: 404.18852734565735 s
train_loss:  0.0013517288130782687  acc:  0.8468688166070747
->>lr:0.031218
test_loss:  0.0017251366938235875  test_acc:  0.7961285519295198
best acc:  84.68792654175456

------Epoch: 63------
[batch_idx--0] train_loss: 0.0014685112982988358, acc: 0.83203125, lr: 0.031217247179121367
[batch_idx--50] train_loss: 0.0013441245035067492, acc: 0.8470435049019608, lr: 0.0311610055298914
[batch_idx--100] train_loss: 0.0013381145758517455, acc: 0.8483524133663366, lr: 0.031104730664032437
[batch_idx--150] train_loss: 0.00133953310799051, acc: 0.8480184188741722, lr: 0.031048422884946483
[batch_idx--200] train_loss: 0.0013375858497106244, acc: 0.8485307835820896, lr: 0.030992082496212964
[batch_idx--250] train_loss: 0.001343109328633701, acc: 0.8480608814741036, lr: 0.030935709801587143
[batch_idx--300] train_loss: 0.0013441910868219758, acc: 0.847578384551495, lr: 0.03087930510499845
[batch_idx--350] train_loss: 0.0013400173210074589, acc: 0.8483128561253561, lr: 0.030822868710548842
[batch_idx--400] train_loss: 0.001337486443497668, acc: 0.8485524470074813, lr: 0.030766400922511174
[batch_idx--450] train_loss: 0.0013419977784442335, acc: 0.8484743291561079, lr: 0.030709902045327583
total time of one epoch: 398.1947979927063 s
train_loss:  0.0013419977784442335  acc:  0.8484743291561079
->>lr:0.030710
test_loss:  0.001551049299106392  test_acc:  0.8273979401910907
best acc:  84.68792654175456

------Epoch: 64------
[batch_idx--0] train_loss: 0.0012468451168388128, acc: 0.85546875, lr: 0.030708771752766397
[batch_idx--50] train_loss: 0.0013535574042037421, acc: 0.844515931372549, lr: 0.030652241478464032
[batch_idx--100] train_loss: 0.0013453544447161625, acc: 0.8458771658415841, lr: 0.03059568073049836
[batch_idx--150] train_loss: 0.0013341668473605978, acc: 0.8481218956953642, lr: 0.030539089813812693
[batch_idx--200] train_loss: 0.0013350891766013271, acc: 0.8486085199004975, lr: 0.03048246903351297
[batch_idx--250] train_loss: 0.0013307787749760477, acc: 0.8488390189243028, lr: 0.030425818694866172
[batch_idx--300] train_loss: 0.0013298946695767368, acc: 0.8490578280730897, lr: 0.030369139103298623
[batch_idx--350] train_loss: 0.0013309940350828347, acc: 0.8490696225071225, lr: 0.030312430564394355
[batch_idx--400] train_loss: 0.001334496222185598, acc: 0.8487764962593516, lr: 0.03025569338389348
[batch_idx--450] train_loss: 0.0013390480310731426, acc: 0.848387544693998, lr: 0.03019892786769053
total time of one epoch: 402.237184047699 s
train_loss:  0.0013390480310731426  acc:  0.848387544693998
->>lr:0.030199
test_loss:  0.0013966776327986859  test_acc:  0.8421640402034992
best acc:  84.68792654175456

------Epoch: 65------
[batch_idx--0] train_loss: 0.001413815189152956, acc: 0.83203125, lr: 0.03019779227044398
[batch_idx--50] train_loss: 0.0013445534505972675, acc: 0.8488817401960784, lr: 0.03014099816711588
[batch_idx--100] train_loss: 0.0013359243218501163, acc: 0.8493966584158416, lr: 0.030084176346456905
[batch_idx--150] train_loss: 0.0013303585884019437, acc: 0.8501914321192053, lr: 0.030027327114817932
[batch_idx--200] train_loss: 0.001339762656954094, acc: 0.8487639925373134, lr: 0.029970450778697578
[batch_idx--250] train_loss: 0.001339000976269701, acc: 0.8487300796812749, lr: 0.02991354764474065
[batch_idx--300] train_loss: 0.0013349050042169954, acc: 0.849499065614618, lr: 0.02985661801973638
[batch_idx--350] train_loss: 0.001336974760303884, acc: 0.8496038105413105, lr: 0.02979966221061685
[batch_idx--400] train_loss: 0.0013387923767880776, acc: 0.8492733011221946, lr: 0.029742680524455323
[batch_idx--450] train_loss: 0.0013414301277169104, acc: 0.8498889158884994, lr: 0.02968567326846454
total time of one epoch: 398.53356432914734 s
train_loss:  0.0013414301277169104  acc:  0.8498889158884994
->>lr:0.029686
test_loss:  0.0019852440045687266  test_acc:  0.7778880754436034
best acc:  84.68792654175456

------Epoch: 66------
[batch_idx--0] train_loss: 0.0015716514317318797, acc: 0.80859375, lr: 0.02968453286464312
[batch_idx--50] train_loss: 0.0013786062972583606, acc: 0.8471966911764706, lr: 0.029627499844060053
[batch_idx--100] train_loss: 0.0013429777636792106, acc: 0.8500928217821783, lr: 0.029570441874636297
[batch_idx--150] train_loss: 0.0013453743593236863, acc: 0.8507605546357616, lr: 0.029513359263995894
[batch_idx--200] train_loss: 0.0013374021851378886, acc: 0.8514070273631841, lr: 0.029456252319895716
[batch_idx--250] train_loss: 0.0013338467634962019, acc: 0.8518737549800797, lr: 0.029399121350223874
[batch_idx--300] train_loss: 0.0013286894571385734, acc: 0.8521205357142857, lr: 0.029341966662997956
[batch_idx--350] train_loss: 0.0013286179719967741, acc: 0.8514734686609686, lr: 0.02928478856636346
[batch_idx--400] train_loss: 0.0013257729412437397, acc: 0.8512507793017456, lr: 0.02922758736859208
[batch_idx--450] train_loss: 0.001329278762264113, acc: 0.8514163224216337, lr: 0.02917036337808005
total time of one epoch: 399.9910342693329 s
train_loss:  0.001329278762264113  acc:  0.8514163224216337
->>lr:0.029170
test_loss:  0.0019426116104353183  test_acc:  0.7713115771187492
best acc:  84.68792654175456

------Epoch: 67------
[batch_idx--0] train_loss: 0.0012819386320188642, acc: 0.85546875, lr: 0.02916921866790256
[batch_idx--50] train_loss: 0.0013181668792979098, acc: 0.8532475490196079, lr: 0.029111971746632322
[batch_idx--100] train_loss: 0.0013206353385720661, acc: 0.8500928217821783, lr: 0.02905470265595496
[batch_idx--150] train_loss: 0.001325656661443067, acc: 0.8490531870860927, lr: 0.028997411704632756
[batch_idx--200] train_loss: 0.0013257562714531572, acc: 0.8488028606965174, lr: 0.02894009920154584
[batch_idx--250] train_loss: 0.0013221736354530748, acc: 0.8492280876494024, lr: 0.02888276545569057
[batch_idx--300] train_loss: 0.0013192290153224455, acc: 0.8492784468438538, lr: 0.0288254107761778
[batch_idx--350] train_loss: 0.0013176298677387973, acc: 0.8498709045584045, lr: 0.028768035472231265
[batch_idx--400] train_loss: 0.001319852393867211, acc: 0.8497993298004988, lr: 0.0287106398531859
[batch_idx--450] train_loss: 0.0013258411015688153, acc: 0.8494029229006839, lr: 0.02865322422848614
total time of one epoch: 404.14488196372986 s
train_loss:  0.0013258411015688153  acc:  0.8494029229006839
->>lr:0.028653
test_loss:  0.00170580807757564  test_acc:  0.801091946891674
best acc:  84.68792654175456

------Epoch: 68------
[batch_idx--0] train_loss: 0.0015024798922240734, acc: 0.8203125, lr: 0.028652075714060296
[batch_idx--50] train_loss: 0.0013093278588106234, acc: 0.8520986519607843, lr: 0.028594640002494582
[batch_idx--100] train_loss: 0.0013011804837180247, acc: 0.855778155940594, lr: 0.028537184910679542
[batch_idx--150] train_loss: 0.001306644682494911, acc: 0.8532439983443708, lr: 0.028479710748380266
[batch_idx--200] train_loss: 0.0013153108933810793, acc: 0.8527091106965174, lr: 0.028422217825464665
[batch_idx--250] train_loss: 0.001311762200898502, acc: 0.8523562001992032, lr: 0.028364706451901797
[batch_idx--300] train_loss: 0.0013103223896192456, acc: 0.8529251453488372, lr: 0.028307176937760206
[batch_idx--350] train_loss: 0.0013127659186800448, acc: 0.8522191061253561, lr: 0.028249629593206222
[batch_idx--400] train_loss: 0.0013134031971112972, acc: 0.8521762001246883, lr: 0.02819206472850232
[batch_idx--450] train_loss: 0.0013191835950194526, acc: 0.851971742979137, lr: 0.02813448265400542
total time of one epoch: 404.6878881454468 s
train_loss:  0.0013191835950194526  acc:  0.851971742979137
->>lr:0.028134
test_loss:  0.001553407195691569  test_acc:  0.8234272242213674
best acc:  84.68792654175456

------Epoch: 69------
[batch_idx--0] train_loss: 0.0012029008939862251, acc: 0.86328125, lr: 0.028133330839107608
[batch_idx--50] train_loss: 0.0013400053162602526, acc: 0.8496476715686274, lr: 0.028075731530447786
[batch_idx--100] train_loss: 0.0013197685677170902, acc: 0.8531482054455446, lr: 0.028018115639197247
[batch_idx--150] train_loss: 0.0013152902979798467, acc: 0.8532698675496688, lr: 0.027960483475988025
[batch_idx--200] train_loss: 0.0013149469275379655, acc: 0.8527479788557214, lr: 0.02790283535153988
[batch_idx--250] train_loss: 0.0013211228327261676, acc: 0.8521071962151394, lr: 0.027845171576658636
[batch_idx--300] train_loss: 0.0013232372226998012, acc: 0.8514716569767442, lr: 0.027787492462234484
[batch_idx--350] train_loss: 0.001320301173679382, acc: 0.8519520121082621, lr: 0.02772979831924033
[batch_idx--400] train_loss: 0.0013186864228570774, acc: 0.8515917238154613, lr: 0.02767208945873009
[batch_idx--450] train_loss: 0.00131980096227852, acc: 0.85191099385566, lr: 0.027614366191837037
total time of one epoch: 399.10080790519714 s
train_loss:  0.00131980096227852  acc:  0.85191099385566
->>lr:0.027614
test_loss:  0.0013601342795104923  test_acc:  0.8548206973569922
best acc:  84.68792654175456
Saving..

------Epoch: 70------
[batch_idx--0] train_loss: 0.0012031953083351254, acc: 0.85546875, lr: 0.02761321158169134
[batch_idx--50] train_loss: 0.0013408575677221605, acc: 0.8514859068627451, lr: 0.027555473940897853
[batch_idx--100] train_loss: 0.0013219610047941603, acc: 0.8512917698019802, lr: 0.027497722522445946
[batch_idx--150] train_loss: 0.0013218222923009405, acc: 0.8521316225165563, lr: 0.027439957637698322
[batch_idx--200] train_loss: 0.0013197468743145243, acc: 0.8521260883084577, lr: 0.027382179598090313
[batch_idx--250] train_loss: 0.0013125499880193654, acc: 0.8531343376494024, lr: 0.027324388715128153
[batch_idx--300] train_loss: 0.0013147394093174327, acc: 0.8526396387043189, lr: 0.027266585300387343
[batch_idx--350] train_loss: 0.001312166029531668, acc: 0.8527866809116809, lr: 0.027208769665510946
[batch_idx--400] train_loss: 0.0013121460373408888, acc: 0.8525853335411472, lr: 0.027150942122207884
[batch_idx--450] train_loss: 0.0013180613609836305, acc: 0.8518762800708162, lr: 0.027093102982251305
total time of one epoch: 399.0145215988159 s
train_loss:  0.0013180613609836305  acc:  0.8518762800708162
->>lr:0.027093
test_loss:  0.0015008678017959566  test_acc:  0.8287628738056831
best acc:  85.48206973569921

------Epoch: 71------
[batch_idx--0] train_loss: 0.001308185514062643, acc: 0.84765625, lr: 0.02709194608330789
[batch_idx--50] train_loss: 0.0013123683120105781, acc: 0.850796568627451, lr: 0.027034095436018247
[batch_idx--100] train_loss: 0.0013090778213676693, acc: 0.8524907178217822, lr: 0.026976233822045795
[batch_idx--150] train_loss: 0.0013115668980811803, acc: 0.8521833609271523, lr: 0.026918361553347366
[batch_idx--200] train_loss: 0.0012992631012124394, acc: 0.8537779850746269, lr: 0.026860478941937244
[batch_idx--250] train_loss: 0.0013007042271853146, acc: 0.8527919571713147, lr: 0.026802586299885446
[batch_idx--300] train_loss: 0.0013021119225126664, acc: 0.8527564368770764, lr: 0.026744683939316106
[batch_idx--350] train_loss: 0.0013018241415843049, acc: 0.8524750712250713, lr: 0.026686772172405743
[batch_idx--400] train_loss: 0.0013019404822015238, acc: 0.8530042082294265, lr: 0.02662885131138157
[batch_idx--450] train_loss: 0.00130781639250567, acc: 0.8527701600305482, lr: 0.026570921668519862
total time of one epoch: 403.8250095844269 s
train_loss:  0.00130781639250567  acc:  0.8527701600305482
->>lr:0.026571
test_loss:  0.0014988774955383615  test_acc:  0.8328576746494603
best acc:  85.48206973569921

------Epoch: 72------
[batch_idx--0] train_loss: 0.0014949181349948049, acc: 0.8203125, lr: 0.026569762988232833
[batch_idx--50] train_loss: 0.0012927153261889722, acc: 0.8569240196078431, lr: 0.026511824709652916
[batch_idx--100] train_loss: 0.001300856868718004, acc: 0.8552753712871287, lr: 0.02645387828017616
[batch_idx--150] train_loss: 0.0013048421300096524, acc: 0.8543046357615894, lr: 0.026395924012216673
[batch_idx--200] train_loss: 0.001309421681451486, acc: 0.853408737562189, lr: 0.02633796221823084
[batch_idx--250] train_loss: 0.0013126198427781345, acc: 0.8523406374501992, lr: 0.026279993210715575
[batch_idx--300] train_loss: 0.0013102757144236683, acc: 0.8530678986710963, lr: 0.026222017302206753
[batch_idx--350] train_loss: 0.0013100002912878777, acc: 0.8529647435897436, lr: 0.02616403480527739
[batch_idx--400] train_loss: 0.0013087635059745755, acc: 0.852906795511222, lr: 0.02610604603253605
[batch_idx--450] train_loss: 0.001309525969308257, acc: 0.8530652272017218, lr: 0.026048051296625147
total time of one epoch: 399.43387842178345 s
train_loss:  0.001309525969308257  acc:  0.8530652272017218
->>lr:0.026048
test_loss:  0.0013854407963881142  test_acc:  0.8507258965132151
best acc:  85.48206973569921

------Epoch: 73------
[batch_idx--0] train_loss: 0.0012934161350131035, acc: 0.84765625, lr: 0.02604689134322999
[batch_idx--50] train_loss: 0.0012927343977578714, acc: 0.8522518382352942, lr: 0.025988890847003655
[batch_idx--100] train_loss: 0.0013076986213869388, acc: 0.8509823638613861, lr: 0.025930885019241706
[batch_idx--150] train_loss: 0.0012983624127212393, acc: 0.8525713990066225, lr: 0.025872874172678507
[batch_idx--200] train_loss: 0.0012993671707183455, acc: 0.8530200559701493, lr: 0.02581485862007545
[batch_idx--250] train_loss: 0.0012959069560793974, acc: 0.8533210906374502, lr: 0.02575683867421932
[batch_idx--300] train_loss: 0.0012930473283728418, acc: 0.8533014950166113, lr: 0.02569881464792059
[batch_idx--350] train_loss: 0.0012928427346621208, acc: 0.8537882834757835, lr: 0.02564078685401172
[batch_idx--400] train_loss: 0.001295012170930818, acc: 0.8537445448877805, lr: 0.025582755605345495
[batch_idx--450] train_loss: 0.0012993901789800839, acc: 0.8534644357274274, lr: 0.02552472121479332
total time of one epoch: 404.86311054229736 s
train_loss:  0.0012993901789800839  acc:  0.8534644357274274
->>lr:0.025525
test_loss:  0.0014615615598468188  test_acc:  0.8349671175083757
best acc:  85.48206973569921

------Epoch: 74------
[batch_idx--0] train_loss: 0.0013714350061491132, acc: 0.84375, lr: 0.025523560497083927
[batch_idx--50] train_loss: 0.001287424318291539, acc: 0.8538602941176471, lr: 0.025465523224145754
[batch_idx--100] train_loss: 0.0012786256133274425, acc: 0.8555461014851485, lr: 0.02540748344137178
[batch_idx--150] train_loss: 0.0012815570611420352, acc: 0.8550031043046358, lr: 0.02534944146167944
[batch_idx--200] train_loss: 0.0012902845567745616, acc: 0.8547691231343284, lr: 0.025291397597997967
[batch_idx--250] train_loss: 0.0012945807782424785, acc: 0.8543015438247012, lr: 0.025233352163266793
[batch_idx--300] train_loss: 0.0013008417321471158, acc: 0.853405315614618, lr: 0.025175305470433812
[batch_idx--350] train_loss: 0.0012985086905971657, acc: 0.8539218304843305, lr: 0.025117257832453683
[batch_idx--400] train_loss: 0.001297792467257319, acc: 0.854231608478803, lr: 0.025059209562286185
[batch_idx--450] train_loss: 0.0013035026100538297, acc: 0.8545318846113792, lr: 0.02500116097289448
total time of one epoch: 396.63676261901855 s
train_loss:  0.0013035026100538297  acc:  0.8545318846113792
->>lr:0.025001
test_loss:  0.001672387500305687  test_acc:  0.8158580469040824
best acc:  85.48206973569921

------Epoch: 75------
[batch_idx--0] train_loss: 0.0014707907103002071, acc: 0.8203125, lr: 0.025
[batch_idx--50] train_loss: 0.0013331978641194747, acc: 0.8481924019607843, lr: 0.024941951407416053
[batch_idx--100] train_loss: 0.0013125364468110226, acc: 0.8513691212871287, lr: 0.024883903127797022
[batch_idx--150] train_loss: 0.0013077914481982589, acc: 0.8509157698675497, lr: 0.02482585547410613
[batch_idx--200] train_loss: 0.0012984218198078597, acc: 0.8530006218905473, lr: 0.024767808759303227
[batch_idx--250] train_loss: 0.0013029816255726633, acc: 0.8536634711155379, lr: 0.024709763296343102
[batch_idx--300] train_loss: 0.0013000126494917758, acc: 0.8545213870431894, lr: 0.024651719398173802
[batch_idx--350] train_loss: 0.0012976460329965395, acc: 0.8547676282051282, lr: 0.024593677377734924
[batch_idx--400] train_loss: 0.0012962220731932215, acc: 0.8550401340399002, lr: 0.02453563754795596
[batch_idx--450] train_loss: 0.0013046015810373901, acc: 0.8551567327385705, lr: 0.024477600221754565
total time of one epoch: 397.2550377845764 s
train_loss:  0.0013046015810373901  acc:  0.8551567327385705
->>lr:0.024478
test_loss:  0.001357804783699101  test_acc:  0.846631095669438
best acc:  85.48206973569921

------Epoch: 76------
[batch_idx--0] train_loss: 0.0013595791533589363, acc: 0.859375, lr: 0.02447643950291608
[batch_idx--50] train_loss: 0.0012760303330187704, acc: 0.8568474264705882, lr: 0.024418405052717584
[batch_idx--100] train_loss: 0.0012876334574792793, acc: 0.8543084777227723, lr: 0.024360373738147447
[batch_idx--150] train_loss: 0.0012924059838463633, acc: 0.8544857201986755, lr: 0.024302345872077406
[batch_idx--200] train_loss: 0.001294365638070068, acc: 0.8543221393034826, lr: 0.024244321767360646
[batch_idx--250] train_loss: 0.0012980634059044588, acc: 0.8540992280876494, lr: 0.024186301736830045
[batch_idx--300] train_loss: 0.0012936075109728547, acc: 0.8545732973421927, lr: 0.024128286093296536
[batch_idx--350] train_loss: 0.0012871451842389004, acc: 0.8553685897435898, lr: 0.02407027514954738
[batch_idx--400] train_loss: 0.001287080998128359, acc: 0.8557609881546134, lr: 0.024012269218344526
[batch_idx--450] train_loss: 0.0012953014271069032, acc: 0.8554431214635332, lr: 0.023954268612422863
total time of one epoch: 399.5109007358551 s
train_loss:  0.0012953014271069032  acc:  0.8554431214635332
->>lr:0.023954
test_loss:  0.0015098518318803927  test_acc:  0.8339744385159449
best acc:  85.48206973569921

------Epoch: 77------
[batch_idx--0] train_loss: 0.001370682381093502, acc: 0.828125, lr: 0.02395310865677001
[batch_idx--50] train_loss: 0.0012950499076396227, acc: 0.85546875, lr: 0.023895113804784887
[batch_idx--100] train_loss: 0.0012829594163104227, acc: 0.856512995049505, lr: 0.02383712490971616
[batch_idx--150] train_loss: 0.0012829048826593584, acc: 0.8566587334437086, lr: 0.023779142284206876
[batch_idx--200] train_loss: 0.0012858648867281478, acc: 0.855585354477612, lr: 0.023721166240866298
[batch_idx--250] train_loss: 0.0012846349465356493, acc: 0.8553909362549801, lr: 0.0236631970922682
[batch_idx--300] train_loss: 0.0012858056987750273, acc: 0.8555336378737541, lr: 0.023605235150949158
[batch_idx--350] train_loss: 0.0012863076068434407, acc: 0.8555132656695157, lr: 0.02354728072940694
[batch_idx--400] train_loss: 0.001287222301942805, acc: 0.8552641832917706, lr: 0.02348933414009873
[batch_idx--450] train_loss: 0.001295620932790751, acc: 0.8548095948901309, lr: 0.02343139569543949
total time of one epoch: 399.0015835762024 s
train_loss:  0.001295620932790751  acc:  0.8548095948901309
->>lr:0.023431
test_loss:  0.0014643974288815467  test_acc:  0.8350912023824296
best acc:  85.48206973569921

------Epoch: 78------
[batch_idx--0] train_loss: 0.0010997321223840117, acc: 0.8828125, lr: 0.023430237011767167
[batch_idx--50] train_loss: 0.001295236572760212, acc: 0.8553921568627451, lr: 0.02337230719645424
[batch_idx--100] train_loss: 0.001290485784434483, acc: 0.8552366955445545, lr: 0.023314386156732855
[batch_idx--150] train_loss: 0.0012859881239548473, acc: 0.8555980960264901, lr: 0.023256474204880216
[batch_idx--200] train_loss: 0.001283542311863872, acc: 0.8565764925373134, lr: 0.023198571653124563
[batch_idx--250] train_loss: 0.001283850838324478, acc: 0.8563402639442231, lr: 0.02314067881364343
[batch_idx--300] train_loss: 0.0012878061121753557, acc: 0.856078696013289, lr: 0.02308279599856199
[batch_idx--350] train_loss: 0.0012860161567735684, acc: 0.8562922898860399, lr: 0.023024923519951404
[batch_idx--400] train_loss: 0.0012822760165404259, acc: 0.8569786471321695, lr: 0.02296706168982706
[batch_idx--450] train_loss: 0.001288152261510645, acc: 0.8567622452876037, lr: 0.022909210820146964
total time of one epoch: 398.50357818603516 s
train_loss:  0.001288152261510645  acc:  0.8567622452876037
->>lr:0.022909
test_loss:  0.0015041534052192167  test_acc:  0.8359597965008065
best acc:  85.48206973569921

------Epoch: 79------
[batch_idx--0] train_loss: 0.0010730482172220945, acc: 0.890625, lr: 0.022908053916692112
[batch_idx--50] train_loss: 0.0012965664705809426, acc: 0.8551623774509803, lr: 0.022850214547982983
[batch_idx--100] train_loss: 0.0012863951200379592, acc: 0.856667698019802, lr: 0.022792386769691267
[batch_idx--150] train_loss: 0.0012737518039205118, acc: 0.8583402317880795, lr: 0.022734570893591363
[batch_idx--200] train_loss: 0.0012783495282443862, acc: 0.8576259328358209, lr: 0.022676767231393526
[batch_idx--250] train_loss: 0.0012846480838423855, acc: 0.8567448954183267, lr: 0.02261897609474213
[batch_idx--300] train_loss: 0.0012847424174993116, acc: 0.8562603820598007, lr: 0.022561197795214035
[batch_idx--350] train_loss: 0.0012882297092112061, acc: 0.8560474537037037, lr: 0.022503432644316902
[batch_idx--400] train_loss: 0.0012857729612334057, acc: 0.8560921913965087, lr: 0.022445680953487472
[batch_idx--450] train_loss: 0.0012867461448875367, acc: 0.8563803936543202, lr: 0.022387943034089947
total time of one epoch: 399.6452956199646 s
train_loss:  0.0012867461448875367  acc:  0.8563803936543202
->>lr:0.022388
test_loss:  0.0014224382810075521  test_acc:  0.8436530586921455
best acc:  85.48206973569921

------Epoch: 80------
[batch_idx--0] train_loss: 0.0013022455386817455, acc: 0.8359375, lr: 0.022386788418308663
[batch_idx--50] train_loss: 0.0012767423633668646, acc: 0.8575367647058824, lr: 0.022329064866462054
[batch_idx--100] train_loss: 0.0012758724601238524, acc: 0.8572865099009901, lr: 0.022271355714774788
[batch_idx--150] train_loss: 0.0012745663773465828, acc: 0.8565811258278145, lr: 0.022213661274381714
[batch_idx--200] train_loss: 0.001272817646774153, acc: 0.857353855721393, lr: 0.022155981856338363
[batch_idx--250] train_loss: 0.0012707302886695857, acc: 0.8571028386454184, lr: 0.022098317771619257
[batch_idx--300] train_loss: 0.0012744846030531382, acc: 0.8565069559800664, lr: 0.022040669331116272
[batch_idx--350] train_loss: 0.0012716716497027424, acc: 0.8567597044159544, lr: 0.021983036845636923
[batch_idx--400] train_loss: 0.0012737040406794397, acc: 0.856140897755611, lr: 0.02192542062590272
[batch_idx--450] train_loss: 0.0012754042535791643, acc: 0.8562762522997882, lr: 0.02186782098254747
total time of one epoch: 401.05772948265076 s
train_loss:  0.0012754042535791643  acc:  0.8562762522997882
->>lr:0.021868
test_loss:  0.001312357183203299  test_acc:  0.8569301402159076
best acc:  85.48206973569921
Saving..

------Epoch: 81------
[batch_idx--0] train_loss: 0.0014499109238386154, acc: 0.8203125, lr: 0.02186666916089239
[batch_idx--50] train_loss: 0.0012949642168321445, acc: 0.8547794117647058, lr: 0.021809086745365924
[batch_idx--100] train_loss: 0.0012752417726257799, acc: 0.8570544554455446, lr: 0.021751521533424346
[batch_idx--150] train_loss: 0.001277752108070136, acc: 0.8573054635761589, lr: 0.021693973835426473
[batch_idx--200] train_loss: 0.0012755546752428312, acc: 0.8577231032338308, lr: 0.021636443961636685
[batch_idx--250] train_loss: 0.0012745009076622022, acc: 0.8578965388446215, lr: 0.021578932222223245
[batch_idx--300] train_loss: 0.0012706335401162505, acc: 0.858232973421927, lr: 0.021521438927256664
[batch_idx--350] train_loss: 0.001268713163580756, acc: 0.8581508190883191, lr: 0.021463964386708015
[batch_idx--400] train_loss: 0.0012733453250097625, acc: 0.8575923472568578, lr: 0.021406508910447243
[batch_idx--450] train_loss: 0.00127881980345383, acc: 0.8576995174783907, lr: 0.021349072808241526
total time of one epoch: 395.47052240371704 s
train_loss:  0.00127881980345383  acc:  0.8576995174783907
->>lr:0.021349
test_loss:  0.0017002996587475205  test_acc:  0.8149894527857054
best acc:  85.69301402159077

------Epoch: 82------
[batch_idx--0] train_loss: 0.0012225441168993711, acc: 0.87890625, lr: 0.021347924285939714
[batch_idx--50] train_loss: 0.001277863981622253, acc: 0.8571537990196079, lr: 0.02129050826428394
[batch_idx--100] train_loss: 0.0012614643126311205, acc: 0.8598004331683168, lr: 0.021233112242092567
[batch_idx--150] train_loss: 0.0012658974683892894, acc: 0.8585471854304636, lr: 0.02117573652881221
[batch_idx--200] train_loss: 0.0012625582227761398, acc: 0.859375, lr: 0.02111838143378
[batch_idx--250] train_loss: 0.0012657743233044547, acc: 0.8590170567729084, lr: 0.021061047266221912
[batch_idx--300] train_loss: 0.0012631167770221063, acc: 0.8592452242524917, lr: 0.021003734335251087
[batch_idx--350] train_loss: 0.001259722064170944, acc: 0.8596087072649573, lr: 0.020946442949866164
[batch_idx--400] train_loss: 0.0012618538935464387, acc: 0.859180174563591, lr: 0.020889173418949643
[batch_idx--450] train_loss: 0.0012694072645228313, acc: 0.8585586836532787, lr: 0.020831926051266162
total time of one epoch: 398.6817569732666 s
train_loss:  0.0012694072645228313  acc:  0.8585586836532787
->>lr:0.020832
test_loss:  0.001433473176082853  test_acc:  0.8426603796997146
best acc:  85.69301402159077

------Epoch: 83------
[batch_idx--0] train_loss: 0.0012689814902842045, acc: 0.859375, lr: 0.020830781332097453
[batch_idx--50] train_loss: 0.001332248848698595, acc: 0.8498008578431373, lr: 0.020773556888877096
[batch_idx--100] train_loss: 0.0012995613995930271, acc: 0.8540377475247525, lr: 0.020716355232228204
[batch_idx--150] train_loss: 0.0012922961710464973, acc: 0.8542011589403974, lr: 0.020659176670549492
[batch_idx--200] train_loss: 0.001289436283790094, acc: 0.8542832711442786, lr: 0.020602021512115154
[batch_idx--250] train_loss: 0.0012846993147005955, acc: 0.8548462400398407, lr: 0.02054489006507322
[batch_idx--300] train_loss: 0.0012820056363850511, acc: 0.8554168397009967, lr: 0.02048778263744388
[batch_idx--350] train_loss: 0.001278981997431163, acc: 0.8563256766381766, lr: 0.02043069953711782
[batch_idx--400] train_loss: 0.0012777794500582961, acc: 0.8568227867830424, lr: 0.020373641071854572
[batch_idx--450] train_loss: 0.0012772266267457666, acc: 0.8572135244905752, lr: 0.020316607549280843
total time of one epoch: 398.15663170814514 s
train_loss:  0.0012772266267457666  acc:  0.8572135244905752
->>lr:0.020317
test_loss:  0.0012483686386229812  test_acc:  0.8663605906440005
best acc:  85.69301402159077
Saving..

------Epoch: 84------
[batch_idx--0] train_loss: 0.0011482288828119636, acc: 0.87890625, lr: 0.020315467135356893
[batch_idx--50] train_loss: 0.0012582331763434352, acc: 0.8600643382352942, lr: 0.02025845937110404
[batch_idx--100] train_loss: 0.0012627579490792486, acc: 0.8587948638613861, lr: 0.020201477170534773
[batch_idx--150] train_loss: 0.0012559696587900453, acc: 0.8591421771523179, lr: 0.020144520840864624
[batch_idx--200] train_loss: 0.001262660313221575, acc: 0.8576648009950248, lr: 0.02008759068916964
[batch_idx--250] train_loss: 0.0012630227933715717, acc: 0.8580988545816733, lr: 0.020030687022384752
[batch_idx--300] train_loss: 0.0012577831663154189, acc: 0.8591803363787376, lr: 0.019973810147302068
[batch_idx--350] train_loss: 0.00125256993464908, acc: 0.8597978988603988, lr: 0.01991696037056928
[batch_idx--400] train_loss: 0.0012537990628504786, acc: 0.8600374064837906, lr: 0.01986013799868798
[batch_idx--450] train_loss: 0.0012575110978143228, acc: 0.8604071926962197, lr: 0.01980334333801198
total time of one epoch: 398.2716498374939 s
train_loss:  0.0012575110978143228  acc:  0.8604071926962197
->>lr:0.019803
test_loss:  0.0013367190914542197  test_acc:  0.8530835091202382
best acc:  86.63605906440004

------Epoch: 85------
[batch_idx--0] train_loss: 0.0013033023569732904, acc: 0.85546875, lr: 0.019802207729556022
[batch_idx--50] train_loss: 0.0012840733489058182, acc: 0.85546875, lr: 0.0197454416497602
[batch_idx--100] train_loss: 0.001265573498590084, acc: 0.8579053217821783, lr: 0.019688703899547008
[batch_idx--150] train_loss: 0.0012680910156102271, acc: 0.8581591473509934, lr: 0.01963199478481404
[batch_idx--200] train_loss: 0.001269779142006231, acc: 0.8579174440298507, lr: 0.019575314611304503
[batch_idx--250] train_loss: 0.0012715269576765568, acc: 0.8575230328685259, lr: 0.019518663684605593
[batch_idx--300] train_loss: 0.0012662667832167144, acc: 0.8580642649501661, lr: 0.01946204231014678
[batch_idx--350] train_loss: 0.0012692467858776068, acc: 0.857894853988604, lr: 0.019405450793198248
[batch_idx--400] train_loss: 0.0012675757694668938, acc: 0.8578651028678305, lr: 0.01934888943886919
[batch_idx--450] train_loss: 0.001271032572587138, acc: 0.8577863019405005, lr: 0.019292358552106172
total time of one epoch: 398.56077814102173 s
train_loss:  0.001271032572587138  acc:  0.8577863019405005
->>lr:0.019292
test_loss:  0.0014040565901942193  test_acc:  0.8437771435661993
best acc:  86.63605906440004

------Epoch: 86------
[batch_idx--0] train_loss: 0.0012328469892963767, acc: 0.85546875, lr: 0.019291228247233613
[batch_idx--50] train_loss: 0.0012645911397960257, acc: 0.8615196078431373, lr: 0.019234728751373553
[batch_idx--100] train_loss: 0.0012722232593407872, acc: 0.8589882425742574, lr: 0.01917826033856888
[batch_idx--150] train_loss: 0.0012618164437058204, acc: 0.859452607615894, lr: 0.019121823313265066
[batch_idx--200] train_loss: 0.0012481510378559357, acc: 0.861396144278607, lr: 0.01906541797973838
[batch_idx--250] train_loss: 0.0012501316190051636, acc: 0.8606200199203188, lr: 0.01900904464209422
[batch_idx--300] train_loss: 0.001243367780539891, acc: 0.8614254568106312, lr: 0.018952703604265476
[batch_idx--350] train_loss: 0.00124698469997052, acc: 0.8610999821937322, lr: 0.018896395170010898
[batch_idx--400] train_loss: 0.0012464122308192872, acc: 0.8610699812967582, lr: 0.01884011964291346
[batch_idx--450] train_loss: 0.0012473726398953462, acc: 0.8613097511021627, lr: 0.018783877326378724
total time of one epoch: 399.3702311515808 s
train_loss:  0.0012473726398953462  acc:  0.8613097511021627
->>lr:0.018784
test_loss:  0.0012822028909136038  test_acc:  0.8605286015634694
best acc:  86.63605906440004

------Epoch: 87------
[batch_idx--0] train_loss: 0.0013465600786730647, acc: 0.83984375, lr: 0.018782752820878636
[batch_idx--50] train_loss: 0.0012669178780496998, acc: 0.8607536764705882, lr: 0.018726544691500546
[batch_idx--100] train_loss: 0.001257107963112395, acc: 0.8606512995049505, lr: 0.01867037038501655
[batch_idx--150] train_loss: 0.0012585797188310137, acc: 0.8600475993377483, lr: 0.018614230204286455
[batch_idx--200] train_loss: 0.0012551971151729794, acc: 0.8606187810945274, lr: 0.018558124451986114
[batch_idx--250] train_loss: 0.0012500764842913207, acc: 0.8611647161354582, lr: 0.018502053430605753
[batch_idx--300] train_loss: 0.001248099888942554, acc: 0.8612307931893688, lr: 0.01844601744244835
[batch_idx--350] train_loss: 0.0012462866644141531, acc: 0.86153400997151, lr: 0.018390016789628004
[batch_idx--400] train_loss: 0.0012460368043253026, acc: 0.861849283042394, lr: 0.018334051774068303
[batch_idx--450] train_loss: 0.001246132794563941, acc: 0.8619953483528309, lr: 0.0182781226975007
total time of one epoch: 395.48238730430603 s
train_loss:  0.001246132794563941  acc:  0.8619953483528309
->>lr:0.018278
test_loss:  0.0013391192989057074  test_acc:  0.8543243578607768
best acc:  86.63605906440004

------Epoch: 88------
[batch_idx--0] train_loss: 0.0010528191924095154, acc: 0.87109375, lr: 0.01827700448461836
[batch_idx--50] train_loss: 0.0012354272162066954, acc: 0.8630514705882353, lr: 0.018221112376465492
[batch_idx--100] train_loss: 0.001238104510397678, acc: 0.8623530321782178, lr: 0.018165256816209563
[batch_idx--150] train_loss: 0.001241024195013062, acc: 0.8616773592715232, lr: 0.018109438104991903
[batch_idx--200] train_loss: 0.001235530734588091, acc: 0.8617653917910447, lr: 0.01805365654375518
[batch_idx--250] train_loss: 0.0012284446604163997, acc: 0.8631100597609562, lr: 0.017997912433241763
[batch_idx--300] train_loss: 0.0012324440360310615, acc: 0.86328125, lr: 0.017942206073992117
[batch_idx--350] train_loss: 0.0012373301960750776, acc: 0.8624020655270656, lr: 0.017886537766343167
[batch_idx--400] train_loss: 0.0012322627518911314, acc: 0.8630474594763092, lr: 0.017830907810426684
[batch_idx--450] train_loss: 0.0012390573950693956, acc: 0.8624726628944354, lr: 0.017775316506167683
total time of one epoch: 397.3028087615967 s
train_loss:  0.0012390573950693956  acc:  0.8624726628944354
->>lr:0.017775
test_loss:  0.001341929124652755  test_acc:  0.8584191587045539
best acc:  86.63605906440004

------Epoch: 89------
[batch_idx--0] train_loss: 0.0013584463158622384, acc: 0.85546875, lr: 0.017774205076388213
[batch_idx--50] train_loss: 0.0012507067180658673, acc: 0.8591452205882353, lr: 0.017718653505586445
[batch_idx--100] train_loss: 0.001240184071870281, acc: 0.8604579207920792, lr: 0.01766314119165336
[batch_idx--150] train_loss: 0.0012434394131969684, acc: 0.8613669288079471, lr: 0.017607668433879703
[batch_idx--200] train_loss: 0.001239841481304695, acc: 0.8626399253731343, lr: 0.017552235531342955
[batch_idx--250] train_loss: 0.0012451407269563571, acc: 0.8619739790836654, lr: 0.017496842782905715
[batch_idx--300] train_loss: 0.0012471684567209494, acc: 0.8622300664451827, lr: 0.017441490487214106
[batch_idx--350] train_loss: 0.001244052876937243, acc: 0.8624131944444444, lr: 0.017386178942696135
[batch_idx--400] train_loss: 0.0012448304766809982, acc: 0.8619077306733167, lr: 0.01733090844756013
[batch_idx--450] train_loss: 0.0012476518239380977, acc: 0.8616308536119693, lr: 0.017275679299793074
total time of one epoch: 397.9201786518097 s
train_loss:  0.0012476518239380977  acc:  0.8616308536119693
->>lr:0.017276
test_loss:  0.0013340645547036808  test_acc:  0.8522149150018613
best acc:  86.63605906440004

------Epoch: 90------
[batch_idx--0] train_loss: 0.001109427073970437, acc: 0.88671875, lr: 0.017274575140626316
[batch_idx--50] train_loss: 0.0012312678770874353, acc: 0.8634344362745098, lr: 0.017219388473930602
[batch_idx--100] train_loss: 0.0012376817043566394, acc: 0.862082301980198, lr: 0.017164243755855953
[batch_idx--150] train_loss: 0.00123103931530792, acc: 0.863332988410596, lr: 0.017109141283711254
[batch_idx--200] train_loss: 0.0012381685062529363, acc: 0.8623678482587065, lr: 0.0170540813545776
[batch_idx--250] train_loss: 0.0012401850254968759, acc: 0.8621918575697212, lr: 0.016999064265306747
[batch_idx--300] train_loss: 0.001243955179959214, acc: 0.8616201204318937, lr: 0.016944090312519478
[batch_idx--350] train_loss: 0.0012417588576321566, acc: 0.8620793269230769, lr: 0.01688915979260398
[batch_idx--400] train_loss: 0.0012400087112551578, acc: 0.8627454800498753, lr: 0.016834273001714316
[batch_idx--450] train_loss: 0.0012366003535819053, acc: 0.8634967195473322, lr: 0.016779430235768767
total time of one epoch: 398.2776052951813 s
train_loss:  0.0012366003535819053  acc:  0.8634967195473322
->>lr:0.016779
test_loss:  0.001262540970506584  test_acc:  0.8622657898002234
best acc:  86.63605906440004

------Epoch: 91------
[batch_idx--0] train_loss: 0.0013087934348732233, acc: 0.85546875, lr: 0.01677833383153542
[batch_idx--50] train_loss: 0.001259750531365474, acc: 0.8599877450980392, lr: 0.016723536275641708
[batch_idx--100] train_loss: 0.0012301138606807679, acc: 0.8642094678217822, lr: 0.01666878334172139
[batch_idx--150] train_loss: 0.0012399636583698803, acc: 0.863177773178808, lr: 0.01661407532497108
[batch_idx--200] train_loss: 0.0012371764948072644, acc: 0.8630286069651741, lr: 0.016559412520345193
[batch_idx--250] train_loss: 0.0012336882087309285, acc: 0.8635925049800797, lr: 0.016504795222554415
[batch_idx--300] train_loss: 0.001230350155630876, acc: 0.8643583887043189, lr: 0.01645022372606408
[batch_idx--350] train_loss: 0.001230265259141755, acc: 0.8644609152421653, lr: 0.01639569832509256
[batch_idx--400] train_loss: 0.0012320578018461174, acc: 0.8642456359102244, lr: 0.016341219313609757
[batch_idx--450] train_loss: 0.0012353042133943142, acc: 0.8641996736904225, lr: 0.01628678698533542
total time of one epoch: 398.85589480400085 s
train_loss:  0.0012353042133943142  acc:  0.8641996736904225
->>lr:0.016287
test_loss:  0.001320453117763246  test_acc:  0.8553170368532076
best acc:  86.63605906440004

------Epoch: 92------
[batch_idx--0] train_loss: 0.0012422290164977312, acc: 0.875, lr: 0.016285698816954627
[batch_idx--50] train_loss: 0.0012399282160342909, acc: 0.8651960784313726, lr: 0.016231314407882003
[batch_idx--100] train_loss: 0.0012290816181247113, acc: 0.8633586014851485, lr: 0.016176977274562434
[batch_idx--150] train_loss: 0.0012203462029474214, acc: 0.8654542632450332, lr: 0.016122687709950775
[batch_idx--200] train_loss: 0.0012188919675675458, acc: 0.8653801305970149, lr: 0.01606844600674539
[batch_idx--250] train_loss: 0.0012213743374816538, acc: 0.8649620268924303, lr: 0.016014252457386614
[batch_idx--300] train_loss: 0.0012245736151788248, acc: 0.864514119601329, lr: 0.015960107354055172
[batch_idx--350] train_loss: 0.0012278382951974806, acc: 0.8643273682336182, lr: 0.01590601098867059
[batch_idx--400] train_loss: 0.0012278955119448317, acc: 0.8644014962593516, lr: 0.015851963652889624
[batch_idx--450] train_loss: 0.001231478273399909, acc: 0.8643385288297983, lr: 0.015797965638104688
total time of one epoch: 401.22468972206116 s
train_loss:  0.001231478273399909  acc:  0.8643385288297983
->>lr:0.015798
test_loss:  0.0013077356136677978  test_acc:  0.8587914133267155
best acc:  86.63605906440004

------Epoch: 93------
[batch_idx--0] train_loss: 0.0011780763743445277, acc: 0.88671875, lr: 0.01579688618288306
[batch_idx--50] train_loss: 0.0012750570860910503, acc: 0.8553921568627451, lr: 0.01574293877543077
[batch_idx--100] train_loss: 0.0012387921739747693, acc: 0.8617728960396039, lr: 0.015689041276774486
[batch_idx--150] train_loss: 0.001241119820948394, acc: 0.8611341059602649, lr: 0.015635193977498796
[batch_idx--200] train_loss: 0.0012313991988341865, acc: 0.8635533271144279, lr: 0.015581397167917649
[batch_idx--250] train_loss: 0.0012359005796530125, acc: 0.8620829183266933, lr: 0.01552765113807274
[batch_idx--300] train_loss: 0.0012365145176769763, acc: 0.8622689991694352, lr: 0.015473956177732033
[batch_idx--350] train_loss: 0.0012352122939151959, acc: 0.8627359330484331, lr: 0.01542031257638813
[batch_idx--400] train_loss: 0.0012359381633046597, acc: 0.8627844451371571, lr: 0.015366720623256752
[batch_idx--450] train_loss: 0.0012371389821679208, acc: 0.8631148679140487, lr: 0.015313180607275165
total time of one epoch: 399.5190122127533 s
train_loss:  0.0012371389821679208  acc:  0.8631148679140487
->>lr:0.015313
test_loss:  0.001482296232580177  test_acc:  0.832981759523514
best acc:  86.63605906440004

------Epoch: 94------
[batch_idx--0] train_loss: 0.001376476138830185, acc: 0.8515625, lr: 0.015312110338697428
[batch_idx--50] train_loss: 0.001268781065329106, acc: 0.8551623774509803, lr: 0.015258623595981367
[batch_idx--100] train_loss: 0.0012557580911480629, acc: 0.859375, lr: 0.015205189373212608
[batch_idx--150] train_loss: 0.0012442040926351255, acc: 0.8611082367549668, lr: 0.015151807958478031
[batch_idx--200] train_loss: 0.0012300159713827927, acc: 0.86328125, lr: 0.015098479639579785
[batch_idx--250] train_loss: 0.0012277360227278089, acc: 0.8638726344621513, lr: 0.015045204704033754
[batch_idx--300] train_loss: 0.0012231071835826228, acc: 0.8642286129568106, lr: 0.01499198343906803
[batch_idx--350] train_loss: 0.0012272343255428232, acc: 0.8633814102564102, lr: 0.014938816131621303
[batch_idx--400] train_loss: 0.0012271101962475388, acc: 0.8635247817955112, lr: 0.014885703068341395
[batch_idx--450] train_loss: 0.0012320524384388056, acc: 0.8634793626549102, lr: 0.014832644535583656
total time of one epoch: 397.0008406639099 s
train_loss:  0.0012320524384388056  acc:  0.8634793626549102
->>lr:0.014833
test_loss:  0.0012911122894594784  test_acc:  0.8610249410596849
best acc:  86.63605906440004

------Epoch: 95------
[batch_idx--0] train_loss: 0.001269037020392716, acc: 0.86328125, lr: 0.014831583923105
[batch_idx--50] train_loss: 0.0011663584634387756, acc: 0.870327818627451, lr: 0.014778581306178257
[batch_idx--100] train_loss: 0.0012054961511293555, acc: 0.8653697400990099, lr: 0.014725633797313148
[batch_idx--150] train_loss: 0.0012169590324706194, acc: 0.8645488410596026, lr: 0.014672741681972468
[batch_idx--200] train_loss: 0.001219028828257871, acc: 0.8641557835820896, lr: 0.01461990524532032
[batch_idx--250] train_loss: 0.0012144483936638887, acc: 0.864230577689243, lr: 0.014567124772220653
[batch_idx--300] train_loss: 0.0012196992317824145, acc: 0.8641377699335548, lr: 0.014514400547235684
[batch_idx--350] train_loss: 0.0012159749102364811, acc: 0.8647725249287749, lr: 0.014461732854624376
[batch_idx--400] train_loss: 0.0012164278734798201, acc: 0.8648203709476309, lr: 0.014409121978340905
[batch_idx--450] train_loss: 0.001218731358601309, acc: 0.8651629812198424, lr: 0.014356568202033099
total time of one epoch: 396.45948219299316 s
train_loss:  0.001218731358601309  acc:  0.8651629812198424
->>lr:0.014357
test_loss:  0.0013762396557009506  test_acc:  0.8507258965132151
best acc:  86.63605906440004

------Epoch: 96------
[batch_idx--0] train_loss: 0.0011107537429779768, acc: 0.875, lr: 0.014355517710873192
[batch_idx--50] train_loss: 0.0011849959253096114, acc: 0.8670343137254902, lr: 0.014303022468435317
[batch_idx--100] train_loss: 0.0012218802199136503, acc: 0.86328125, lr: 0.014250584898001182
[batch_idx--150] train_loss: 0.0012201080052490463, acc: 0.8635916804635762, lr: 0.014198205282284266
[batch_idx--200] train_loss: 0.0012155264455000338, acc: 0.8644278606965174, lr: 0.014145883903685591
[batch_idx--250] train_loss: 0.0012073766306113169, acc: 0.8654133466135459, lr: 0.014093621044292189
[batch_idx--300] train_loss: 0.0012146100686921853, acc: 0.864501142026578, lr: 0.014041416985875627
[batch_idx--350] train_loss: 0.0012116177948496897, acc: 0.8650062321937322, lr: 0.013989272009890398
[batch_idx--400] train_loss: 0.0012132582801075982, acc: 0.8648106296758105, lr: 0.013937186397472484
[batch_idx--450] train_loss: 0.0012189667004245254, acc: 0.8644079563994862, lr: 0.01388516042943782
total time of one epoch: 398.474734544754 s
train_loss:  0.0012189667004245254  acc:  0.8644079563994862
->>lr:0.013885
test_loss:  0.0013445396439019438  test_acc:  0.854200272986723
best acc:  86.63605906440004

------Epoch: 97------
[batch_idx--0] train_loss: 0.001067458768375218, acc: 0.8828125, lr: 0.01388412052037681
[batch_idx--50] train_loss: 0.001241634056592981, acc: 0.8602175245098039, lr: 0.01383215567857612
[batch_idx--100] train_loss: 0.0012329154334372223, acc: 0.8639387376237624, lr: 0.013780251047424422
[batch_idx--150] train_loss: 0.0012264179014940036, acc: 0.8645229718543046, lr: 0.013728406906761904
[batch_idx--200] train_loss: 0.0012281546340235949, acc: 0.8645055970149254, lr: 0.013676623536102595
[batch_idx--250] train_loss: 0.0012254556249066504, acc: 0.8644017679282868, lr: 0.013624901214632912
[batch_idx--300] train_loss: 0.0012300504969844465, acc: 0.8633072051495017, lr: 0.01357324022121012
[batch_idx--350] train_loss: 0.0012265801490443703, acc: 0.8636039886039886, lr: 0.013521640834360844
[batch_idx--400] train_loss: 0.001227055192911101, acc: 0.8634078865336658, lr: 0.013470103332279566
[batch_idx--450] train_loss: 0.001225315878842082, acc: 0.8640261047662027, lr: 0.013418627992827087
total time of one epoch: 397.7615978717804 s
train_loss:  0.001225315878842082  acc:  0.8640261047662027
->>lr:0.013419
test_loss:  0.0014321119173804678  test_acc:  0.8456384166770071
best acc:  86.63605906440004

------Epoch: 98------
[batch_idx--0] train_loss: 0.00135336653329432, acc: 0.8515625, lr: 0.013417599122003463
[batch_idx--50] train_loss: 0.0011969586176907316, acc: 0.8653492647058824, lr: 0.013366187474337023
[batch_idx--100] train_loss: 0.0011949823203376761, acc: 0.868541150990099, lr: 0.013314838549554453
[batch_idx--150] train_loss: 0.001201432463882602, acc: 0.867161630794702, lr: 0.013263552624499875
[batch_idx--200] train_loss: 0.0012079387401063828, acc: 0.8669348569651741, lr: 0.01321232997567776
[batch_idx--250] train_loss: 0.0012083070355456368, acc: 0.8669851842629482, lr: 0.01316117087925142
[batch_idx--300] train_loss: 0.001210677798333086, acc: 0.8667462624584718, lr: 0.013110075611041534
[batch_idx--350] train_loss: 0.0012077903277187628, acc: 0.8669983084045584, lr: 0.01305904444652466
[batch_idx--400] train_loss: 0.0012079846375782108, acc: 0.8668660380299252, lr: 0.013008077660831736
[batch_idx--450] train_loss: 0.001210398904659294, acc: 0.8666296386294998, lr: 0.01295717552874661
total time of one epoch: 398.5240240097046 s
train_loss:  0.001210398904659294  acc:  0.8666296386294998
->>lr:0.012957
test_loss:  0.0013085316045214157  test_acc:  0.8596600074450924
best acc:  86.63605906440004

------Epoch: 99------
[batch_idx--0] train_loss: 0.0010539768263697624, acc: 0.875, lr: 0.012956158147457115
[batch_idx--50] train_loss: 0.0011587190206673946, acc: 0.8735447303921569, lr: 0.012905322244772761
[batch_idx--100] train_loss: 0.0011888455748235308, acc: 0.8693146658415841, lr: 0.012854551549694835
[batch_idx--150] train_loss: 0.0011953217272696066, acc: 0.8670581539735099, lr: 0.012803846335949954
[batch_idx--200] train_loss: 0.0012040953774500953, acc: 0.8660991915422885, lr: 0.012753206876911727
[batch_idx--250] train_loss: 0.001204110706592372, acc: 0.8661759213147411, lr: 0.012702633445599246
[batch_idx--300] train_loss: 0.0012056194510747156, acc: 0.8660195182724253, lr: 0.012652126314675622
[batch_idx--350] train_loss: 0.001202006803751204, acc: 0.8664307336182336, lr: 0.012601685756446507
[batch_idx--400] train_loss: 0.0012036157923488136, acc: 0.8662425966334164, lr: 0.012551312042858621
[batch_idx--450] train_loss: 0.0012053394268640944, acc: 0.8662043947651612, lr: 0.012501005445498313
total time of one epoch: 393.59363174438477 s
train_loss:  0.0012053394268640944  acc:  0.8662043947651612
->>lr:0.012501
test_loss:  0.001266870409608967  test_acc:  0.8640029780369773
best acc:  86.63605906440004

------Epoch: 100------
[batch_idx--0] train_loss: 0.0010604712879285216, acc: 0.890625, lr: 0.012500000000000006
[batch_idx--50] train_loss: 0.0011700409517039125, acc: 0.8717064950980392, lr: 0.012449762140604802
[batch_idx--100] train_loss: 0.0011778405411076722, acc: 0.8709390470297029, lr: 0.012399591944936346
[batch_idx--150] train_loss: 0.0011845584006653174, acc: 0.8696450745033113, lr: 0.012349489683483728
[batch_idx--200] train_loss: 0.0011835550829717213, acc: 0.8702386504975125, lr: 0.012299455626369788
[batch_idx--250] train_loss: 0.0011835512661085691, acc: 0.8704401145418327, lr: 0.012249490043349598
[batch_idx--300] train_loss: 0.001189046563345481, acc: 0.869640261627907, lr: 0.01219959320380913
[batch_idx--350] train_loss: 0.001195043986769356, acc: 0.86893474002849, lr: 0.012149765376763677
[batch_idx--400] train_loss: 0.001197558545514458, acc: 0.8685707605985037, lr: 0.012100006830856476
[batch_idx--450] train_loss: 0.0011997142249349298, acc: 0.8689207484292012, lr: 0.01205031783435723
total time of one epoch: 395.22288036346436 s
train_loss:  0.0011997142249349298  acc:  0.8689207484292012
->>lr:0.012050
test_loss:  0.0012519782124093455  test_acc:  0.8620176200521157
best acc:  86.63605906440004

------Epoch: 101------
[batch_idx--0] train_loss: 0.0009725234122015536, acc: 0.890625, lr: 0.012049324765671741
[batch_idx--50] train_loss: 0.0011898015166961534, acc: 0.8681066176470589, lr: 0.01199970698555119
[batch_idx--100] train_loss: 0.0011962465832406415, acc: 0.8669167698019802, lr: 0.011950159295598187
[batch_idx--150] train_loss: 0.001177468505188428, acc: 0.8703435430463576, lr: 0.011900681962945607
[batch_idx--200] train_loss: 0.0011804413695620437, acc: 0.8698499689054726, lr: 0.011851275254347019
[batch_idx--250] train_loss: 0.0011822514122804678, acc: 0.8698020418326693, lr: 0.011801939436175232
[batch_idx--300] train_loss: 0.0011844483120645398, acc: 0.8696921719269103, lr: 0.01175267477442085
[batch_idx--350] train_loss: 0.0011872570264216862, acc: 0.8694021545584045, lr: 0.011703481534690844
[batch_idx--400] train_loss: 0.001190580046030825, acc: 0.8687168796758105, lr: 0.011654359982207095
[batch_idx--450] train_loss: 0.001195964858685438, acc: 0.8686864303815045, lr: 0.011605310381805019
total time of one epoch: 396.6080513000488 s
train_loss:  0.001195964858685438  acc:  0.8686864303815045
->>lr:0.011605
test_loss:  0.0012666479479750328  test_acc:  0.864251147785085
best acc:  86.63605906440004

------Epoch: 102------
[batch_idx--0] train_loss: 0.0012577814050018787, acc: 0.84375, lr: 0.01160433012552509
[batch_idx--50] train_loss: 0.001208213088330904, acc: 0.867953431372549, lr: 0.011555354188677439
[batch_idx--100] train_loss: 0.0012239634599951602, acc: 0.8638613861386139, lr: 0.011506450737694249
[batch_idx--150] train_loss: 0.001202236904935381, acc: 0.8665149006622517, lr: 0.011457620036235043
[batch_idx--200] train_loss: 0.0011950867868547527, acc: 0.8667599502487562, lr: 0.011408862347567132
[batch_idx--250] train_loss: 0.0011917807459107701, acc: 0.8677633217131474, lr: 0.011360177934564142
[batch_idx--300] train_loss: 0.001191645547781647, acc: 0.8676546926910299, lr: 0.011311567059704701
[batch_idx--350] train_loss: 0.001196053734963277, acc: 0.8675324964387464, lr: 0.01126302998507092
[batch_idx--400] train_loss: 0.0011972743222963744, acc: 0.8675966334164589, lr: 0.011214566972347026
[batch_idx--450] train_loss: 0.0011987945378306723, acc: 0.8676363383899747, lr: 0.01116617828281797
total time of one epoch: 402.72590136528015 s
train_loss:  0.0011987945378306723  acc:  0.8676363383899747
->>lr:0.011166
test_loss:  0.001274229612195443  test_acc:  0.8626380444223849
best acc:  86.63605906440004

------Epoch: 103------
[batch_idx--0] train_loss: 0.001409905031323433, acc: 0.83984375, lr: 0.011165211268916392
[batch_idx--50] train_loss: 0.0011657115606152836, acc: 0.8694087009803921, lr: 0.011116898657806221
[batch_idx--100] train_loss: 0.0011709191188640376, acc: 0.8695853960396039, lr: 0.01106866089646273
[batch_idx--150] train_loss: 0.0011760914572576271, acc: 0.8690242135761589, lr: 0.011020498244956429
[batch_idx--200] train_loss: 0.0011865085738581322, acc: 0.8679259950248757, lr: 0.010972410962952879
[batch_idx--250] train_loss: 0.0011832126800297386, acc: 0.8688215886454184, lr: 0.010924399309711284
[batch_idx--300] train_loss: 0.0011877118701894963, acc: 0.8685501453488372, lr: 0.010876463544083113
[batch_idx--350] train_loss: 0.0011844469451257943, acc: 0.8694021545584045, lr: 0.010828603924510663
[batch_idx--400] train_loss: 0.001183836686336656, acc: 0.8694279925187033, lr: 0.010780820709025727
[batch_idx--450] train_loss: 0.0011883114535092157, acc: 0.8693633491859617, lr: 0.010733114155248157
total time of one epoch: 399.00357699394226 s
train_loss:  0.0011883114535092157  acc:  0.8693633491859617
->>lr:0.010733
test_loss:  0.0012243002771458505  test_acc:  0.8697108822434545
best acc:  86.63605906440004
Saving..

------Epoch: 104------
[batch_idx--0] train_loss: 0.0008601525332778692, acc: 0.91015625, lr: 0.010732160807889211
[batch_idx--50] train_loss: 0.0011822992693815454, acc: 0.8707873774509803, lr: 0.010684532714024482
[batch_idx--100] train_loss: 0.0011888398641333132, acc: 0.8688118811881188, lr: 0.010636981800997085
[batch_idx--150] train_loss: 0.0011789855325212146, acc: 0.8696968129139073, lr: 0.01058950832517444
[batch_idx--200] train_loss: 0.0011782420570938964, acc: 0.8699665733830846, lr: 0.010542112542506449
[batch_idx--250] train_loss: 0.0011822941211660752, acc: 0.8698642928286853, lr: 0.01049479470852415
[batch_idx--300] train_loss: 0.001182833702134841, acc: 0.8693547549833887, lr: 0.010447555078338317
[batch_idx--350] train_loss: 0.0011795049420812637, acc: 0.8695690883190883, lr: 0.010400393906638123
[batch_idx--400] train_loss: 0.0011853640859869966, acc: 0.8689409289276808, lr: 0.010353311447689712
[batch_idx--450] train_loss: 0.0011903490000486697, acc: 0.8685736105807617, lr: 0.01030630795533484
total time of one epoch: 395.9547357559204 s
train_loss:  0.0011903490000486697  acc:  0.8685736105807617
->>lr:0.010306
test_loss:  0.0013471922502873892  test_acc:  0.854076188112669
best acc:  86.97108822434545

------Epoch: 105------
[batch_idx--0] train_loss: 0.001180934370495379, acc: 0.859375, lr: 0.010305368692688175
[batch_idx--50] train_loss: 0.0011855406120565592, acc: 0.8686427696078431, lr: 0.010258446007324987
[batch_idx--100] train_loss: 0.0011805696026790924, acc: 0.8691986386138614, lr: 0.010211602800015714
[batch_idx--150] train_loss: 0.0011853960304928093, acc: 0.8699037665562914, lr: 0.010164839323312217
[batch_idx--200] train_loss: 0.0011882234381544242, acc: 0.8693641169154229, lr: 0.010118155829336504
[batch_idx--250] train_loss: 0.001185316201002593, acc: 0.8692729083665338, lr: 0.010071552569779364
[batch_idx--300] train_loss: 0.0011849799945693699, acc: 0.8689913828903655, lr: 0.010025029795898983
[batch_idx--350] train_loss: 0.001184038879904376, acc: 0.8688011930199431, lr: 0.00997858775851964
[batch_idx--400] train_loss: 0.001185117764084918, acc: 0.868444124064838, lr: 0.00993222670803032
[batch_idx--450] train_loss: 0.0011826703847944374, acc: 0.8688686777519353, lr: 0.009885946894383374
total time of one epoch: 400.50221276283264 s
train_loss:  0.0011826703847944374  acc:  0.8688686777519353
->>lr:0.009886
test_loss:  0.0012616929319067885  test_acc:  0.8640029780369773
best acc:  86.97108822434545

------Epoch: 106------
[batch_idx--0] train_loss: 0.0009394161170348525, acc: 0.88671875, lr: 0.00988502212844063
[batch_idx--50] train_loss: 0.0011696376433760365, acc: 0.8694087009803921, lr: 0.009838825433419594
[batch_idx--100] train_loss: 0.001174795478789855, acc: 0.8701655321782178, lr: 0.009792710478807351
[batch_idx--150] train_loss: 0.0011752819744962582, acc: 0.8699813741721855, lr: 0.009746677513229449
[batch_idx--200] train_loss: 0.0011775382135332149, acc: 0.8704912935323383, lr: 0.00970072678486938
[batch_idx--250] train_loss: 0.0011748778091120232, acc: 0.8714050049800797, lr: 0.009654858541467274
[batch_idx--300] train_loss: 0.0011822761069717152, acc: 0.8703540282392026, lr: 0.009609073030318542
[batch_idx--350] train_loss: 0.0011775379191534833, acc: 0.8711493945868946, lr: 0.009563370498272567
[batch_idx--400] train_loss: 0.0011808781684585325, acc: 0.8705872038653366, lr: 0.009517751191731351
[batch_idx--450] train_loss: 0.0011844542291975322, acc: 0.8703092998229597, lr: 0.00947221535664816
total time of one epoch: 402.03707909584045 s
train_loss:  0.0011844542291975322  acc:  0.8703092998229597
->>lr:0.009472
test_loss:  0.0012800241392353123  test_acc:  0.8607767713115771
best acc:  86.97108822434545

------Epoch: 107------
[batch_idx--0] train_loss: 0.0010823897318914533, acc: 0.87890625, lr: 0.009471305493042243
[batch_idx--50] train_loss: 0.0011551016485135928, acc: 0.8713235294117647, lr: 0.00942585505176061
[batch_idx--100] train_loss: 0.001159807940308779, acc: 0.8725247524752475, lr: 0.009380488577388602
[batch_idx--150] train_loss: 0.0011620776510384205, acc: 0.8712489652317881, lr: 0.009335206314516387
[batch_idx--200] train_loss: 0.001169090921149603, acc: 0.870918843283582, lr: 0.0092900085072801
[batch_idx--250] train_loss: 0.0011790367875311272, acc: 0.8699576693227091, lr: 0.009244895399360565
[batch_idx--300] train_loss: 0.001175053071530777, acc: 0.8703150955149501, lr: 0.009199867233981912
[batch_idx--350] train_loss: 0.0011746342581805595, acc: 0.870292467948718, lr: 0.009154924253910346
[batch_idx--400] train_loss: 0.0011733001737595254, acc: 0.87044108478803, lr: 0.009110066701452797
[batch_idx--450] train_loss: 0.0011748821567495078, acc: 0.8708560419342521, lr: 0.0090652948184556
total time of one epoch: 400.12911796569824 s
train_loss:  0.0011748821567495078  acc:  0.8708560419342521
->>lr:0.009065
test_loss:  0.0012230080937108534  test_acc:  0.8705794763618315
best acc:  86.97108822434545
Saving..

------Epoch: 108------
[batch_idx--0] train_loss: 0.0011525513837113976, acc: 0.89453125, lr: 0.009064400256282757
[batch_idx--50] train_loss: 0.0011931386064080631, acc: 0.8676470588235294, lr: 0.009019716004806225
[batch_idx--100] train_loss: 0.0011702913970751043, acc: 0.8703589108910891, lr: 0.0089751179099095
[batch_idx--150] train_loss: 0.0011798396366586698, acc: 0.8682222682119205, lr: 0.008930606212040063
[batch_idx--200] train_loss: 0.0011796531613814222, acc: 0.8682758084577115, lr: 0.00888618115117962
[batch_idx--250] train_loss: 0.0011818857654368883, acc: 0.8686970866533864, lr: 0.00884184296684277
[batch_idx--300] train_loss: 0.0011785591477172393, acc: 0.8691211586378738, lr: 0.00879759189807571
[batch_idx--350] train_loss: 0.0011794259589287502, acc: 0.8693798967236467, lr: 0.008753428183455004
[batch_idx--400] train_loss: 0.0011799483036882526, acc: 0.8696228179551122, lr: 0.008709352061086187
[batch_idx--450] train_loss: 0.0011834928316962331, acc: 0.8702398722532718, lr: 0.008665363768602597
total time of one epoch: 397.1097993850708 s
train_loss:  0.0011834928316962331  acc:  0.8702398722532718
->>lr:0.008665
test_loss:  0.0012341616082419266  test_acc:  0.8662365057699466
best acc:  87.05794763618314

------Epoch: 109------
[batch_idx--0] train_loss: 0.0011995111126452684, acc: 0.87109375, lr: 0.008664484900247363
[batch_idx--50] train_loss: 0.0011931100230225746, acc: 0.8682598039215687, lr: 0.00862058643856546
[batch_idx--100] train_loss: 0.0011894449229711795, acc: 0.8680770420792079, lr: 0.0085767762853424
[batch_idx--150] train_loss: 0.0011836092098807263, acc: 0.8687396523178808, lr: 0.008533054676777554
[batch_idx--200] train_loss: 0.0011832899456283086, acc: 0.8689754353233831, lr: 0.008489421848592919
[batch_idx--250] train_loss: 0.001179355985820813, acc: 0.8699109810756972, lr: 0.008445878036031801
[batch_idx--300] train_loss: 0.0011716472743809273, acc: 0.8710288621262459, lr: 0.008402423473857626
[batch_idx--350] train_loss: 0.0011735601348011751, acc: 0.8706374643874644, lr: 0.008359058396352615
[batch_idx--400] train_loss: 0.0011713335504221203, acc: 0.8705872038653366, lr: 0.008315783037316537
[batch_idx--450] train_loss: 0.0011744312766154307, acc: 0.87092546950394, lr: 0.008272597630065468
total time of one epoch: 395.24504494667053 s
train_loss:  0.0011744312766154307  acc:  0.87092546950394
->>lr:0.008273
test_loss:  0.0012293471889469815  test_acc:  0.8654919965256235
best acc:  87.05794763618314

------Epoch: 110------
[batch_idx--0] train_loss: 0.0011305627413094044, acc: 0.8828125, lr: 0.008271734841028545
[batch_idx--50] train_loss: 0.0011953502840946848, acc: 0.8673406862745098, lr: 0.008228641424457422
[batch_idx--100] train_loss: 0.0011730516377818025, acc: 0.8708230198019802, lr: 0.00818563842948918
[batch_idx--150] train_loss: 0.0011577713245445776, acc: 0.8725165562913907, lr: 0.008142726087971458
[batch_idx--200] train_loss: 0.0011578320600300917, acc: 0.8725124378109452, lr: 0.00809990463126313
[batch_idx--250] train_loss: 0.001155026657534652, acc: 0.8732569721115537, lr: 0.008057174290233077
[batch_idx--300] train_loss: 0.0011612490143246355, acc: 0.872326619601329, lr: 0.008014535295258926
[batch_idx--350] train_loss: 0.0011592233376749963, acc: 0.8724626068376068, lr: 0.00797198787622585
[batch_idx--400] train_loss: 0.001160368908741314, acc: 0.8722821851620948, lr: 0.007929532262525246
[batch_idx--450] train_loss: 0.001164470138997186, acc: 0.8721578088659007, lr: 0.007887168683053591
total time of one epoch: 400.4657828807831 s
train_loss:  0.001164470138997186  acc:  0.8721578088659007
->>lr:0.007887
test_loss:  0.0013038956367550896  test_acc:  0.8589154982007693
best acc:  87.05794763618314

------Epoch: 111------
[batch_idx--0] train_loss: 0.0014742807252332568, acc: 0.8125, lr: 0.00788632235178279
[batch_idx--50] train_loss: 0.0011776374075470456, acc: 0.8675704656862745, lr: 0.00784405288251919
[batch_idx--100] train_loss: 0.0011720895827148515, acc: 0.8696627475247525, lr: 0.007801875908340622
[batch_idx--150] train_loss: 0.0011848192800773887, acc: 0.8682998758278145, lr: 0.007759791656641275
[batch_idx--200] train_loss: 0.001177376068998777, acc: 0.8686644900497512, lr: 0.007717800354315446
[batch_idx--250] train_loss: 0.0011713579505778463, acc: 0.8695530378486056, lr: 0.007675902227756282
[batch_idx--300] train_loss: 0.0011727780999423955, acc: 0.8695883513289037, lr: 0.007634097502854598
[batch_idx--350] train_loss: 0.0011716455476891855, acc: 0.8696247329059829, lr: 0.007592386404997634
[batch_idx--400] train_loss: 0.0011734163365094573, acc: 0.8691162718204489, lr: 0.007550769159067847
[batch_idx--450] train_loss: 0.001176063964005606, acc: 0.8695803103412365, lr: 0.00750924598944171
total time of one epoch: 398.41911816596985 s
train_loss:  0.001176063964005606  acc:  0.8695803103412365
->>lr:0.007509
test_loss:  0.0011946936298029079  test_acc:  0.8708276461099392
best acc:  87.05794763618314
Saving..

------Epoch: 112------
[batch_idx--0] train_loss: 0.001247626030817628, acc: 0.859375, lr: 0.007508416487165862
[batch_idx--50] train_loss: 0.0011504047205580363, acc: 0.8756127450980392, lr: 0.007466989505996053
[batch_idx--100] train_loss: 0.0011671063165171163, acc: 0.8715965346534653, lr: 0.007425657052821996
[batch_idx--150] train_loss: 0.0011533764645839666, acc: 0.8722061258278145, lr: 0.007384419350484717
[batch_idx--200] train_loss: 0.0011594529757137173, acc: 0.8723180970149254, lr: 0.0073432766213143985
[batch_idx--250] train_loss: 0.0011596167107591354, acc: 0.8719030129482072, lr: 0.007302229087129178
[batch_idx--300] train_loss: 0.0011620100742697939, acc: 0.8719892026578073, lr: 0.007261276969233954
[batch_idx--350] train_loss: 0.0011659055431519352, acc: 0.8713385861823362, lr: 0.007220420488419194
[batch_idx--400] train_loss: 0.0011643097843937668, acc: 0.871571072319202, lr: 0.007179659864959754
[batch_idx--450] train_loss: 0.0011643103976646467, acc: 0.871775957232617, lr: 0.007138995318613667
total time of one epoch: 398.7355535030365 s
train_loss:  0.0011643103976646467  acc:  0.871775957232617
->>lr:0.007139
test_loss:  0.0012182852243841664  test_acc:  0.8677255242585928
best acc:  87.08276461099392

------Epoch: 113------
[batch_idx--0] train_loss: 0.0014370183926075697, acc: 0.84375, lr: 0.007138183009179922
[batch_idx--50] train_loss: 0.00111873019669278, acc: 0.8778339460784313, lr: 0.007097616687346986
[batch_idx--100] train_loss: 0.0011409074442673215, acc: 0.873646349009901, lr: 0.00705714688495745
[batch_idx--150] train_loss: 0.0011498037889902018, acc: 0.8726717715231788, lr: 0.007016773820201414
[batch_idx--200] train_loss: 0.0011529756075151227, acc: 0.8724735696517413, lr: 0.00697649771074741
[batch_idx--250] train_loss: 0.0011549996763126427, acc: 0.8721364541832669, lr: 0.006936318773741257
[batch_idx--300] train_loss: 0.00115235029248694, acc: 0.8729235880398671, lr: 0.00689623722580488
[batch_idx--350] train_loss: 0.0011558525040055866, acc: 0.8725182514245015, lr: 0.006856253283035133
[batch_idx--400] train_loss: 0.0011571057618681591, acc: 0.8725939058603491, lr: 0.00681636716100264
[batch_idx--450] train_loss: 0.001158489860661777, acc: 0.8728347276703579, lr: 0.006776579074750619
total time of one epoch: 399.35528898239136 s
train_loss:  0.001158489860661777  acc:  0.8728347276703579
->>lr:0.006777
test_loss:  0.0012340096678001913  test_acc:  0.867601439384539
best acc:  87.08276461099392

------Epoch: 114------
[batch_idx--0] train_loss: 0.0010017937747761607, acc: 0.90234375, lr: 0.006775784314464717
[batch_idx--50] train_loss: 0.0011746743796667194, acc: 0.8673406862745098, lr: 0.006736096445698165
[batch_idx--100] train_loss: 0.0011782235313797056, acc: 0.8683090965346535, lr: 0.0066965070454860194
[batch_idx--150] train_loss: 0.0011701789905859885, acc: 0.8701365894039735, lr: 0.006657016327271753
[batch_idx--200] train_loss: 0.001161113785943526, acc: 0.8715990360696517, lr: 0.006617624503966805
[batch_idx--250] train_loss: 0.0011599271231705686, acc: 0.8717940737051793, lr: 0.006578331787949427
[batch_idx--300] train_loss: 0.0011566381132233257, acc: 0.8725083056478405, lr: 0.006539138391063526
[batch_idx--350] train_loss: 0.0011526474361360985, acc: 0.8730858262108262, lr: 0.006500044524617568
[batch_idx--400] train_loss: 0.0011562235762848242, acc: 0.87261338840399, lr: 0.0064610503993833834
[batch_idx--450] train_loss: 0.0011582355946949008, acc: 0.872756621654459, lr: 0.006422156225595066
total time of one epoch: 398.42507338523865 s
train_loss:  0.0011582355946949008  acc:  0.872756621654459
->>lr:0.006422
test_loss:  0.0012353662928867495  test_acc:  0.8679736940067005
best acc:  87.08276461099392

------Epoch: 115------
[batch_idx--0] train_loss: 0.001153904595412314, acc: 0.87890625, lr: 0.00642137936306515
[batch_idx--50] train_loss: 0.0011298497887693491, acc: 0.8728553921568627, lr: 0.006382587355775901
[batch_idx--100] train_loss: 0.001145004032013735, acc: 0.8734916460396039, lr: 0.006343895722960522
[batch_idx--150] train_loss: 0.0011366992789499512, acc: 0.8739652317880795, lr: 0.006305304673222229
[batch_idx--200] train_loss: 0.0011426261122296773, acc: 0.8736590485074627, lr: 0.0062668144146219495
[batch_idx--250] train_loss: 0.0011390343526901448, acc: 0.8742996762948207, lr: 0.006228425154677217
[batch_idx--300] train_loss: 0.001139884626266989, acc: 0.8745198297342193, lr: 0.0061901371003610295
[batch_idx--350] train_loss: 0.0011467692656827258, acc: 0.8734085648148148, lr: 0.00615195045810075
[batch_idx--400] train_loss: 0.0011453714948658484, acc: 0.8736849283042394, lr: 0.006113865433776986
[batch_idx--450] train_loss: 0.0011512305205134072, acc: 0.8732599715346965, lr: 0.006075882232722457
total time of one epoch: 399.61593794822693 s
train_loss:  0.0011512305205134072  acc:  0.8732599715346965
->>lr:0.006076
test_loss:  0.0011956469398645983  test_acc:  0.8713239856061546
best acc:  87.08276461099392
Saving..

------Epoch: 116------
[batch_idx--0] train_loss: 0.0010071052238345146, acc: 0.89453125, lr: 0.006075123608706093
[batch_idx--50] train_loss: 0.00115944896870311, acc: 0.8721660539215687, lr: 0.006037244478350651
[batch_idx--100] train_loss: 0.0011592198515974796, acc: 0.8732595915841584, lr: 0.00599946758436096
[batch_idx--150] train_loss: 0.0011630836498016947, acc: 0.8717404801324503, lr: 0.005961793130408489
[batch_idx--200] train_loss: 0.001147653466491353, acc: 0.8738145211442786, lr: 0.005924221319612417
[batch_idx--250] train_loss: 0.0011413841516677424, acc: 0.8749066235059761, lr: 0.005886752354538527
[batch_idx--300] train_loss: 0.0011429014846611385, acc: 0.8742732558139535, lr: 0.0058493864371981065
[batch_idx--350] train_loss: 0.001139592100399151, acc: 0.8742766203703703, lr: 0.005812123769046874
[batch_idx--400] train_loss: 0.0011418113980542154, acc: 0.8740745791770573, lr: 0.005774964550983902
[batch_idx--450] train_loss: 0.0011433011389210715, acc: 0.8742146006179053, lr: 0.005737908983350504
total time of one epoch: 398.31246876716614 s
train_loss:  0.0011433011389210715  acc:  0.8742146006179053
->>lr:0.005738
test_loss:  0.00121469971914418  test_acc:  0.8695867973694007
best acc:  87.13239856061546

------Epoch: 117------
[batch_idx--0] train_loss: 0.001176212914288044, acc: 0.8671875, lr: 0.005737168930605272
[batch_idx--50] train_loss: 0.0011481446551852952, acc: 0.8740042892156863, lr: 0.005700219292222111
[batch_idx--100] train_loss: 0.0011527601503859284, acc: 0.8735303217821783, lr: 0.005663373707252357
[batch_idx--150] train_loss: 0.001156630949348532, acc: 0.8723096026490066, lr: 0.005626632374346372
[batch_idx--200] train_loss: 0.001152737353712932, acc: 0.8720460199004975, lr: 0.005589995491592479
[batch_idx--250] train_loss: 0.0011523478187665166, acc: 0.8719808266932271, lr: 0.005553463256515865
[batch_idx--300] train_loss: 0.0011523280882948014, acc: 0.8726640365448505, lr: 0.005517035866077508
[batch_idx--350] train_loss: 0.0011515631459844417, acc: 0.8729077635327636, lr: 0.0054807135166731365
[batch_idx--400] train_loss: 0.0011484720889348861, acc: 0.8738018235660848, lr: 0.005444496404132135
[batch_idx--450] train_loss: 0.0011555245743285498, acc: 0.8738761412156767, lr: 0.005408384723716528
total time of one epoch: 397.16821241378784 s
train_loss:  0.0011555245743285498  acc:  0.8738761412156767
->>lr:0.005408
test_loss:  0.001250929044189103  test_acc:  0.8636307234148157
best acc:  87.13239856061546

------Epoch: 118------
[batch_idx--0] train_loss: 0.0009435287793166935, acc: 0.90234375, lr: 0.005407663566854007
[batch_idx--50] train_loss: 0.0011263691247258261, acc: 0.8776041666666666, lr: 0.005371659627775735
[batch_idx--100] train_loss: 0.001113851591575854, acc: 0.8785581683168316, lr: 0.005335761513517229
[batch_idx--150] train_loss: 0.0011242288924192406, acc: 0.8771212748344371, lr: 0.0052999694176206515
[batch_idx--200] train_loss: 0.0011272232059217915, acc: 0.8759328358208955, lr: 0.005264283533056586
[batch_idx--250] train_loss: 0.0011310082824577937, acc: 0.8756225099601593, lr: 0.0052287040522229575
[batch_idx--300] train_loss: 0.001133745159115333, acc: 0.875687811461794, lr: 0.005193231166944048
[batch_idx--350] train_loss: 0.0011350249512083934, acc: 0.8755675747863247, lr: 0.005157865068469426
[batch_idx--400] train_loss: 0.0011351184917734634, acc: 0.8757500779301746, lr: 0.005122605947472936
[batch_idx--450] train_loss: 0.001140808445757537, acc: 0.8753167632867012, lr: 0.0050874539940516635
total time of one epoch: 397.2241942882538 s
train_loss:  0.001140808445757537  acc:  0.8753167632867012
->>lr:0.005087
test_loss:  0.0012200676022162877  test_acc:  0.8690904578731853
best acc:  87.13239856061546

------Epoch: 119------
[batch_idx--0] train_loss: 0.00105731887742877, acc: 0.90234375, lr: 0.005086752049395094
[batch_idx--50] train_loss: 0.0011533892521744266, acc: 0.8720128676470589, lr: 0.005051709602139323
[batch_idx--100] train_loss: 0.0011393751564094483, acc: 0.8738397277227723, lr: 0.005016774704691432
[batch_idx--150] train_loss: 0.001134307433647529, acc: 0.8757760761589404, lr: 0.004981947545400465
[batch_idx--200] train_loss: 0.0011426236032188607, acc: 0.8746307524875622, lr: 0.004947228312034608
[batch_idx--250] train_loss: 0.0011446895154352593, acc: 0.8741751743027888, lr: 0.004912617191780173
[batch_idx--300] train_loss: 0.0011400621329462062, acc: 0.8749870224252492, lr: 0.004878114371240583
[batch_idx--350] train_loss: 0.0011381334368142158, acc: 0.8752893518518519, lr: 0.004843720036435387
[batch_idx--400] train_loss: 0.0011412378667942028, acc: 0.8748441396508728, lr: 0.004809434372799207
[batch_idx--450] train_loss: 0.0011423487339992419, acc: 0.8752733710556462, lr: 0.004775257565180805
total time of one epoch: 397.6269826889038 s
train_loss:  0.0011423487339992419  acc:  0.8752733710556462
->>lr:0.004775
test_loss:  0.0011595618541401333  test_acc:  0.8757910410720933
best acc:  87.13239856061546
Saving..

------Epoch: 120------
[batch_idx--0] train_loss: 0.0010554986074566841, acc: 0.89453125, lr: 0.004774575140626317
[batch_idx--50] train_loss: 0.0011734840638168594, acc: 0.8694852941176471, lr: 0.004740509555968578
[batch_idx--100] train_loss: 0.001150566705912905, acc: 0.8730275371287128, lr: 0.004706553198931926
[batch_idx--150] train_loss: 0.001149799569127526, acc: 0.8736548013245033, lr: 0.004672706252589681
[batch_idx--200] train_loss: 0.0011472360683322436, acc: 0.8738145211442786, lr: 0.004638968899425284
[batch_idx--250] train_loss: 0.0011406315233654888, acc: 0.8749221862549801, lr: 0.004605341321331294
[batch_idx--300] train_loss: 0.0011405129731320266, acc: 0.8748832018272426, lr: 0.004571823699608443
[batch_idx--350] train_loss: 0.0011401016998470912, acc: 0.8747885505698005, lr: 0.0045384162149646355
[batch_idx--400] train_loss: 0.0011444679270393942, acc: 0.8742304395261845, lr: 0.004505119047513989
[batch_idx--450] train_loss: 0.0011468834741301707, acc: 0.8741017808171625, lr: 0.0044719323767758445
total time of one epoch: 399.4143054485321 s
train_loss:  0.0011468834741301707  acc:  0.8741017808171625
->>lr:0.004472
test_loss:  0.0011923460821194809  test_acc:  0.8716962402283162
best acc:  87.57910410720933

------Epoch: 121------
[batch_idx--0] train_loss: 0.001030539395287633, acc: 0.88671875, lr: 0.004471269771657399
[batch_idx--50] train_loss: 0.0011298533303060515, acc: 0.8775275735294118, lr: 0.004438195991889007
[batch_idx--100] train_loss: 0.001133565555239041, acc: 0.8766243811881188, lr: 0.004405233069644058
[batch_idx--150] train_loss: 0.0011381508400108641, acc: 0.875103476821192, lr: 0.004372381182639854
[batch_idx--200] train_loss: 0.0011325232726313284, acc: 0.8759717039800995, lr: 0.004339640507995033
[batch_idx--250] train_loss: 0.001126111694240564, acc: 0.8767897161354582, lr: 0.00430701122222864
[batch_idx--300] train_loss: 0.001119535291633968, acc: 0.8778291112956811, lr: 0.004274493501259191
[batch_idx--350] train_loss: 0.0011235482657747475, acc: 0.8769698183760684, lr: 0.004242087520403681
[batch_idx--400] train_loss: 0.0011263420376253135, acc: 0.8768216178304239, lr: 0.004209793454376692
[batch_idx--450] train_loss: 0.0011314385043514116, acc: 0.8767660638039365, lr: 0.0041776114772894115
total time of one epoch: 404.18714451789856 s
train_loss:  0.0011314385043514116  acc:  0.8767660638039365
->>lr:0.004178
test_loss:  0.0012254534761431436  test_acc:  0.8666087603921082
best acc:  87.57910410720933

------Epoch: 122------
[batch_idx--0] train_loss: 0.0010227513266727328, acc: 0.90625, lr: 0.004176968982247515
[batch_idx--50] train_loss: 0.0011687000024168954, acc: 0.8720894607843137, lr: 0.004144901514621361
[batch_idx--100] train_loss: 0.0011593789106585308, acc: 0.8731435643564357, lr: 0.0041129464857952575
[batch_idx--150] train_loss: 0.001147052690244915, acc: 0.8741980546357616, lr: 0.004081104068052505
[batch_idx--200] train_loss: 0.001143531703832675, acc: 0.8746501865671642, lr: 0.00404937443306925
[batch_idx--250] train_loss: 0.0011431769344054045, acc: 0.8746731822709163, lr: 0.004017757751913604
[batch_idx--300] train_loss: 0.0011452660535035215, acc: 0.8743511212624585, lr: 0.003986254195044678
[batch_idx--350] train_loss: 0.0011427099025473953, acc: 0.8747774216524217, lr: 0.003954863932311695
[batch_idx--400] train_loss: 0.0011378515390110227, acc: 0.8754870635910225, lr: 0.003923587132953052
[batch_idx--450] train_loss: 0.0011424537285524576, acc: 0.8753688339639671, lr: 0.003892423965595415
total time of one epoch: 404.81449723243713 s
train_loss:  0.0011424537285524576  acc:  0.8753688339639671
->>lr:0.003892
test_loss:  0.0012065636500011737  test_acc:  0.8704553914877776
best acc:  87.57910410720933

------Epoch: 123------
[batch_idx--0] train_loss: 0.0009479260770604014, acc: 0.90234375, lr: 0.003891801862449629
[batch_idx--50] train_loss: 0.001133481655772045, acc: 0.8763020833333334, lr: 0.003860754772816863
[batch_idx--100] train_loss: 0.0011250438983552158, acc: 0.8761602722772277, lr: 0.0038298216539413596
[batch_idx--150] train_loss: 0.001123309694384749, acc: 0.8762675910596026, lr: 0.0037990026725968685
[batch_idx--200] train_loss: 0.0011252641257371253, acc: 0.8759328358208955, lr: 0.003768297994941761
[batch_idx--250] train_loss: 0.0011216573495106156, acc: 0.8757314492031872, lr: 0.0037377077865181603
[batch_idx--300] train_loss: 0.0011237379008025377, acc: 0.8756748338870431, lr: 0.003707232212251013
[batch_idx--350] train_loss: 0.0011299086508786895, acc: 0.8747106481481481, lr: 0.003676871436447249
[batch_idx--400] train_loss: 0.0011321801298583608, acc: 0.874522677680798, lr: 0.0036466256227948553
[batch_idx--450] train_loss: 0.0011349492484738124, acc: 0.874483632450446, lr: 0.003616494934362016
total time of one epoch: 401.861763715744 s
train_loss:  0.0011349492484738124  acc:  0.874483632450446
->>lr:0.003616
test_loss:  0.0011818861326045353  test_acc:  0.8739297679612855
best acc:  87.57910410720933

------Epoch: 124------
[batch_idx--0] train_loss: 0.0010290649952366948, acc: 0.88671875, lr: 0.003615893495987335
[batch_idx--50] train_loss: 0.0010974654179139464, acc: 0.8800551470588235, lr: 0.003585880402627581
[batch_idx--100] train_loss: 0.001108852835224554, acc: 0.8788675742574258, lr: 0.0035559827619909834
[batch_idx--150] train_loss: 0.0011131398870134787, acc: 0.8785440811258278, lr: 0.0035262007352685563
[batch_idx--200] train_loss: 0.001112353246061326, acc: 0.8784592661691543, lr: 0.003496534483028016
[batch_idx--250] train_loss: 0.0011135217795367408, acc: 0.8782837400398407, lr: 0.0034669841652128805
[batch_idx--300] train_loss: 0.0011149642378342434, acc: 0.8786596760797342, lr: 0.00343754994114161
[batch_idx--350] train_loss: 0.0011181945319186652, acc: 0.8782385149572649, lr: 0.0034082319695067616
[batch_idx--400] train_loss: 0.001116448905646448, acc: 0.8785555642144638, lr: 0.003379030408374123
[batch_idx--450] train_loss: 0.0011174302524504726, acc: 0.8784149685840247, lr: 0.00334994541518186
total time of one epoch: 397.7079327106476 s
train_loss:  0.0011174302524504726  acc:  0.8784149685840247
->>lr:0.003350
test_loss:  0.0012133584056987494  test_acc:  0.8692145427472391
best acc:  87.57910410720933

------Epoch: 125------
[batch_idx--0] train_loss: 0.0008871638565324247, acc: 0.89453125, lr: 0.003349364905389038
[batch_idx--50] train_loss: 0.0011018119334681507, acc: 0.8777573529411765, lr: 0.003320398973036992
[batch_idx--100] train_loss: 0.001100117542393653, acc: 0.880259900990099, lr: 0.0032915499247325843
[batch_idx--150] train_loss: 0.0011100408301953943, acc: 0.8785699503311258, lr: 0.003262817916013447
[batch_idx--200] train_loss: 0.0011174236073862964, acc: 0.8782649253731343, lr: 0.0032342031017861847
[batch_idx--250] train_loss: 0.0011179342692480441, acc: 0.8785483067729084, lr: 0.003205705636325565
[batch_idx--300] train_loss: 0.0011199468592463365, acc: 0.8779459094684385, lr: 0.0031773256732736594
[batch_idx--350] train_loss: 0.0011160553294032325, acc: 0.8783386752136753, lr: 0.0031490633656390573
[batch_idx--400] train_loss: 0.0011169370795086843, acc: 0.8782828086034913, lr: 0.0031209188657960046
[batch_idx--450] train_loss: 0.0011227763284010835, acc: 0.8779636893810532, lr: 0.0030928923254835983
total time of one epoch: 399.3017258644104 s
train_loss:  0.0011227763284010835  acc:  0.8779636893810532
->>lr:0.003093
test_loss:  0.001204655339883832  test_acc:  0.8702072217396699
best acc:  87.57910410720933

------Epoch: 126------
[batch_idx--0] train_loss: 0.0010745157487690449, acc: 0.890625, lr: 0.0030923329989034107
[batch_idx--50] train_loss: 0.001135008849030105, acc: 0.8761488970588235, lr: 0.003064426932974329
[batch_idx--100] train_loss: 0.001115132939868081, acc: 0.877707301980198, lr: 0.003036639131148192
[batch_idx--150] train_loss: 0.0011174500733305583, acc: 0.8773282284768212, lr: 0.003008969743240972
[batch_idx--200] train_loss: 0.0011163078247342462, acc: 0.8777207711442786, lr: 0.002981418918430234
[batch_idx--250] train_loss: 0.0011242755734643703, acc: 0.8766185258964143, lr: 0.002953986805254319
[batch_idx--300] train_loss: 0.0011231664667196845, acc: 0.8771542774086378, lr: 0.002926673551611542
[batch_idx--350] train_loss: 0.0011212802261573148, acc: 0.8772146545584045, lr: 0.002899479304759398
[batch_idx--400] train_loss: 0.0011230639994615906, acc: 0.8772891988778054, lr: 0.0028724042113137424
[batch_idx--450] train_loss: 0.0011274593200073042, acc: 0.8774603395008158, lr: 0.002845448417248059
total time of one epoch: 400.41729068756104 s
train_loss:  0.0011274593200073042  acc:  0.8774603395008158
->>lr:0.002845
test_loss:  0.001184433212364884  test_acc:  0.8730611738429086
best acc:  87.57910410720933

------Epoch: 127------
[batch_idx--0] train_loss: 0.0013276621466502547, acc: 0.8671875, lr: 0.0028449105192196373
[batch_idx--50] train_loss: 0.0011535310973961126, acc: 0.8720894607843137, lr: 0.0028180765602363435
[batch_idx--100] train_loss: 0.0011433207183283302, acc: 0.8746132425742574, lr: 0.0027913621935367313
[batch_idx--150] train_loss: 0.0011329166390717227, acc: 0.8765004139072847, lr: 0.002764767563149445
[batch_idx--200] train_loss: 0.0011218250511950854, acc: 0.8778568097014925, lr: 0.002738292812457563
[batch_idx--250] train_loss: 0.001127317954556074, acc: 0.876960906374502, lr: 0.00271193808419784
[batch_idx--300] train_loss: 0.00112560275300836, acc: 0.8768947259136213, lr: 0.002685703520459948
[batch_idx--350] train_loss: 0.0011243940731696254, acc: 0.8771256232193733, lr: 0.0026595892626856965
[batch_idx--400] train_loss: 0.001125236528843149, acc: 0.8770261845386533, lr: 0.0026335954516682747
[batch_idx--450] train_loss: 0.0011240008043074644, acc: 0.8776773006560905, lr: 0.0026077222275514957
total time of one epoch: 398.5303864479065 s
train_loss:  0.0011240008043074644  acc:  0.8776773006560905
->>lr:0.002608
test_loss:  0.0011634475570382397  test_acc:  0.8781486536791165
best acc:  87.57910410720933
Saving..

------Epoch: 128------
[batch_idx--0] train_loss: 0.0009700580849312246, acc: 0.875, lr: 0.0026072059940146775
[batch_idx--50] train_loss: 0.0011331409377995513, acc: 0.8739276960784313, lr: 0.002581455912238459
[batch_idx--100] train_loss: 0.001132214483390055, acc: 0.8765857054455446, lr: 0.0025558266984695406
[batch_idx--150] train_loss: 0.0011274517677255615, acc: 0.8774834437086093, lr: 0.002530318490886033
[batch_idx--200] train_loss: 0.001116079351556631, acc: 0.8787507773631841, lr: 0.0025049314270136516
[batch_idx--250] train_loss: 0.0011212181833765628, acc: 0.8779880478087649, lr: 0.0024796656437249655
[batch_idx--300] train_loss: 0.0011188165368620567, acc: 0.878218438538206, lr: 0.0024545212772386807
[batch_idx--350] train_loss: 0.0011163480354982435, acc: 0.8783052884615384, lr: 0.0024294984631188735
[batch_idx--400] train_loss: 0.0011150791149231096, acc: 0.8787211658354115, lr: 0.0024045973362742893
[batch_idx--450] train_loss: 0.0011220263492389849, acc: 0.8782674349984378, lr: 0.0023798180309576172
total time of one epoch: 398.88178634643555 s
train_loss:  0.0011220263492389849  acc:  0.8782674349984378
->>lr:0.002380
test_loss:  0.001169534094325661  test_acc:  0.8740538528353393
best acc:  87.81486536791165

------Epoch: 129------
[batch_idx--0] train_loss: 0.001138952560722828, acc: 0.87109375, lr: 0.0023793236883495163
[batch_idx--50] train_loss: 0.0011055835045636724, acc: 0.8815104166666666, lr: 0.002354668778617275
[batch_idx--100] train_loss: 0.0011061084661909406, acc: 0.8809173886138614, lr: 0.0023301359595992556
[batch_idx--150] train_loss: 0.0011097272154134976, acc: 0.8815966473509934, lr: 0.0023057253635624278
[batch_idx--200] train_loss: 0.001118358818290579, acc: 0.8797419154228856, lr: 0.0022814371221148186
[batch_idx--250] train_loss: 0.0011160272411052212, acc: 0.8799800796812749, lr: 0.0022572713662047635
[batch_idx--300] train_loss: 0.0011156127059853873, acc: 0.8798665905315615, lr: 0.0022332282261202457
[batch_idx--350] train_loss: 0.001113745701987498, acc: 0.8801860754985755, lr: 0.0022093078314881667
[batch_idx--400] train_loss: 0.0011132303330678018, acc: 0.8802408042394015, lr: 0.002185510311273653
[batch_idx--450] train_loss: 0.0011185356226517623, acc: 0.8797340924080953, lr: 0.0021618357937793764
total time of one epoch: 401.4067130088806 s
train_loss:  0.0011185356226517623  acc:  0.8797340924080953
->>lr:0.002162
test_loss:  0.0011686001045559814  test_acc:  0.874302022583447
best acc:  87.81486536791165

------Epoch: 130------
[batch_idx--0] train_loss: 0.0009398423717357218, acc: 0.91015625, lr: 0.0021613635589349755
[batch_idx--50] train_loss: 0.0011210578491491284, acc: 0.8764552696078431, lr: 0.0021378146357049848
[batch_idx--100] train_loss: 0.0011223478900904923, acc: 0.8755027846534653, lr: 0.0021143889723431067
[batch_idx--150] train_loss: 0.001117688679253522, acc: 0.8768367135761589, lr: 0.0020910866951471623
[batch_idx--200] train_loss: 0.0011157317762378956, acc: 0.876962842039801, lr: 0.0020679079297497515
[batch_idx--250] train_loss: 0.0011148401526771337, acc: 0.8770075946215139, lr: 0.0020448528011175527
[batch_idx--300] train_loss: 0.0011153077713269555, acc: 0.8770764119601329, lr: 0.0020219214335506857
[batch_idx--350] train_loss: 0.0011130862136668608, acc: 0.8773482015669516, lr: 0.0019991139506819965
[batch_idx--400] train_loss: 0.0011102804710027155, acc: 0.8778444513715711, lr: 0.001976430475476429
[batch_idx--450] train_loss: 0.0011156283560305544, acc: 0.8777640851182005, lr: 0.0019538711302303584
total time of one epoch: 400.94885993003845 s
train_loss:  0.0011156283560305544  acc:  0.8777640851182005
->>lr:0.001954
test_loss:  0.001177419807689334  test_acc:  0.8731852587169624
best acc:  87.81486536791165

------Epoch: 131------
[batch_idx--0] train_loss: 0.0009305714629590511, acc: 0.90234375, lr: 0.00195342121028749
[batch_idx--50] train_loss: 0.0011064140925037803, acc: 0.8801317401960784, lr: 0.001930988602895767
[batch_idx--100] train_loss: 0.0011141302616169474, acc: 0.8796024133663366, lr: 0.001908680370460203
[batch_idx--150] train_loss: 0.0011094922152816609, acc: 0.8795012417218543, lr: 0.0018864966332540673
[batch_idx--200] train_loss: 0.0011119176199270496, acc: 0.8786536069651741, lr: 0.0018644375108794243
[batch_idx--250] train_loss: 0.0011143668525039675, acc: 0.8787973107569721, lr: 0.0018425031222664813
[batch_idx--300] train_loss: 0.001110650837248148, acc: 0.8790879360465116, lr: 0.0018206935856729584
[batch_idx--350] train_loss: 0.0011124399338419049, acc: 0.8783164173789174, lr: 0.0017990090186834396
[batch_idx--400] train_loss: 0.0011162544875591529, acc: 0.8779321228179551, lr: 0.0017774495382087503
[batch_idx--450] train_loss: 0.0011173713099185978, acc: 0.8785017530461346, lr: 0.001756015260485311
total time of one epoch: 437.23695969581604 s
train_loss:  0.0011173713099185978  acc:  0.8785017530461346
->>lr:0.001756
test_loss:  0.0011631049412713038  test_acc:  0.8740538528353393
best acc:  87.81486536791165

------Epoch: 132------
[batch_idx--0] train_loss: 0.0011431806487962604, acc: 0.890625, lr: 0.0017555878527937164
[batch_idx--50] train_loss: 0.001087007442644487, acc: 0.8805147058823529, lr: 0.0017342814009232738
[batch_idx--100] train_loss: 0.0011002669464750677, acc: 0.880569306930693, lr: 0.0017131003845420657
[batch_idx--150] train_loss: 0.0011013639286709394, acc: 0.8796823261589404, lr: 0.0016920449178460556
[batch_idx--200] train_loss: 0.0010961526944024017, acc: 0.8798779539800995, lr: 0.0016711151143543159
[batch_idx--250] train_loss: 0.0010887621804530105, acc: 0.8811472858565738, lr: 0.0016503110869084154
[batch_idx--300] train_loss: 0.0010910205629289125, acc: 0.8809567068106312, lr: 0.0016296329476718054
[batch_idx--350] train_loss: 0.001097653417694157, acc: 0.879707532051282, lr: 0.0016090808081292208
[batch_idx--400] train_loss: 0.0010964522282523278, acc: 0.8800362375311721, lr: 0.0015886547790860768
[batch_idx--450] train_loss: 0.0011045302943931002, acc: 0.8801940500572778, lr: 0.0015683549706678873
total time of one epoch: 408.7099814414978 s
train_loss:  0.0011045302943931002  acc:  0.8801940500572778
->>lr:0.001568
test_loss:  0.0011560455314100402  test_acc:  0.8770318898126318
best acc:  87.81486536791165

------Epoch: 133------
[batch_idx--0] train_loss: 0.001080664456821978, acc: 0.875, lr: 0.0015679502627027138
[batch_idx--50] train_loss: 0.001107912256117618, acc: 0.8769148284313726, lr: 0.0015477793120675237
[batch_idx--100] train_loss: 0.001111235633829037, acc: 0.8777459777227723, lr: 0.0015277348024344995
[batch_idx--150] train_loss: 0.00110100880488815, acc: 0.8793718956953642, lr: 0.001507816841872195
[batch_idx--200] train_loss: 0.0011023929500743857, acc: 0.8797807835820896, lr: 0.0014880255377669072
[batch_idx--250] train_loss: 0.0011030284720806932, acc: 0.8796221364541833, lr: 0.0014683609968220602
[batch_idx--300] train_loss: 0.0011034853602883304, acc: 0.8795551287375415, lr: 0.0014488233250576467
[batch_idx--350] train_loss: 0.001103044356527258, acc: 0.8794070512820513, lr: 0.0014294126278096538
[batch_idx--400] train_loss: 0.001104227006795382, acc: 0.8790328865336658, lr: 0.0014101290097294967
[batch_idx--450] train_loss: 0.0011028869148494718, acc: 0.8793435623286007, lr: 0.0013909725747834447
total time of one epoch: 456.81640338897705 s
train_loss:  0.0011028869148494718  acc:  0.8793435623286007
->>lr:0.001391
test_loss:  0.0011641807962342577  test_acc:  0.8736815982131778
best acc:  87.81486536791165

------Epoch: 134------
[batch_idx--0] train_loss: 0.0013611315516754985, acc: 0.83984375, lr: 0.001390590744062975
[batch_idx--50] train_loss: 0.0011320685643666222, acc: 0.8784466911764706, lr: 0.0013715641423086456
[batch_idx--100] train_loss: 0.001119249453076558, acc: 0.8780940594059405, lr: 0.0013526649316081968
[batch_idx--150] train_loss: 0.0011180584690539746, acc: 0.8777421357615894, lr: 0.0013338932138554
[batch_idx--200] train_loss: 0.0011228101417209155, acc: 0.8777790733830846, lr: 0.0013152490902566538
[batch_idx--250] train_loss: 0.0011179205723592929, acc: 0.877972485059761, lr: 0.0012967326613304436
[batch_idx--300] train_loss: 0.0011160711586116457, acc: 0.8781665282392026, lr: 0.0012783440269067943
[batch_idx--350] train_loss: 0.0011125281599066365, acc: 0.8785167378917379, lr: 0.0012600832861267342
[batch_idx--400] train_loss: 0.0011084978147920805, acc: 0.8790523690773068, lr: 0.0012419505374417718
[batch_idx--450] train_loss: 0.0011101529665854364, acc: 0.8793175269899677, lr: 0.0012239458786133446
total time of one epoch: 400.49688935279846 s
train_loss:  0.0011101529665854364  acc:  0.8793175269899677
->>lr:0.001224
test_loss:  0.001160398033198063  test_acc:  0.8776523141829011
best acc:  87.81486536791165

------Epoch: 135------
[batch_idx--0] train_loss: 0.0011175989639014006, acc: 0.87890625, lr: 0.0012235870926211618
[batch_idx--50] train_loss: 0.0010969756769162475, acc: 0.8845741421568627, lr: 0.0012057131854440546
[batch_idx--100] train_loss: 0.001115534096693454, acc: 0.8790609529702971, lr: 0.0011879675634946297
[batch_idx--150] train_loss: 0.0011222369642003088, acc: 0.8779490894039735, lr: 0.0011703503224471529
[batch_idx--200] train_loss: 0.0011093411331102067, acc: 0.878925684079602, lr: 0.001152861557283752
[batch_idx--250] train_loss: 0.0011055128877533534, acc: 0.8794042579681275, lr: 0.0011355013622938726
[batch_idx--300] train_loss: 0.0011056591248050011, acc: 0.8792047342192691, lr: 0.0011182698310737928
[batch_idx--350] train_loss: 0.0011033903932772004, acc: 0.8788394764957265, lr: 0.0011011670565261005
[batch_idx--400] train_loss: 0.0011020850436936163, acc: 0.8793446072319202, lr: 0.0010841931308592041
[batch_idx--450] train_loss: 0.001105908583781776, acc: 0.8795865588225085, lr: 0.00106734814558683
total time of one epoch: 401.2151355743408 s
train_loss:  0.001105908583781776  acc:  0.8795865588225085
->>lr:0.001067
test_loss:  0.0011728032212323062  test_acc:  0.8738056830872317
best acc:  87.81486536791165

------Epoch: 136------
[batch_idx--0] train_loss: 0.0013873300049453974, acc: 0.8359375, lr: 0.001067012561698319
[batch_idx--50] train_loss: 0.0010950526339001954, acc: 0.8811274509803921, lr: 0.0010502991891848613
[batch_idx--100] train_loss: 0.0011181910579913471, acc: 0.8759282178217822, lr: 0.0010337149398027378
[batch_idx--150] train_loss: 0.001108287970476864, acc: 0.8780525662251656, lr: 0.001017259902964765
[batch_idx--200] train_loss: 0.001109789173403727, acc: 0.8784981343283582, lr: 0.0010009341673871241
[batch_idx--250] train_loss: 0.0011063226495416783, acc: 0.8787506225099602, lr: 0.000984737821088863
[batch_idx--300] train_loss: 0.001106326930469329, acc: 0.8785169227574751, lr: 0.000968670951391451
[batch_idx--350] train_loss: 0.0011057431162520713, acc: 0.8786836716524217, lr: 0.0009527336449182884
[batch_idx--400] train_loss: 0.001107261940300409, acc: 0.8784678927680798, lr: 0.0009369259875942449
[batch_idx--450] train_loss: 0.0011100557825073885, acc: 0.8789790675877391, lr: 0.0009212480646451971
total time of one epoch: 403.8470194339752 s
train_loss:  0.0011100557825073885  acc:  0.8789790675877391
->>lr:0.000921
test_loss:  0.001158041743401455  test_acc:  0.8750465318277701
best acc:  87.81486536791165

------Epoch: 137------
[batch_idx--0] train_loss: 0.0010444171493873, acc: 0.8671875, lr: 0.0009209358300585474
[batch_idx--50] train_loss: 0.0011252572853574711, acc: 0.8736979166666666, lr: 0.0009053903232463079
[batch_idx--100] train_loss: 0.0011091070401823462, acc: 0.8771658415841584, lr: 0.0008899747208313852
[batch_idx--150] train_loss: 0.0010978969608877618, acc: 0.8795529801324503, lr: 0.0008746891059259105
[batch_idx--200] train_loss: 0.001095560702219587, acc: 0.8797224813432836, lr: 0.0008595335609412142
[batch_idx--250] train_loss: 0.0010955735226625585, acc: 0.8799489541832669, lr: 0.0008445081675873518
[batch_idx--300] train_loss: 0.0010940588833191788, acc: 0.8804116486710963, lr: 0.0008296130068726787
[batch_idx--350] train_loss: 0.0010934826062907307, acc: 0.8806980056980057, lr: 0.0008148481591034013
[batch_idx--400] train_loss: 0.0010954273656763119, acc: 0.8802700280548629, lr: 0.0008002137038831625
[batch_idx--450] train_loss: 0.001101303992679616, acc: 0.880003124240636, lr: 0.000785709720112604
total time of one epoch: 404.2347116470337 s
train_loss:  0.001101303992679616  acc:  0.880003124240636
->>lr:0.000786
test_loss:  0.0011596571502000379  test_acc:  0.8730611738429086
best acc:  87.81486536791165

------Epoch: 138------
[batch_idx--0] train_loss: 0.0010288436897099018, acc: 0.90234375, lr: 0.0007854209717842232
[batch_idx--50] train_loss: 0.0010854543994783478, acc: 0.8836550245098039, lr: 0.0007710501494462701
[batch_idx--100] train_loss: 0.0011000802727775777, acc: 0.8823483910891089, lr: 0.0007568099557912517
[batch_idx--150] train_loss: 0.0011004709761238208, acc: 0.8808981788079471, lr: 0.000742700467594179
[batch_idx--200] train_loss: 0.0011003437809372757, acc: 0.8809468283582089, lr: 0.0007287217609253605
[batch_idx--250] train_loss: 0.0011032500723562393, acc: 0.8807582171314741, lr: 0.0007148739111500131
[batch_idx--300] train_loss: 0.0011004015137719924, acc: 0.8810994601328903, lr: 0.0007011569929278511
[batch_idx--350] train_loss: 0.0010993453367889204, acc: 0.8811320334757835, lr: 0.0006875710802126706
[batch_idx--400] train_loss: 0.0010966381906970704, acc: 0.8811077774314214, lr: 0.0006741162462519713
[batch_idx--450] train_loss: 0.0010987519977362305, acc: 0.8811139653556427, lr: 0.0006607925635865458
total time of one epoch: 400.44218254089355 s
train_loss:  0.0010987519977362305  acc:  0.8811139653556427
->>lr:0.000661
test_loss:  0.0011528942640165875  test_acc:  0.8767837200645241
best acc:  87.81486536791165

------Epoch: 139------
[batch_idx--0] train_loss: 0.0010885280789807439, acc: 0.875, lr: 0.0006605274281709927
[batch_idx--50] train_loss: 0.0010754293613774958, acc: 0.8849571078431373, lr: 0.0006473375938249676
[batch_idx--100] train_loss: 0.0010971496173291292, acc: 0.8819616336633663, lr: 0.0006342790551494393
[batch_idx--150] train_loss: 0.001093875324594116, acc: 0.8819329470198676, lr: 0.0006213518825486042
[batch_idx--200] train_loss: 0.0011050369157872871, acc: 0.8805192786069652, lr: 0.0006085561457184031
[batch_idx--250] train_loss: 0.0011046498761590258, acc: 0.8804158366533864, lr: 0.0005958919136461599
[batch_idx--300] train_loss: 0.0011051904753955125, acc: 0.8802948504983389, lr: 0.000583359254610194
[batch_idx--350] train_loss: 0.0011009475552248755, acc: 0.8806312321937322, lr: 0.0005709582361794502
[batch_idx--400] train_loss: 0.0010969966436339138, acc: 0.8808350218204489, lr: 0.0005586889252131494
[batch_idx--450] train_loss: 0.0011014848885193302, acc: 0.8804544034436075, lr: 0.0005465513878604278
total time of one epoch: 407.62241411209106 s
train_loss:  0.0011014848885193302  acc:  0.8804544034436075
->>lr:0.000547
test_loss:  0.001161166856566705  test_acc:  0.8744261074575009
best acc:  87.81486536791165

------Epoch: 140------
[batch_idx--0] train_loss: 0.0010121443774551153, acc: 0.8984375, lr: 0.0005463099816548578
[batch_idx--50] train_loss: 0.0011164586838133925, acc: 0.8800551470588235, lr: 0.0005343069207980278
[batch_idx--100] train_loss: 0.0011085771862186934, acc: 0.8809560643564357, lr: 0.0005224357650086414
[batch_idx--150] train_loss: 0.0011074278351005833, acc: 0.8804584023178808, lr: 0.0005106965782891965
[batch_idx--200] train_loss: 0.0011044130744574713, acc: 0.8805775808457711, lr: 0.0004990894239306987
[batch_idx--250] train_loss: 0.0011019911988085485, acc: 0.880851593625498, lr: 0.0004876143645123038
[batch_idx--300] train_loss: 0.0011036079154547885, acc: 0.8803467607973422, lr: 0.00047627146190098725
[batch_idx--350] train_loss: 0.0011024884093536907, acc: 0.8802751068376068, lr: 0.00046506077725121944
[batch_idx--400] train_loss: 0.0011006389630486971, acc: 0.8804745947630923, lr: 0.00045398237100461594
[batch_idx--450] train_loss: 0.0011026125112747944, acc: 0.8805498663519283, lr: 0.0004430363028896239
total time of one epoch: 402.57661962509155 s
train_loss:  0.0011026125112747944  acc:  0.8805498663519283
->>lr:0.000443
test_loss:  0.001161158600742815  test_acc:  0.8744261074575009
best acc:  87.81486536791165

------Epoch: 141------
[batch_idx--0] train_loss: 0.0010657638777047396, acc: 0.890625, lr: 0.00044281873178278475
[batch_idx--50] train_loss: 0.0010794499790862057, acc: 0.8851102941176471, lr: 0.0004320077093543484
[batch_idx--100] train_loss: 0.0010747721068339773, acc: 0.884011448019802, lr: 0.0004213291435323757
[batch_idx--150] train_loss: 0.0010859762003879673, acc: 0.882864238410596, lr: 0.0004107830918895994
[batch_idx--200] train_loss: 0.0010837271539679734, acc: 0.8835121268656716, lr: 0.00040036961128431806
[batch_idx--250] train_loss: 0.0010860983727117666, acc: 0.8830926294820717, lr: 0.00039008875786008537
[batch_idx--300] train_loss: 0.0010903337266469418, acc: 0.8823193521594684, lr: 0.00037994058704539927
[batch_idx--350] train_loss: 0.0010979325740075434, acc: 0.8810763888888888, lr: 0.0003699251535534104
[batch_idx--400] train_loss: 0.0011005957501747663, acc: 0.8804551122194514, lr: 0.0003600425113816253
[batch_idx--450] train_loss: 0.0011011929837617944, acc: 0.8805151525670843, lr: 0.0003502927138116147
total time of one epoch: 402.24616742134094 s
train_loss:  0.0011011929837617944  acc:  0.8805151525670843
->>lr:0.000350
test_loss:  0.0011633765070295495  test_acc:  0.8734334284650701
best acc:  87.81486536791165

------Epoch: 142------
[batch_idx--0] train_loss: 0.0009716300992295146, acc: 0.90234375, lr: 0.00035009907323737546
[batch_idx--50] train_loss: 0.0010996605246784347, acc: 0.8814338235294118, lr: 0.00034048483130907914
[batch_idx--100] train_loss: 0.0010958856414302741, acc: 0.881458849009901, lr: 0.00033100353942642217
[batch_idx--150] train_loss: 0.001099592370801414, acc: 0.8801997102649006, lr: 0.0003216552487071145
[batch_idx--200] train_loss: 0.0011008946287019447, acc: 0.8799362562189055, lr: 0.00031244000955181765
[batch_idx--250] train_loss: 0.0010987373970567705, acc: 0.8800734561752988, lr: 0.00030335787164384453
[batch_idx--300] train_loss: 0.0010944446245211477, acc: 0.8807101328903655, lr: 0.00029440888394890454
[batch_idx--350] train_loss: 0.0010936308875706504, acc: 0.8809317129629629, lr: 0.00028559309471483943
[batch_idx--400] train_loss: 0.001095188477081235, acc: 0.8806304551122195, lr: 0.00027691055147135437
[batch_idx--450] train_loss: 0.001097693243128161, acc: 0.8807755059534141, lr: 0.0002683613010297709
total time of one epoch: 401.59547448158264 s
train_loss:  0.001097693243128161  acc:  0.8807755059534141
->>lr:0.000268
test_loss:  0.0011550990978117424  test_acc:  0.8759151259461472
best acc:  87.81486536791165

------Epoch: 143------
[batch_idx--0] train_loss: 0.0011271493276581168, acc: 0.86328125, lr: 0.0002681916759252945
[batch_idx--50] train_loss: 0.001082226109015299, acc: 0.8825061274509803, lr: 0.00025977843162139916
[batch_idx--100] train_loss: 0.001104316308213822, acc: 0.8787515470297029, lr: 0.0002514985724860308
[batch_idx--150] train_loss: 0.0010966098268318995, acc: 0.8803290562913907, lr: 0.00024335214315946986
[batch_idx--200] train_loss: 0.001091295202837247, acc: 0.8812772077114428, lr: 0.00023533918756261376
[batch_idx--250] train_loss: 0.0010917773685952374, acc: 0.8814585408366534, lr: 0.00022745974889675503
[batch_idx--300] train_loss: 0.0010926834625916006, acc: 0.8812292358803987, lr: 0.0002197138696433315
[batch_idx--350] train_loss: 0.001092054245514567, acc: 0.8817552528490028, lr: 0.0002121015915637098
[batch_idx--400] train_loss: 0.0010956218834859586, acc: 0.8817117362842892, lr: 0.0002046229556989493
[batch_idx--450] train_loss: 0.0010976151247979965, acc: 0.8815044954351373, lr: 0.00019727800236959416
total time of one epoch: 400.92465376853943 s
train_loss:  0.0010976151247979965  acc:  0.8815044954351373
->>lr:0.000197
test_loss:  0.0011576724297977555  test_acc:  0.8744261074575009
best acc:  87.81486536791165

------Epoch: 144------
[batch_idx--0] train_loss: 0.0011522731510922313, acc: 0.87109375, lr: 0.0001971324671380531
[batch_idx--50] train_loss: 0.0010986007811665973, acc: 0.8838848039215687, lr: 0.00018992391078557493
[batch_idx--100] train_loss: 0.0010922188037259522, acc: 0.8825804455445545, lr: 0.00018284911621737067
[batch_idx--150] train_loss: 0.0010937028094225667, acc: 0.8821140314569537, lr: 0.00017590812157669555
[batch_idx--200] train_loss: 0.0010972463132568001, acc: 0.8811994713930348, lr: 0.00016910096428543743
[batch_idx--250] train_loss: 0.0010961956980886805, acc: 0.8806492778884463, lr: 0.00016242768104390848
[batch_idx--300] train_loss: 0.0010966730332682745, acc: 0.8802818729235881, lr: 0.00015588830783064834
[batch_idx--350] train_loss: 0.0010927905173683035, acc: 0.8810541310541311, lr: 0.0001494828799022241
[batch_idx--400] train_loss: 0.0010936878949050742, acc: 0.8812344139650873, lr: 0.00014321143179305552
[batch_idx--450] train_loss: 0.0010955627262385405, acc: 0.8812875342798625, lr: 0.00013707399731520964
total time of one epoch: 401.3170440196991 s
train_loss:  0.0010955627262385405  acc:  0.8812875342798625
->>lr:0.000137
test_loss:  0.0011549170998844175  test_acc:  0.8755428713239856
best acc:  87.81486536791165

------Epoch: 145------
[batch_idx--0] train_loss: 0.0012398204999044538, acc: 0.8671875, lr: 0.00013695261579316776
[batch_idx--50] train_loss: 0.0010631775230114512, acc: 0.8841911764705882, lr: 0.0001309519093031647
[batch_idx--100] train_loss: 0.00108491768311285, acc: 0.8812654702970297, lr: 0.0001250852825408405
[batch_idx--150] train_loss: 0.0010888953982321977, acc: 0.8814931705298014, lr: 0.0001193527671357053
[batch_idx--200] train_loss: 0.001086706873342228, acc: 0.8812383395522388, lr: 0.00011375439399421428
[batch_idx--250] train_loss: 0.0010880051355575215, acc: 0.8811472858565738, lr: 0.00010829019329959833
[batch_idx--300] train_loss: 0.0010932380439128814, acc: 0.8802559177740864, lr: 0.00010296019451171701
[batch_idx--350] train_loss: 0.0010968342204870087, acc: 0.8797854344729344, lr: 9.776442636688366e-05
[batch_idx--400] train_loss: 0.0010945307347224444, acc: 0.8800654613466334, lr: 9.270291687771548e-05
[batch_idx--450] train_loss: 0.0010960610908597008, acc: 0.8801159440413788, lr: 8.77756933329893e-05
total time of one epoch: 402.30556440353394 s
train_loss:  0.0010960610908597008  acc:  0.8801159440413788
->>lr:0.000088
test_loss:  0.0011569292706700084  test_acc:  0.8741779377093932
best acc:  87.81486536791165

------Epoch: 146------
[batch_idx--0] train_loss: 0.0009288416476920247, acc: 0.8984375, lr: 8.767851876239075e-05
[batch_idx--50] train_loss: 0.0010990515013462772, acc: 0.8792126225490197, lr: 8.288829424305533e-05
[batch_idx--100] train_loss: 0.0011061176399488261, acc: 0.8786741955445545, lr: 7.82324085830094e-05
[batch_idx--150] train_loss: 0.0011062029354422297, acc: 0.8793977649006622, lr: 7.371088688413186e-05
[batch_idx--200] train_loss: 0.0010960054093281464, acc: 0.8801888992537313, lr: 6.93237535238922e-05
[batch_idx--250] train_loss: 0.001095376369604596, acc: 0.8801979581673307, lr: 6.507103215520893e-05
[batch_idx--300] train_loss: 0.0010942157438764367, acc: 0.880749065614618, lr: 6.09527457063358e-05
[batch_idx--350] train_loss: 0.0010917474725681683, acc: 0.8809984864672364, lr: 5.6968916380720215e-05
[batch_idx--400] train_loss: 0.0010965232318731726, acc: 0.880338216957606, lr: 5.311956565690057e-05
[batch_idx--450] train_loss: 0.001098873223366474, acc: 0.8804196896587635, lr: 4.9404714288381335e-05
total time of one epoch: 402.5101773738861 s
train_loss:  0.001098873223366474  acc:  0.8804196896587635
->>lr:0.000049
test_loss:  0.0011578727772875183  test_acc:  0.8745501923315547
best acc:  87.81486536791165

------Epoch: 147------
[batch_idx--0] train_loss: 0.001249233027920127, acc: 0.86328125, lr: 4.933178929321103e-05
[batch_idx--50] train_loss: 0.0010950774018305773, acc: 0.8805912990196079, lr: 4.57541478953355e-05
[batch_idx--100] train_loss: 0.0010929676009074664, acc: 0.8804532797029703, lr: 4.231104556289278e-05
[batch_idx--150] train_loss: 0.0010926948763146404, acc: 0.8805618791390728, lr: 3.9002500859128264e-05
[batch_idx--200] train_loss: 0.0010975526034164784, acc: 0.8803638059701493, lr: 3.582853162182598e-05
[batch_idx--250] train_loss: 0.0010978509249922586, acc: 0.8805403386454184, lr: 3.2789154963222546e-05
[batch_idx--300] train_loss: 0.0011003640208832697, acc: 0.880437603820598, lr: 2.9884387269901725e-05
[batch_idx--350] train_loss: 0.0010964807787607622, acc: 0.8810875178062678, lr: 2.7114244202716688e-05
[batch_idx--400] train_loss: 0.001100620668569575, acc: 0.8803966645885287, lr: 2.4478740696695647e-05
[batch_idx--450] train_loss: 0.0011017616449872046, acc: 0.8807234352761482, lr: 2.1977890960975244e-05
total time of one epoch: 408.00906109809875 s
train_loss:  0.0011017616449872046  acc:  0.8807234352761482
->>lr:0.000022
test_loss:  0.0011574568057980308  test_acc:  0.874302022583447
best acc:  87.81486536791165

------Epoch: 148------
[batch_idx--0] train_loss: 0.0009702297975309193, acc: 0.92578125, lr: 2.192924752854042e-05
[batch_idx--50] train_loss: 0.0011121228602075693, acc: 0.87890625, lr: 1.9565758523884538e-05
[batch_idx--100] train_loss: 0.0010863914065717692, acc: 0.883121905940594, lr: 1.7336949777524425e-05
[batch_idx--150] train_loss: 0.0010893739261109358, acc: 0.8819846854304636, lr: 1.524283330592846e-05
[batch_idx--200] train_loss: 0.0010862198414452449, acc: 0.8823460820895522, lr: 1.3283420399376467e-05
[batch_idx--250] train_loss: 0.0010910332448728591, acc: 0.8819409860557769, lr: 1.14587216219042e-05
[batch_idx--300] train_loss: 0.001089485359078032, acc: 0.8823582848837209, lr: 9.768746811253394e-06
[batch_idx--350] train_loss: 0.0010862182616853179, acc: 0.8828792735042735, lr: 8.213505078799587e-06
[batch_idx--400] train_loss: 0.0010867370231578736, acc: 0.8826274158354115, lr: 6.793004809518832e-06
[batch_idx--450] train_loss: 0.0010867188388340326, acc: 0.8824591245183462, lr: 5.507253661940492e-06
total time of one epoch: 415.01750683784485 s
train_loss:  0.0010867188388340326  acc:  0.8824591245183462
->>lr:0.000006
test_loss:  0.0011562714026160357  test_acc:  0.8746742772056086
best acc:  87.81486536791165

------Epoch: 149------
[batch_idx--0] train_loss: 0.0010260900016874075, acc: 0.88671875, lr: 5.482913128862511e-06
[batch_idx--50] train_loss: 0.0010976431932409898, acc: 0.8809742647058824, lr: 4.334613221818051e-06
[batch_idx--100] train_loss: 0.0010864704220306756, acc: 0.8818069306930693, lr: 3.321075690718156e-06
[batch_idx--150] train_loss: 0.0010865941221227511, acc: 0.8814673013245033, lr: 2.4423059999861833e-06
[batch_idx--200] train_loss: 0.0010794487634710782, acc: 0.8826181592039801, lr: 1.6983088874406029e-06
[batch_idx--250] train_loss: 0.0010807592562303333, acc: 0.8825946215139442, lr: 1.089088364294999e-06
[batch_idx--300] train_loss: 0.001078540406095489, acc: 0.8829033430232558, lr: 6.146477151164343e-07
[batch_idx--350] train_loss: 0.0010819194975715035, acc: 0.8828236289173789, lr: 2.749894978198997e-07
[batch_idx--400] train_loss: 0.0010857541248216259, acc: 0.882228023690773, lr: 7.011554364610984e-08
[batch_idx--450] train_loss: 0.0010906156470223403, acc: 0.8816954212517791, lr: 2.6957161503027296e-11
total time of one epoch: 417.0399465560913 s
train_loss:  0.0010906156470223403  acc:  0.8816954212517791
->>lr:0.000000
test_loss:  0.001156428960346232  test_acc:  0.8744261074575009
best acc:  87.81486536791165